{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c88e90be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following packages are missing and will be installed:\n",
      "['beautifulsoup4']\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Error: The following packages could not be installed:\n",
      "['beautifulsoup4']\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "required_packages = [\n",
    "    \"requests\",\n",
    "    \"beautifulsoup4\",\n",
    "    \"langdetect\",\n",
    "    \"pymongo\"\n",
    "]\n",
    "\n",
    "# Check if each package is installed, install missing ones\n",
    "missing_packages = [package for package in required_packages if package not in sys.modules]\n",
    "if missing_packages:\n",
    "    print(\"The following packages are missing and will be installed:\")\n",
    "    print(missing_packages)\n",
    "    for package in missing_packages:\n",
    "        try:\n",
    "            __import__(package)\n",
    "        except ImportError:\n",
    "            !pip install {package}\n",
    "\n",
    "    # Check again if all packages are installed\n",
    "    missing_packages = [package for package in required_packages if package not in sys.modules]\n",
    "    if missing_packages:\n",
    "        print(\"Error: The following packages could not be installed:\")\n",
    "        print(missing_packages)\n",
    "        sys.exit(1)\n",
    "else:\n",
    "    print(\"All required packages are already installed. You can proceed with running the program.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a236d9",
   "metadata": {},
   "source": [
    "# Web Crawler for docs.logrhythm.com\n",
    "This notebook contains a script to crawl `docs.logrhythm.com`, focusing on English content within the domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5551e5b6",
   "metadata": {},
   "source": [
    "# Web Scraping and Data Storage in MongoDB\n",
    "This notebook contains a script to scrape data from `docs.logrhythm.com` and store it in MongoDB, avoiding duplicate entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea39f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries (uncomment if not already installed)\n",
    "#!pip install requests beautifulsoup4 langdetect pymongo\n",
    "\n",
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from urllib.robotparser import RobotFileParser\n",
    "from langdetect import detect, DetectorFactory\n",
    "import pymongo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523081d",
   "metadata": {},
   "source": [
    "**MongoDB Connection Setup**\n",
    "\n",
    "Establishing a connection to MongoDB and defining the database and collections to be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edec1456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB connection\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"WS_Data_DB\"]  # Database name\n",
    "collection = db[\"LogRhythmDocs\"]  # Collection name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf58e393",
   "metadata": {},
   "source": [
    "**Initial Setup for Language Detection**\n",
    "\n",
    "Set the seed for the language detection library to ensure consistent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca76d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for consistent language detection\n",
    "DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0fa1ba",
   "metadata": {},
   "source": [
    "**Function Definitions**\n",
    "\n",
    "Define the functions needed for web crawling. This includes functions to get page content, check `robots.txt` compliance, extract information from HTML, detect if the content is English, and extract valid links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b0c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch page content\n",
    "def get_page_content(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response.content\n",
    "        else:\n",
    "            print(f\"Failed to fetch content. Status code: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching content: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to check robots.txt compliance\n",
    "def is_allowed_by_robots(url):\n",
    "    base_url = urljoin(url, '/')\n",
    "    if not base_url.endswith('/'):\n",
    "        base_url += '/'\n",
    "    robots_txt_url = urljoin(base_url, 'robots.txt')\n",
    "    try:\n",
    "        response = requests.get(robots_txt_url)\n",
    "        response.raise_for_status()\n",
    "        robots_txt_content = response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching robots.txt: {e}\")\n",
    "        return False\n",
    "    rp = RobotFileParser()\n",
    "    rp.parse(robots_txt_content.splitlines())\n",
    "    return rp.can_fetch(\"*\", url)\n",
    "\n",
    "# Function to extract information from HTML content\n",
    "def extract_information(html_content, url):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    text_content = soup.get_text(separator='\\n', strip=True)\n",
    "\n",
    "    # Check if the document already exists to avoid duplicates\n",
    "    if collection.count_documents({\"url\": url}) == 0:\n",
    "        document = {\n",
    "            \"url\": url,\n",
    "            \"content\": text_content\n",
    "        }\n",
    "        collection.insert_one(document)\n",
    "        \n",
    "# Function to check if content is in English\n",
    "def is_english_content(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    text_samples = soup.get_text(separator=' ', strip=True)\n",
    "    try:\n",
    "        return detect(text_samples[:1000]) == 'en'  # Sample first 1000 characters\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Function to extract valid links\n",
    "def extract_links(html_content, base_url):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    links = [link.get('href') for link in soup.find_all('a', href=True)]\n",
    "    valid_links = []\n",
    "    for link in links:\n",
    "        if not link.startswith('http'):\n",
    "            link = urljoin(base_url, link)\n",
    "        parsed_link = urlparse(link)\n",
    "        if parsed_link.netloc == 'docs.logrhythm.com':\n",
    "            valid_links.append(link)\n",
    "    return valid_links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b40dc0",
   "metadata": {},
   "source": [
    "**Crawl Function**\n",
    "\n",
    "Define the `crawl` function to recursively crawl the website, adhering to the specified rules such as staying within the `docs.logrhythm.com` domain and processing only English content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4be53cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive crawl function\n",
    "def crawl(url, visited):\n",
    "    if url in visited or not url.startswith('http'):\n",
    "        return\n",
    "    visited.add(url)\n",
    "    if is_allowed_by_robots(url) and urlparse(url).netloc == 'docs.logrhythm.com':\n",
    "        content = get_page_content(url)\n",
    "        if content and is_english_content(content):\n",
    "            extract_information(content, url)\n",
    "            for link in extract_links(content, url):\n",
    "                crawl(link, visited)\n",
    "    else:\n",
    "        print(f\"Crawling not allowed or outside domain for: {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75acbcd",
   "metadata": {},
   "source": [
    "**Start Crawling**\n",
    "\n",
    "Initiate the web crawler from the main page of `docs.logrhythm.com`. The crawler will recursively visit each link, staying within the specified domain and processing only English content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f985e3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch content. Status code: 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch content. Status code: 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch content. Status code: 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n",
      "Error fetching content: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "Error fetching robots.txt: HTTPSConnectionPool(host='docs.logrhythm.com', port=443): Max retries exceeded with url: /robots.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001D211A946D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Crawling not allowed or outside domain for: https://docs.logrhythm.com/lrsiem/7.13.0/object\n",
      "Failed to fetch content. Status code: 404\n",
      "Failed to fetch content. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "# Start URL\n",
    "start_url = \"https://docs.logrhythm.com/\"\n",
    "\n",
    "# Set of visited URLs to avoid revisiting\n",
    "visited_urls = set()\n",
    "\n",
    "# Start the web scraping process\n",
    "crawl(start_url, visited_urls)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
