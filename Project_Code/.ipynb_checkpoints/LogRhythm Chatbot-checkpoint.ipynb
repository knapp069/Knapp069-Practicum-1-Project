{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2387c1",
   "metadata": {},
   "source": [
    "# LogRhythm Chatbot\n",
    "\n",
    "This script implements a chatbot using Word2Vec embeddings and TF-IDF vectors to provide relevant information based on user input. The overall process includes:\n",
    "\n",
    "1. **Importing Necessary Libraries**: Importing libraries required for data processing, embedding generation, and model loading.\n",
    "2. **Downloading NLTK Resources**: Downloading necessary NLTK resources for tokenization.\n",
    "3. **Loading Models and Data**: Loading the trained Word2Vec model, TF-IDF vectorizer, and cleaned data with categories.\n",
    "4. **Defining Categories and Keywords**: Defining categories and their associated keywords for categorizing user input.\n",
    "5. **Determining Category**: Implementing a function to determine the category of user input based on keywords.\n",
    "6. **Generating Combined Embedding**: Implementing a function to generate a combined embedding for a given text.\n",
    "7. **Finding Most Relevant Document**: Implementing a function to find the most relevant document based on user input.\n",
    "8. **Generating Chatbot Response**: Implementing a function to generate a chatbot response based on user input and relevant documents.\n",
    "9. **Main Chatbot Interaction Loop**: Implementing the main interaction loop where users can input queries and receive responses from the chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520e00e2",
   "metadata": {},
   "source": [
    "### Import Libraries and Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd0600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Downloading necessary NLTK resources\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e069156b",
   "metadata": {},
   "source": [
    "### Load CSV and Trained Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bd65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the trained Word2Vec model and TF-IDF vectorizer\n",
    "word2vec_model = Word2Vec.load(\"word2vec_model.bin\")\n",
    "tfidf_vectorizer = joblib.load(\"tfidf_model.pkl\")\n",
    "\n",
    "# Loading the cleaned data with categories\n",
    "df = pd.read_csv('cleaned_section_data_with_categories.csv')\n",
    "\n",
    "# Loading the combined embeddings\n",
    "combined_embeddings = np.load('combined_features.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eb5c21",
   "metadata": {},
   "source": [
    "### Define Categories with Associated Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f8baa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining categories and their associated keywords\n",
    "categories = {\n",
    "    'Installation & Setup': [\n",
    "        'install', 'setup', 'implementation', 'deployment', 'configure', 'initialization', \n",
    "        'installing', 'deploy', 'configuration', 'set-up', 'initiate', 'launch', 'activate',\n",
    "        'how to install', 'setting up', 'installation guide', 'deploying', 'configuring'\n",
    "    ],\n",
    "    'Maintenance & Management': [\n",
    "        'maintain', 'maintenance', 'servicing', 'management', 'optimization', 'service', \n",
    "        'manage', 'routine check', 'system upkeep', 'system care', 'upkeep', 'tune-up',\n",
    "        'maintaining', 'managing', 'service routine', 'optimizing', 'how to maintain'\n",
    "    ],\n",
    "    'Troubleshooting & Support': [\n",
    "        'troubleshoot', 'error', 'issue', 'problem', 'diagnosis', 'resolution', 'fix', \n",
    "        'solve', 'rectify', 'repair', 'resolve', 'correct', 'debug', 'fault finding',\n",
    "        'troubleshooting', 'solving issues', 'fixing errors', 'diagnosing problems', 'resolving'\n",
    "    ],\n",
    "    'Upgrades & Updates': [\n",
    "        'upgrade', 'update', 'new version', 'patch', 'release', 'enhancement', 'updating', \n",
    "        'upgrading', 'version upgrade', 'system update', 'software update', 'patching',\n",
    "        'how to upgrade', 'applying updates', 'version updating', 'software enhancement'\n",
    "    ],\n",
    "    'General Information & Overview': [\n",
    "        'overview', 'introduction', 'info', 'summary', 'guide', 'documentation', \n",
    "        'information', 'details', 'background', 'basics', 'general data', 'key points',\n",
    "        'what is', 'explain', 'description of', 'details about'\n",
    "    ],\n",
    "    'Security & Monitoring': [\n",
    "        'surveillance', 'log management', 'event tracking', 'real-time analysis', \n",
    "        'security watch', 'monitoring', 'security check', 'system monitoring', 'network watch',\n",
    "        'security overview', 'monitoring setup', 'event tracking system'\n",
    "    ],\n",
    "    'Threat Detection & Analysis': [\n",
    "        'threat detection', 'anomaly detection', 'intrusion detection', 'threat intelligence', \n",
    "        'security alerts', 'risk detection', 'threat identification', 'vulnerability detection', \n",
    "        'security threat detection', 'analyzing threats', 'identifying risks', 'detecting anomalies'\n",
    "    ],\n",
    "    'Incident Response & Management': [\n",
    "        'incident response', 'incident management', 'forensics', 'mitigation', 'recovery', \n",
    "        'incident handling', 'crisis management', 'incident analysis', 'emergency response',\n",
    "        'responding to incidents', 'managing incidents', 'incident recovery'\n",
    "    ],\n",
    "    'Compliance & Auditing': [\n",
    "        'compliance', 'regulatory compliance', 'audit', 'reporting', 'policy enforcement', \n",
    "        'regulation management', 'compliance tracking', 'legal compliance', 'audit management',\n",
    "        'compliance policies', 'auditing processes', 'regulatory reporting'\n",
    "    ],\n",
    "    'Integration & Compatibility': [\n",
    "        'integration', 'compatibility', 'third-party integration', 'API', 'interoperability', \n",
    "        'system merging', 'software integration', 'data integration', 'platform integration',\n",
    "        'integrating systems', 'API usage', 'compatibility issues'\n",
    "    ],\n",
    "    'Network Security & Protection': [\n",
    "        'network security', 'firewall', 'traffic analysis', 'intrusion prevention', \n",
    "        'network protection', 'cybersecurity', 'network defense', 'network safeguard',\n",
    "        'protecting networks', 'network firewalls', 'cybersecurity measures'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b188f68a",
   "metadata": {},
   "source": [
    "## Define Functions for the Chatbot\n",
    "\n",
    "Here the functions used by the Chatbot are defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820aa9b3",
   "metadata": {},
   "source": [
    "### Determining Category\n",
    "\n",
    "This is used to help associate intent from user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a9ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine the category of user input based on keywords\n",
    "def determine_category(user_input):\n",
    "    \"\"\"\n",
    "    Determine the category of user input based on keywords.\n",
    "\n",
    "    Args:\n",
    "    - user_input (str): User input text.\n",
    "\n",
    "    Returns:\n",
    "    - str: Category determined from the keywords.\n",
    "    \"\"\"\n",
    "    for category, keywords in categories.items():\n",
    "        if any(keyword in user_input.lower() for keyword in keywords):\n",
    "            return category\n",
    "    return 'Other'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0190e9",
   "metadata": {},
   "source": [
    "### Generating Combined Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a combined embedding for a given text\n",
    "def get_combined_embedding(text):\n",
    "    \"\"\"\n",
    "    Generate a combined embedding for a given text using Word2Vec and TF-IDF.\n",
    "\n",
    "    Args:\n",
    "    - text (str): Input text.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Combined embedding vector.\n",
    "    \"\"\"\n",
    "    words = word_tokenize(text)\n",
    "    word_embeddings = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "    w2v_embedding = np.mean(word_embeddings, axis=0) if word_embeddings else np.zeros(word2vec_model.vector_size)\n",
    "    tfidf_embedding = tfidf_vectorizer.transform([text]).toarray()[0]\n",
    "    return np.hstack((w2v_embedding, tfidf_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a6208",
   "metadata": {},
   "source": [
    "### Finding Most Relevant Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b10daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the most relevant document\n",
    "def find_most_relevant_document(input_text, filtered_df):\n",
    "    \"\"\"\n",
    "    Find the most relevant document based on user input.\n",
    "\n",
    "    Args:\n",
    "    - input_text (str): User input text.\n",
    "    - filtered_df (DataFrame): Filtered DataFrame containing relevant documents.\n",
    "\n",
    "    Returns:\n",
    "    - int: Index of the most relevant document.\n",
    "    - float: Cosine similarity score with the most relevant document.\n",
    "    \"\"\"\n",
    "    input_embedding = get_combined_embedding(input_text)\n",
    "    max_similarity = 0\n",
    "    most_similar_doc_index = None\n",
    "    for index, row in filtered_df.iterrows():\n",
    "        doc_embedding = combined_embeddings[index]\n",
    "        similarity = cosine_similarity([input_embedding], [doc_embedding])[0][0]\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            most_similar_doc_index = index\n",
    "    return most_similar_doc_index, max_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating Chatbot Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6f0e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate chatbot response\n",
    "def generate_chatbot_response(user_input):\n",
    "    \"\"\"\n",
    "    Generate a response from the chatbot based on user input.\n",
    "\n",
    "    Args:\n",
    "    - user_input (str): User input text.\n",
    "\n",
    "    Returns:\n",
    "    - str: Chatbot response.\n",
    "    \"\"\"\n",
    "    user_category = determine_category(user_input)\n",
    "    filtered_df = df[df['Category'] == user_category]\n",
    "    doc_index, similarity = find_most_relevant_document(user_input, filtered_df)\n",
    "    \n",
    "    if similarity > 0.15 and doc_index is not None:\n",
    "        full_text = df.iloc[doc_index]['content']  # Fetching the unprocessed text\n",
    "        return full_text\n",
    "    else:\n",
    "        return \"I'm sorry, I couldn't find relevant information based on your query.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04097aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main Chatbot Interaction Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main chatbot interaction loop\n",
    "print(\"LogRhythm Chatbot â€” Type 'quit' to exit.\")\n",
    "while True:\n",
    "    user_input = input(\"You: \").strip()\n",
    "    if user_input.lower() == \"quit\":\n",
    "        print(\"\\033[1mLogRhythm Chatbot: Goodbye!\\033[0m\")\n",
    "        break\n",
    "    response = generate_chatbot_response(user_input)\n",
    "    print(\"\\033[1mLogRhythm Chatbot:\\033[0m\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
