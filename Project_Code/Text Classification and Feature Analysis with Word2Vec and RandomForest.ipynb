{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d06846e2",
   "metadata": {},
   "source": [
    "# Text Classification and Analysis using Word2Vec and RandomForest\n",
    "\n",
    "This notebook performs text classification on a dataset using Word2Vec for word embeddings and RandomForest for classification. The process includes the following steps:\n",
    "\n",
    "1. **Data Loading and Preprocessing**: Load the cleaned textual data, fill missing values, and filter out categories with fewer than 3 samples.\n",
    "2. **Data Filtering and Tokenization**: Tokenize the text data for Word2Vec model training using the filtered dataframe.\n",
    "3. **Word2Vec Model Training**: Train a Word2Vec model on the tokenized text to create word embeddings.\n",
    "4. **Feature Extraction with TF-IDF and Combining Features**: Extract features using TF-IDF and combine them with Word2Vec features for a more robust feature set.\n",
    "5. **Handling Class Imbalance with SMOTE**: Use SMOTE to handle class imbalance in the dataset, creating synthetic samples for under-represented classes.\n",
    "6. **Data Splitting and Classifier Training**: Split the data into training and testing sets and train a RandomForest classifier.\n",
    "7. **Enhanced Cross-Validation**: Perform enhanced cross-validation to ensure robust model evaluation.\n",
    "8. **Model Evaluation**: Evaluate the performance of the classifier using the test set.\n",
    "9. **Confusion Matrix and ROC Curve**: Visualize the confusion matrix and ROC curve for a comprehensive evaluation.\n",
    "10. **Additional Metrics**: Calculate additional metrics like the Matthews Correlation Coefficient and Area Under Precision-Recall Curve for further analysis.\n",
    "11. **Learning Curve Analysis**: Analyze the learning curves to understand the model's behavior with varying training set sizes.\n",
    "12. **Feature Importance Analysis**: Examine the feature importances to understand the contribution of different features to the model.\n",
    "13. **Saving Models and Results**: Save the trained models and processed data for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4299391c",
   "metadata": {},
   "source": [
    "#### Import Libraries and Resouces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc, precision_recall_curve, matthews_corrcoef\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import joblib\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "# Download the punkt tokenizer for word tokenization\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4dc538",
   "metadata": {},
   "source": [
    "### Define Script Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c51b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a feature vector for a document by averaging its word vectors\n",
    "def document_vector(word2vec_model, doc):\n",
    "    # Filter out words not in the model's vocabulary\n",
    "    doc = [word for word in doc if word in word2vec_model.wv]\n",
    "    return np.mean(word2vec_model.wv[doc], axis=0) if doc else np.zeros(word2vec_model.vector_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b434b60",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing\n",
    "\n",
    "Load the cleaned textual data and preprocess it for classification. This involves filling missing values and defining category rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a182e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned data from the CSV file\n",
    "df = pd.read_csv('cleaned_section_data_with_categories.csv')\n",
    "df['Cleaned Text'] = df['Cleaned Text'].fillna('')  # Fill missing text with empty strings\n",
    "\n",
    "# Filter out categories with fewer than 3 samples\n",
    "min_samples_threshold = 3  \n",
    "category_counts = df['Category'].value_counts()\n",
    "categories_to_keep = category_counts[category_counts >= min_samples_threshold].index\n",
    "df_filtered = df[df['Category'].isin(categories_to_keep)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b1c77",
   "metadata": {},
   "source": [
    "### Data Filtering and Tokenization\n",
    "\n",
    "Filter out categories with insufficient samples and tokenize the text for the Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8470ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data for Word2Vec model training using the filtered dataframe\n",
    "tokenized_text_filtered = [word_tokenize(text) for text in df_filtered['Cleaned Text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d2107",
   "metadata": {},
   "source": [
    "### Word2Vec Model Training\n",
    "\n",
    "Train a Word2Vec model on the tokenized text to create word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e7e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train a Word2Vec model\n",
    "word2vec_model = Word2Vec(tokenized_text_filtered, vector_size=200, window=10, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac4672",
   "metadata": {},
   "source": [
    "### Feature Extraction with TF-IDF and Combining Features\n",
    "\n",
    "Extract features using TF-IDF and combine them with Word2Vec features for a more robust feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0662a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit a TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "tfidf_feature_vectors_filtered = tfidf_vectorizer.fit_transform(df_filtered['Cleaned Text']).toarray()\n",
    "\n",
    "# Create feature vectors for each document using the Word2Vec model on the filtered text\n",
    "w2v_feature_vectors_filtered = np.array([document_vector(word2vec_model, doc) for doc in tokenized_text_filtered])\n",
    "\n",
    "# Combine Word2Vec and TF-IDF features for the filtered text\n",
    "combined_features_filtered = np.hstack((w2v_feature_vectors_filtered, tfidf_feature_vectors_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6661e7a",
   "metadata": {},
   "source": [
    "### Handling Class Imbalance with SMOTE\n",
    "\n",
    "Use SMOTE to handle class imbalance in the dataset, creating synthetic samples for under-represented classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15fe6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SMOTE and apply it to the combined feature set\n",
    "smote = SMOTE(random_state=42, k_neighbors=1)\n",
    "X_resampled, y_resampled = smote.fit_resample(combined_features_filtered, df_filtered['Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e03dc2",
   "metadata": {},
   "source": [
    "### Data Splitting and Classifier Training\n",
    "\n",
    "Split the data into training and testing sets and train a RandomForest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f583dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a RandomForest classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42af8682",
   "metadata": {},
   "source": [
    "### Enhanced Cross-Validation\n",
    "\n",
    "Perform enhanced cross-validation to ensure robust model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3521795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RepeatedKFold for robust cross-validation\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "cv_scores = cross_val_score(classifier, X_resampled, y_resampled, cv=rkf, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Average Cross-Validation Score:\", np.mean(cv_scores))\n",
    "print(\"Standard Deviation of Cross-Validation Scores:\", np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486e2b49",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c545cc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the classifier using the test set.\n",
    "predictions = classifier.predict(X_test)\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8576a7c1",
   "metadata": {},
   "source": [
    "### Confusion Matrix and ROC Curve\n",
    "\n",
    "Visualize the confusion matrix and ROC curve for a comprehensive evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd640a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the confusion matrix and ROC curve for a comprehensive evaluation.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# Binarize the output classes for multi-class ROC AUC\n",
    "y_bin = label_binarize(y_test, classes=list(np.unique(y_resampled)))\n",
    "n_classes = y_bin.shape[1]\n",
    "\n",
    "# Calculate the ROC-AUC for each class\n",
    "fpr, tpr, roc_auc = {}, {}, {}\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], classifier.predict_proba(X_test)[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "colors = cycle(['blue', 'red', 'green', 'yellow', 'orange', 'purple', 'cyan', 'magenta', 'brown', 'black', 'grey'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2, label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2641da",
   "metadata": {},
   "source": [
    "### Additional Metrics\n",
    "\n",
    "Calculate additional metrics like the Matthews Correlation Coefficient and Area Under Precision-Recall Curve for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9993a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matthews Correlation Coefficient\n",
    "mcc = matthews_corrcoef(y_test, predictions)\n",
    "print(\"Matthews Correlation Coefficient:\", mcc)\n",
    "\n",
    "# Area Under Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_bin.ravel(), classifier.predict_proba(X_test).ravel())\n",
    "auprc = auc(recall, precision)\n",
    "print(\"Area Under Precision-Recall Curve:\", auprc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bdce31",
   "metadata": {},
   "source": [
    "### Learning Curve Analysis\n",
    "\n",
    "Analyze the learning curves to understand the model's behavior with varying training set sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f6ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the learning curves to understand the model's behavior with varying training set sizes.\n",
    "train_sizes, train_scores, test_scores = learning_curve(classifier, X_resampled, y_resampled, n_jobs=-1, cv=5, train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"r\", alpha=0.1)\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"g\", alpha=0.1)\n",
    "plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training Set Size\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b69c8",
   "metadata": {},
   "source": [
    "### Feature Importance Analysis\n",
    "\n",
    "Examine the feature importances to understand the contribution of different features to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d27958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the feature importances to understand the contribution of different features to the model.\n",
    "importances = classifier.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(f\"{f + 1}. feature {indices[f]} ({importances[indices[f]]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684fc1d2",
   "metadata": {},
   "source": [
    "### Saving Models and Results\n",
    "\n",
    "Save the trained models and processed data for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf97be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained models and processed data for future use.\n",
    "joblib.dump(tfidf_vectorizer, \"tfidf_model.pkl\")\n",
    "word2vec_model.save('word2vec_model.bin')\n",
    "np.save('combined_features.npy', combined_features_filtered)\n",
    "joblib.dump(classifier, \"random_forest_classifier.pkl\")\n",
    "df_filtered.to_csv('cleaned_section_data_with_categories.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
