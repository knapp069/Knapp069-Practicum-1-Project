{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e94a61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Chatbot! Type 'exit' to end the conversation.\n",
      "You: siem\n",
      "Bot: To effectively fight threats, you need the right tools. The LogRhythm SIEM Platform aligns your team, technology, and processes. It helps you see across your IT environment, identify threats, and quickly mitigate and recover from security incidents.\n",
      "\n",
      "You: logrhythm\n",
      "Bot: To effectively fight threats, you need the right tools. The LogRhythm SIEM Platform aligns your team, technology, and processes. It helps you see across your IT environment, identify threats, and quickly mitigate and recover from security incidents.\n",
      "\n",
      "You: agent\n",
      "Bot: LogRhythm provides support for Agent failover across several Data Processors (up to three is the most common configuration). Three prioritized Processors configured into the Agent as mediator1, mediator2, and mediator3 (ordered list). Collection performance is maintained across Mediator failover, and this capability can also be used to support Agent load balancing.\n",
      "One of three scenarios can cause an Agent to failover to a different Processor:\n",
      "The Processor currently serving the Agent is already servicing its maximum agent count.\n",
      "The Processor is unavailable due to inability to establish connection or a lost connection (for example, a network issue).\n",
      "The Processor issues a suspense condition.\n",
      "The Failback Delay can be configured in the System Monitor Agent Advanced Properties dialog box.\n",
      "\n",
      "You: log source\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ted59\\AppData\\Local\\Temp\\ipykernel_4392\\2587809179.py:123: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  topic_scores = {topic: input_vec.similarity(nlp(topic)) for topic in predefined_topics}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Onboarding new log sources should be easy. That’s why we’ve expanded the number of Beats LogRhythm Administrators\n",
      "can manage from the Web Console\n",
      ". By onboarding log sources in the Web Console, you can save time and cut your Beat Administration workload in half. In this latest release, LogRhythm now supports management for six additional Beats including:\n",
      "Gmail Message Tracking\n",
      "Gmail Message Tracking\n",
      "GSuite\n",
      "GSuite\n",
      "Okta\n",
      "Okta\n",
      "Darktrace\n",
      "Darktrace\n",
      "Sophos\n",
      "Sophos\n",
      "Qualys FIM\n",
      "Qualys FIM\n",
      "\n",
      "\n",
      "You: manager\n",
      "Bot: The Platform Manager (PM) is the hub of a LogRhythm installation. It serves as the central repository for events, configuration and licensing information, the LogRhythm Knowledge Base, and LogMart. In small deployments, the Platform Manager can also host other LogRhythm components. In larger deployments, it should be a dedicated system. There is only one PM per deployment\n",
      "The Platform Manager (PM) is a Windows Server system running SQL Server, the LogRhythm Alarming and Response Manager (ARM) service, and the LogRhythm Job Manager service.\n",
      "The ARM processes alarm rules and takes the appropriate response, such as sending email to people on a notification list.\n",
      "The Job Manager runs scheduled report jobs and other background functions such as automated List imports and heartbeat monitoring. You can schedule report packages to run and be delivered automatically using the Scheduled Report Job Manager. The Job Manager then creates, exports, notifies, and delivers the reports.\n",
      "\n",
      "You: axon\n",
      "Bot: I'm sorry, I don't understand.\n",
      "You: collector\n",
      "Bot: I'm sorry, I don't understand.\n",
      "You: open collector\n",
      "Bot: I'm sorry, I don't understand.\n",
      "You: logrhythm\n",
      "Bot: To effectively fight threats, you need the right tools. The LogRhythm SIEM Platform aligns your team, technology, and processes. It helps you see across your IT environment, identify threats, and quickly mitigate and recover from security incidents.\n",
      "\n",
      "You: agent\n",
      "Bot: LogRhythm provides support for Agent failover across several Data Processors (up to three is the most common configuration). Three prioritized Processors configured into the Agent as mediator1, mediator2, and mediator3 (ordered list). Collection performance is maintained across Mediator failover, and this capability can also be used to support Agent load balancing.\n",
      "One of three scenarios can cause an Agent to failover to a different Processor:\n",
      "The Processor currently serving the Agent is already servicing its maximum agent count.\n",
      "The Processor is unavailable due to inability to establish connection or a lost connection (for example, a network issue).\n",
      "The Processor issues a suspense condition.\n",
      "The Failback Delay can be configured in the System Monitor Agent Advanced Properties dialog box.\n",
      "\n",
      "You: data processors\n",
      "Bot: Sorry, I don't have information on that topic.\n",
      "You: data processor\n",
      "Bot: Sorry, I don't have information on that topic.\n",
      "You: processor\n",
      "Bot: Sorry, I don't have information on that topic.\n",
      "You: Data Processor\n",
      "Bot: You must be logged in as an Administrator to take this action.\n",
      "On the main toolbar, click\n",
      "Deployment Manager\n",
      ".\n",
      "Click the\n",
      "Data Processors\n",
      "tab.\n",
      "Right-click a Data Processor to license, and then click\n",
      "Properties\n",
      ".\n",
      "The Data Processor Properties dialog box appears.\n",
      "Click\n",
      "Licensing Wizard\n",
      ".\n",
      "Follow the steps of the wizard to complete the process.\n",
      "Click\n",
      "OK\n",
      "when the process is complete.\n",
      "\n",
      "You: Agent\n",
      "Bot: LogRhythm provides support for Agent failover across several Data Processors (up to three is the most common configuration). Three prioritized Processors configured into the Agent as mediator1, mediator2, and mediator3 (ordered list). Collection performance is maintained across Mediator failover, and this capability can also be used to support Agent load balancing.\n",
      "One of three scenarios can cause an Agent to failover to a different Processor:\n",
      "The Processor currently serving the Agent is already servicing its maximum agent count.\n",
      "The Processor is unavailable due to inability to establish connection or a lost connection (for example, a network issue).\n",
      "The Processor issues a suspense condition.\n",
      "The Failback Delay can be configured in the System Monitor Agent Advanced Properties dialog box.\n",
      "\n",
      "You: Beats\n",
      "Bot: I'm sorry, I don't understand.\n",
      "You: Beat\n",
      "Bot: I'm sorry, I don't understand.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymongo\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "# Load the DataFrame from the Pickle file\n",
    "df = pd.read_pickle('C:\\\\Users\\\\ted59\\\\Knapp069-Practicum-1-Project\\\\Processed Data\\\\processed_document_data.pkl')\n",
    "\n",
    "# Load the pre-trained spaCy model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Load the pre-trained LDA model\n",
    "lda_model = gensim.models.LdaMulticore.load('C:\\\\Users\\\\ted59\\\\Knapp069-Practicum-1-Project\\\\Processed Data\\\\lda_model.pkl')\n",
    "\n",
    "# Create a dictionary for topic modeling\n",
    "dictionary = corpora.Dictionary(df['Trigram'].apply(lambda x: x.split()))\n",
    "\n",
    "# MongoDB Connection\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"WS_Data_DB\"]\n",
    "collection = db[\"LogRhythm7_15Docs\"]\n",
    "\n",
    "# Define predefined topics\n",
    "predefined_topics = [\n",
    "    \"agent\",\n",
    "    \"siem\",\n",
    "    \"logrhythm\",\n",
    "    \"network monitoring\", \n",
    "    \"threat detection\", \n",
    "    \"system configuration\",\n",
    "    \"AI Engine\",\n",
    "    \"AI Engine Rules\",\n",
    "    \"System Monitor Agent\",\n",
    "    \"Disaster Recovery\",\n",
    "    \"High Availability\",\n",
    "    \"Log Sources\",\n",
    "    \"Data Processor\",\n",
    "    \"Mediator\",\n",
    "    \"Open Collector\",\n",
    "    \"Installation\",\n",
    "    \"Upgrade\",\n",
    "    \"MPE\",\n",
    "    \"Message Processing Engine\",\n",
    "    \"Platform Manager\",\n",
    "    \"Configuration Manager\",\n",
    "    \"Data Indexer\",\n",
    "    \"Global Log Processing\",\n",
    "    \"Security Policies\",\n",
    "    \"Log Source Virtualization\",\n",
    "    \"Advanced Reporting\",\n",
    "    \"SIEM Platform Optimization\",\n",
    "    \"Real-Time Data Analysis\",\n",
    "    \"Log Data Normalization\",\n",
    "    \"Security Event Correlation\",\n",
    "    \"Network Behavior Analysis\",\n",
    "    \"Custom Rule Creation\",\n",
    "    \"Cloud-Based Log Management\",\n",
    "    \"Data Privacy and Protection\",\n",
    "    \"Automated Threat Hunting\",\n",
    "    \"Log Source Integration\",\n",
    "    \"Compliance Reporting\",\n",
    "    \"Scalable Architecture\",\n",
    "    \"Customizable Dashboards\",\n",
    "    \"Security Information Management\",\n",
    "    \"Advanced Threat Intelligence\",\n",
    "    \"AI-Driven Security Analysis\",\n",
    "    \"User and Entity Behavior Profiling\",\n",
    "    \"Security Workflow Automation\",\n",
    "    \"Incident Management and Response\",\n",
    "    \"Endpoint Data Collection\",\n",
    "    \"Forensic Data Analysis\",\n",
    "    \"Cybersecurity Risk Assessment\",\n",
    "    \"Log Archive and Retrieval\",\n",
    "    \"Security Operations Center (SOC) Analytics\",\n",
    "    \"Threat Lifecycle Management Framework\",\n",
    "    \"LogRhythm NetMon Integration\",\n",
    "    \"CloudAI Security Analytics\",\n",
    "    \"LogRhythm Labs Threat Research\",\n",
    "    \"Managed Security Services\",\n",
    "    \"Data Exfiltration Detection\",\n",
    "    \"Customizable Alerting System\",\n",
    "    \"Cyber Resilience Strategies\",\n",
    "    \"Log Source Management\",\n",
    "    \"Advanced Security Orchestration\",\n",
    "    \"Regulatory Compliance Assurance\",\n",
    "    \"Multi-Tenant Security Management\",\n",
    "    \"Extended Detection and Response (XDR)\",\n",
    "    \"LogRhythm API Capabilities\",\n",
    "    \"Security Data Lake\",\n",
    "    \"Cross-Platform Security Integration\",\n",
    "    \"LogRhythm Training Programs\",\n",
    "    \"Cybersecurity Policy Enforcement\",\n",
    "    \"Threat Detection Algorithms\",\n",
    "    \"Security Data Visualization\",\n",
    "    \"Log Management Best Practices\"\n",
    "]\n",
    "    \n",
    "# Function to fetch content for a given topic from MongoDB\n",
    "def fetch_content_for_topic(topic):\n",
    "    documents = collection.find({})\n",
    "    for doc in documents:\n",
    "        content_sections = doc.get('content_sections', {})\n",
    "        if isinstance(content_sections, dict):\n",
    "            for section_title, section_content in content_sections.items():\n",
    "                if topic.lower() in section_title.lower():\n",
    "                    return section_content\n",
    "    return \"Sorry, I don't have information on that topic.\"\n",
    "\n",
    "# Define the keyword_based_extraction function\n",
    "def keyword_based_extraction(input_text):\n",
    "    lower_text = input_text.lower()\n",
    "    for keyword in predefined_topics:\n",
    "        if keyword in lower_text:\n",
    "            return keyword\n",
    "    return None\n",
    "\n",
    "# Enhanced topic extraction function\n",
    "def enhanced_extract_topics(input_text):\n",
    "    input_vec = nlp(input_text)\n",
    "    topic_scores = {topic: input_vec.similarity(nlp(topic)) for topic in predefined_topics}\n",
    "    relevant_topic = max(topic_scores, key=topic_scores.get, default=None)\n",
    "    return relevant_topic if relevant_topic and topic_scores[relevant_topic] > 0.5 else None\n",
    "\n",
    "# Main chat loop\n",
    "print(\"Welcome to the Chatbot! Type 'exit' to end the conversation.\")\n",
    "while True:\n",
    "    user_input = input(\"You: \").strip()\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Bot: Goodbye! Have a great day!\")\n",
    "        break\n",
    "\n",
    "    # First, try keyword-based extraction\n",
    "    topic = keyword_based_extraction(user_input)\n",
    "    if not topic:\n",
    "        # If no keyword match, use enhanced topic modeling\n",
    "        topic = enhanced_extract_topics(user_input)\n",
    "\n",
    "    response = fetch_content_for_topic(topic) if topic else \"I'm sorry, I don't understand.\"\n",
    "    print(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10a423a",
   "metadata": {},
   "source": [
    "document = collection.find_one({\"topic\": \"agent\"})\n",
    "if document:\n",
    "    print(document['content'])  # This should print the content related to LogRhythm\n",
    "else:\n",
    "    print(\"Content not found in the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f72f9ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content for 'Network':\n",
      "Sorry, I don't have information on that topic.\n"
     ]
    }
   ],
   "source": [
    "# Example topic for testing\n",
    "test_topic = \"Network\"  # Replace with a known topic from your database\n",
    "\n",
    "# Call the function and print the result\n",
    "test_result = fetch_content_for_topic(test_topic)\n",
    "print(\"Content for '{}':\\n{}\".format(test_topic, test_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3412dc",
   "metadata": {},
   "source": [
    "print(\"Content for 'SIEM':\", fetch_content_for_topic(\"SIEM\"))\n",
    "print(\"Content for 'Agent':\", fetch_content_for_topic(\"Agent\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dea496d",
   "metadata": {},
   "source": [
    "import pymongo\n",
    "\n",
    "# MongoDB connection setup\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"WS_Data_DB\"]  # Replace with your database name\n",
    "collection = db[\"LogRhythm7_15Docs\"]  # Replace with your collection name\n",
    "\n",
    "# Define your predefined topics\n",
    "predefined_topics = [\n",
    "    \"agent\",\n",
    "    \"siem\",\n",
    "    \"logrhythm\",\n",
    "    \"network monitoring\", \n",
    "    \"threat detection\", \n",
    "    \"system configuration\",\n",
    "    \"AI Engine\",\n",
    "    \"AI Engine Rules\",\n",
    "    \"System Monitor Agent\",\n",
    "    \"Disaster Recovery\",\n",
    "    \"High Availability\",\n",
    "    \"Log Sources\",\n",
    "    \"Data Processor\",\n",
    "    \"Mediator\",\n",
    "    \"Open Collector\",\n",
    "    \"Installation\",\n",
    "    \"Upgrade\",\n",
    "    \"MPE\",\n",
    "    \"Message Processing Engine\",\n",
    "    \"Platform Manager\",\n",
    "    \"Configuration Manager\",\n",
    "    \"Data Indexer\",\n",
    "    \"Global Log Processing\",\n",
    "    \"Security Policies\",\n",
    "    \"Log Source Virtualization\",\n",
    "    \"Advanced Reporting\",\n",
    "    \"SIEM Platform Optimization\",\n",
    "    \"Real-Time Data Analysis\",\n",
    "    \"Log Data Normalization\",\n",
    "    \"Security Event Correlation\",\n",
    "    \"Network Behavior Analysis\",\n",
    "    \"Custom Rule Creation\",\n",
    "    \"Cloud-Based Log Management\",\n",
    "    \"Data Privacy and Protection\",\n",
    "    \"Automated Threat Hunting\",\n",
    "    \"Log Source Integration\",\n",
    "    \"Compliance Reporting\",\n",
    "    \"Scalable Architecture\",\n",
    "    \"Customizable Dashboards\",\n",
    "    \"Security Information Management\",\n",
    "    \"Advanced Threat Intelligence\",\n",
    "    \"AI-Driven Security Analysis\",\n",
    "    \"User and Entity Behavior Profiling\",\n",
    "    \"Security Workflow Automation\",\n",
    "    \"Incident Management and Response\",\n",
    "    \"Endpoint Data Collection\",\n",
    "    \"Forensic Data Analysis\",\n",
    "    \"Cybersecurity Risk Assessment\",\n",
    "    \"Log Archive and Retrieval\",\n",
    "    \"Security Operations Center (SOC) Analytics\",\n",
    "    \"Threat Lifecycle Management Framework\",\n",
    "    \"LogRhythm NetMon Integration\",\n",
    "    \"CloudAI Security Analytics\",\n",
    "    \"LogRhythm Labs Threat Research\",\n",
    "    \"Managed Security Services\",\n",
    "    \"Data Exfiltration Detection\",\n",
    "    \"Customizable Alerting System\",\n",
    "    \"Cyber Resilience Strategies\",\n",
    "    \"Log Source Management\",\n",
    "    \"Advanced Security Orchestration\",\n",
    "    \"Regulatory Compliance Assurance\",\n",
    "    \"Multi-Tenant Security Management\",\n",
    "    \"Extended Detection and Response (XDR)\",\n",
    "    \"LogRhythm API Capabilities\",\n",
    "    \"Security Data Lake\",\n",
    "    \"Cross-Platform Security Integration\",\n",
    "    \"LogRhythm Training Programs\",\n",
    "    \"Cybersecurity Policy Enforcement\",\n",
    "    \"Threat Detection Algorithms\",\n",
    "    \"Security Data Visualization\",\n",
    "    \"Log Management Best Practices\"\n",
    "]\n",
    "\n",
    "# Function to fetch and print content for a given topic\n",
    "def print_content_for_topic(topic):\n",
    "    document = collection.find_one({\"topic\": topic})\n",
    "    if document:\n",
    "        print(f\"Content for '{topic}': {document['content']}\")\n",
    "    else:\n",
    "        print(f\"No content found for topic '{topic}'.\")\n",
    "\n",
    "# Test each predefined topic\n",
    "for topic in predefined_topics:\n",
    "    print_content_for_topic(topic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7c10355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\n', 'LogRhythm SIEM': 'To effectively fight threats, you need the right tools. The LogRhythm SIEM Platform aligns your team, technology, and processes. It helps you see across your IT environment, identify threats, and quickly mitigate and recover from security incidents.\\n', 'Documentation': '7.15.0.64 Release Notes - 5 February 2024\\n7.15.0 GA Release Notes - 4 January 2024\\n7.14.0.107 Release Notes - 18 October 2023\\n7.14.1 Release Notes - 13 November 2023\\n7.14.0 GA Release Notes - 2 October 2023\\n7.13.0.78 Release Notes - 2 August 2023\\n7.13.0.76 Release Notes - 17 July 2023\\n7.13.0 GA Release Notes - 29 June 2023\\n7.12.0 GA Release Notes - 3 April 2023\\n7.11.0.43 Release Notes - 6 March 2023\\n7.10.0.124 Release Notes - 6 March 2023\\n7.11.0 GA Release Notes - 5 January 2023\\n7.10.0.123 Release Notes - 11 October 2022\\n7.10.0 GA Release Notes - 29 September 2022\\n7.9.0 GA Release Notes - 23 June 2022\\n7.8.0 GA Release Notes\\n7.7.0 GA Release Notes\\nLog in to the Client Console\\nComplete the New Deployment Wizard\\nAssign LogRhythm Licenses\\nLog in to the Web Console\\nVerify the Web Console Connection Status\\nConfigure NetMon to Integrate with the Web Console\\nAdvanced Intelligence Engine\\nAlarm Rules\\nAutomatic Host Contextualization\\nData Archives and Restoration\\nData Indexer\\nData Processor\\nDeployment Health\\nDeployment Manager\\nDeployment Security\\nEndpoint Monitoring\\nEntities\\nGlobal Log Processing Rules\\nHost Records\\nKnowledge Base\\nLog Distribution Services\\nLog Processing Policies\\nLog Sources\\nNetwork Monitor\\nNetwork Records\\nObject Permissions Manager\\nPeople and Users\\nPlatform Manager\\nSmartResponse\\nSystem Monitor\\nFilters and Wizards\\nGeneral Console Features\\nLayouts\\nLists in the Client Console\\nMessage Processing Engine Rule Builder\\nMonitor, Search, and Analysis\\nMy LogRhythm\\nReport Center\\nAlarms\\nAnalyzer Grid\\nCase Management\\nCloud to Cloud Log Collection\\nDashboards\\nLists in Web Console\\nLog Collection in Web Console\\nPlaybooks\\nReports\\nSearch\\nSecondLook - Web Console\\nSingle Sign-On\\nTrueIdentity\\nUser Interface\\nUser Settings\\nWidgets\\nApplication Tab\\nKbytes/Packets Tab\\nClassification Tab\\nHost Tab\\nIdentity Tab\\nLocation Tab\\nLog Tab\\nNetwork Tab\\nOther MPE Fields\\nDerived Data\\nThreat Intelligence Service\\nLogRhythm Diagnostics Tool\\nLogRhythm Echo\\nTrueIdentity Sync Client User Guide\\nLicensing\\nLog Processing\\nLogRhythm SIEM Databases\\nLogs, Events, and Alarms\\nNetworking and Communication\\nComponent Reference\\nCustomer Support Guide\\nUpgrade FAQ and Determining the Correct Upgrade Path\\nEnd of Life Policies for Software and Hardware\\nGlossary of LogRhythm Products and Components\\nOpen Source License Acknowledgements\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n', 'Client Console Administrator Guide': \"Administrators are tasked with performing setup, troubleshooting and general care and maintenance of the LogRhythm system. Administrators will setup Log Sources, User Access, Reporting and system advanced settings. Administrators also work with Analysts to ensure that Advanced Intelligence Engine rules are created and tuned for optimal use.\\n\\nAdvanced Intelligence Engine, LogRhythm AI Engine detects conditions in your deployment that occur over multiple data sources and time ranges. AI Engine provides realtime visibility to risks, threats, and critical operations issues.\\nAlarm Rules, The Alarming and Response Manager (ARM) evaluates system and user-defined alarm rules to determine whether an Event should incur an alarm.\\nAutomatic Host Contextualization, LogRhythm contextualizes a host or service automatically to improve the aggregation of log data for unique IP and port combinations. Based on the port values, LogRhythm can infer the relationship of the two hosts if a log contains parsed values for the following fields: SIP/SName, DIP/DName, Source Port (SPort), Destination Port (DPort)\\nData Archives and Restoration, The LogRhythm Mediator Server service is responsible for archiving specified log data from active indexes to the LogRhythm Archives. When you need access to archived logs, the Archive Restoration Wizard allows you to import them into a special archives index.\\nData Indexer, The Data Indexer (Indexer) provides persistence and search capabilities, as well as high-performance, distributed, and highly scalable indexing of machine and forensic data.\\nData Processor, The Data Processor's Mediator Server service handles communications with LogRhythm Agents. The Mediator is also responsible for processing logs against the Knowledge Base and sending processed log messages to the Data Indexer. The Data Processor contains a log processing engine known as the Message Processing Engine (MPE).\\nDeployment Health, LogRhythm provides configuration and tuning to ensure your solution starts off at an optimal configuration for your log processing needs. The health and maintenance of your LogRhythm solution is crucial for its optimal performance.\\nDeployment Manager, LogRhythm administrators use the Deployment Manager to configure and manage LogRhythm components and functionality.\\nDeployment Security, This section provides information about some of the security features in LogRhythm, including passwords and password encryption, support for Public Key Infrastructure (PKI), users and security roles, and user security permissions.\\nEndpoint Monitoring, Endpoint Monitoring is a client/server information security (IS) methodology used to audit log files generated by endpoint devices, such as laptops, smartphones, and routers. Endpoint monitoring collects the generated log files and sends them to the Data Processor for analysis. If unusual behavior is detected, an alarm is generated.\\nEntities, An Entity represents a physical location where LogRhythm is deployed. It is used to organize the deployment and contain network and host records and LogRhythm components.\\nGlobal Log Processing Rules, Global Log Processing Rules (GLPR) provide a way to override settings defined in Classification Based Data Management (CBDM) or Standard Data Management modes. A GLPR provide a way to apply Data Management settings across all Data Processors, Log Sources and Log Processing Policies to logs that meet your specific criteria.\\nHost Records, Host records identify and assign useful information—such as\\xa0purpose of the system, any known issues, and key contacts—to important systems in your network.\\nKnowledge Base, The Knowledge Base (KB) consists of a Core Base Module and individual KB modules. The KB Core Base Module must be installed and updated on all deployments and each module must be updated to meet the organization's needs.\\nLog Distribution Services, Log Distribution Services (LDS) allow you to forward specified syslog and non-syslog log messages to an external syslog receiver over TCP or UDP in a format and configuration that best meets your needs.\\nLog Processing Policies, Log Processing Policies, or Message Processing Engine (MPE) policies, determine which rules are processed against a Log Message Source and how matching log messages are treated.\\nLog Sources, A Log Source is a unique source of log data that is collected from a Host. Every log is associated to a single Log Source, which is the key link LogRhythm uses to determine the origin of a log message.\\nNetwork Monitor, LogRhythm NetMon provides visibility into all data traversing your network through in-depth packet capture and multiple recognition methodologies.\\nNetwork Records, Network records identify and logically group a range of IP addresses to assign a Risk-Based Priority (RBP) to events and determine direction such as inbound or outbound for the activity being logged.\\nObject Permissions Manager, The Object Permissions Manager enables a Global Administrator to manage Investigations, Tails, Lists, and Alarm Rules by setting read and write access permissions for an object and to assigning it to a new owner and/or entity.\\nPeople and Users, LogRhythm employs Person Records to identify users so they can log in with personal credentials instead of the default LogRhythmAdmin or LogRhythmAnalyst accounts. Person records are also used for Alarm Notifications.\\nPlatform Manager, The Platform Manager (PM) serves as the central repository for events, configuration and licensing information, the LogRhythm Knowledge Base, and LogMart.\\nSmartResponse, SmartResponse lets you execute preventative actions when threatening activity is observed. Actions may provide deeper forensic or operational data, automate operations tasks, or implement security controls in defense of an attack or intrusion, such as disabling a compromised user account or terminating a connection between attacker and target.\\nSystem Monitor, The System Monitor is a software component that provides local and remote log data collection across various English-based operating systems including Windows and *NIX.\\nThe Platform Manager (PM) serves as the central repository for events, configuration and licensing information, the LogRhythm Knowledge Base, and LogMart.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n', 'Client Console Analyst Guide': '\\nThe LogRhythm SIEM platform allows analysts to efficiently capture logs and use advanced analytics to surface known and unknown threats, all while automating manual tasks with embedded security orchestration, automation, and response (SOAR) capabilities.\\n\\nFilters and Wizards, Filtering is used in searches and configuration in many parts of the LogRhythm Client Console, including AI Engine Rules, Alarms, Investigations, Tails, and Reports.\\nGeneral Console Features, Some basic functionality of the Client Console is used in multiple tools and windows. This includes exporting data and generating crash reports.\\nLayouts, Layouts consist of the look and feel for how widgets appear within the Personal Dashboard and Investigate.\\nLists in the Client Console, Lists provide a mechanism for organizing and saving common search criteria used within filters throughout the Client Console.\\nMessage Processing Engine Rule Builder, The MPE Rule Builder allows you to view, create, and edit new MPE base rules and sub-rules. New rules are needed to collect and process logs from any new log source type.\\nMonitor, Search, and Analysis, Monitoring, searching, and analyzing are done through a number of features in the Client Console. These include: Alarm Viewer, Investigator, Personal Dashboard, Quick Search Toolbar, Tail, and TopX Analysis.\\nMy LogRhythm, The My LogRhythm menu provides access to several tools that allow you to modify preferences, settings, and records in LogRhythm that are unique to you.\\nReport Center, The Report Center includes predefined templates, reports, and Report Packages, which are sets of reports that pertain to a single topic such as security compliance standards, usage auditing, or LogRhythm diagnostics.\\nMonitoring, searching, and analyzing are done through a number of features in the Client Console. These include: Alarm Viewer, Investigator, Personal Dashboard, Quick Search Toolbar, Tail, and TopX Analysis.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n', 'Download PDFs': '\\nThis section provides downloadable PDFs of LogRhythm 7.15.0 documentation.\\n', 'Core Documentation': 'Release Notes for 7.15.0 GA\\nSIEM Help\\nWeb Console User Guide\\n', 'Supplemental Documentation': 'Schema Dictionary\\nLeast Privileged User Guide\\nLucene Search Syntax Guide\\nRealtime Antivirus Exclusions\\nMPE Rule Builder Parsing Guide\\nSmartResponse Plugin Development Guide\\nDark Spare Configuration Guide\\nThreat Intelligence Service Installation and User Guide\\nTrue Identity Sync Client Guide\\nMetrics App Release Notes\\nMetrics App User Guide\\nDiagnostics Tool Release Notes\\nDiagnostics Tool Installation and User Guide\\nLogRhythm ECHO Release Notes\\nLogRhythm ECHO Installation and User Guide\\nSQL Server Trace File Converter Release Notes\\nSQL Server Trace File Converter User Guide\\nFor documentation relating to previous versions of LogRhythm, visit the Documentation & Downloads tab on the\\nLogRhythm Community\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n', 'Find More Information': '\\nThe information found on this site is accurate for the most current release of LogRhythm.\\nFor documentation relating to previous versions of LogRhythm, visit the Documentation & Downloads tab on the\\nLogRhythm Community\\n.\\n', 'LogRhythm Support': 'For complete customer support information, refer to the\\nCustomer Support Guide\\n.\\n', 'Normal Business Hours': '7:00 AM - 6:00 PM Mountain Time\\n', 'LogRhythm Support Portal': 'http://support.logrhythm.com\\n', 'Phone Support (7am - 6pm, Monday-Friday)': '11 x 5 Support, Phone Number\\nToll Free in North America (MT), +1-866-255-0862\\nDirect Dial in the Americas (MT), +1-720-407-3990\\nEMEA (GMT), +44 (0) 844 3245898\\nMETA (GMT+4), +971 8000-3570-4506\\nAPAC (SGT), +65 31572044\\nCorporate, 303-413-8745, Option 2\\n+971 8000-3570-4506\\nCustomers that purchase Platinum Support are provided with a phone number to contact Support Services outside of normal business hours.\\n', '© LogRhythm, Inc. All rights reserved.': 'This document contains proprietary and confidential information of LogRhythm, Inc., which is protected by copyright and possible non-disclosure agreements. The Software described in this Guide is furnished under the End User License Agreement or the applicable Terms and Conditions (“Agreement”) which governs the use of the Software. This Software may be used or copied only in accordance with the Agreement. No part of this Guide may be reproduced or transmitted in any form or by any means, electronic or mechanical, including photocopying and recording for any purpose other than what is permitted in the Agreement.\\n', 'Disclaimer': 'The information contained in this document is subject to change without notice. LogRhythm, Inc. makes no warranty of any kind with respect to this information. LogRhythm, Inc. specifically disclaims the implied warranty of merchantability and fitness for a particular purpose. LogRhythm, Inc. shall not be liable for any direct, indirect, incidental, consequential, or other damages alleged in connection with the furnishing or use of this information.\\n', 'Trademark': 'LogRhythm is a registered trademark of LogRhythm, Inc. All other company or product names mentioned may be trademarks, registered trademarks, or service marks of their respective holders.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n', 'Get Started with LogRhythm SIEM': '\\nAfter you install or upgrade your deployment, follow these steps to get started using LogRhythm SIEM.\\n\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n', 'Inclusions Library': '\\nThe purpose of this page is to set up an inclusions library for content snippets that have heavy reuse in the NextGen SIEM space. This is primarily relevant for installation and upgrade guides.\\nThis page does not appear in the left panel navigation tree in\\nConfluence\\nwhen viewing any page other than this one and its children. It is an orphaned page that can only be accessed by clicking on Space Tools at the bottom of the navigation tree and selecting Reorder Pages.\\nThese pages can appear in search results but generally will not since most search macros in this space are configured to search by specific label. Regardless, each page has a disclaimer on the top that the content on the page is out of context and not meant to be read alone. The content for reuse is inside an Excerpt macro. Therefore, to use it, you must use the Excerpt Include macro, not the Page Include macro, which would also display the disclaimer.\\nThe available snippets are the following:\\n\\n\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n', 'LogRhythm Release Notes': '', 'Overview': 'LogRhythm release notes provide users information regarding new features, deprecated features, improvements, resolved issues, and upgrade considerations for each LogRhythm Enterprise SIEM release.\\n', 'Components': 'This release contains the following LogRhythm components (64-bit unless otherwise noted):\\nInfrastructure Installer\\nAdmin API\\nAlarm API\\nAI Engine\\nAIE Drilldown Cache\\nAlarming and Response Manager\\nAuthentication Services\\nCase API\\nConfiguration Manager\\nClient Console\\nData Indexer\\nJob Manager\\nMediator Server\\nMetrics API\\nNotification Service\\nSearch API\\nWindows System Monitor (32-bit and 64-bit)\\nWindows System Monitor for Server 2008/2008R2/2012R2 Core/2016/2019\\n*NIX System Monitors (see\\nLogRhythm System Monitor Compatibility and Functionality\\nfor details about supported versions/distributions)\\nWeb Console\\n', 'Important Information for Upgrades to any LogRhythm 7.14.x Release': 'Upgrades to LogRhythm 7.14 are supported from LogRhythm 7.13, 7.12, 7.11, 7.10, 7.9, 7.8, 7.7, 7.6.x, 7.5.x, and 7.4.x. If you are on an older version of LogRhythm, first upgrade to 7.4.10 using the documentation available on the\\nLogRhythm Community\\n, and then upgrade to LogRhythm 7.14.x.\\nL\\nogRhythm 7.14.0 does not support upgrades to\\nMicrosoft SQL Server 2019 and Windows Server 2019 on existing High Availability (HA) and Disaster Recovery (DR) environments.\\n', 'LogRhythm SIEM Releases': '\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n', 'LogRhythm Schema Dictionary and Guide': '\\nThis schema guide contains descriptions of every field, including the intent for the field, guidance for how to parse data into the field, use cases for each field, and sample logs showing correct, incorrect, and ambiguous examples.\\nThe fields in this guide are organized according to the tabs in the Analyzer grid in the LogRhythm Web Console. To access the Analyzer grid on the Dashboards page or Analyze page, at the lower-right side of the page, click the\\nLogs\\ntab.\\nFields that are listed with [7.2] after the field name are not available in LogRhythm versions earlier than 7.2.1.\\n', 'Origin vs. Impacted': '', 'Definition and Guidelines': 'LogRhythm presents log sources from the perspective of the impacted system, the origin system, or both. Although origin and impacted align with the network-centric view of \"source\" and \"destination,\" origin and impacted are meant to represent a security-centric view, in which:\\nIn a security-centric view:\\nOrigin represents:\\nThe client in “client server.”\\nThe attacker in a security context.\\nThe cause of an observation.\\nThe user account who performed an action.\\nThe client in “client server.”\\nThe attacker in a security context.\\nThe cause of an observation.\\nThe user account who performed an action.\\nImpacted represents:\\nThe server in \"client server.\"\\nThe target in a security context, or the device impacted by a security event.\\nThe effect of an observation.\\nThe user affected by an action.\\nThe server in \"client server.\"\\nThe target in a security context, or the device impacted by a security event.\\nThe effect of an observation.\\nThe user affected by an action.\\n', 'Use in Schema': 'The use of origin and impacted is particularly important for understanding the schema. Origin and impacted apply to IP addresses, hosts, users, and other fields that describe the object in the log. These fields include:\\nHostname\\nMAC address\\nInterface\\nIP address\\nUser\\nFor an IP address, the schema parses into fields called SIP and DIP, where SIP represents origin and DIP represents impacted.\\n', 'What Determines Origin/Impacted?': 'The origin/impacted context can be defined and changed in multiple places:\\nSelecting correct parsing fields\\n. This is important when converting the network view of source and destination to the security view of origin and impacted. Origin is not always source and impacted is not always destination.\\nRule definition with explicit options\\n. The rule can explicitly force a conversion of direction.\\nAutomatic Host Contextualization (AHC)\\n. The AHC feature can change direction based on tables of well-known ports and protocols.\\n', 'Examples': \"O365 SharePoint. SIP is explicitly called out, but because O365 is the cloud, there is no discernable impacted hostname.\\nTS=2016-10-20T20:22:23 SESSID=8b157afd-eb80-45e4-926f-08d3f926cd63 COMMAND=AnonymousLinkUsed USERTYPE=Regular USERKEY=anonymous WORKLOAD=SharePoint RESULTCODE= OBJECT=\\nhttps://dummysitez.com/Dummy/Shared\\nDocuments/abuse_ch_copy.txt USER=anonymous\\nSIP=1.1.1.1\\nITEMTYPE=File EVENTSOURCE=SharePoint USERAGENT=Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.59 Safari/537.36 DOMAIN= FILENAME= DESTINATION= DESTINATIONFILENAME= USERSHAREDWITH= SHARINGTYPE= MODIFIEDPROPERTIES=\\nThis is not a security event, so apply the network-centric view of client vs. server. The client is referenced in the SIP, and therefore SIP (origin) is the IP Origin. The IP Impacted is undefined, but the Impacted Host can be inferred from the log source. It is ambiguous whether the log source is the agent calling the API or refers to O365.\\nOracle 10g Audit. Client is the source of the session, but also impacted by the logoff.\\n20101115202959.307904 AUDIT_TYPE=Standard Audit STATEMENT_TYPE=LOGOFF BY CLEANUP RETURNCODE=0 AUDIT_OPTION= PRIV _USED=CREATE SESSION OS_USER=shenja DB_USER=SYSTEM UHOST=WKST0005 TERM=UNKNOWN OBJECT_SCHEMA= OBJECT_NAME= POLICY_NAME= NEW_OWNER= NEW_ NAME= EXT_NAME= SQL_TEXT= COMMENT_ TEXT=Authenticated by: DATABASE; Client address: (ADDRESS=(PROTOCOL=tcp)(\\nHOST=1.1.1.1\\n)(PORT=4888)) SES_ACTIONS= GLOBAL_UID= SESSION_ID=325213 PROXY_SESSIONID= STATEMENTID=1 ENTRYID=1 CLIENT_ID= ECONTEXT_ID= TRANSACTIONID= OS_PROCESS=610338 INSTANCE_NUMBER=0 ACTION=102 SQL_BIND= OBJ_PRIVILEGE= SYS_PRIVILEGE= OS_PRIVILEGE=NONE SCN= GRANTEE= LOGOFF_TIME=11/15/2010 3:32:42 PM LOGOFF_LREAD=1386 LOGOFF_PREAD=80 LOGOFF_LWRITE=36 LOGOFF_DLOCK=0 SESSION_CPU=10\\nBecause this is not a security log, the host is likely the client (in client server). The host becomes the Origin Host. The Impacted Host is the Oracle server (automatically resolved by the log source).\\nWindows Application. <computer> is where the event log was written.\\n<Event xmlns='http://dummysitex.com/win/2004/08/events/event'><System><Provider Name='MSSQLSERVER'/><EventID Qualifiers='49152'>32040</EventID><Level>Information</Level><Task>Server</Task><Keywords>Classic</Keywords><TimeCreated SystemTime='2013-12-18T20:19:48.000000000Z'/><EventRecordID>5652</EventRecordID><Channel>Application</Channel>\\n<Computer>ACMEPREM01</Computer>\\n<Security/></System><EventData>The alert for 'oldest unsent transaction' has been raised. The current value of '3' surpasses the threshold '1'.</EventData></Event>\\nThe computer is the Impacted Host because there is no other context. Because the log came from this computer, it is the source of the log message.\\nCb Response. The endpoint is where the file originated in the scan, but is also likely impacted.\\n02 07 2017 17:30:21 1.1.1.1 <USER:NOTE> LEEF:1.0|CB|CB|5.1|watchlist.storage.hit.binary|cb_server=cbserver cb_version=525 copied_mod_len=8704 digsig_result=Unsigned digsig_result_code=2148204800\\nendpoint=PIA-EX2010-01\\n|2018 file_desc= file_version=1.1.1.1 group=Default Servers host_count=1 internal_name=rwl_hdls.dll is_64bit=false is_executable_image=false last_seen=2017-02-07T23:26:29.825Z legal_copyright= link_md5=\\nhttps://dum-dummy-01.dummy.net/#/binary/5F897E95044D43F58E30806857092186\\nmd5=5F897E95044D43F58E30806857092186 observed_filename=c:\\\\\\\\windows\\\\\\\\temp\\\\\\\\rwl_hdls.dll orig_mod_len=8704 original_filename=rwl_hdls.dll os_type=Windows product_version=1.1.1.1 server_added_timestamp=2017-02-07T23:26:29.825Z server_name=localhost timestamp=1486510220.266 type=watchlist.storage.hit.binary watchlist_2=2017-02-07T23:30:03.972203Z watchlist_id=2 watchlist_name=Default: Newly Loaded Modules\\nBecause this is a security event that occurred on the endpoint, the endpoint is the Impacted Host. The other hosts involved (for example, CB server or agent reading syslog) are not relevant to the security context.\\nCylancePROTECT. The threat originated from the device and IP, but is also impacted by the threat and the quarantine.\\n05 09 2016 01:33:03 1.1.1.1 <SLOG:WARN> 1 2016-05-09T06:32:55.1224002Z sysloghost CylancePROTECT - - - Event Type: Threat, Event Name: threat_quarantined,\\nDevice Name: GQ-6FPLVZ1, IP Address: (1.1.1.1)\\n, File Name: SOP.EXE, Path: E:\\\\HESS\\\\Corrosion\\\\HESS Okume Lab C drive Backup\\\\NALCO\\\\Okume CD training\\\\programme\\\\OkumeBandC\\\\ProdWellManifolds\\\\fscommand\\\\, Drive Type: Internal Hard Drive, SHA256: 8050FE3DCA43D594611492AA149AF09FC9669149602BB2945AFEA4148A24B175 , MD5: 59E0D058686BD35B0D5C02A4FD8BD0E0 , Status: Quarantined, Cylance Score: 97, Found Date: 1/7/2016 5:03:51 PM, File Type: Executable, Is Running: False, Auto Run: False, Detected By: BackgroundThreatDetection\\nBecause this is a security event, the Device Name is the Impacted Host.\\n\", 'Polyfields and Parsing Field Aggregation': 'Not all fields that are parsed in a rule are stored in the Data Indexer as parsed or displayed in the console as parsed. For example, the Web Console Duration field is a calculation based on one or more time-based parsing fields. Similarly, there are more than a dozen fields for bytes as a size, but only one value is stored and only one value is displayed.\\nPolyfields are a special type of display field used for aggregating across similar source data. For example, the Impacted Host polyfield could contain a hostname, an IP address, or a well-known entity. The hostname and IP address may also be stored separately. The polyfield generally has preference logic at the code level to determine which source field to display.\\nWhen reading this document, pay particular attention to fields that are called out as source data for a polyfield, or parsing fields that are transformed into final data fields.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n', 'Other LogRhythm Applications': '\\nLogRhythm applications allow you to\\nmaintain the integrity of shared information distributed between LogRhythm and other external data sources, as well as\\nautomate the exchange and synchronize configuration data to enhance administrative functions, as well as extend monitoring and analysis functions.\\n\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n', 'Understand the LogRhythm Architecture': '\\nLogRhythm has been designed with a highly flexible modular architecture. Each key LogRhythm function exists in a separate software program, or service.\\nA multitude of devices are generating thousands of raw logs in your network at every moment. These devices can include servers, firewalls, routers, network services, applications, and email systems. Depending on the device, the logs are generated in a wide variety of formats and can include information related to system health, user interaction with an application, and so on. All of this log data has varying degrees of importance, from mundane activity to a potential security compromise.\\nLogRhythm SIEM is a fully integrated Security Information and Event Management (SIEM) solution that processes this raw log data to make information available to you in a meaningful and uniform context. The following diagram shows the key LogRhythm components for collecting and processing logs: the Agents, the Data Processor, the AI Engine, and the Platform Manager.\\n\\nThe individual services are installed on hosts to create the overall LogRhythm solution. All LogRhythm services can be installed on a single server providing all LogRhythm capabilities or the services can be installed on separate servers in high performance and redundant configurations.\\n\\nChanging the default SQL Server Collation from “SQL_Latin1_General_CP1_CI_AS” is not supported and can leave your deployment in a non-working state.\\n', 'General Guidelines for Deployment Architecture': \"A minimal deployment of LogRhythm consists of:\\nOne Platform Manager\\nOne Data Processor\\nOne Data Indexer\\nOne System Monitor\\nThe modular nature of LogRhythm's components allows the Platform Manager, Data Processor, and Data Indexer to reside on the same server for low-volume deployments, or on dedicated servers for high-volume deployments. The following general guidelines apply to any LogRhythm deployment, large or small:\\nThe Platform Manager and its associated database contain the record of events generated by LogRhythm as well as all the LogRhythm configuration data. It is important that the Platform Manager always be placed in a secure internal network.\\nThe Platform Manager is a Windows server running SQL Server 2016 Standard SP1 or higher and should be deployed accordingly.\\nThe Data Processor forwards Agent log data to the Data Indexer. It is the recommended practice to deploy Data Processors and Data Indexers in a secure internal network. However, in some scenarios it may be advisable to place the Data Processor in a DMZ when Agents will be used to collect from Remote Sites.\\nThe Data Processor is a Windows server. The Data Indexer is a Windows or Linux server, and it should be protected with strict access controls placed on devices that can connect to the log repository if deployed in a DMZ or an untrusted environment.\\nCommunications to DMZ or remotely deployed Data Processors, from Platform Managers and Consoles, can be encrypted to provide secure log delivery.\\nThe System Monitor, which collects log data and forwards it to a Data Processor, can:\\nbe deployed on supported Windows, Linux, or UNIX systems in an internal DMZ or on remote network hosts.\\nencrypt collected log data before forwarding it across untrusted networks (for example, the Internet).\\nread collected log data before forwarding it across untrusted networks (for example, flat files).\\nread local Windows Event Logs (the Windows System Monitor).\\nread Windows Event Logs residing on remote systems (the Windows System Monitor).\\nhave an integrated Syslog server for collection of Syslog data.\\nhave an integrated NetFlow server (the Windows System Monitor) for collecting NetFlow/J-Flow data from Cisco devices.\\nhave an integrated sFlow server for collecting Flow data from network devices.\\nhave an integrated SNMP trap receiver.\\ncollect the following logs:\\nCheck Point Firewall logs\\nCisco IDS logs\\nLogs residing in database tables\\nQualys, Nessus, and other vulnerability scanners\\nbe deployed on supported Windows, Linux, or UNIX systems in an internal DMZ or on remote network hosts.\\nencrypt collected log data before forwarding it across untrusted networks (for example, the Internet).\\nread collected log data before forwarding it across untrusted networks (for example, flat files).\\nread local Windows Event Logs (the Windows System Monitor).\\nread Windows Event Logs residing on remote systems (the Windows System Monitor).\\nhave an integrated Syslog server for collection of Syslog data.\\nhave an integrated NetFlow server (the Windows System Monitor) for collecting NetFlow/J-Flow data from Cisco devices.\\nhave an integrated sFlow server for collecting Flow data from network devices.\\nhave an integrated SNMP trap receiver.\\ncollect the following logs:\\nCheck Point Firewall logs\\nCisco IDS logs\\nLogs residing in database tables\\nQualys, Nessus, and other vulnerability scanners\\nCheck Point Firewall logs\\nCisco IDS logs\\nLogs residing in database tables\\nQualys, Nessus, and other vulnerability scanners\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n', 'Web Console User Guide': '\\nThe LogRhythm Web Console allows you to monitor network log activity from supported browsers on desktop computers and laptops.\\nTo support the most common end-user activities, the Web Console offers a customizable user interface with colorful visualizations and a range of powerful analytical and forensic features, including the following:\\nCritical data analysis tools, vibrant charts and graphs, and quick access to raw logs. Sift through tens of thousands of data rows without the hindrance of pagination. An array of grid tools helps reduce the time that you need to make informed determinations about network activities.\\nMultiple real-time, interchangeable dashboard layouts. You can create and share dashboard layouts to support different information needs.\\nDedicated alarm management with SmartResponse action integration and a streamlined interface for viewing, filtering, and sorting alarms.\\nCollaborative forensic tools for identifying suspicious logs, collecting evidence, and building cases around network activities that appear to be related to the same threat.\\nUser-created saved and shared searches for routine queries.\\nDirect web access to authorized report packages. Download available reports in PDF format or create and run new searches based on their reporting filters.\\nDirect web access to browse, view, create, and edit lists used in searches, alarms, and more. Add values to lists directly from the Analyzer grid.\\nLogRhythm currently supports up to three Web Console instances with 60 concurrent users.\\xa0However, other usage limitations apply. For more information, see the Web Services Host API information in the Configuration Manager.\\n', 'Getting Started in the Web Console': 'The\\nGet Started with LogRhythm SIEM\\nsection of the LogRhythm SIEM Help provides information on the following Web Console topics:\\nLogging in\\nSupported browsers\\nSmart Cards\\nMulti-factor authentication\\nSupported browsers\\nSmart Cards\\nMulti-factor authentication\\nVerifying the Web Console connection\\nIntegrating NetMon with the Web Console\\n', 'Web Console vs. Client Console Tasks': 'LogRhythm SIEM Task, Available In...\\n, Client Console, Web Console\\nViewing dashboards, X, X\\nViewing alarms (including opening, closing, and commenting), X, X\\nDefining alarm rules, X, \\nSearching metadata, X, X\\nAnalyzing logs, X, X\\nViewing reports, X, X\\nConfiguring and administering LogRhythm SIEM, X, \\nMonitoring system health, X, Limited\\nCase collaborating and management, , X\\nList management, X, Limited\\nLogRhythm SIEM Task\\n', 'User Permissions': 'The Web Console logins are associated with the same User Profiles defined in the Client Console. For more information, see the\\nObject Permissions Manager\\ntopic in the SIEM Help.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Advanced Intelligence Engine': 'LogRhythm AI Engine detects conditions in your deployment that occur over multiple data sources and time ranges. AI Engine can connect the dots to paint a picture that is far more enlightening than its individual parts and reveal potential problems while you still have time to take effective action. It provides realtime visibility to risks, threats, and critical operations issues. There are more than 100 preconfigured rule sets that can be used in the wizard-based drag and drop GUI.\\nFor information on the Risk-Based Priority calculations used with AI Engine Rules, see\\nGlobal Risk Based Priority\\n.\\nThe AI Engine components include:\\nAI Engine (service on the AI Engine server)\\nAI Engine Communication Manager (service on the AI Engine server)\\nAI Engine Data Provider (within the LogRhythm Mediator)\\n', 'AI Engine Log Files': 'There are three log files that can be reviewed for success, error, and general log messages related to the AI Engine. The number of logs you see depends on the LogLevel that is set in the AI Engine configuration file.\\nThe LRAIEComMgr.log and LRAIEEngine.log files are on the AI Engine Server in the location selected during installation. The default location is C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm AI Engine\\\\logs\\nThe LRAIEDP.log file is on the Data Processor Server in the location selected during installation of the mediator. The default location is C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Mediator Server\\\\logs\\n', 'AI Engine System Rules': 'There are several system rules that come packaged with the AI Engine software. The rules must be downloaded and imported using the Knowledge Base Import Wizard. For more information, see\\nImport a Knowledge Base\\n.\\n', 'AI Engine Diagnostic Alarms': 'The following table lists the AI Engine Diagnostic Alarm Rules and their properties.\\nRule ID and Name, Primary Criteria, Aggregation, Suppression\\n105 - AI Engine:Critical Condition, Classification = CriticalImpacted Known Applications:LogRhythm AI EngineLogRhythm AI Engine Communications ManagerLogRhythm AI Engine Data Provider, Alarm after 1 EventWithin 0:00:00Group Events:Impacted Application Impacted Host, 15 Minutes\\n106 - AI Engine:Excessive Warnings, Classification = Critical, Error, WarningImpacted Known Applications:LogRhythm AI EngineLogRhythm AI Engine Communications ManagerLogRhythm AI Engine Data Provider, Alarm after 50 Events Within 1:00:00Group Events:Impacted Application Impacted Host, 1 Hour\\n107 - AI Engine:Successive Errors, Classification = Critical, ErrorImpacted Known Applications:LogRhythm AI EngineLogRhythm AI Engine Communications ManagerLogRhythm AI Engine Data Provider, Alarm after 3 EventsWithin 0:15:00Group Events:Impacted Application Impacted Host, 30 Minutes\\n194 - AI Engine:Rule Suspended Due to Memory Triage, Common Event = Rule Suspended TriageVendor Message ID = 8025, Alarm after 1 Event OccurrenceNot Grouped, None\\nClassification = Critical\\nImpacted Known Applications:\\nLogRhythm AI Engine\\nLogRhythm AI Engine Communications Manager\\nLogRhythm AI Engine Data Provider\\nAlarm after 1 Event\\nWithin 0:00:00\\nGroup Events:\\nImpacted Application Impacted Host\\nClassification = Critical, Error, Warning\\nImpacted Known Applications:\\nLogRhythm AI Engine\\nLogRhythm AI Engine Communications Manager\\nLogRhythm AI Engine Data Provider\\nAlarm after 50 Events Within 1:00:00\\nGroup Events:\\nImpacted Application Impacted Host\\nClassification = Critical, Error\\nImpacted Known Applications:\\nLogRhythm AI Engine\\nLogRhythm AI Engine Communications Manager\\nLogRhythm AI Engine Data Provider\\nAlarm after 3 Events\\nWithin 0:15:00\\nGroup Events:\\nImpacted Application Impacted Host\\nCommon Event = Rule Suspended Triage\\nVendor Message ID = 8025\\nAlarm after 1 Event Occurrence\\nNot Grouped\\n', 'AI Engine Communication Manager Performance Counters': 'The AI Engine Installer installs performance counters for the AI Engine Communication Manager. The Performance Category is called LogRhythm AI Engine Communication Manager, and it consists of the following counters:\\nPerformance Counter, Description\\nConnected LMs, The number of currently connected Data Processors providing data\\nRate Data Flushed / Sec, The amount of data sent to the correlation engine per second (bytes/sec).\\nRate Data Received / Sec, The amount of data received from the Data Processor & Indexer per second (bytes/sec).\\nTotal # of Data Files, The number of data files currently in the data folder\\nTotal Data Flushed, The total amount of data sent to the correlation engine (in bytes).\\nTotal Data Received, The total amount of data received from the Data Processor & Indexer (in bytes).\\nThe Mediator Installer installs performance counters for the AI Engine Data Provider. LogRhythm AI Engine Data Provider consists of the following counters:\\nPerformance Counter, Description\\nData Queue Size (KB), The kilobytes of log data waiting to be sent to the AI\\xa0Engine Data Receiver.\\nRate Logs Flushed / Sec, The number of logs sent to the AI Engine Data Receiver per second.\\nTotal Logs Flushed, The total number of logs sent to the AI Engine Data Receiver.\\n', 'AI Engine Components': '', 'AI Engine': 'The AI Engine runs the Windows Service LRAIEngine. It receives the logs sent from the AI Engine Communication Manager and applies the AI Engine Rules to process the logs. It generates Events when those rules are satisfied. The AI Engine also provides diagnostic performance data and can save and reload state when it is shut down and restarted.\\nThe AI Engine design uses time-binned aggregated data when it processes logs against the AI Engine rules. Therefore, processing is not affected by the order the data arrives.\\n', 'AI Engine Communication Manager (ComMgr)': 'AI Engine ComMgr consists of these two parts:\\nAI Engine Data Provider (AIEDP) located in the Data Processor Mediator.\\nAIEDP runs on the LogRhythm Mediator and sends logs to the AIEDR in all specified AI Engine servers. It starts and stops along with the Mediator service.\\nAIEDP configuration data is on the system where the Mediator resides: C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Mediator Server\\\\config\\\\LRAIEDP.ini\\nAIEDP writes logs to the following: C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Mediator Server\\\\logs\\\\LRAIEDP.log\\nAIEDP runs on the LogRhythm Mediator and sends logs to the AIEDR in all specified AI Engine servers. It starts and stops along with the Mediator service.\\nAIEDP configuration data is on the system where the Mediator resides: C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Mediator Server\\\\config\\\\LRAIEDP.ini\\nAIEDP writes logs to the following: C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Mediator Server\\\\logs\\\\LRAIEDP.log\\nAIEDP writes logs to the following: C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Mediator Server\\\\logs\\\\LRAIEDP.log\\nAI Engine Data Receiver (AIEDR) located in the Communication Manager service on the AI Engine Server.\\nAIEDR can be started and stopped from either the command line or from the Service Control Manager. It starts and stops along with the AI Engine ComMgr service (LRAIEComMgr).\\nAIEDR configuration data is on the system where the AI Engine resides: C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm AI Engine\\\\config\\\\LRAIEEngine.ini\\nAIEDR can be started and stopped from either the command line or from the Service Control Manager. It starts and stops along with the AI Engine ComMgr service (LRAIEComMgr).\\nAIEDR configuration data is on the system where the AI Engine resides: C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm AI Engine\\\\config\\\\LRAIEEngine.ini\\n\\n', 'Event Log': 'The ComMgr writes logs to the following: C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm AI Engine\\\\logs\\\\LRAIEComMgr.log\\n', 'AI Engine User Interface': 'The AI Engine User Interface has an AI Engine Rule Manager that lists the current AI Engine Rules, and an AI Engine Rule Wizard where you create and modify rules.\\nThese screens and other information are described in detail in the AI Engine Rule Manager and the AI Engine Rule Wizard.\\n', 'How AI Engine Rules Use Time Limits': 'AI Engine rule blocks include user-selected time limits to define the time span within which the rule block condition must be met. In multiple-block rules, a time limit may be contingent on a preceding rule block. For example, you can create an event if rule block B (a specific application starts) occurs or does not occur within X minutes after rule block A (the nightly backup finishes) occurs.\\nDepending on rule properties, you can set a time limit from one of the following locations in the AI Engine Rule Wizard:\\nThreshold tab\\nUnique Values tab\\nRule Block Relationship window\\nRule Block Time pane\\n', 'AI Engine Rule Structure': 'AI Engine rules are able to span multiple data sources and time ranges by using up to three separate rule blocks. The AI Engine Rule Wizard provides a means for you to create custom rules. Each rule block has its own specific properties, which are applied in the following order:\\nLog Source\\nDay and Time\\nPrimary Criteria\\nInclude Filters\\nExclude Filters\\nThe Rule Block Relationship window allows you to identify the common fields shared by two rule blocks and identify any time constraints that one block imposes on the other. For example, you can instruct the second rule block to become effective one hour after the first rule block is satisfied.\\nUsing multiple rule blocks and relationships, the AI Engine can detect situations such as:\\nA server was attacked and later started transferring large amounts of data out of the network.\\nA backup started but never finished.\\nA critical service or system did not restart.\\nWorm propagation.\\n', 'AI Engine Rule Wizard Tabs': 'The AI Engine Rule Wizard consists of the following tabs:\\nRule Blocks\\n. The Rule Blocks tab is divided into four panes:\\nRule Block Types. Used to add new Rule Blocks to an AI Engine Rule. The types are separated into four categories:\\nRule Block Designer\\n. Used to edit the properties of a Rule Block.\\nRule Block Times\\n. Displays the time spans in which Rule Block processes log messages.\\nSummary\\n. Displays details for the item selected in the Rule Block Designer.\\nRule Blocks\\n. The Rule Blocks tab is divided into four panes:\\nRule Block Types. Used to add new Rule Blocks to an AI Engine Rule. The types are separated into four categories:\\nRule Block Types. Used to add new Rule Blocks to an AI Engine Rule. The types are separated into four categories:\\nRule Block Designer\\n. Used to edit the properties of a Rule Block.\\nRule Block Designer\\n. Used to edit the properties of a Rule Block.\\nRule Block Times\\n. Displays the time spans in which Rule Block processes log messages.\\nRule Block Times\\n. Displays the time spans in which Rule Block processes log messages.\\nSummary\\n. Displays details for the item selected in the Rule Block Designer.\\nSummary\\n. Displays details for the item selected in the Rule Block Designer.\\nSettings. The Settings tab allows you to configure common event properties, alarm properties, and general properties for the AI Engine Rule. When the Sync with rule name box is selected, the Common Event name is synchronized with the rule name. For information on the settings you can configure on the Settings tab, see\\nFilters—Settings\\n.\\nNotify. The Notify tab allows you to designate the Roles, People, and Groups to be notified when a rule has been satisfied. If you are using data segregation to limit alarm notifications to only people who have access to a certain entity, each recipient on this tab must have an associated user profile that grants them access to that entity. For more information, see User Profile Manager and Configure Notifications in the Filter Editor.\\nActions. For information on the settings you can configure on the Settings tab, see\\nFilters—Action\\n.\\nInformation. For information on the settings you can configure on the Settings tab, see\\nFilters—Information\\n.\\nWhen you access the AI Engine Rule Wizard to Create an AI Engine Rule (Complete Guide) or modify one, the Rule Blocks tab appears by default.\\n', 'Types of Rule Blocks': 'An AI Engine rule can include up to three sub-components called rule blocks. Each rule block has its own data source, filter criteria, time frame, and conditions.\\nAll rule blocks continuously receive logs that match their designated data source and filter criteria. The AI Engine periodically checks each block to see if its condition has been detected. When the condition is met, the AI Engine checks related blocks in the rule to see if their conditions are also met. If that happens, an event is generated. An alarm may also be generated depending on the rule configuration.\\nThere are four basic rule block types:\\nLog\\nThreshold\\nUnique Values\\nBehavioral\\nExcept Behavioral, each type contains three variations:\\nObserved\\nNot Observed Compound\\nNot Observed Scheduled\\nThe variations for Behavioral are: Whitelist, Statistical, and Trend.\\n', 'AI Engine Rule Manager Grid': \"The Rule Manager grid includes the following columns. When changing the View from All Rules to a Server, there are some changes to the columns shown.\\nColumn Head, All Rules, Per Server, Description\\nAction, Y, Y, Select one or more check boxes.\\nAI Engine Rule Name, Y, Y, Name of the AI Engine Rule. Max characters = 100Because rules are identified by ID, the name is not required to be unique. However, use a naming convention that promotes clarity for your deployment.The AI Engine rule name is automatically assigned to the associated Common Event and Alarm Rule in the formatAIE: followed by the first 45 characters of the rule name.\\nRule Status, Y, Y, DisabledThe rule is not processed. Intended for temporary usage.When you disable a rule, the in-memory log data supporting that rule is discarded. If you re-enable the rule, the in-memory log data supporting that rule begins to be accumulated again.EnabledThe rule is processed as normal.ExpiredThe rule was configured with an expiration date/time which has passed. The rule is not processed.LearningA rule with one or more applicable Behavioral Rule Blocks is accumulating state information. All data is being collected for the rule, but it is not yet being evaluated. When the Activation Date is reached, it goes into the Enabled state.PausedA rule has been paused to stop generating New events, but continues to maintain all state data for the rule.RetiredThe rule is not processed and by default does not appear in the grid. Intended for long-range or permanent usage.SuspendedRules with errors or which consume too many resources such as memory or CPU time are automatically suspended and are not processed. The Suspend Reason column displays more information. After diagnosing the reason for the suspension, you must re-enable the rule manually to take it out of Suspended status.When a rule is suspended, the in-memory log data supporting that rule is discarded. If you re-enable the rule, the in-memory log data supporting that rule begins to be accumulated again.UnassignedThe rule is not assigned to any engine. Either the rule is not in a rule set mapped to a workload or the workload is not assigned to an engine.\\nRestart, , Y, Displays the Restart status.blank:\\xa0No Restart RequiredRestart Needed : Rule has been edited and requires a restartRestart Pending: Restart button pressed but restart has not yet completed\\nActivation, Y, Y, For Behavioral Rules with an Activation Date, indicates when the Rule goes from Learning status to Enabled status.\\nExpiration, Y, Y, Date the rule expires if one is set. N/A indicates that no expiration date is associated with this rule.This cell is selected for expired rules.\\nData Segregation Mode, Y, Y, DisabledNo Data segregation is in effect.EntityAll rule processing and events are segregated by the Entity of the logs.Root EntityAll rule processing and events are segregated by the Root Entity of the logs.\\nAlarm Status, Y, Y, Identifies the alarm status of a rule as Enabled or Disabled. An enabled rule that has its alarm status disabled generates events, but not alarms.\\nAuto Drilldown, , , If the Alarm Status column shows Enabled, this column shows Enabled or Disabled.If the Alarm Status column shows Disabled, this column shows N/A.\\nEDF, Y, Y, [E]nvironmental [D]ependence [F]actor is used in risk calculation and is set on Settings tab of the AI Engine Rule Wizard Tabs. It estimates how much additional configuration is required for the rule to function as expected within different network environments.Possible values:None = No additional configuration required.Low = Minimum additional configuration required.Medium = Additional configuration required.High = Significant additional configuration required.\\nFPP, Y, Y, FalsePositiveProbability is used in risk calculation and is set on Settings tab of the AI Engine Rule Wizard Tabs. It estimates how likely the rule is to generate a false positive response.\\nSuppress For, Y, Y, The amount of time repeated events are suppressed. The event associated with this rule is not created more frequently than the value stated here once every 15 minutes for a unique occurrence. For example, if the rule detects server failures, it does not create an event more than once every 15 minutes for a particular server. It can create events more than once every 15 minutes for different servers.When the rule's alarm is enabled, it is always generated for every event.\\nRuntime Priority, Y, Y, Values = Low, Normal, or High.If the AI Engine begins to run out of memory, it tries to reclaim memory by first reducing excess log grace period then, second, suspending rules starting with the lowest runtime priority.Best Practice: Start new, untested rules with a Runtime Priority = Low until processing is verified. Set important, well-tested rules to Runtime Priority = High.\\nCPU\\xa0Cost, , Y, Displays the percentage of CPU this rule consumes relative to all rules in the engine.\\nUnshared Mem Cost, , Y, Displays the percent of unshared memory this rule consumes relative to all memory consumed by all rules.\\nShared Mem Cost, , Y, Displays the percent of shared memory this rule consumes relative to all memory consumed by all rules.\\nUnshared Mem KB, , Y, Displays the number of KB of unshared memory consumed.\\nShared Mem KB, , Y, Displays the number of KB of unshared memory consumed.\\nTotal Mem KB, , Y, Displays the total memory used in KB.\\nCurrent Event Forward Rate, Y, Y, Displays the Average event forwarding rate (events/hour) over the last 3 minutes.\\nAverage Event Forward Rate, Y, Y, Displays the Average event forwarding rate (events/hour) over the last 24 hours.\\nCurrent Event Feedback\\xa0Rate, Y, Y, Displays the Average event feedback rate (events/hour) over the last 3 minutes.\\nAverage Event Feedback Rate, Y, Y, Displays the Average event feedback rate (events/hour) over the last 24 hours.\\nRule Group, Y, Y, Name of the group to which this rule has been assigned, if any.\\nDescription, Y, Y, The first part of the rule description. The entire description can be seen in the rule properties\\nRule Set, Y, Y, Displays the name of the assigned Rule Set.\\nPermissions, Y, Y, System: Global Admin - A System AI Engine Rule can only be created by LogRhythm. It imports in a disabled state and must be enabled by a user that logs in with Global Admin permissions.Custom: Global Admin - a Custom AI Engine Rule can be created by a user that logs in with Global Admin permissions.\\nDate Updated, Y, Y, Date of last update.\\nRule ID, Y, Y, A unique number generated by AI Engine and assigned to an AI Engine Rule.The first System AI Engine Rule increments from 1.The first Custom AI Engine Rule increments from 1000000001.\\nAll Rules\\nName of the AI Engine Rule. Max characters = 100\\nBecause rules are identified by ID, the name is not required to be unique. However, use a naming convention that promotes clarity for your deployment.\\nThe AI Engine rule name is automatically assigned to the associated Common Event and Alarm Rule in the format\\nAIE\\n: followed by the first 45 characters of the rule name.\\nDisabled\\nThe rule is not processed. Intended for temporary usage.\\nWhen you disable a rule, the in-memory log data supporting that rule is discarded. If you re-enable the rule, the in-memory log data supporting that rule begins to be accumulated again.\\nEnabled\\nThe rule is processed as normal.\\nExpired\\nThe rule was configured with an expiration date/time which has passed. The rule is not processed.\\nLearning\\nA rule with one or more applicable Behavioral Rule Blocks is accumulating state information. All data is being collected for the rule, but it is not yet being evaluated. When the Activation Date is reached, it goes into the Enabled state.\\nPaused\\nA rule has been paused to stop generating New events, but continues to maintain all state data for the rule.\\nRetired\\nThe rule is not processed and by default does not appear in the grid. Intended for long-range or permanent usage.\\nSuspended\\nRules with errors or which consume too many resources such as memory or CPU time are automatically suspended and are not processed. The Suspend Reason column displays more information. After diagnosing the reason for the suspension, you must re-enable the rule manually to take it out of Suspended status.\\nWhen a rule is suspended, the in-memory log data supporting that rule is discarded. If you re-enable the rule, the in-memory log data supporting that rule begins to be accumulated again.\\nUnassigned\\nThe rule is not assigned to any engine. Either the rule is not in a rule set mapped to a workload or the workload is not assigned to an engine.\\nDisplays the Restart status.\\nblank:\\xa0No Restart Required\\nRestart Needed : Rule has been edited and requires a restart\\nRestart Pending: Restart button pressed but restart has not yet completed\\nDate the rule expires if one is set. N/A indicates that no expiration date is associated with this rule.\\nThis cell is selected for expired rules.\\nDisabled\\nNo Data segregation is in effect.\\nEntity\\nAll rule processing and events are segregated by the Entity of the logs.\\nRoot Entity\\nAll rule processing and events are segregated by the Root Entity of the logs.\\nIf the Alarm Status column shows Enabled, this column shows Enabled or Disabled.\\nIf the Alarm Status column shows Disabled, this column shows N/A.\\n[E]nvironmental [D]ependence [F]actor is used in risk calculation and is set on Settings tab of the AI Engine Rule Wizard Tabs. It estimates how much additional configuration is required for the rule to function as expected within different network environments.\\nPossible values:\\nNone = No additional configuration required.\\nLow = Minimum additional configuration required.\\nMedium = Additional configuration required.\\nHigh = Significant additional configuration required.\\nF\\nalse\\nP\\nositive\\nP\\nrobability is used in risk calculation and is set on Settings tab of the AI Engine Rule Wizard Tabs. It estimates how likely the rule is to generate a false positive response.\\nThe amount of time repeated events are suppressed. The event associated with this rule is not created more frequently than the value stated here once every 15 minutes for a unique occurrence. For example, if the rule detects server failures, it does not create an event more than once every 15 minutes for a particular server. It can create events more than once every 15 minutes for different servers.\\nWhen the rule's alarm is enabled, it is always generated for every event.\\nValues = Low, Normal, or High.\\nIf the AI Engine begins to run out of memory, it tries to reclaim memory by first reducing excess log grace period then, second, suspending rules starting with the lowest runtime priority.\\nBest Practice: Start new, untested rules with a Runtime Priority = Low until processing is verified. Set important, well-tested rules to Runtime Priority = High.\\nSystem: Global Admin - A System AI Engine Rule can only be created by LogRhythm. It imports in a disabled state and must be enabled by a user that logs in with Global Admin permissions.\\nCustom: Global Admin - a Custom AI Engine Rule can be created by a user that logs in with Global Admin permissions.\\nA unique number generated by AI Engine and assigned to an AI Engine Rule.\\nThe first System AI Engine Rule increments from 1.\\nThe first Custom AI Engine Rule increments from 1000000001.\\n\", 'AI Engine Servers': 'LogRhythm deployments support multiple AI Engine servers providing a horizontally scalable deployment architecture for very large deployments. Each AIE node can receive all or a subset of processed log data. Each AIE node can be assigned a workload that determines which AIE rules it should run.\\n', 'AI Engine Rule Sets': \"AIE rule sets allow for the gathering of rules into a group (set) as well as for providing a filter to specify which logs will be sent to the rule set's workload.\\nA workload specifies all the AIE rules to be in use by a given AIE server, and is comprised of one or more rule sets. If more than one rule set is included in a workload, any log that matches the criteria (filters) specified by at least one of the rule sets is forwarded to that workload's server and is evaluated against all rules in all of the workload's rule sets. As an example, if Rule Set A filters in only logs from Entity A, and Rule Set B filters in only logs from Entity B, and Workload C on Server C includes Rule Sets A and B, all logs coming from Entity A or B go to Server C and are evaluated against both Rule Sets A and B.\\nThe data segregation option in an AIE rule may be used to ensure that a rule is triggered only by logs that all have the same entity or root entity. Data segregation by entity also ensures that alarm notification emails sent by the Notification Service are only sent to recipients who have access to that entity. For the Notification Service to work, the AIE Drill Down Cache must be enabled in the LogRhythm Configuration Manager and TLS 1.2 must be enabled.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Alarm Rules': '\\nThe Alarming and Response Manager (ARM) evaluates system and user-defined alarm rules to determine whether an Event should incur an alarm. The Alarm Rule Wizard moves you through the process of creating and configuring an alarm rule. You can enable, disable, retire, and restore, alarm rules from the Alarm Rules tab of the Deployment Manager.\\n', 'Alarm Rule Permissions': 'There are two types of Security Permissions, System and Custom. System Permissions are created by LogRhythm and come in two types, Global and Private, as defined below. Custom Security Permissions are created by users.\\nSystem alarm rules are created by LogRhythm and cannot be removed:\\nSystem Global\\n. Administrators can modify filters and notifications, as well as enable or disable these rules.\\nIf you select Synchronize Alarm Rule Criteria when you import a Knowledge Base file, local modifications that conflict with the synchronization are overwritten.\\nSystem Private\\n. This rule is used for Alarm Rules that provide a specific function that should be kept identical across all deployments. It has fewer editable properties so it can be more fully synchronized during a Knowledge Base import. You can add custom Include and Exclude filters, but not Primary filters that are not overwritten when a Knowledge Base is imported.\\nSystem Global\\n. Administrators can modify filters and notifications, as well as enable or disable these rules.\\nIf you select Synchronize Alarm Rule Criteria when you import a Knowledge Base file, local modifications that conflict with the synchronization are overwritten.\\nSystem Global\\n. Administrators can modify filters and notifications, as well as enable or disable these rules.\\nIf you select Synchronize Alarm Rule Criteria when you import a Knowledge Base file, local modifications that conflict with the synchronization are overwritten.\\nSystem Private\\n. This rule is used for Alarm Rules that provide a specific function that should be kept identical across all deployments. It has fewer editable properties so it can be more fully synchronized during a Knowledge Base import. You can add custom Include and Exclude filters, but not Primary filters that are not overwritten when a Knowledge Base is imported.\\nCustom alarm rules are created by LogRhythm Administrators:\\nCustom Global Alarm Rules\\n. Can only be created and managed by LogRhythm Administrators from the Alarms Rule tab of the Deployment Manager.\\nCustom Global Alarm Rules\\n. Can only be created and managed by LogRhythm Administrators from the Alarms Rule tab of the Deployment Manager.\\nYou can view Alarm Rule permissions in the Alarm rules grid in the Deployment Manager.\\n', 'Text File Notifications': '', 'Event Counts': 'The ARM compares new events to active alarm rules. When an Alarm Rule is configured to create Text File notifications, one line of text is appended to the current output file each time the alarm is triggered. Like other alarm notification types, file-based alarm notifications may include alarm values such as the Alarm Rule Name and Alarm Date. Unlike other alarm notification types, it only includes event values for the first event associated with an alarm.\\nYou may see an alarm record for an aggregate alarm rule that shows an Event Count of 3 yet has only one Origin Host value. The ARM appends one line of text to the output file.\\n', 'Selected Time Zone vs. System Time': 'To maintain consistency between date values that appear inside the alarm records and in the file name timestamp, all dates are translated to the selected Time Zone. This may result in a discrepancy between the system clock and the timestamp shown in the file name. For example, if the ARM host is in Mountain Time (UTC-07:00) and the Time Zone selected in the Text File Notification Policy is UTC, then daily rollover will occur at or after 12:00 AM UTC, which is 5:00 PM MST. Although the new file may be created at 5:00:35 PM local time, the timestamp as shown here is in UTC time: LogRhythmAlarms20101116_000035_8347937.txt\\n', 'Byte Order Mark': 'When UTF-8 Text Encoding is selected, the ARM automatically writes the Byte Order Mark (BOM) to the beginning of the file. For example, BareTail displays the mark as a special character at the beginning of the file, but correctly recognizes the text encoding as UTF-8.\\n', 'Formatting': 'Data format used by Text File Notification is identical to the data formatting used by the LogRhythm Log Exporter:\\nIntegers:\\nInteger values are region-invariant (the format doesn’t change from region to region).\\nCommas and/or periods are not used.\\nExample: 1935\\nInteger values are region-invariant (the format doesn’t change from region to region).\\nCommas and/or periods are not used.\\nExample: 1935\\nDecimals:\\nDecimal values are region-invariant.\\nUp to 9 digits to the right of the decimal are supported.\\nThe format is always #0.#########.\\nExamples: 0.3474304 or 84627.34545\\nDecimal values are region-invariant.\\nUp to 9 digits to the right of the decimal are supported.\\nThe format is always #0.#########.\\nExamples: 0.3474304 or 84627.34545\\nDateTime values are always represented in one of the following formats:\\n2010-11-14 11:22:36 AM\\n2010-11-14 11:22:36 AM-07:00\\n2010-11-14 11:22:36 AM\\n2010-11-14 11:22:36 AM-07:00\\nLocations\\nCommas are always converted to colons in the typical location string:Example: United States: Colorado: Boulder\\nIf Quote Strings is checked, then the location string is quotes, but commas are still converted to colons:Example: “United States: Colorado: Boulder”\\nCommas are always converted to colons in the typical location string:Example: United States: Colorado: Boulder\\nIf Quote Strings is checked, then the location string is quotes, but commas are still converted to colons:Example: “United States: Colorado: Boulder”\\n', 'Error Handling': 'If the ARM cannot write to the output file, it automatically rolls over and attempts to create a new output file. This may happen if a program such as Notepad opens the file with write access. If the ARM cannot write to an output file after three attempts, then it logs an error and stops trying.\\nSome reasons that Text File Notification might fail all three attempts are:\\nOne or more directories in the specified Base File Path cannot be found.\\nThe ARM process does not have permission to create and/or write files in the specified directory.\\nOne or more directories in the specified Base File Path cannot be found.\\nThe ARM process does not have permission to create and/or write files in the specified directory.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Automatic Host Contextualization': 'Automatic Host Contextualization has been disabled by default for almost all log sources as of Knowledge Base 7.1.507 and Knowledge Base 6.1.507. If you have Knowledge Base synced to one of those versions, you can re-enable automatic host contextualization on a log source by creating a custom policy copy and re-enabling this feature on the rules that require it.\\n', 'Issue': 'There are several fields that store information about hosts that are referenced within a log message:\\nHost (Impacted)\\n. The host or device impacted by log activity.\\nHost (Origin)\\n. The host or device from which log activity originated.\\nInterface (Impacted)\\n. The impacted interface number of a device or the physical port number of a switch.\\nInterface (Origin)\\n. The origin interface number of a device or the physical port number of a switch.\\nMAC Address (Impacted)\\n. The MAC address of the impacted host or device.\\nMAC Address (Origin)\\n. The MAC address of the origin host or device.\\nNAT IP Address (Impacted)\\n. The IP address from which the impacted IP was translated via NAT device logs.\\nNAT IP Address (Origin)\\n. The IP address from which the origin IP was translated via NAT device logs.\\nThe stored value for these fields is often derived from values parsed from IP address and host name tags. For example, the value parsed for the Source IP tag is stored in Origin Host, and the value parsed for the Destination IP tag is stored in Impacted Host.\\nHowever, system logs do not consistently store the origin/source or impacted/destination values in the same respective parsing field as is often the case for network devices reporting on network flow data. These devices do not contextualize client vs. server traffic and report the server as Source IP (SIP) in one log and server as Destination IP (DIP) in another, even when it is part of the same network flow.\\n', 'Solution': 'Based on the port values, LogRhythm can infer the relationship of the two hosts if a log contains parsed values for the following fields:\\nSIP/SName\\nDIP/DName\\nSource Port (SPort)\\nDestination Port (DPort)\\nPort values can reliably determine which system is running a server process (impacted host/DIP/DName) vs. the system connecting to that server process (origin host/SIP/SName). This is performed by referring to IANA port allocation rules combined with internal known port lookup tables.\\n', 'Automatic Host Contextualization Algorithm': 'The process LogRhythm uses to evaluate port numbers to determine whether it is an origin host or impacted host is to check to see if values parsed for SPort and DPort are a mapping port:\\nIf both SPort and DPort are mapping ports, infer via IANA logic.\\nIf one value is a mapping port, host associated with mapped port = impacted host.\\nIANA Inference Logic\\nIf value parsed for DPort <= 1023 AND value parsed for SPort > 1023Impacted host or port = parsed DPort host or port values\\nIf value parsed for SPort <= 1023 AND value parsed for DPort > 1023Impacted host or port = parsed SPort host or port values\\nIf value parsed for DPort (>= 1024 AND <= 49151) AND value parsed for SPort > 49151Impacted host or port = parsed DPort host or port values\\nIf value parsed for SPort (>= 1024 AND <= 49151) AND value parsed for DPort > 49151Impacted host or port = parsed SPort host or port values\\nElse, Impacted host or port = parsed DPort host or port values\\n', 'Automatic Host Contextualization Processing': 'Automatic Host Contextualization is performed only if all the following are true:\\nThe log has parsed values for Origin Host, Impacted Host, Origin Port, and Impacted Port.\\nThe host context is set Tags Normal or Tags Reversed.\\nThe service context is set to Tags Normal or Tags Reversed.\\n', 'LogMart Treatment': 'One of the key reasons to contextualize a host or service automatically is to improve the aggregation of log data for unique IP and port combinations. Currently, network data can be aggregated on the following fields:\\nOrigin Host\\nImpacted Host\\nOrigin Port (disabled by default LogMartMode)\\nImpacted Port\\nProtocol\\nServiceId\\nIf the Impacted Port is the origin port and, as a result, is random in nature, aggregation is much less effective and LogMart utilization is reduced.\\nAs a solution, whenever Automatic Host Contextualization is performed, LogMart is updated according to the following rules:\\nOrigin Port is set to Null regardless LogMartMode setting.\\nThe parsed value for Impacted Port is saved if any of the following conditions are true:\\nImpacted port is determined via Port Mapping.\\nImpacted port is determined via IANA algorithm.\\nImpacted port is determined via Port Mapping.\\nImpacted port is determined via IANA algorithm.\\nIf none of the above are true:\\nImpacted Port is set to NULL.\\nServiceId is set to one of the following three values:\\nUnknown UDP\\nUnknown TCP\\nUnknown\\nThis value is also set for the associated log and event.\\nImpacted Port is set to NULL.\\nServiceId is set to one of the following three values:\\nUnknown UDP\\nUnknown TCP\\nUnknown\\nUnknown UDP\\nUnknown TCP\\nUnknown\\nThis value is also set for the associated log and event.\\n', 'Considerations for Bytes In/Out and Items In/Out': 'Because bytes in/out and items in/out always pertain to the value stored for impacted host, the values parsed must be set accordingly. Therefore, if host context is determined to be reversed (what was parsed for SIP/SName is stored as DIP/DName), the values parsed for bytes in/out and items in/out are also reversed.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Data Archives and Restoration': '\\nThe LogRhythm Mediator Server service is responsible for archiving specified log data from active indexes to the LogRhythm Archives. The integrity of LogRhythm archives are protected during their various stages of processing through file attribute monitoring and SHA1 hashing. Archive file attributes, hashes or both are recorded by the LogRhythm system for use in verifying integrity during archive restoration and other operations. The Mediator Server uses configuration parameters that control the way the deployment archives data.\\nWhen you need access to archived logs, the SecondLook Wizard allows you to import them into a special archives index.\\n', 'Active vs. Inactive Archives': 'The contents of active and inactive archive files are the same: original log data and metadata generated during LogRhythm’s log processing. Active and inactive archive files are written to separate directories to ease backup of sealed archive files. The differences between the two are:\\nActive archive files have not reached the maximum size allowed and are still in the process of having data written to them. The maximum size is configurable.\\nInactive archive files have been sealed.\\nSealed archive files have been hashed for data integrity verification and compressed for storage.\\n', 'Archive File Structure': 'LogRhythm archive files are binary files with a formatted file name. Uncompressed archives end with the file name extension .LUA and compressed archives end with the file name extension of .LCA.\\nA LogRhythm archive has the following naming scheme:\\n<NormalMsgDate>_<LogSourceId>_<HostID>_<MediatorID>_<CreationTicks>.<EXT>\\nLogRhythm archives are placed in the folders specified by the Mediator Server configuration.\\nAdditionally, inactive archives are placed inside folders, grouped by day, for convenience. Inactive archive directories use this naming convention: YYYYMMDD_MediatorID_Ticks where ticks = milliseconds since 12:00:00 midnight, January 1, 0001.\\n', 'Archive File Protection': 'Archive file protection refers to the method used to ensure the integrity of the contents of an archive file. During writes to the active archives, the archiver applies the appropriate level of file protection to ensure it is the only process that has written to, or altered, the file. Inactive file protection allows the archive file to be verified prior to restoration to ensure the integrity of the log data contained therein. Active and inactive archives have configurable levels of protection. The file protection levels are governed by the Mediator Server configuration.\\nThe following protection levels are available:\\nNone\\n. No protection used. Fastest, least computationally expensive option.\\nFile Attribute Tracking\\n. The file size and last modification date are tracked by the archiver, to ensure it is the only process that has written to the file. Good performance, with lightweight data integrity verification.\\nSHA1 Hashing\\n. A SHA1 hash of the file is calculated. Most computationally expensive, but most reliable method for data integrity verification.\\nBy default the archiver uses File Attribute Tracking on the active archive files, and SHA1 Hashing of the inactive archive files. This configuration offers the most balanced combination of computational efficiency, and file protection. The File Attributes or SHA1 Hash of each archive file is captured and stored in the Platform Manager database.\\nIt is highly recommended that SHA1 Hashing protection not be used on the active archives, unless significant CPU and IO resources are available on the system running the Mediator service.\\n', 'Archive Sealing': \"When an active archive is sealed, and becomes an inactive archive, the following steps are taken:\\nThe final file protection parameters are gathered for the active archive (File Attributes or SHA1 Hash), if archive file protection is enabled.\\nThe final file protection attributes are recorded in the LogRhythm Platform Manager database.\\nThe archive is compressed, if compression is enabled.\\nThe active archive is moved to the inactive directory and into that day's folder.\\n\", 'Maintenance Process': 'The Mediator Server handles archiving of log data to LogRhythm archive files, while Elasticsearch on the Data Indexer handles the deletion of expired log data and index maintenance.\\nIn addition to archiving, there are SQL Server stored procedures that handle database maintenance on the LogRhythm Platform Manager. Some have parameters that can be configured to help prevent SQL deadlocks. For example, with the\\xa0LogRhythm_Events_PartitionMaintenance_Msg\\xa0procedure, increasing the\\xa0Retry Count and decreasing the Wait Interval\\xa0can shorten the elapsed time for the maintenance job to run. For more information, contact\\nLogRhythm Support\\n.\\nTo automate the maintenance, the stored procedures are scheduled to run as SQL Server jobs which, by default, run daily at 12:00 AM.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Data Indexer': 'The Data Indexer (Indexer) provides persistence and search capabilities, as well as high-performance, distributed, and highly scalable indexing of machine and forensic data. Indexers can be clustered in a replicated configuration to enable high-availability, improved search performance, and support for a greater number of simultaneous users. Indexers store both the original and structured copy of data to enable search-based analytics. The Indexer is supported on\\nWindows and Linux\\n, as follows:\\nWindows\\n. You can install the Indexer on an XM Appliance, an upgraded Data Processor Appliance, your own server, or a virtual machine. This configuration is called a DPX, and the Indexer is \"pinned\" to the Data Processor.\\nLinux\\n. You can install one or 3-10 physical hot nodes, and 1-10 warm nodes (optional) on a Linux Indexer Appliance(s), your own server(s), or virtual machine(s). This configuration is called a DX or DX cluster, and the Indexer is installed alone.\\nFor more information about installing or upgrading the Indexer, see the\\nLogRhythm Software Installation Guide\\non the\\nLogRhythm Community\\n.\\n', 'Indexer Services': 'The Indexer is a highly scalable, open-source, full-text search and analytics engine based on Elasticsearch. The full functionality of the Indexer is provided by the following micro services:\\nService, Description\\nBulldozer, Registers the Elasticsearch cluster name and nodes in the EMDB. Writes cluster statistics to the EMDB for use in the Deployment Monitor.\\nCarpenter, Synchronizes LogRhythm KB and deployment data to Data Indexer indexes.\\nColumbo, Executes query requests from LogRhythm components.\\nElasticsearch Service, Log persistence and indexing data store.\\nGoMaintain, Maintains Data Indexer indices for disk space and time to live (TTL).\\nTransporter, Facilitates interfacing to the Data Indexer through HTTP/REST.\\nWatchTower, Receives analytic data from CloudAI. If CloudAI is not in use in your deployment, this service remains idle, even though it is enabled.\\n', 'Data Indexer File Locations': 'Windows, Linux\\nData Indexer File Binaries\\nC:\\\\Program Files\\\\LogRhythm\\\\Data Indexer, /usr/local/logrhythm\\nData Indexer Log Files\\nC:\\\\Program Files\\\\LogRhythm\\\\Data Indexer\\\\logsC:\\\\Program Files\\\\LogRhythm\\\\Data Indexer\\\\Elasticsearch\\\\logs, /var/log/elasticsearch/var/log/persistent\\nData Indexer logs- Repository (Default Path)\\n${DXDATAPATH}\\\\elasticsearch\\\\data${DXDATAPATH} = D:\\\\LRIndexer, /usr/local/logrhythm/db/elasticsearch/data\\nData Indexer Service Start/Stop Scripts\\nC:\\\\Program Files\\\\LogRhythm\\\\Data Indexer\\\\tools\\\\start-allservices.batC:\\\\Program Files\\\\LogRhythm\\\\Data Indexer\\\\tools\\\\stop-allservices.bat, /usr/local/logrhythm/tools/start-all-serviceslinux.sh/usr/local/logrhythm/tools/stop-all-serviceslinux.sh\\nC:\\\\Program Files\\\\LogRhythm\\\\Data Indexer\\\\logs\\nC:\\\\Program Files\\\\LogRhythm\\\\Data Indexer\\\\Elasticsearch\\\\logs\\n/var/log/elasticsearch\\n/var/log/persistent\\n${DXDATAPATH}\\\\elasticsearch\\\\data\\n${DXDATAPATH} = D:\\\\LRIndexer\\nC:\\\\Program Files\\\\LogRhythm\\\\Data Indexer\\\\tools\\\\start-allservices.bat\\nC:\\\\Program Files\\\\LogRhythm\\\\Data Indexer\\\\tools\\\\stop-allservices.bat\\n/usr/local/logrhythm/tools/start-all-serviceslinux.sh\\n/usr/local/logrhythm/tools/stop-all-serviceslinux.sh\\n', 'Information About Automatic Maintenance': 'Automatic maintenance is governed by several Data Indexer settings in the Configuration Manager.\\nThe disk utilization limit i\\nndicates the percentage of disk utilization that triggers maintenance. The default is 80, which means that maintenance starts when the Elasticsearch data disk is 80% full.\\xa0The value for Disk Util Limit should not be set higher than 80. This value can have an impact on the ability of Elasticsearch to store replica shards for the purpose of failover.\\nThe heap utilization limit is the maximum Elasticsearch heap usage above which GoMaintain performs index TTL management. The default is 85, which means that management begins when the heap pressure exceeds that amount.\\nThe DX monitors Elasticsearch memory and DX storage capacity. GoMaintain tracks heap pressure on the nodes. If the pressure constantly crosses the threshold, GoMaintain decreases the number of days of indices by closing the index. Closing the index removes the resource needs of managing that data and relieves the heap pressure on Elasticsearch. GoMaintain continues to close days until the memory is under the warning threshold and continues to delete days based on the disk utilization setting of 80% by default.\\nThe default config is -1. This value monitors the systems resources and automanages the time-to-live (TTL).\\nYou can configure a lower TTL by changing this number. If this number is no longer achievable, the DX\\nsends a diagnostic warning and starts closing the indices.\\nIndices that have been closed by GoMaintain are not active searchable in 8.0.0 but are maintained for reference purposes. To see which indices are closed, you can run a curl command such as the following:\\nYou can also open a browser to\\nhttp://localhost:9200/_cat/indices?v\\nto show both open and closed indices.\\nIndices can be reopened with the following query as long as you have enough heap memory and disk space to support this index. If you do not, it immediately closes again.\\nAfter you open the index in this way, you can investigate the data in either the Web Console or Client Console.\\nUsers can now enable/disable the maintenance settings in the Configuration Manager for indices created by SecondLook. This allows the user to configure GoMaintain’s TTL and Disk settings for restored indices. The following changes have been made in the Configuration Manager:\\nSetting, Field Type, Description, Default\\nGoMaintain Logsar - Maintenance, Toggle: Enabled/Disabled, Enable or disable automatic maintenance of archive indices created by SecondLook., Disabled\\nGoMaintain TTL Logsar - (#indices), Text BoxRange: -1 to 100000000, Maximum number of logsar indices to store. Default setting (-1) automatically manages number of indices based on available resources., -1\\nGoMaintain Max. Archive Index Disk Size, Text BoxRange: -1 to 100000000, Maximum disk size in GB, above which GoMaintain performs index TTL management., 100\\nToggle: Enabled/Disabled\\nText Box\\nRange: -1 to 100000000\\nText Box\\nRange: -1 to 100000000\\nForce Merge settings are not preserved during an upgrade. They must be re-enabled in the Configuration Manager after performing an upgrade.\\nParameter, Description, Default\\nGoMaintain ForceMerge, The Force Merge configuration combines index segments to improve search performance. In larger deployments, search performance could degrade over time due to a large number of segments. Force merge can alleviate this issue by optimizing older indices and reducing heap usage., Disabled\\nGoMaintain ForceMerge Hour (UTC hour of day), The hour of the day, in UTC, when the merge operation should begin. If Only Merge Periodically is set to false, GoMaintain merges segments continuously, and this setting is not used., 1\\nGoMaintain ForceMerge Days to Exclude (#days), The number of days into the past of the index to merge., 10\\nLogging of configuration and results for Force Merge can be found in C:\\\\Program Files\\\\LogRhythm\\\\DataIndexer\\\\logs\\\\GoMaintain.log on Windows machines. On Linux, use the following command:\\n/var/log/persistent/gomaintain.log\\n.\\nIf the Data Indexer is a multi-node cluster, there will only be a log for one of the nodes with a GoMaintain lock. To find out which node has the lock, use the following command:\\nsudo /usr/local/logrhythm/tools/\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Data Processor': \"The Data Processor has three primary interface points with the LogRhythm SIEM:\\nThe Data Processor (Mediator) sends logs to the Data\\xa0Indexer.\\nThe Data\\xa0Indexer reads information from the EMDB.\\nThe Client Console and Web Console issue queries about logs to the Data Indexer.\\nThe Data Processor's Mediator Server service handles communications with LogRhythm Agents, such as authenticating Agent connections, receiving log data, and informing\\nSystem Monitors\\nto shut down or failover when required. The Mediator is also responsible for processing logs against the Knowledge Base and sending processed log messages to the\\nData Indexer\\n.\\nThe Data Processor contains a log processing engine known as the Message Processing Engine (MPE). The MPE processes logs against rules (MPE rules) to identify logs, parse information from the logs, and forward certain logs as events to the Platform Manager.\\nIn medium-to-large deployments, Data Processors should be dedicated systems. In small deployments, the Data Processor can coexist on the same system as the\\nPlatform Manager\\n.\\n\", 'Agent Failback': 'LogRhythm provides support for Agent failover across several Data Processors (up to three is the most common configuration). Three prioritized Processors configured into the Agent as mediator1, mediator2, and mediator3 (ordered list). Collection performance is maintained across Mediator failover, and this capability can also be used to support Agent load balancing.\\nOne of three scenarios can cause an Agent to failover to a different Processor:\\nThe Processor currently serving the Agent is already servicing its maximum agent count.\\nThe Processor is unavailable due to inability to establish connection or a lost connection (for example, a network issue).\\nThe Processor issues a suspense condition.\\nThe Failback Delay can be configured in the System Monitor Agent Advanced Properties dialog box.\\n', 'Failback Delay': 'All Agents support a configurable timer for failback and can be configured on a per Agent basis.\\nParameter, Value\\nMinimum, 1 minute\\nMaximum, 3600 minutes\\nDefault, 60 minutes\\nDisabled, 0\\nUpon expiration, the Agent waits for a randomized delay period (1-30 seconds) prior to attempting to connect.\\n', 'Load Balancing': 'Load balanced virtual log sources let you specify the log sources that are being sent to a load balancer and the System Monitor Agents to which the load balancer is sending log messages. These options enable deployments with larger volumes to utilize load balanced log sources without data loss. Even though Agents don’t send data to more than one Data Processor at a time, the Agents used with load balanced log sources must be configured to communicate with all Mediators that are used for load balancing for that set of agents.\\nFor more information on how to configure the Agents correctly, see the\\xa0Data Processor Settings Tab information in\\nModify System Monitor Basic Properties\\n.\\n', 'Load Balance Delay': 'All Agents support a configurable timer for load balancing and can be configured on a per Agent basis. When an Agent has connected to a Processor after being in a failure condition due to the Processor reaching the maximum Agent connections, the Agent attempts load balancing after a configurable time period.\\nParameter, Value\\nMinimum, 60 minutes\\nMaximum, 10080 minutes (7 days)\\nDefault, 4320 minutes (3 days)\\nDisabled, 0\\nUpon expiration of this timer, the Agent waits for a randomized delay period (1-30 minutes) prior to attempting to reconnect. This is to prevent a surge of Agents reconnecting.\\nAfter waiting for the randomized delay period, the Agent attempts to connect to the primary Data Processor. If it does not succeed because of maximum Agent connections, it attempts the secondary and then the tertiary.\\n', 'Log Files': 'The Mediator Server writes the following log files to the logs directory in the Mediator Server installation directory:\\nLog Type, Contents\\nscmedsvr.log, Errors, warnings, and data pertaining to agent connections, and network operations\\nscmpe.log, Errors, warnings, and data pertaining to the MPE component of the server\\narchive.log, Data concerning the archiving processing performed by the Mediator Server\\nevtmsgprocessor.log, Data concerning the Insert Manager EM\\nlogmsgprocessor.log, Data concerning the Insert Manager LM\\n', 'State': 'The Mediator Server maintains files for keeping track of processed and unprocessed logs, events when the server shuts down with logs, and events in memory. These files are stored in a directory structure in the state sub-directory of the Mediator Server. When the server is restarted, the logs and events are read in from the files and processed. To ensure the reliable processing of collected log data, do not move, alter or manipulate the files in the state directory in any way.\\n', 'Missing Heartbeat Detection': \"The Data Processors actively monitor themselves and Agents for a heartbeat signal at regular intervals. After receiving the signal, the database is updated with a timestamp of the last successful signal from that component. The ARM service regularly checks the amount of time that passed since the last successful heartbeat from each component and compares it with the component's unique Heartbeat Warning Interval setting, set in the Properties dialog box. If the expected reporting time is greater than the Heartbeat Warning Interval, a Missing Heartbeat Warning event is generated. The warnings continue to be generated each time an additional Heartbeat Warning Interval passes without a signal.\\nAfter a heartbeat is received from the component, a Heartbeat Returned event is generated and the system again waits for a missing heartbeat condition.\\nSet a reasonable Heartbeat Warning Interval. Take special notice of systems that reside on non-persistent connections or are removable from the network, such as notebook computers.\\nYou can see the Heartbeat status in the grid on the top of the Data Processors tab and in the grid on the bottom of the System Monitors tab.\\nIf a Heartbeat is not received for one full Heartbeat Warning Interval, the Last Heartbeat field is yellow.\\nIf a Heartbeat is not received for two full Heartbeat Warning Intervals, the Last Heartbeat field is red.\\n\", 'Last Data Processor': 'The Last Data Processor column in the grid on the bottom of the System Monitors tab contains the name of the last Data Processor the Agent was connected to.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Deployment Health': '\\nDuring the deployment of your LogRhythm solution, LogRhythm provides configuration and tuning to ensure that your solution starts at an optimal configuration for your log processing needs. The health and maintenance of your LogRhythm solution is crucial for its optimal performance.\\nMaintaining an effective, efficient, healthy LogRhythm deployment requires regular system maintenance and monitoring. While this does not require a lot of work from the end user, it is important to understand how to monitor the health of your solution and maintain a healthy deployment.\\n', 'Monitor LogRhythm Health': \"There are many ways to keep your system healthy, and various monitoring tools can give you a status of your deployment's health:\\nThe\\nDeployment Monitor\\nprovides a quick snapshot of the health of your system, including details such as the status of your hosts, host performance, database utilization, Data Processor metrics, and log volume statistics. It can be accessed from the Client Console by a LogRhythm Administrator.\\nThe\\nLogRhythm Performance Counters\\nprovide visibility into the performance of the various LogRhythm components.\\nThe\\nLog Processing Reports\\nprovide input into system performance and the efficiency of rules being used in log processing.\\nThe\\nLogRhythm Diagnostics Tool\\nis a standalone application that collects log and data files from LogRhythm components, runs Platform Manager database queries, and performs health, capacity, and oversubscription analysis on a LogRhythm deployment. The data is consolidated into a local .zip file for subsequent evaluation, capacity analysis and planning, and troubleshooting.\\nLogRhythm Echo\\nis a standalone Windows application that simulates a LogRhythm System Monitor Agent and allows users to replay native raw logs and PCAPs into LogRhythm to quickly build, demo, validate, verify, and tear down security use cases. ECHO comes with more than 30 use cases ready for replay, and users can create, modify, and share use cases using the web interface or a text editor.\\nCentralized Service Metrics\\ncaptures all your performance counters from all your servers in the LogRhythm deployment and gathers them into one database that can be utilized to create dashboards showing the overall health of your deployment.\\nLogRhythm diagnostic alarm rules provide alarms to notify you of errors or warnings related to the LogRhythm components. These alarm rules are imported with the Knowledge Base and are required for all deployments. The Alarm Rule Group is LogRhythm Diagnostics. These alarms should be enabled and configured to notify Global Administrators, who are the only users who can view these alarms. They are managed from the Alarm Rules tab within Deployment Manager.\\nFor more detailed information, you can review the log files. All LogRhythm components have log files that provide specific details of the component's state and current processing. The log files are stored in the logs folder in the location where the component files were installed (for example, C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Job Manager\\\\logs) and are also available from the component's Local Configuration Manager. The components log at a level of detail as specified in the Log Level value within the properties of the component, which is configured within the Client Console. Log Level is set to ‘info’ by default, but can be updated as necessary to provide more or less detail.\\n\", 'Understand and Manage Oversubscription': \"LogRhythm Oversubscription means that the number of logs being processed in your system, given how your system is currently configured, has surpassed your deployment's size and processing capacity.\\nLogRhythm Appliances are sized to provide different levels of processing capability. They are also configured to support optimal processing. As you start processing more logs and depending on the configuration of your Mediator and System Agent advanced properties, your deployment may need to be reconfigured or expanded to support these needs.\\nThe Mediator and System Monitor Agent have advanced property values such as max memory, queue size, max queue size, max logs cached, and flush batch that are configured at your initial deployment to best serve your platform. If these values change, they could impact the performance of your solution and cause oversubscription to occur.\\nTo fully understand oversubscription, an understanding of the System Monitor Agent and Mediators state and suspense handling, as well as Database capacity is required. These are described in the next section.\\n\", 'Understand State Handling in System Monitor and Mediator': 'The System Monitor and the Mediator manage logs through queues to prevent log data loss. When these components shutdown they take whatever data they have in memory and write it to disk. Likewise, when the agent or the mediator starts up, the data on the disk is ready back into memory to continue processing.\\n', 'System Monitor': 'On service shutdown, the System Monitor Agent writes its Message Queue to the state/processedlogs directory.\\nOn service startup, the System Monitor Agent reads its Message Queue from the state/processedlogs directory.\\n', 'Mediator': 'On service shutdown, the Mediator writes its queues (unprocessed, processed, archive, loginsert, eventinsert, ldsengine) to the appropriate state directory.\\nOn service shutdown, the Mediator writes final queue state/suspense counts to the scmedsvr.log (INFO level).\\nOn service startup, the Mediator reads its state data file back into the queues.\\n', 'Understand Suspense Handling in System Monitor and Mediator': 'A suspense state is reached when one of the following conditions is met\\nArchiveQueue size > QueueSize\\nAvailable state drive disk space < 10GB (that is, disk space for suspense and state spool files)\\nIn a suspense state, the mediator disconnects all agents and does not allow connection until resources have stabilized. Each service will spool incoming logs to disk to maintain the processing level. The component systematically reads the spooled log data files back into the queues and processes them as soon as the log rate has decreased back to its specified operating rate. The spooled suspense files live in the component’s state directory.\\nWhen a System Monitor receives more data than its current configuration can handle, it begins removing data from memory and persisting it to disk. When the Agent is no longer under the unsustainable load, it gradually reads the disk persisted data back in to continue processing.\\nWhen a Mediator receives more data than its current configuration can handle, it begins removing data from memory and persisting it to disk. When the Mediator is no longer under the unsustainable load, it gradually reads the disk persisted data back to continue processing.\\n', 'Understand Database Capacity': 'Five databases exist within the LogRhythm Solution:\\nPlatform Manager Database\\n. LogRhythmEMDB\\nAlarms Database\\n. LogRhythm_Alarms\\nCase Management Database\\n. LogRhythm_CMDB\\nCase Management Database\\n. LogRhythm_CMDB\\nEvents Database\\n. LogRhythm_Events\\nLogMart Database\\n. LogRhythm_LogMart\\nThe LogMart and Events databases have a time to live (TTL) setting within the Global Data Management Settings. This value determines the number of days the data for that database should be stored online before being removed by the maintenance process. Setting these values high takes up more capacity in the database.\\nChanging the default SQL Server Collation from “SQL_Latin1_General_CP1_CI_AS” is not supported and can leave your deployment in a non-working state.\\n', 'Platform Manager (EMDB), Alarms, CMDB, Events, and LogMart Databases': 'The EMDB, Alarms, CMDB, Events, and LogMart databases are set for auto growth, so they continue to grow until the host system runs out of disk space.\\nIf disk space is not available, the LogRhythm components issue errors in the log files to indicate that there is a problem. You may see some of the following logs:\\nMediator\\n. ***WARNING*** Suspend condition detected: The minimum disk space available for log data spool files is less than 1 GB\\nAgent\\n. CanLoadSpoolFiles=False : Reason=Agent run state not RUNNING or MaxLogQueueMemory exceeded\\nAgent\\n. ***WARNING*** Received Data Processor unavailable message from mediator 1\\nEnable all of the Alarm Rules in the Alarm Rule Group LogRhythm Diagnostics and configure them to notify the appropriate personnel to ensure you receive alerts.\\nAs with any production server, disk space must be monitored. This can be set up so that LogRhythm itself is monitoring with alarms or other third party monitoring tools, that might be in the environment, are monitoring.\\n', 'LogRhythm AI Engine Data File Processing': 'Each AI Engine Communication Manager has local, persistent storage for the log data files it receives from Mediators. The AI Engine reads the log data files, processes them, and then deletes the data files from the file system based on the configurable parameter MaxLogDataSize, which is the maximum amount of log data to keep on disk.\\nIf the size of the data files exceeds the configurable amount, the AI Communication Manager begins to delete the oldest data files while continuing to write the newest logs to new data files on the file system. The AI Communication Manager writes logs to the Windows Event Log indicating that the deletions are occurring.\\nThe value is configured in the AIEEngine.ini configuration file on the AI Engine System:\\n# Maximum amount of log data from Data Processors to keep on disk (in MB).\\n# If this amount is exceeded, the AI Engine Communication Manager will begin to delete the\\n# oldest data files until the data file size is less than the specified maximum.\\n# Values: 100-1000000 (100 MB - 1000 GB)\\n# Default: 2000 (2 GB)\\nMaxLogDataSize=2000\\nOn the mediator side, the AI Engine data is stored in memory until the limit is reached. The data is then written out to spool files until it can be transmitted to AI Engine. When the storage limit is reached, the oldest spool file is deleted.\\nThe parameters are configured by accessing the LogRhythm Data Processor Advanced Properties window and filtering the Name field for MaxDataQueueSize or MaxSpoolStorage. For more information on configuring these parameters, see Configure Data Processor Properties.\\nAs with any production server, disk space must be monitored. This can be set up so that LogRhythm itself is monitoring with alarms or other third party monitoring tools that might be in the environment are monitoring.\\nLogRhythm has several maintenance jobs that age data from the databases and rebuild indexes to maintain efficient search functions. If the maintenance jobs do not run, it will have an impact on your system and could create suspense conditions and fill the databases to capacity.\\nThe database maintenance jobs are implemented as SQL Server Agent jobs. Two jobs are in place on any LogRhythm database server:\\nLogRhythm Weekday Maintenance\\n. Runs Monday-Friday at a default time of 12:15 AM.\\nPlatform Manager Sunday Maintenance\\n.\\xa0Runs Sunday at a default time of 12:15 AM.\\nTwo additional jobs appear on Platform Managers only:\\nLogRhythm Backup.\\nCalled by the Platform Manager Sunday Maintenance Job.\\nDelete Old Database Backups.\\nThis job, disabled by default, will clean up old database backup files that are older than the value for Database Backup Days to Keep, set in\\xa0[LogRhythmEMDB]\\n.\\n[dbo]\\n.\\n[SCMaint].\\nDelete Old Database Backups.\\nThis job, disabled by default, will clean up old database backup files that are older than the value for Database Backup Days to Keep, set in\\xa0[LogRhythmEMDB]\\n.\\n[dbo]\\n.\\n[SCMaint].\\nEach job comprises individual steps that perform a specific maintenance function.\\nIt is critical that the SQL Server Agent service be running on all LogRhythm database servers to ensure that all maintenance is performed on schedule.\\nTo ensure that the Startup Type is set to Automatic and that the Status is Started, open the Services application and find\\nSQL Server Agent (MSSQLSERVER)\\non the list.\\n', 'LogRhythm Health Checks and Tune-Up Services': 'LogRhythm is designed to run with a minimum of required maintenance. However, as with any complex system, a LogRhythm Deployment can benefit from periodic assessment, maintenance, and tuning.\\nLogRhythm’s Health Check and Tune-Up Services are designed to regularly assess a customer’s deployment and ensure it is fully operational and functioning.\\nYou can read more about these services on the\\nLogRhythm\\nwebsite. To learn more or to sign up for these services, contact your Customer Relationship Manager.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Deployment Manager': 'LogRhythm administrators use the Deployment Manager to configure and manage LogRhythm components and functionality such as alarming and reporting.\\n', 'Deployment Manager Tabs': 'The Deployment Manager is accessed in any of the following three ways:\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nDeployment Manager\\n.\\nPress\\nCtrl + y\\n.\\nWhen you access Deployment Manager, the following tabs appear.\\nTab, Description, Administrators with Access\\nEntities, An entity represents a physical location in a deployment, such as network records, and host records, and LogRhythm components. The Entities tab opens by default when you access the Deployment Manager., Global/Restricted\\nPlatform Manager, The Platform Manager is the hub of a LogRhythm deployment and is the central repository for events, configuration and licensing information, the LogRhythm Knowledge Base, and LogMart., Global\\nData Processors, The Data Processor provides high-performance, distributed, and highly available processing of machine and forensic data. Processors receive machine and forensic data from Collectors and Forensic Sensors. The number of Data Processors per deployment is based on log data volume and redundancy requirements., Global\\nAI Engine, The AI Engine is a Windows Server system. It is LogRhythm’s advanced analysis platform that performs correlation, pattern recognition, and behavioral analysis., Global\\nNetwork Monitors, LogRhythm NetMon sensor technology provides deep packet inspection (DPI) of network traffic, application identification, application behavior monitoring, and full packet capture., Global\\nSystem Monitors, The System Monitor collects and forwards log data to Data Processors and can perform file integrity monitoring (FIM). When File Integrity Monitor detects changes in files and directories, the System Monitor Pro or Collector license generates and sends a log to the Data Processor., Global/Restricted\\nLog Sources, Log sources are single, unique origins of log data that is collected from a Host and is assigned a Message Processing Engine (MPE) policy. A single Host can have multiple Log Sources. A Log Source is the key link LogRhythm uses to determine a log message’s origin., Global/Restricted\\nLog Processing Policies, Policies determine which rules are processed against a Log Message Source and how matching logs are treated, including how long it stays online for reporting, if it is archived, and if a copy is sent to the Platform Manager., Global\\nAlarm Rules, Alarm rules are evaluated by the Alarming and Response Manager to determine if an Event should incur an alarm. They can be system rules supplied by LogRhythm, or custom rules created by users., Global/Restricted\\nPeople and Users, Create and maintain person records for user login identification and contact information for alarm notification., Global\\n', 'Deployment Manager Specific Tools Menu Options': 'The following table lists the Tools menu options that are available in the Deployment Manager.\\nAn * indicates that the option is not available to Restricted Administrators.\\nOption, Sub-Option\\nMonitor, Alarm ViewerPersonal Dashboard(Ctrl + P)Tail(Ctrl + T)\\nSearch, Investigator(Ctrl + I)SecondLook\\nReport, Report Center(Ctrl + I)View a Report*Scheduled Reports Job Manager\\nKnowledge, Lists Manager(Ctrl + L)*Common Event Change ManagerApplication ManagerLog Source Type ManagerMPE Rule BuilderCommon Event ManagerActive Directory Browsers*Knowledge Base Manager\\nAdministration, *Deployment Monitor67379931*Windows Host Wizard*Automatic Log Source Configuration*Global Log Processing Rule Manager*Data Masking Rule Manager*Access the SmartResponse Plugin ManagerBulk Updates with the System Monitor Package ManagerSystem Monitor Configuration Policy Manager*Data Loss Defender Policy Manager*File Integrity Monitor Policy Manager*Registry Integrity Monitor Policy ManagerOpen the Log Source Virtualization Template ManagerAutomatic Log Source Acceptance Rule Manager*Object Permissions Manager*Security Manager*User Profile Manager*Filter Manager\\n*Distribution, *Notifications and CollaborationCreate Group Notifications for AlarmsAccess the Notification Policy Manager*Log Distribution ServiceLog Distribution Policy ManagerLog Distribution Receiver Manager\\nAlarm Viewer\\nPersonal Dashboard\\n(Ctrl + P)\\nTail\\n(Ctrl + T)\\nInvestigator\\n(Ctrl + I)\\nSecondLook\\nReport Center\\n(Ctrl + I)\\nView a Report\\n*\\nScheduled Reports Job Manager\\nLists Manager\\n(Ctrl + L)\\n*\\nCommon Event Change Manager\\nApplication Manager\\nLog Source Type Manager\\nMPE Rule Builder\\nCommon Event Manager\\nActive Directory Browsers\\n*\\nKnowledge Base Manager\\n*\\nDeployment Monitor\\n67379931\\n*\\nWindows Host Wizard\\n*\\nAutomatic Log Source Configuration\\n*\\nGlobal Log Processing Rule Manager\\n*\\nData Masking Rule Manager\\n*\\nAccess the SmartResponse Plugin Manager\\nBulk Updates with the System Monitor Package Manager\\nSystem Monitor Configuration Policy Manager\\n*\\nData Loss Defender Policy Manager\\n*\\nFile Integrity Monitor Policy Manager\\n*\\nRegistry Integrity Monitor Policy Manager\\nOpen the Log Source Virtualization Template Manager\\nAutomatic Log Source Acceptance Rule Manager\\n*\\nObject Permissions Manager\\n*\\nSecurity Manager\\n*\\nUser Profile Manager\\n*\\nFilter Manager\\n*\\nNotifications and Collaboration\\nCreate Group Notifications for Alarms\\nAccess the Notification Policy Manager\\n*\\nLog Distribution Service\\nLog Distribution Policy Manager\\nLog Distribution Receiver Manager\\n', 'Deployment Manager Specific File Menu Options': 'The File menu options available from most Deployment Manager tabs are described in the table below.\\nOption, Description\\nNew, Starts the process of adding an additional item to the active tab. Does not appear when the Entities tab is active.\\nNew Root Entity, Starts the process of creating a top-level Entity and only appears when the Entities tab is active.\\nNew Child Entity, Starts the process of creating a child Entity under the selected Entity and only appears when the Entities tab is active.\\nProperties, Displays information about the item currently selected on the active tab.\\nImport License File, Starts the process to update LogRhythm Licensing.\\nClose, Closes the Deployment Manager, but does not close the LogRhythm Client Console.\\nReconnect, Re-establishes the connection to the Platform Manager database (EMDB).\\nExit, Closes the LogRhythm Client Console.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Deployment Security': 'This section provides information about some of the security features in LogRhythm, including passwords and password encryption, support for Public Key Infrastructure (PKI), users and security roles, and user security permissions.\\n', 'Authentication and Secure Message Transport Search': 'All login activity and services run by any user on the Client Console are secured by OAuth2. Services include searches performed with the following:\\nTail\\nInvestigation\\nPersonal Dashboard\\nTopX\\nReports (when run as Investigations)\\nSecondLook\\nTo audit secure message transport search, you can review Console.log. You can find Console.log in the following location: %APPDATA%\\\\LogRhythm\\\\logs.\\n', 'LogRhythm Password Encryption': 'All passwords stored in configuration flat files, such as .ini files, or SQL Server database tables, such as SMTP server password in the EMDB.ARM table, are encrypted. All password entries in the Client Console are masked.\\nLogRhythm supports passwords up to 255 characters long for SIEM services and the Client Console.\\nEncryption Method:\\nGenerated key (64 bytes) is hashed (SHA1) into 20-byte array (256 bits)\\nAES encryption: cipher mode is ECB and padding mode is PKCS7\\nWhere passwords are stored and entered in a LogRhythm deployment:\\nConfiguration (.ini) files (scmedsvr, scarm, lrjobmgr, LRAIEEngine, sdee)\\nDatabase Tables\\nEMDB System Monitor\\nEMDB ARM\\nEMDB System Monitor\\nEMDB ARM\\nClient Console\\nLogin\\nLog Exporter (SMTP)\\nAutomatic Log Source Configuration (SNMP Connections)\\nLogin\\nLog Exporter (SMTP)\\nAutomatic Log Source Configuration (SNMP Connections)\\nLocal Configuration Managers (LCM)\\nAI Engine\\nData Processor\\nJob Manager\\nPlatform Manager\\nSystem Monitor Agent\\nAI Engine\\nData Processor\\nJob Manager\\nPlatform Manager\\nSystem Monitor Agent\\nThe LogRhythm Encryption Utility does the following:\\nEncrypts passwords and writes output to the Client Console.\\nEncrypts Cisco IPS, Qualys, Nessus, NeXpose, Metasploit, Sourcefire, Retina, and eStreamer passwords used by the LogRhythm System Monitor for event and vulnerability collection. Encrypted passwords will be written to the value of the \"Password=\" parameter in the specified configuration (.ini) file — the configuration file must already exist.\\nThe lrcrypt.exe file is located in one of the following locations: C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm System Monitor\\\\lrcrypt.exeC:\\\\Program Files (x86)\\\\LogRhythm\\\\LogRhythm System Monitor\\\\lrcrypt.exe\\nUsage: lrcrypt [-e passwordtoencrypt] [path\\\\inifile]\\nFor example, if the user runs lrcrypt -e password config\\\\nessus.ini, the value specified by password is encrypted and written as the value for the Password parameter in the nessus.ini file.\\n\\nTo get encrypted values for other configuration file parameters — those other than Password — you must run lrcrypt without specifying the path to the .ini file.\\nFor example: C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm System Monitor>lrcrypt -e mypassword\\nLogRhythm Password Encryption Utility\\nEncrypted password: 3||//y/XnKOyOls8HGOb6WaBw==\\nIn this case, mark and copy the encrypted password value and manually paste it into the configuration file.\\nFor security reasons, you should ensure that strong passwords are used and that all passwords are protected.\\n', 'LogRhythm Users': 'A LogRhythm user is created within LogRhythm as a person record and user account. A person record doesn’t require a user account, but a user account requires a person record. A user account is also required to log in to the system. By default, a LogRhythm Administrator and LogRhythm Analyst user is created and available with a new LogRhythm Deployment. Each LogRhythm user is granted database access under a specific security role.\\nLogRhythm users access the LogRhythm solution via the LogRhythm Client Console by entering a user ID and password. As part of the login, all communications can be encrypted by selecting the Encrypt all communications check box from the Login window. Users can log in with a Windows Account or a specific user account. In either case, the record must exist as a person/user within the LogRhythm solution as created via the Client Console. If FIPS is enabled in the local security policy, Windows Authentication is required and therefore is the only method to log in to the Client Console.\\nEach LogRhythm user account must be assigned a User Profile. A User Profile is assigned one of the following Security Roles: Global Administrator, Restricted Administrator, Global Analyst, Restricted Analyst, or SOAP API Service Administrator.\\nThe general permissions for each Security Role are described below.\\n', 'Global Administrator': 'Full control of LogRhythm functionality\\nNever disable the LogRhythm Administrator role. Doing so will break your ability to perform other key functions in both the Client Console and the Web Console.\\nFull control of LogRhythm functionality\\nNever disable the LogRhythm Administrator role. Doing so will break your ability to perform other key functions in both the Client Console and the Web Console.\\n', 'Global Analyst': 'Has LogRhythm database permissions that are limited only to read-only functions (investigations, tails, alarms, and reports)\\nHas no access to Deployment Manager to make configuration changes (LogRhythm enforced)\\n', 'Restricted Administrator': 'Has LogRhythm database permissions that permit configuration changes as well as read-only functions (investigations, tails, alarms and reports)\\nHas specific permissions to view and modify host, SM\\xa0Agent, and log source properties (SQL Server enforced, View). Also known as LogRhythm Discretionary Access Control. This access control is segregated by Entity.\\nHas limited access to Deployment Manager to make configuration changes to permitted resources (LogRhythm enforced)\\nA Restricted Administrator can be explicitly granted permission to perform almost all tasks a Global Administator can, on a task-by-task basis. For more information, see\\nModify User Profile Management Permissions\\n.\\nHas limited access to Deployment Manager to make configuration changes to permitted resources (LogRhythm enforced)\\nA Restricted Administrator can be explicitly granted permission to perform almost all tasks a Global Administator can, on a task-by-task basis. For more information, see\\nModify User Profile Management Permissions\\n.\\n', 'Restricted Analyst': 'Has LogRhythm database permissions that are limited only to read-only functions (investigations, tails, alarms and reports)\\nHas specific permissions to view data from log sources, entities, and Data Processors (SQL Server enforced, View). Also known as LogRhythm Discretionary Access Control. This access control is primarily segregated by Entity, but can also be granted at a Data Processor and/or Log Source level.\\nHas no access to Deployment Manager to make administrative changes (LogRhythm enforced)\\n', 'SOAP API Service Administrator': 'Full control of LogRhythm API functionality\\nFor more information, see\\nPeople and Users\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Endpoint Monitoring': 'Endpoint Monitoring is a client/server information security (IS) methodology used to audit log files generated by endpoint devices, such as laptops, smartphones, and routers. Endpoint monitoring collects the generated log files and sends them to the Data Processor for analysis. If unusual behavior is detected, an alarm is generated.\\nLogRhythm endpoint monitoring has six features. Each feature is used to monitor a different type of endpoint.\\nFile Integrity Monitor (FIM).\\nMonitors critical database and application files for unauthorized changes. FIM provides independent auditing of access to and modification of files and directories. When FIM detects a change, a System Monitor Agent generates a log and sends it to the Data Processor where you can manage it like any other log. Logs can be forwarded to LogMart and the Platform Manager, can generate alarms, and can be included in reports.\\nRegistry Integrity Monitor (RIM).\\nProvides independent, realtime auditing of modifications to Windows registries. When RIM detects a change, the System Monitor Agent generates a log and sends it to the Data Processor where it can manage it like any other log. The logs can be forwarded to LogMart and to the Platform Manager so alarms can be generated and included in reports.\\nData Loss Defender (DLD).\\nIndependently monitors and logs the connection and disconnection of external data devices to the host computer where the Agent is running. It also monitors and logs the transmission of files to an external storage device. You can configure DLD to protect against external data device connections by ejecting specified devices upon detection. External USB drive storage devices include Flash/RAM drives and CD/DVD drives.\\nProcess Monitor.\\nIndependently monitors when processes start and end on a Windows or UNIX host where the Agent is running. The Agent generates one log when a process starts on the host (log includes process name, owner name, and start time, duration, etc.) and another log when the Agent detects the process has stopped. If enabled, the Process Monitor logs contain UAM information to log what users were connected to the host at the time the process was started/stopped.\\nNetwork Connection Monitor (NCM).\\nIndependently monitors when network connections are opened and closed on a Windows or UNIX host where a LogRhythm Agent is running and configured to do so. The Agent generates a log when a connection opens on the host (log includes protocol, local IP address and port, remote IP address and port, open time, close time, duration, etc.) and another log when the Agent detects the connection has been closed. If enabled, the Network Connection Monitor logs contain UAM information to log what users were connected to the host at the time the connection was opened/closed.\\nUser Activity Monitor (UAM).\\nUsed in conjunction with File Integrity Monitor. The UAM tracks when a user logs on to and off a Windows or UNIX host. The login time can then be compared to any FIM activities that occur.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Entities': 'An Entity represents a physical location where LogRhythm is deployed. It is used to organize the deployment and contain network and host records and LogRhythm components. In small, single-site deployments, one Entity record may be enough, but deployments that span many sites require multiple Entity records.\\n', 'Global Entity': 'The Global Entity is part of every deployment and is used to declare hosts and networks residing outside internal or organic networks. The Message Processing Engine (MPE) uses this information to match rules and create Events. For example, a network range could be defined for an IP address range prone to security risks. Then you could create Alarm Rules to notify someone each time the internal IDS registered an attack from these IPs. For more information, see\\nGlobal Risk Based Priority\\n.\\nUsers may not remove the Global Entity or perform tasks such as deploying Data Processors or Agents in it. Such tasks can only be performed within user-created Entities.\\nThe Global Entity is intentionally unlisted except in the Deployment Manager, in the Entity tab where it is always at the top of the tree.\\n', 'Primary Site Entity': 'In every deployment, a Primary Site Entity is listed after the Global Entity. It is the default, user-definable Entity. If you have the proper credentials, you can modify its name and properties and add additional Entities.\\n', 'Entity Relationships to Networks and Hosts': 'The Message Processing Engine (MPE) uses Network and Host records to set the Risk-Based Priority (RBP) and to associate the log and associated event to a known host. The Entity acts as a boundary for the MPE. The MPE only analyzes a log message against the Network and Host records of the Entity where the sending Agent is assigned. For example, if the sending Agent is assigned to the Site1 Entity, the MPE only analyzes log messages against Network and Host records that are also assigned to Site1. It is very important to keep this in mind when you create the Entity structure and assign Agents, Networks, and Host records.\\nIf you have sites that have overlapping IP space, you must create separate entity records for each site.\\n', 'Origin and Impacted Entities': 'An Origin and Impacted Entity is assigned to every log message based on the following hierarchy:\\nUse the Entity associated with resolved Known Host.\\nUse the Entity associated with resolved Known Network.\\nUse the IP Address:\\nIf there is an IP Private address, use Root Entity of Log Source Host.\\nIf there is an IP Public address, use the Global Entity.\\nIf there is no IP address, use Root Entity of Log SourceHost.\\nIf there is an IP Private address, use Root Entity of Log Source Host.\\nIf there is an IP Public address, use the Global Entity.\\nIf there is no IP address, use Root Entity of Log SourceHost.\\nThis approach assumes an unresolved IP address that is not resolved to a known host or network, which is not a Private IP address, is most likely an external address and should be assigned to the Global Entity.\\nThe Entity resolution performed in the MPE assigns Origin and Impacted Entity based on finding matching Host Identifiers assigned to Hosts in the respective Entities and DOES NOT fall back to matching on network ranges assigned to Networks. Furthermore, the Origin and Impacted Entity values resolved by the MPE are what gets saved to a Data Indexer record.\\nThe Origin and Impacted Entity Networks are determined by matching on network ranges for Networks defined in the entity structure.\\n', 'Entities Reorganization Wizard Overview': 'The Reorganization Wizard provides a method for LogRhythm administrators to migrate Host and Network records between Entities. This enables logical restructuring of the log management system to match real-world changes in network topology and system placement.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Global Log Processing Rules': 'Global Log Processing Rules (GLPR) are a part of the Advanced Data Management settings which provide a way to override settings defined in Classification Based Data Management (CBDM) or Standard Data Management modes (Log Message Source, Log Processing Policy). A GLPR provide a way to apply Data Management settings across all Data Processors, Log Sources and Log Processing Policies to logs that meet your specific criteria.\\nGLPR overrides are globally applied to log messages that match Classification Criteria (such as Network/Deny, Authentication/Failure, etc), and are customized with Include and/or Exclude Filters for log metadata. This flexibility provides a manageable way to determine how logs are processed throughout the system, regardless of settings used by various Log Sources and/or Log Processing Policies. Logs that do not match the GLPR filters are processed normally per CBDM or Standard Data Management settings.\\nLogRhythm diagnostic common events are not affected by Global Log Processing rules.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Host Records': 'Host records identify and assign useful information to important systems in your network. When analyzing log messages and creating events, the MPE tries to associate the actors involved in the event such as the source IP of an event to a known host. If a known host can be identified, the risk threshold identified by the host records is used to create the Risk-Based Priority (RBP). If a host record is not found, the network risk threshold is used. Host records are also good places to add information such as the purpose of the system, any known issues, and key contacts.\\n', 'Duplicate Host Names': 'Host names within Entities should be unique. However, some sites may have hosts in two different entities that have identical host names or host name identifiers as shown in the following diagram.\\n\\nWhen the situation that is shown in the preceding diagram occurs, an additional step is required in LogRhythm to allow an unregistered agent to auto-register. A LogRhythm administrator must specify the EntityID in the General section of the scsm.ini file in the format:\\n[General]\\nEntityID=X\\nWhen the EntityID is present, the agent sends this to the mediator in its identification message (otherwise known as the agent info string). In an example where the EntityID=5, the agent info string sent to the mediator will look like:\\nHOSTGUID=00093D13802A,HOSTNAME=platinum.schq.secious.com,VERSION=1.2.3.4,OS=Linux,OSVERSION=2.6.23.17,IPS=[10.1.1.38],CLIENTADDRESS=10.1.1.38,CPU=0.40,MEMORY=3785445376,MEMORYFREE=3230511104,AGENTMEMORYUSED=0,AGENTCPU=0,DISKIDLE=0,DISK=0,DISKFREE=0,ENTITYID=5\\n', 'Known Hosts': 'Known Hosts are specific devices and hosts that are entered in LogRhythm to:\\nProvide a consolidated roll-up of log message activity.\\nBe used in the calculation of Risk Based Priority and Direction.\\nBe available as criteria for all filtering functions across the product.\\nLog messages are associated to Known Hosts based on host identifiers in the log. The identifiers can be: Windows Host Name(s), DNS Host Name(s), and IP Address(s). When applicable, host is searched for first by host name then IP.\\n', 'Zones': 'Hosts and Networks are also assigned a Zone value of Internal, External, or DMZ. The Zone is assigned in the order:\\nZone of the resolved Known Host.\\nZone of the resolved Network.\\nThe IP address:\\nIf the IP Address is private, set the Zone to Internal.\\nIf the IP Address is public, set the Zone to External.\\nIf there is no IP Address, set the Zone to Unknown.\\nIf the IP Address is private, set the Zone to Internal.\\nIf the IP Address is public, set the Zone to External.\\nIf there is no IP Address, set the Zone to Unknown.\\n', 'Direction': 'A Direction is assigned to log messages when the zone of both Origin and Impacted Host is known.\\nDirection, Set If\\nLocal, Origin and Impacted Host are the same\\nExternal, Origin Zone External and Impacted Zone anything\\nInternal, Origin Zone Internal and Impacted Zone InternalOrigin Zone DMZ and Impacted Zone InternalOrigin Zone Internal and Impacted Zone DMZOrigin Zone DMZ and Impacted Zone DMZ\\nOutbound, Origin Zone Internal and Impacted Zone ExternalOrigin Zone DMZ and Impacted Zone External\\nUnknown, No value for both Origin and Impacted HostOrigin Zone undeterminedImpacted Zone undeterminedUnidentified logs\\nOrigin Zone Internal and Impacted Zone Internal\\nOrigin Zone DMZ and Impacted Zone Internal\\nOrigin Zone Internal and Impacted Zone DMZ\\nOrigin Zone DMZ and Impacted Zone DMZ\\nOrigin Zone Internal and Impacted Zone External\\nOrigin Zone DMZ and Impacted Zone External\\nNo value for both Origin and Impacted Host\\nOrigin Zone undetermined\\nImpacted Zone undetermined\\nUnidentified logs\\n', 'Batch Import Host Records Overview': 'Global Administrators can add hosts to an entity in batch using a clipboard paste/copy option or importing from an existing file of hosts.\\xa0The clipboard functionality uses the Windows copy/paste feature. Whatever you copy from a document is pasted into the Host Import Manager when you select that option. You can then review what has been pasted and choose to accept or reject. When adding hosts from the clipboard, hosts are added to the selected Entity. The file functionality allows you to import data from an existing file in a specified format. The feature allows you to review the hosts that were pasted from the clipboard or hosts that were imported from a file prior to persisting them to your LogRhythm Deployment.\\n', 'Host Import Manager': 'When batch importing Host Records, the Host Import Manager appears. The Host Import Manager grid contains the following columns.\\nColumn, Explanation\\nAction, Used in conjunction with the context menu actions option\\nStatus, The status of that host record based on its current existence in the deployment\\nLogRhythm Host Name, \\nEntity Name, \\nDescription, \\nDetails, \\nRisk Level, Integer from 0 (None/No risk) to 9 (high-high/highest risk)\\nThreat Level, Integer from 0 (None/No threat) to 9 (high-high/highest threat)\\nZone, Internal, External, or DMZ\\nWindows Name, \\nDNS Name, \\nIP Address, \\n', 'Status Column Values in the Host Import Manager': 'The Status column displays different values based on the record being imported and its current existence in your deployment. The table below outlines the outcome of Host Record Analysis and its associated status value.\\nHost Record Analysis Outcome, Status Value\\nNo existing Host conflicts, New Host: The host record will be added as a new host.\\nHost exists in selected entity and is enabled, Warning Type 1: Host exists in specified entity and is active. Accepting this Host will add any new identifiers and overwrite other specified values of the existing Host.\\nHost exists in selected entity and is retired, Warning Type 2: Host exists in specified entity and is retired. Accepting this Host will re-enable the existing host, add any new identifiers and overwrite other specified values of the existing Host.\\nHost exists in root or child entity and is enabled, Warning Type 3: Host exists for another Entity within the specified Entity family and is active. Creating a new Host with the same identifiers is not recommended. Accepting this Host causes a new Host to be created in the specified Entity.\\nHost exists in root or child entity and is disabled, Warning Type 4: Host exists for another Entity within the specified Entity family and is retired. Creating a new Host with the same identifiers is not recommended. Select the action you would like to take for this Host within the Warning Type 4 Acceptance Mode control.When a Warning Type 4 is experienced, there is an Acceptance Mode on the Host Import Manager that allows you to choose an action to take for the host record with that warning type.\\nWarning Type 4: Host exists for another Entity within the specified Entity family and is retired. Creating a new Host with the same identifiers is not recommended. Select the action you would like to take for this Host within the Warning Type 4 Acceptance Mode control.\\nWhen a Warning Type 4 is experienced, there is an Acceptance Mode on the Host Import Manager that allows you to choose an action to take for the host record with that warning type.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Knowledge Base': \"The Knowledge Base (KB) consists of a Core Base Module and individual KB modules. The KB Core Base Module must be installed and updated on all deployments. Then, each individual KB module must be updated to meet the organization's needs.\\nEach KB module is organized around a single theme or purpose. For example, KB modules are used in the following scenarios:\\nCompliance Modules (FIM, PCI, NERC CIP, etc.)\\nOperations Modules\\nSecurity Modules\\nThe Knowledge Base Wizard can be run in two cases:\\nIn a new deployment, as part of the New Deployment Wizard.\\nFrom the Client Console, during periodic Knowledge Base updates.\\nInformation and downloads for all Knowledge Base modules are available under Documentation & Downloads on the\\nLogRhythm Community\\n.\\n\", 'Common Event Change Manager': 'The Common Event (CE) Change Manager was introduced to consolidate Common Events to support easier search, reporting, and AI Engine rules. If custom objects reference a consolidated Common Event, that object may no longer function properly. Impacted custom objects include: Saved Investigations, Saved Tails, Personal Dashboard Filters, Reports, Alarm Rules, GLPRs, AI Engine Rules, MPE Rules, and Common Event Lists.\\nWith the Common Event Change Manager, you can make the appropriate updates based on user input for common events that have been modified.\\nWhen the KB is updated, all the new Common Events are added to the CommonEvents table, and the original Common Events are left in place. The rules that assigned the old Common Events to a specific log have been changed to assign the new Common Events.\\n', 'The Difference Between Common Event to Common Event or Common Event to MPE Rule': 'Here is a Common Event Filter containing two common events:\\nVPN Authentication\\nVPN-Authentication - Admin\\nIn this example, the VPN Authentication and VPN Authentication – Admin Common Events were both migrated to User Logon.\\nIf you select Common Event to Common Event, the resulting list of Common Events in the filter are:\\nVPN Authentication\\nVPN-Authentication - Admin\\nUser Logon\\nThe old Common Events are left in the filter so that an operation including historic logs would catch the logs with those Common Events. The new Common Events are added to the filter to catch current logs.\\nVPN Authentication\\nVPN-Authentication - Admin\\nUser Logon\\nThe old Common Events are left in the filter so that an operation including historic logs would catch the logs with those Common Events. The new Common Events are added to the filter to catch current logs.\\nIf you select Common Event to MPE Rule, the Common Event filter is removed and an MPERule filter that contains all the rules that referred to the OLD Common Events is inserted in its place. The result would be an MPE Rule filter containing the following MPE Rules:\\nMS-SysLog EVID 20142 : Successful VPN Auth\\nMID 139 : VPN Client Authentication\\nLogin Packet\\nMIA: ID 0406 MUVPN User Logged In\\nID 013299601: SSL Authentication\\nID 013299601: SSL Authentication\\nSSL-VPN ID-1: User Login Successful\\n%AUTH-6-41: VPN Authentication\\nLogin Succeeded : VPN Authentication\\nASA-6-716038 : WebVPN Authentication Success\\nVMID 400 : VPN Authentication\\nID 013299601: SSL Authentication\\nMID 235 : VPN Admin Login\\nVMID 403 : Administrator Authentication\\nMS-SysLog EVID 20142 : Successful VPN Auth\\nMID 139 : VPN Client Authentication\\nLogin Packet\\nMIA: ID 0406 MUVPN User Logged In\\nID 013299601: SSL Authentication\\nID 013299601: SSL Authentication\\nSSL-VPN ID-1: User Login Successful\\n%AUTH-6-41: VPN Authentication\\nLogin Succeeded : VPN Authentication\\nASA-6-716038 : WebVPN Authentication Success\\nVMID 400 : VPN Authentication\\nID 013299601: SSL Authentication\\nMID 235 : VPN Admin Login\\nVMID 403 : Administrator Authentication\\n', 'Migrating Items After Updating a Knowledge Base': 'Let’s say you already have a Common Event filter using the User Logon Common Event in a report, investigation, GLPR, or something else. In the 201 KB, there are 72 rules that have User Logon as a Common Event. In the 203 KB, there are 728 rules that have User Logon as a Common Event.\\nIf you do not migrate any configuration items, you have 728 rules that assign a common event of User Logon instead of just 72. The potential to have many more items matching the Common Event filter of User Logon when performing Investigations, running Tails, or running Reports, is huge. This also affects GLPRs, as many more items will match the GLPR.\\nHere, 111 individual Common Events were migrated from their original value to User Logon. If you migrate using Common Event to Common Event, 111 old Common Events that were something else are now also User Logon, and therefore match the User Logon Common Event Filter. This is another case where performing operations no longer returns only the data you are looking for.\\nBecause using the Common Event to MPE Rule option replaces the original common event with the MPE rule(s) that called it, all the rules that refer to the new Common Event are not included in the filter. In this example, 14 rules are called the VPN Authentication or VPN Authentication – Admin Common Events. Those same 14 rules now call the User Logon Common Event. Using those 14 rules as a filter retains the original intent of the filter and retrieves the OLD and NEW Common Events, whereas using the new Common Event for the filter does not.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Log Distribution Services': 'The Log Distribution Services (LDS) allows you to forward specified syslog and non-syslog log messages to an external syslog receiver over TCP or UDP. This flexibility allows you to forward log messages in a format and configuration that best meets your needs.\\nGlobal Administrators can configure LDS from the LogRhythm Client Console through the Log Distribution Policy Manager or the Log Distribution Receiver Manager.\\nLDS Component, Purpose\\nThe Log Distribution Receiver Manager, Used to define the external receivers where the syslog messages are forwarded.\\nThe Log Distribution Policy Manager, Used to define the policies that specify which syslog messages are forwarded.\\nThe Mediator Server service, Must be running for LDS to process the logs for forwarding.\\n', 'Log Distribution Services Startup and Logging': 'During Data Processor initialization, the Mediator starts the LDS Engine automatically and logs the result to scmedsvr.log.\\nDuring startup, the LDS Engine creates its own log file, ldsengine.log, in the Mediator logs directory.\\nIf the Mediator is shut down or restarted, the LDS Engine spools out any unsent logs to disk in the Mediator directory under \\\\state\\\\LDS_Spool\\\\, and a log message is written to ldsengine.log.\\n', 'Non-Syslog Priority Calculation': 'When forwarding a message from a syslog source, Log Distribution Services always preserves the original Priority value. For non-syslog sources, the Priority value is based on your selection from the Facility list and the following formula.\\nThe Priority Formula is Priority = Facility * 8 + Severity.\\n', 'Facility Values': 'Facility, Value\\nlocal 0, 16\\nlocal 1, 17\\nlocal 2, 18\\nlocal 3, 19\\nlocal 4, 20\\nlocal 5, 21\\nlocal 6, 22\\nlocal 7, 23\\nlocal 0\\nlocal 1\\n', 'Message Class ID Severity Values': 'MsgClassId, Severity\\n1000, 6\\n1020, 6\\n1040, 5\\n1060, 6\\n1080, 5\\n1100, 5\\n1120, 5\\n1140, 6\\n1160, 5\\n1200, \\n1220, \\n1400, \\n1500, \\n1600, \\n1998, 5\\n1999, 6\\n2000, 6\\n2100, 5\\n2200, 4\\n2250, 4\\n2300, 2\\n2400, 2\\n2500, 1\\n2600, 1\\n2700, 4\\n2810, 5\\n2820, \\n2830, \\n2840, \\n2850, \\n2860, \\n2900, 5\\n2999, 6\\n3000, 6\\n3100, 1\\n3200, 3\\n3300, 4\\n3400, 6\\n3500, 6\\n3510, 5\\n3520, 6\\n3999, 6\\nElse, 0\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Log Processing Policies': 'Log Processing Policies, or Message Processing Engine (MPE) policies, determine which rules are processed against a Log Message Source and how matching log messages are treated. This includes how long the log remains online for reporting (Time-To-Live), whether the log should be archived, and whether a copy of the log should be forwarded to the Platform Manager.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Log Sources': 'A Log Source is a unique source of log data that is collected from a Host. Every log is associated to a single Log Source which is the key link LogRhythm uses to determine the origin of a log message. Hosts can have one or more Log Sources.\\nA typical Windows Server Host has the following Log Sources:\\nSystem Event Logs\\nApplication Event Logs\\nSecurity Event Logs\\nSystem Event Logs\\nApplication Event Logs\\nSecurity Event Logs\\nOn a Linux system, an example of a log source would be a Messages Syslog File.\\nLog Sources are centrally administered through the LogRhythm Client Console. This includes creating Source records and configuring parameters that affect how the Agent collection process functions. After configuration, the settings are pushed out to Agents at each heartbeat communication.\\xa0Only Global Admins or Restricted Admins with elevated View and Manage privileges can take this action.\\nBackwards Compatibility\\nStarting with the 7.4.3 System Monitor Agent, in order to collect new log sources via the API, the only component that must be at the latest version is the System Monitor. Your core deployment (Mediator, Platform Manager, etc.) can be at any 7.3.x version or above. The only exception to this is the Office 365 Message Tracking log source type which requires a 7.4.x core version. All other API log sources will allow you to use a 7.4.3 agent to collect if your core is at least version 7.3.x.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Network Monitor': 'LogRhythm NetMon provides visibility into all data traversing your network. With its in-depth packet capture and multiple recognition methodologies, LogRhythm NetMon allows administrators to:\\nSet a baseline for normal network behavior, which helps pinpoint abnormal activity immediately.\\nPerform full-session packet capture for advanced forensics.\\nPrevent sensitive data loss.\\nDetect unauthorized or suspicious application activity.\\nMonitor the bandwidth consumption of applications running in the network.\\nNetwork Monitor can be deployed as a fully integrated component of the LogRhythm TLM Platform. Together, LogRhythm NetMon and LogRhythm SIEM provide detailed security analytics across the entire network.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Network Records': 'Network records identify and logically group a range of IP addresses to:\\nAssign a Risk-Based Priority (RBP) to events.\\nDetermine direction such as inbound or outbound for the activity being logged.\\nNetwork records do not need to correspond to physical networks. Their function is to identify a contiguous range of IP addresses that share a common risk threshold. For direction identification, all undefined network ranges are considered to be external in nature; although for risk rating, networks may also be defined explicitly as external.\\n', 'Known Networks': 'In LogRhythm, Known Networks are used:\\nTo help calculate Risk Based Priority (RBP) and Direction.\\nAs criteria for Alarm Rules.\\nMPE resolves the Network at run-time when it calculates RBP and direction. The Alarm and Response Manager (ARM) resolves the network at run time for rules evaluation.\\n', 'Zones': 'Hosts and Networks are also assigned a Zone value of Internal, External, or DMZ. The Zone is assigned in the order:\\nZone of the resolved Known Host.\\nZone of the resolved Network.\\nThe IP address:\\nIf the IP Address is private, set the Zone to Internal.\\nIf the IP Address is public, set the Zone to External.\\nIf there is no IP Address, set the Zone to Unknown.\\nIf the IP Address is private, set the Zone to Internal.\\nIf the IP Address is public, set the Zone to External.\\nIf there is no IP Address, set the Zone to Unknown.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Object Permissions Manager': 'The Object Permissions Manager enables a Global Administrator or a Restricted Administrator with elevated privileges to manage secured objects (Investigations, Tails, Lists, and Alarm Rules). It enables the administrator to set new read and write access permissions for an object and to assign it to a new owner and/or entity.\\nFor information on granting elevated privileges to a Restricted Administrator, see\\nModify User Profile Management Permissions\\n.\\n', 'LogRhythm User Permissions': 'Before assigning permissions to an object, it is important to understand how permissions in LogRhythm behave. The Read Access permissions override the Write Access permissions. For example, if the Read Access permissions are set to Private, the Write Access permissions cannot be set to anything other than Private.\\nThe Read permissions have to be less restrictive than the Write Permissions. The Read permissions cannot be set to Private if the Write permissions are set to Public All.\\nUser Type, Read Access Rights\\nGlobal Administrator, Public Global AdministratorPublic Global AnalystPublic Restricted AdminPublic Restricted AnalystPublic All UsersPrivate\\nGlobal Analyst, Public Global AnalystPublic Restricted AdminPublic Restricted AnalystPublic All UsersPrivate\\nRestricted Administrator, Public Restricted AdminPublic Restricted AnalystPrivate\\nRestricted Analyst, Public Restricted AnalystPrivate\\nPublic Global Administrator\\nPublic Global Analyst\\nPublic Restricted Admin\\nPublic Restricted Analyst\\nPublic All Users\\nPrivate\\nPublic Global Analyst\\nPublic Restricted Admin\\nPublic Restricted Analyst\\nPublic All Users\\nPrivate\\nPublic Restricted Admin\\nPublic Restricted Analyst\\nPrivate\\nPublic Restricted Analyst\\nPrivate\\n\\nUser Type, Available Write Access Rights\\nPublic All Users, PrivatePublic All UsersPublic Global AdministratorPublic Global AnalystPublic Restricted AdminPublic Restricted Analyst\\nPrivate, PrivatePublic Global Administrator\\nPublic Global Administrator, PrivatePublic Global Administrator\\nPublic Global Analyst, PrivatePublic Global AdministratorPublic Global Analyst\\nPublic Restricted Admin, PrivatePublic Global AdministratorPublic Global AnalystPublic Restricted Admin\\nPublic Restricted Analyst, PrivatePublic Global AdministratorPublic Global AnalystPublic Restricted AdminPublic Restricted Analyst\\nPrivate\\nPublic All Users\\nPublic Global Administrator\\nPublic Global Analyst\\nPublic Restricted Admin\\nPublic Restricted Analyst\\nPrivate\\nPublic Global Administrator\\nPrivate\\nPublic Global Administrator\\nPrivate\\nPublic Global Administrator\\nPublic Global Analyst\\nPrivate\\nPublic Global Administrator\\nPublic Global Analyst\\nPublic Restricted Admin\\nPrivate\\nPublic Global Administrator\\nPublic Global Analyst\\nPublic Restricted Admin\\nPublic Restricted Analyst\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'People and Users': 'LogRhythm employs Person Records to identify users so they can log in with personal credentials instead of the default LogRhythmAdmin or LogRhythmAnalyst accounts. Person records are also used for Alarm Notifications and allow you to configure Alarm Rules to notify users based on their Person Record and the email address associated with it.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'Platform Manager': 'The Platform Manager (PM) is the hub of a LogRhythm installation. It serves as the central repository for events, configuration and licensing information, the LogRhythm Knowledge Base, and LogMart. In small deployments, the Platform Manager can also host other LogRhythm components. In larger deployments, it should be a dedicated system. There is only one PM per deployment\\nThe Platform Manager (PM) is a Windows Server system running SQL Server, the LogRhythm Alarming and Response Manager (ARM) service, and the LogRhythm Job Manager service.\\nThe ARM processes alarm rules and takes the appropriate response, such as sending email to people on a notification list.\\nThe Job Manager runs scheduled report jobs and other background functions such as automated List imports and heartbeat monitoring. You can schedule report packages to run and be delivered automatically using the Scheduled Report Job Manager. The Job Manager then creates, exports, notifies, and delivers the reports.\\n', 'Platform Manager Databases': 'The Platform Manager contains the LogRhythm databases described in the following table.\\nPlatform Manager Database, Description, Date Resolution\\nLogRhythmEMDB, All configuration information for a LogRhythm deployment (entities, hosts, networks, agents, log sources, and so on).All records of the archive file properties such as physical properties and hash for verification.All Knowledge Base information that is imported via the KB import process (MPE Rules/Policies, Investigations, Reports, etc.)., N/A\\nLogRhythm_Alarms, Tables of all alarms, alarm notifications, and alarm histories generated by the LogRhythm ARM., Millisecond\\nLogRhythm_CMDB, Tables of Case Management data from the LogRhythm Web Console., Millisecond\\nLogRhythm_Events, Tables of all events - log data and metadata - that have been forwarded from Data Processors., Millisecond\\nLogRhythm_LogMart, Tables that track unique log messages with aggregated occurrence information for collected log dataStatistics tables that track the volume of log data collected from each log source., Hour\\nLogRhythmEMDB\\nAll configuration information for a LogRhythm deployment (entities, hosts, networks, agents, log sources, and so on).\\nAll records of the archive file properties such as physical properties and hash for verification.\\nAll Knowledge Base information that is imported via the KB import process (MPE Rules/Policies, Investigations, Reports, etc.).\\nN/A\\nLogRhythm_LogMart\\nTables that track unique log messages with aggregated occurrence information for collected log data\\nStatistics tables that track the volume of log data collected from each log source.\\nHour\\n', 'Platform Manager Window': 'The Platform Manager windows contains the following four sections:\\nAlarming, Reporting, and Response Manager Services\\n,\\nJob Manager Services\\n,\\nSystem Management Settings\\n, and\\nGlobal Risk Based Priority\\n.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'SmartResponse': \"SmartResponse lets you execute preventative actions when threatening activity is observed. Actions may provide deeper forensic or operational data, automate operations tasks, or implement security controls in defense of an attack or intrusion, such as disabling a compromised user account or terminating a connection between attacker and target. Based on the change management controls of an organization, SmartResponse actions can be executed immediately or after a quorum-based approval process.\\nSmartResponse is managed in the Client Console and processed through the Advanced Intelligence (AI) Engine and the Platform Manager's Alarming and Response Manager (ARM).\\nSome examples of SmartResponse use cases are listed below:\\nAfter an alarm is generated from a compromised system, a SmartResponse can initiate a vulnerability scan or packet capture on the target host.\\nAfter observing near concurrent successful logins using the same account from two different countries, a SmartResponse can disable the account.\\nAfter a critical operations issue is observed on a network device, a SmartResponse can automatically set the device to debug-level logging.\\nWhen an inappropriate process is detected on a server, such as BitTorrent or a Peer2Peer application, a SmartResponse can kill the process.\\nYou can enable SmartResponse in LogRhythm by importing SmartResponse plugins. Plugins are self-contained binary files (*.lpi) containing one or more actions. Actions can leverage custom or commercial programs and scripts, and they can be executed when an assigned Alarm Rule or AI Engine Rule is triggered.\\nLogRhythm provides plugins that contain the most commonly requested actions. For all currently available SmartResponse Plugins, see\\nDownload SmartResponse Shareables\\n. Users can develop their own SmartResponse plugins for custom needs. For information on how to develop them, see the\\nDevelop SmartResponse Plugins\\n.\\nCreating a SmartResponse plugin is an advanced procedure. You must be familiar with XML and with writing executable scripts. For help creating a SmartResponse plugin, please contact your Customer Relationship Manager (CRM) or Professional Services Engineer.\\n\", 'Quorum-Based Approval for SmartResponse Actions': 'LogRhythm supports a quorum-based approval process where up to three levels of approval can be required before an action is executed. Individuals or groups can be assigned to each level. When multiple individuals are assigned to the same level, only one needs to provide approval. If any individual rejects the action, the action is immediately aborted prior to execution.\\nYou should carefully consider SmartResponse approvals when more than one SmartResponse is assigned to an Alarm or AI Engine Rule. If an action requires approval, no subsequent actions can be executed until approval is granted.\\n', 'SmartResponse Requirements': 'Manage plugins with the SmartResponse Plugin Manager.\\nConfigure plugin actions in an AI Engine Rule or Alarm Rule actions.\\nIf AI Engine Rule actions or Alarm Rule actions require approval, one of the following must be completed:\\nApproval of the Action\\nDenial of the Action\\nApproval of the Action\\nApproval of the Action\\nDenial of the Action\\nDenial of the Action\\n\\n', 'The SmartResponse Plugin Manager': 'The SmartResponse Plugin Manager window has four options within the menu bar. From left to right they include:\\nRefresh\\n. Refreshes the grid.\\nActions\\n. Provides a menu to Activate, Retire, Import, or Export SmartResponse Plugins.\\nCreate Plugin\\n. Opens the Create SmartResponse Plugin window to browse to the location of an existing configuration file and its executables to create the SmartResponse Plugin.\\nProperties\\n. Allows you to set Execution Access permissions. In order for users to view and run SmartResponse actions from the Web Console, their user profile must correspond to the Execution Access permission set here. The default Write Access permission is Public Global Administrator and the default entity is Global Entity. These are not configurable settings. To prevent all ad hoc execution of a SmartResponse from the Web Console, select the\\nDisable ad hoc execution\\ncheck box.\\nThe SmartResponse Plugin Manager contains two grids. The top grid lists all plugins. If no plugins have been imported, both grids are empty.\\nThe top grid displays the following details for each plugin:\\nColumn Name, Description\\nAction, A check box that is used to select rows for performing batch actions.\\nName, The name of the plugin as defined in the configuration file.\\nStatus, The plugin status, active or retired.\\nVersion, The version of the plugin as defined in the configuration file.\\nLast Updated On, The date and time when the plugin was last modified.\\nPlugin ID, The database assigned ID for the plugin.\\nPlugin GUID, The unique ID for the plugin as specified by the creator in the plugin configuration file.\\nAIE\\xa0Count, The number of AIE rules in which the plugin is used.\\nAlarm Count, The number of Alarms in which the plugin is used.\\nActions, The number of actions available in the plugin.\\nRead Access, The Read permissions for the list.\\nWrite Access, The Write permissions for the list. The default is Public Global Administrator.\\nEntity, The Entity with which the plugin is associated. The default is Global Entity.\\nOwner, The user who created the plugin. The default is LogRhythmAdmin.\\nThe SmartResponse Plugin Manager context menu, access by right-clicking the top grid, allows the user to select and clear plugin records, clear filters, take actions, set properties, and toggle the view of retired plugins.\\nThe bottom grid lists the available actions for each of the selected plugins and the number of parameters taken by the action.\\nYou can download SmartResponse plugins by going to the\\nLogRhythm Community\\nand clicking on the\\nShareables\\nlink on menu at the top of the page. The filters allow you to choose from supported and unsupported plugins, as well as ones created by LogRhythm or by other users.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n', 'System Monitor': 'The System Monitor is a software component that provides local and remote log data collection across various English-based operating systems including Windows and *NIX. For a complete list of supported operating systems,\\xa0see the\\nLogRhythm System Monitor Compatibility and Functionality\\nguide.\\nThe agent serves as a central log data collector, collecting logs from many devices, servers, databases, and applications, performing host activity monitoring and forwarding logs, via authenticated TLC connections, to the Data Processor.\\nThis section describes working with System Monitors in the Client Console. The System Monitor component releases on a separate schedule from the SIEM. For information on System Monitor releases and installation, see the separate\\nSystem Monitor\\ndocumentation.\\n', 'File Integrity Monitoring': 'Standard and Realtime FIM are included with the System Monitor Lite license for desktop operating systems only. Server operating systems require System Monitor Pro or Collector. For a list of supported agents, see the\\nRealtime File Integrity Monitor (FIM) Support by Operating System\\ntable.\\n', 'System Monitor Functionality': 'To view a table that lists Agent Functionality of the 32-bit and 64-bit System Monitor Agents, see the\\nSystem Monitor Functionality by Operating System\\n.\\n', 'System Monitor Agent Licensing': 'You must license each System Monitor to connect to a Data Processor and forward data.\\nLogRhythm provides the following three types of Agent licenses:\\nSystem Monitor Lite\\nSystem Monitor Pro\\nSystem Monitor Collector\\nWhen a LogRhythm Agent is registered in the Deployment Manager, it is automatically assigned a System Monitor Pro license, if one is available; otherwise it is assigned a System Monitor Lite license.\\nTo view a table that lists Agent functionality by license, see\\nSystem Monitor Functionality by License: Lite, Pro, and Collector\\n.\\n', 'Supported Character Sets and Languages': 'With the exception of flat file collection and Windows Event Logs (see Unicode (Double-Byte) Character Support below), LogRhythm only supports ASCII and extended ASCII characters within collected log data.\\nLogRhythm extended ASCII support is only available for code page 1252 encoding for the following languages:\\nAfrikaans\\nBasque\\nCatalan\\nDanish\\nDutch\\nEnglish\\nFaroese\\nFinnish\\nFrench\\nGalician\\nGerman\\nIcelandic\\nIndonesian\\nItalian\\nMalay\\nNorwegian\\nPortuguese\\nSpanish\\nSwahili\\nSwedish\\n', 'Unicode (Double-Byte) Character Support': 'LogRhythm supports Unicode characters when collected from Windows Event Logs and flat file Log Sources on Windows and *NIX. Search for Unicode characters is supported only in raw log and metadata searches against the Data Indexer. Currently, Unicode characters are not supported in:\\nEvents (PM search)\\nAlarms\\nLists\\nWeb Console search\\nIf you have log message sources that are not flat file sources, and these sources contain Unicode or double-byte characters, you can do the following (listed in order of preference to create the least impact when working with such sources):\\nReconfigure the logging device to create ASCII log messages only.\\nRewrite processing rules so that they only identify text up to the first non-ASCII character.\\nDisable the specific rules that process non-ASCII characters.\\nDisable all processing for the log source.\\n', 'Tuning': 'Running the System Monitor initially with a LogLevel of Verbose is useful to allow you to troubleshoot and tune the System Monitor configuration parameters. The two most important parameters to tune are:\\nCycleTime\\n. The minimum time the Agent spends in a processing cycle. If the processing cycle takes longer than the CycleTime, the Agent immediately begins the next cycle. If the processing cycle is shorter than the CycleTime, the agent sleeps for the remainder of the CycleTime. This property is set in the Agent Advanced Properties window. For more information, see\\nModify System Monitor Advanced Properties\\n. Default: 10 seconds.\\nMaxMessageCount\\n. Should be set to a value that keeps up reasonably with the log sources being monitored. Forwarding log data in small batches with smaller a CycleTime is generally better than sending large batches over a long CycleTime. This prevents extended periods of concentrated network traffic and is easier for the Data Processor to process. This property is set in the Message Source Properties window. For more information, see\\nLog Sources\\n. Default: 100.\\nTo extract the log data in a timely manner, these parameters must be set to keep up with the source in question. It is useful to observe if the System Monitor reads its full MaxMessageCount in each cycle. This can be found in the System Monitor Agent log - scsm.log (Agent LogLevel must be set to Verbose). When the System Monitor is started on a new source, it spends some time catching up to the most recent log. After it reaches the end, if it is still reading MaxMessageCount log entries each cycle, then this parameter should probably be increased to keep up with the log.\\n', 'Monitoring Intervals': 'If a given source is not critical for real-time monitoring, then consider scheduling it to run at a time when the log is not very busy using the MonitorStart and MonitorStop parameters in the Log Source Advanced Properties window.\\n', 'Log Rotation and Compression': 'The Agent can follow log rotations while collecting from files, but cannot finish reading a log file that is compressed. The results of reading a compressed file are unpredictable. Disable compression of the log sources that the Agent is monitoring. Most Linux systems use the logrotate utility and its corresponding config file logrotate.conf to control this compression. See the logrotate documentation for details.\\n', 'Position Files': 'The System Monitor produces a state tracking file (*.pos files) for each source in its configuration that it is monitoring. These files maintain position information across program shutdowns and subsequent startup. It is important not to remove or delete these files unless you really want the System Monitor to begin at the start of the log file again. The position tracking files are located in the state directory of the Agent.\\n', 'Suspense File': 'The System Monitor spools in memory log data to a file if necessary, such as when a local shutdown is requested after having lost connection to a Data Processor. The log data in suspense.log is read by the System Monitor on startup for immediate forwarding to the Data Processor. The suspense.log file is hidden and deleted after being loaded at startup.\\nThe Windows Agent also spools syslog data to a local file if its memory cap is exceeded. The syslog data written to file is then read and sent to a Data Processor when the Agent memory usage falls below its memory cap. The syslog suspense file is located in the state directory of the Agent. TCP suspense folder and UDP suspense folder are combined together as one single suspense folder (syslogsuspense) due to the underlying reason that TCP/UDP is a protocol/communication type and not a log source type.\\n', 'Firewall Considerations': \"The Agent initiates all connections to the Data Processor. In order for the Agent to communicate across a firewall, a two-way TCP pinhole, or exception rule, must be opened from the Agent's host IP and Client TCP Port to the Data Processor's host IP and ServerSSLPort, and back. Client TCP Port is specified on the Data Processor Settings tab in the System Monitor Agent properties, and ServerSSLPort is specified in the Advanced Data Processor Properties window. For more information, see\\nModify Data Processor Advanced Properties\\n. Agents prior to v4.0.0 connect to the Data Processor without using SSL, and instead connect to the port controlled by the ServerPort setting specified in the advanced properties of the Data Processor record.\\n\", 'Syslog Server Operation': \"The LogRhythm Windows Agent can be configured to listen on the standard syslog UDP/TCP port of 514 for incoming syslog data. When a syslog message is received, the following process occurs:\\nThe time the syslog message was received by the syslog server is captured. The time is relative to the Agent receiving the syslog and is reflected by the Normal Message Date of the log. This Normal Message Date may also be corrected by the Data Processor to account for time offsets between the Agent and the Data Processor.\\nThe IP endpoint and the IP address contained in the syslog packet are captured by the Agent.\\nIf the IP address captured from the syslog packet is present in the Agent's Syslog Relay Hosts parameter, the Agent runs the syslog message through the list of regex strings contained in the Agent's Syslog Relay Regular Expressions parameter to parse out an IP address or host name identifier.\\nThe regex match is done against the pre-processed log with the syslog header, not against the raw log after it reaches the Data Processor.\\nIf the IP address captured from the syslog packet is not present in the Agent's Syslog Relay Hosts, then the Agent uses the IP address contained in the syslog packet as an IP address identifier.\\nIf the IP address captured from the syslog packet is present in the Agent's Syslog Relay Hosts parameter, the Agent runs the syslog message through the list of regex strings contained in the Agent's Syslog Relay Regular Expressions parameter to parse out an IP address or host name identifier.\\nThe regex match is done against the pre-processed log with the syslog header, not against the raw log after it reaches the Data Processor.\\nIf the IP address captured from the syslog packet is present in the Agent's Syslog Relay Hosts parameter, the Agent runs the syslog message through the list of regex strings contained in the Agent's Syslog Relay Regular Expressions parameter to parse out an IP address or host name identifier.\\nThe regex match is done against the pre-processed log with the syslog header, not against the raw log after it reaches the Data Processor.\\nIf the IP address captured from the syslog packet is not present in the Agent's Syslog Relay Hosts, then the Agent uses the IP address contained in the syslog packet as an IP address identifier.\\nIf present, the syslog priority is parsed from the syslog data and converted into a syslog facility and severity that is appended to the syslog message. If no syslog priority is present, the facility is set to local0 and the severity is set to information.\\nThe Agent then performs a lookup into its syslog virtual message sources to see if the identifier has a virtual message source assigned and assigns the proper message source parameters (source id, TTL, and archive mode). If the Agent does not find a virtual message source, it submits a virtual source lookup request to the Mediator Server.\\nThe Agent then either adds the syslog data to the message queue for delivery to a Data Processor or may spool it to the syslogsuspense directory if it cannot be delivered to a Data Processor (connection issue, unauthenticated syslog source, etc.). If the data is spooled to disk, then the agent periodically reloads this data after it is connected to a Data Processor.\\n\", 'Example Syslog Format': 'Following is an example of the syslog data received by the LogRhythm Windows Agent and the final syslog format format stored in the Data Indexer:\\nSyslog data received:\\nThe following syslog message was received from host 192.168.1.10 on Dec 12 11:00:01 AM 2006.\\n<13>Dec 12 11:00:00 This is a syslog message\\nPriority = 13\\nDate = Dec 12 11:00:00\\nMessage = This is a syslog message\\nThe following syslog message was received from host 192.168.1.10 on Dec 12 11:00:01 AM 2006.\\nSyslog message stored in Data Processor:\\nThe syslog message would appear as follows in the Data Indexer:\\n12 12 2006 11:00:01 192.168.1.10 <1:5> Dec 12 11:00:00 This is a syslog message\\nDate = 12 12 2006 11:00:01\\nHost = 192.168.1.10\\nFacility = 1 (uselevel)\\nSeverity = 5 (notice)\\nMessage = Dec 12 11:00:00 This is a syslog message.\\nThe syslog message would appear as follows in the Data Indexer:\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nAdvanced Intelligence Engine\\n', 'Configure the Advanced Intelligence Engine': '\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nAI Engine\\ntab.\\nClick the\\nServers\\ntab at the bottom.\\nDouble-click the server name.\\nThe AI Engine Server Properties dialog box appears.\\nConfigure the AI Engine Server Properties.\\nHost\\nName\\nWorkload (default is Global Workload)\\nIPv4 Address\\n(Optional)\\nIPv6 Address\\nHost\\nName\\nWorkload (default is Global Workload)\\nIPv4 Address\\n(Optional)\\nIPv6 Address\\n(Optional)\\nClick\\nAdvanced\\n.\\nThe AI Engine Server Advanced Properties dialog box appears.\\nChange any property values you need to, and then click\\nOK\\n.\\nOnly make changes to the AI Engine Server Advanced Properties with the assistance of\\nLogRhythm Support\\n.\\nIf you have a firewall turned on in the system that has either the Mediator or the AI Engine, you must change the ServerMgmtPort value to 30000 and the ServerDataPort value to 30001.\\nChange any property values you need to, and then click\\nOK\\n.\\nOnly make changes to the AI Engine Server Advanced Properties with the assistance of\\nLogRhythm Support\\n.\\nIf you have a firewall turned on in the system that has either the Mediator or the AI Engine, you must change the ServerMgmtPort value to 30000 and the ServerDataPort value to 30001.\\nClick\\nOK\\n.\\nClick the\\nData Processors\\ntab.\\nDouble-click on the server name or right-click and then click\\nProperties\\n.\\nThe Data Processor Properties dialog box appears.\\nClick the\\nAI Engine\\ntab.\\nClick the\\nAI Engine\\ntab.\\nClick\\nProperties\\n.\\nThe Data Processor to AI Engine Server Advanced Properties dialog box appears.\\nClick\\nProperties\\n.\\nThe Data Processor to AI Engine Server Advanced Properties dialog box appears.\\nEdit the Properties.\\nSelect the\\nEnable communication to this AI Engine Server\\ncheck box.\\nThe Data Processor automatically sends logs to the Server based on the assigned workload.\\n(Optional)\\nEnter the Client Management Port.Specify the Sending Port. Management and Data must use distinct ports.\\nDefault = 0 for a random sending port (recommended)\\nIf you have a firewall turned on in the system that has either the Mediator or the AI Engine, you must change the Client Management Port to 3334.\\n(Optional)\\nEnter the Client Data Port.Specify the Sending Port. Management and Data must use distinct ports.\\nDefault = 0 for random sending port (recommended)\\nIf you have a firewall turned on in the system that has either the Mediator or the AI Engine, you must change the Client Data Port to 3335.\\n(Optional)\\nSelect the Client (sending) Address Override check box.Enter a valid IPv4 or IPv6 address on the Data Processor.\\n(Optional)\\nSelect the Server Address/DNS Name Override check box.Enter a valid IPv4 or IPv6 address on the AI Engine Server Communication Manager.\\n(Optional)\\nIf this check box is selected, the AIE Communication Manager skips the validation check on the IP address and Port. As a result, the AIE Communication Manager starts working for environments in which the IP address or port is not predictable, for example, with Network Address Translation.\\nEdit the Properties.\\nSelect the\\nEnable communication to this AI Engine Server\\ncheck box.\\nThe Data Processor automatically sends logs to the Server based on the assigned workload.\\nSelect the\\nEnable communication to this AI Engine Server\\ncheck box.\\nThe Data Processor automatically sends logs to the Server based on the assigned workload.\\n(Optional)\\nEnter the Client Management Port.Specify the Sending Port. Management and Data must use distinct ports.\\nDefault = 0 for a random sending port (recommended)\\nIf you have a firewall turned on in the system that has either the Mediator or the AI Engine, you must change the Client Management Port to 3334.\\n(Optional)\\nEnter the Client Management Port.Specify the Sending Port. Management and Data must use distinct ports.\\nDefault = 0 for a random sending port (recommended)\\nIf you have a firewall turned on in the system that has either the Mediator or the AI Engine, you must change the Client Management Port to 3334.\\n(Optional)\\nEnter the Client Data Port.Specify the Sending Port. Management and Data must use distinct ports.\\nDefault = 0 for random sending port (recommended)\\nIf you have a firewall turned on in the system that has either the Mediator or the AI Engine, you must change the Client Data Port to 3335.\\n(Optional)\\nEnter the Client Data Port.Specify the Sending Port. Management and Data must use distinct ports.\\nDefault = 0 for random sending port (recommended)\\nIf you have a firewall turned on in the system that has either the Mediator or the AI Engine, you must change the Client Data Port to 3335.\\n(Optional)\\nSelect the Client (sending) Address Override check box.Enter a valid IPv4 or IPv6 address on the Data Processor.\\n(Optional)\\nSelect the Client (sending) Address Override check box.Enter a valid IPv4 or IPv6 address on the Data Processor.\\n(Optional)\\nSelect the Server Address/DNS Name Override check box.Enter a valid IPv4 or IPv6 address on the AI Engine Server Communication Manager.\\n(Optional)\\nSelect the Server Address/DNS Name Override check box.Enter a valid IPv4 or IPv6 address on the AI Engine Server Communication Manager.\\n(Optional)\\nIf this check box is selected, the AIE Communication Manager skips the validation check on the IP address and Port. As a result, the AIE Communication Manager starts working for environments in which the IP address or port is not predictable, for example, with Network Address Translation.\\n(Optional)\\nIf this check box is selected, the AIE Communication Manager skips the validation check on the IP address and Port. As a result, the AIE Communication Manager starts working for environments in which the IP address or port is not predictable, for example, with Network Address Translation.\\nClick\\nOK\\n.\\nClick\\nOK\\n.\\nClick\\nOK\\n.\\nThe Restart Component dialog box appears if a setting has been modified. A restart is required for changes to take effect.\\nClick\\nOK\\n.\\nThe Restart Component dialog box appears if a setting has been modified. A restart is required for changes to take effect.\\nClick\\nOK.\\nClick\\nOK.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nAdvanced Intelligence Engine\\n', 'Create New AI Engine Rules': '\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nAI Engine\\ntab.\\nOn the bottom of the grid, click the\\nRules\\ntab.\\nOn the Rules tab toolbar, click the plus icon.\\nIn the Rule Block Types pane, select and drag a rule block to the Rule Block Designer from one of the twelve possible types of rule blocks.\\nRule Blocks\\nDescription\\nLOG\\nObserved\\nA log message that met the user-defined parameters was observed.\\nIt can be in any position in the rule.\\nNot Observed Compound\\nNo log message that met the user-defined parameters was observed after a preceding rule block was satisfied.\\nIt must follow another rule block and be the last block in the rule.\\nNot Observed Scheduled\\nNo log message that met the user-defined parameters was observed when expected based on a defined schedule. It must be the only block in the rule.\\nThis type of Log Rule Block cannot be enabled with Entity Segregation.\\nTHRESHOLD\\nObserved\\nThe defined threshold was reached across one or more log messages that met user-defined parameters. A threshold is quantitative such as number of bytes out. It can be in any position in the rule.\\nNot Observed Compound\\nThe defined threshold was not reached across one or more log messages after a preceding rule block was satisfied. It must follow another rule block and be the last block in the rule.\\nNot Observed Scheduled\\nThe defined threshold was not reached across one or more log messages based on a defined schedule. It must be the only block in the rule.\\nThis type of Threshold Rule Block cannot be enabled with Entity Segregation.\\nUNIQUE VALUES\\nObserved\\nUnique values were observed for a specified metadata field across two or more log messages having specific characteristics. Examples of unique values: 10 unique logins or 10 unique hosts. It can be in any position in the rule.\\nNot Observed Compound\\nUnique values were not observed for a specified metadata field across two or more log messages after a preceding rule block was satisfied. Examples of unique values: 10 unique logins or 10 unique hosts. It must follow another rule block and be the last block in the rule.\\nNot Observed Scheduled\\nUnique values were not observed for a specified metadata field across two or more log messages based on a defined schedule. Examples of unique values: 10 unique logins or 10 unique hosts. It must be the only block in the rule.\\nThis type of Unique Values Rule Block cannot be enabled with Entity Segregation.\\nBEHAVIORAL\\nWhitelist\\nSimilar to a Log Observed block, except that it only triggers when the selected Grouped By values of the Log are not found in the associated whitelist of the Whitelist Profile block to which it is linked. (The linked Whitelist Profile block is created automatically and cannot be separately deleted or created.) In this case, a log is observed in a metadata field that is not in the associated whitelist.\\nA Whitelist Rule Block enables users to record almost any behavior from a source integrated with the LogRhythm Data Filters. By comparing current logs to historical behavior, a Whitelist can be used to send an alert when behavior from a user or a system changes.\\nUse Case\\n. Whitelisting processes on production servers – In this scenario, the user creates a rule that records all processes observed on production servers. The rule runs for a set amount of time called a learning period. After the learning period, any processes observed that are not on the whitelist trigger an alarm. The event triggering the alarm could be a web server that has been compromised launching a malicious process to allow attackers to gain shell access.\\nStatistical\\nDuring runtime of the AIE Engine, a particular set of statistics will be collected. These statistics are collected within the AIE Runtime object the statistic observed. At a regular interval, a routine will be executed to collect the data from the various runtime engine components and send the information to the database for persistence.\\nUse Case\\n. Look for an abnormal number of authentication failures. Statistical rules compare live data to live data. If I know that the number of successful logins to unsuccessful logins in a 10 to 1 ratio, I can create a statistical rule that looks for the ratio of successes to failures to drop below 10 to 1. For example, if the amount of unsuccessful logins increases to a 12 to 2 ratio, an alarm is triggered.\\nMultiple expression can be written into the rule to reflect a range, for example, there must be between 5 and 10 times as many successful logins. Also floors can be implemented, such as the ratio must be greater than a 10 to 1 ratio and there must be at least 100 successful logins so a very low log rate won’t cause false positives. This also lets you compare static data fields within the same window. You can compare the origin user to the impacted user to make sure they are different in an account modification log if your environment does not allow people to modify their own accounts.\\nTrend\\nThe AIE Trending Rule Block provides for automatic base-lining of log and flow data against which various trends can be established. These trends can then be evaluated against current log and flow data to determine if a deviation has occurred. Deviations in a trend might be an indication of a security, compliance, or operations issue. In this case, a set of criteria is met comparing current log messages with recent log messages.\\nThe Trend Rule block compares prerecorded data to live data in an attempt to identify anomalies in behavior. Unlike other rule blocks, the Trend Rule block is able to add additional data to the baseline to accommodate changes in behavior over a period of time. Comparing a baseline that is able to change over time to live data enables the Trend Rule Block to look for anomalies in behavior while accommodating normal changes in the organization.\\nUse Case\\n. Look for increased traffic on the network. You can build a baseline, over a week, measuring the amount of traffic your network receives through its ports. If the traffic increases by a predetermined percentage, an alarm is triggered. This is also how rogue host detection is implemented. In this case, the MAC addresses seen on the network are recorded over a 30 day period. When a MAC address is observed that does not exist in the baseline, this means a new host is on the network. This causes an alarm to trigger.\\nThe AI Engine Rule Block Wizard appears. The number of tabs may differ based on the type of Rule Block selected.\\nIn the Rule Block Types pane, select and drag a rule block to the Rule Block Designer from one of the twelve possible types of rule blocks.\\nRule Blocks, Description\\nLOG\\nObserved, A log message that met the user-defined parameters was observed.It can be in any position in the rule.\\nNot Observed Compound, No log message that met the user-defined parameters was observed after a preceding rule block was satisfied.It must follow another rule block and be the last block in the rule.\\nNot Observed Scheduled, No log message that met the user-defined parameters was observed when expected based on a defined schedule. It must be the only block in the rule.This type of Log Rule Block cannot be enabled with Entity Segregation.\\nTHRESHOLD\\nObserved, The defined threshold was reached across one or more log messages that met user-defined parameters. A threshold is quantitative such as number of bytes out. It can be in any position in the rule.\\nNot Observed Compound, The defined threshold was not reached across one or more log messages after a preceding rule block was satisfied. It must follow another rule block and be the last block in the rule.\\nNot Observed Scheduled, The defined threshold was not reached across one or more log messages based on a defined schedule. It must be the only block in the rule.This type of Threshold Rule Block cannot be enabled with Entity Segregation.\\nUNIQUE VALUES\\nObserved, Unique values were observed for a specified metadata field across two or more log messages having specific characteristics. Examples of unique values: 10 unique logins or 10 unique hosts. It can be in any position in the rule.\\nNot Observed Compound, Unique values were not observed for a specified metadata field across two or more log messages after a preceding rule block was satisfied. Examples of unique values: 10 unique logins or 10 unique hosts. It must follow another rule block and be the last block in the rule.\\nNot Observed Scheduled, Unique values were not observed for a specified metadata field across two or more log messages based on a defined schedule. Examples of unique values: 10 unique logins or 10 unique hosts. It must be the only block in the rule.This type of Unique Values Rule Block cannot be enabled with Entity Segregation.\\nBEHAVIORAL\\nWhitelist, Similar to a Log Observed block, except that it only triggers when the selected Grouped By values of the Log are not found in the associated whitelist of the Whitelist Profile block to which it is linked. (The linked Whitelist Profile block is created automatically and cannot be separately deleted or created.) In this case, a log is observed in a metadata field that is not in the associated whitelist.A Whitelist Rule Block enables users to record almost any behavior from a source integrated with the LogRhythm Data Filters. By comparing current logs to historical behavior, a Whitelist can be used to send an alert when behavior from a user or a system changes.Use Case. Whitelisting processes on production servers – In this scenario, the user creates a rule that records all processes observed on production servers. The rule runs for a set amount of time called a learning period. After the learning period, any processes observed that are not on the whitelist trigger an alarm. The event triggering the alarm could be a web server that has been compromised launching a malicious process to allow attackers to gain shell access.\\nStatistical, During runtime of the AIE Engine, a particular set of statistics will be collected. These statistics are collected within the AIE Runtime object the statistic observed. At a regular interval, a routine will be executed to collect the data from the various runtime engine components and send the information to the database for persistence.Use Case. Look for an abnormal number of authentication failures. Statistical rules compare live data to live data. If I know that the number of successful logins to unsuccessful logins in a 10 to 1 ratio, I can create a statistical rule that looks for the ratio of successes to failures to drop below 10 to 1. For example, if the amount of unsuccessful logins increases to a 12 to 2 ratio, an alarm is triggered.Multiple expression can be written into the rule to reflect a range, for example, there must be between 5 and 10 times as many successful logins. Also floors can be implemented, such as the ratio must be greater than a 10 to 1 ratio and there must be at least 100 successful logins so a very low log rate won’t cause false positives. This also lets you compare static data fields within the same window. You can compare the origin user to the impacted user to make sure they are different in an account modification log if your environment does not allow people to modify their own accounts.\\nTrend, The AIE Trending Rule Block provides for automatic base-lining of log and flow data against which various trends can be established. These trends can then be evaluated against current log and flow data to determine if a deviation has occurred. Deviations in a trend might be an indication of a security, compliance, or operations issue. In this case, a set of criteria is met comparing current log messages with recent log messages.The Trend Rule block compares prerecorded data to live data in an attempt to identify anomalies in behavior. Unlike other rule blocks, the Trend Rule block is able to add additional data to the baseline to accommodate changes in behavior over a period of time. Comparing a baseline that is able to change over time to live data enables the Trend Rule Block to look for anomalies in behavior while accommodating normal changes in the organization.Use Case. Look for increased traffic on the network. You can build a baseline, over a week, measuring the amount of traffic your network receives through its ports. If the traffic increases by a predetermined percentage, an alarm is triggered. This is also how rogue host detection is implemented. In this case, the MAC addresses seen on the network are recorded over a 30 day period. When a MAC address is observed that does not exist in the baseline, this means a new host is on the network. This causes an alarm to trigger.\\nNo log message that met the user-defined parameters was observed when expected based on a defined schedule. It must be the only block in the rule.\\nThis type of Log Rule Block cannot be enabled with Entity Segregation.\\nThe defined threshold was not reached across one or more log messages based on a defined schedule. It must be the only block in the rule.\\nThis type of Threshold Rule Block cannot be enabled with Entity Segregation.\\nUnique values were not observed for a specified metadata field across two or more log messages based on a defined schedule. Examples of unique values: 10 unique logins or 10 unique hosts. It must be the only block in the rule.\\nThis type of Unique Values Rule Block cannot be enabled with Entity Segregation.\\nSimilar to a Log Observed block, except that it only triggers when the selected Grouped By values of the Log are not found in the associated whitelist of the Whitelist Profile block to which it is linked. (The linked Whitelist Profile block is created automatically and cannot be separately deleted or created.) In this case, a log is observed in a metadata field that is not in the associated whitelist.\\nA Whitelist Rule Block enables users to record almost any behavior from a source integrated with the LogRhythm Data Filters. By comparing current logs to historical behavior, a Whitelist can be used to send an alert when behavior from a user or a system changes.\\nUse Case\\n. Whitelisting processes on production servers – In this scenario, the user creates a rule that records all processes observed on production servers. The rule runs for a set amount of time called a learning period. After the learning period, any processes observed that are not on the whitelist trigger an alarm. The event triggering the alarm could be a web server that has been compromised launching a malicious process to allow attackers to gain shell access.\\nDuring runtime of the AIE Engine, a particular set of statistics will be collected. These statistics are collected within the AIE Runtime object the statistic observed. At a regular interval, a routine will be executed to collect the data from the various runtime engine components and send the information to the database for persistence.\\nUse Case\\n. Look for an abnormal number of authentication failures. Statistical rules compare live data to live data. If I know that the number of successful logins to unsuccessful logins in a 10 to 1 ratio, I can create a statistical rule that looks for the ratio of successes to failures to drop below 10 to 1. For example, if the amount of unsuccessful logins increases to a 12 to 2 ratio, an alarm is triggered.\\nMultiple expression can be written into the rule to reflect a range, for example, there must be between 5 and 10 times as many successful logins. Also floors can be implemented, such as the ratio must be greater than a 10 to 1 ratio and there must be at least 100 successful logins so a very low log rate won’t cause false positives. This also lets you compare static data fields within the same window. You can compare the origin user to the impacted user to make sure they are different in an account modification log if your environment does not allow people to modify their own accounts.\\nThe AIE Trending Rule Block provides for automatic base-lining of log and flow data against which various trends can be established. These trends can then be evaluated against current log and flow data to determine if a deviation has occurred. Deviations in a trend might be an indication of a security, compliance, or operations issue. In this case, a set of criteria is met comparing current log messages with recent log messages.\\nThe Trend Rule block compares prerecorded data to live data in an attempt to identify anomalies in behavior. Unlike other rule blocks, the Trend Rule block is able to add additional data to the baseline to accommodate changes in behavior over a period of time. Comparing a baseline that is able to change over time to live data enables the Trend Rule Block to look for anomalies in behavior while accommodating normal changes in the organization.\\nUse Case\\n. Look for increased traffic on the network. You can build a baseline, over a week, measuring the amount of traffic your network receives through its ports. If the traffic increases by a predetermined percentage, an alarm is triggered. This is also how rogue host detection is implemented. In this case, the MAC addresses seen on the network are recorded over a 30 day period. When a MAC address is observed that does not exist in the baseline, this means a new host is on the network. This causes an alarm to trigger.\\nThe AI Engine Rule Block Wizard appears. The number of tabs may differ based on the type of Rule Block selected.\\nComplete the appropriate information on each tab and click\\nNext\\n. For information on the options in the all the tabs of the wizard, see\\nUse the Filter Editor\\n.\\nComplete the appropriate information on each tab and click\\nNext\\n. For information on the options in the all the tabs of the wizard, see\\nUse the Filter Editor\\n.\\nClick\\nOK\\nwhen complete.\\nClick\\nOK\\nwhen complete.\\n(Optional)\\nAdd another rule block.\\nThe AI Engine Rule Block Wizard appears.\\n(Optional)\\nAdd another rule block.\\nThe AI Engine Rule Block Wizard appears.\\nComplete the appropriate information on all the tabs and click\\nOK\\n.\\nIf this is the second or third rule block in this rule, the AI Engine Rule Block <Rule Block Number> Relationship window appears to allow you to define the connection between rule blocks.\\nComplete the appropriate information on all the tabs and click\\nOK\\n.\\nIf this is the second or third rule block in this rule, the AI Engine Rule Block <Rule Block Number> Relationship window appears to allow you to define the connection between rule blocks.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nAlarm Rules\\n', 'Alarm Notification Policies': '\\nThe Alarm Notification Policy is used to specify information that is included in an Alarm Notification, as well as throttle the number of notifications in an allotted time.\\n', 'Notification Policy Types': 'The Alarming and Response Manager is capable of sending alarm notification in several ways, each with a unique type of Notification Policy. People and roles may be assigned contact methods using the available policy types.\\nSMTP\\n. Used for creating policies that notify users via email. This is the only notification type that can be used for receiving AI Engine Drill Down Cache results.\\nSMTP notifications can be text or HTML. Only HTML notifications include the Rule Block section and Origin/Impacted section. The Rule Block sections provides data according to both Group By Fields and AIE Summary Fields. HTML notifications also show log messages, rather than the AIE Event XML. Note:\\nThe AIE Drill Down Cache feature must be enabled for HTML notifications.\\xa0Both the AIE Drill Down Cache API and the Notification Service settings can be modified in the Configuration Manager.\\nSMTP\\n. Used for creating policies that notify users via email. This is the only notification type that can be used for receiving AI Engine Drill Down Cache results.\\nSMTP notifications can be text or HTML. Only HTML notifications include the Rule Block section and Origin/Impacted section. The Rule Block sections provides data according to both Group By Fields and AIE Summary Fields. HTML notifications also show log messages, rather than the AIE Event XML. Note:\\nThe AIE Drill Down Cache feature must be enabled for HTML notifications.\\xa0Both the AIE Drill Down Cache API and the Notification Service settings can be modified in the Configuration Manager.\\nSNMP\\n. Used for creating policies that notify users via SNMP traps.\\nText\\n. Used for creating policies that notify users via text files.\\n', 'Additional Information About Alarm Text File Notifications': '', 'Event Counts': 'The ARM compares new events to active alarm rules. When an Alarm Rule is configured to create Text File notifications, one line of text is appended to the current output file each time the alarm is triggered. Like other alarm notification types, file-based alarm notifications may include alarm values such as the Alarm Rule Name and Alarm Date. Unlike other alarm notification types, it only includes event values for the first event associated with an alarm.\\nAs shown here, you may see an alarm record for an aggregate alarm rule that shows an Event Count of 3 yet has only one Origin Host value. The ARM appends one line of text to the output file.\\n', 'Selected Time Zone vs. System Time': 'To maintain consistency between date values that appear inside the alarm records and in the file name timestamp, all dates are translated to the selected Time Zone. This may result in a discrepancy between the system clock and the timestamp shown in the file name. For example, if the ARM host is in Mountain Time (UTC-07:00) and the Time Zone selected in the Text File Notification Policy is UTC, then daily rollover will occur at or after 12:00 AM UTC, which is 5:00 PM MST. Although the new file may be created at 5:00:35 PM local time, the timestamp as shown here is in UTC time: LogRhythmAlarms20101116_000035_8347937.txt\\n', 'Byte Order Mark': 'When UTF-8 Text Encoding is selected, the ARM automatically writes the Byte Order Mark (BOM) to the beginning of the file. For example, BareTail displays the mark as a special character at the beginning of the file, but correctly recognizes the text encoding as UTF-8.\\n', 'Formatting': 'Data format used by Text File Notification is identical to the data formatting used by the LogRhythm Log Exporter:\\nIntegers:\\nInteger values are region-invariant (the format doesn’t change from region to region).\\nCommas and/or periods are not used.\\nExample: 1935\\nInteger values are region-invariant (the format doesn’t change from region to region).\\nCommas and/or periods are not used.\\nExample: 1935\\nDecimals:\\nDecimal values are region-invariant.\\nUp to 9 digits to the right of the decimal are supported.\\nThe format is always #0.#########.\\nExamples: 0.3474304 or 84627.34545\\nDecimal values are region-invariant.\\nUp to 9 digits to the right of the decimal are supported.\\nThe format is always #0.#########.\\nExamples: 0.3474304 or 84627.34545\\nDateTime values are always represented in one of the following formats:\\n2010-11-14 11:22:36 AM\\n2010-11-14 11:22:36 AM-07:00\\n2010-11-14 11:22:36 AM\\n2010-11-14 11:22:36 AM-07:00\\nLocations\\nCommas are always converted to colons in the typical location string:Example: United States: Colorado: Boulder\\nIf Quote Strings is checked, then the location string is quotes, but commas are still converted to colons:Example: “United States: Colorado: Boulder”\\nCommas are always converted to colons in the typical location string:Example: United States: Colorado: Boulder\\nIf Quote Strings is checked, then the location string is quotes, but commas are still converted to colons:Example: “United States: Colorado: Boulder”\\n', 'Error Handling': 'If the ARM cannot write to the output file, it automatically rolls over and attempts to create a new output file. This may happen if a program such as Notepad opens the file with write access. If the ARM cannot write to an output file after three attempts, then it logs an error and stops trying.\\nSome reasons that Text File Notifications might fail all three attempts are:\\nOne or more directories in the specified Base File Path cannot be found.\\nThe ARM process does not have permission to create and/or write files in the specified directory.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nAlarm Rules\\n', 'Create Alarm Rules': 'The Alarm Rule Wizard guides you through creating an alarm rule. When you access the wizard, it opens to the Primary Criteria tab by default. You are only required to enter information on the Primary Criteria and Information tabs. All the other tabs are optional. Click Next to skip any of the tabs as you work through the Alarm Rule Wizard.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nAlarm Rules\\ntab.\\nRight-click the grid, and then click\\nNew\\n.\\nIn the dialog box, choose from the following:\\nYes\\n. Create a Global Rule. Actions can be assigned to Global Rules.\\nNo\\n. Create a private rule. Actions cannot be assigned to Private Rules.\\nThe Alarm Rule window appears.\\nThe Filter Editor for alarm rules is the same as that used in Investigations, Tails, Personal Dashboards, Reports, Log Distribution Services, and the SecondLook Wizard.\\nYes\\n. Create a Global Rule. Actions can be assigned to Global Rules.\\nNo\\n. Create a private rule. Actions cannot be assigned to Private Rules.\\nThe Alarm Rule window appears.\\nThe Filter Editor for alarm rules is the same as that used in Investigations, Tails, Personal Dashboards, Reports, Log Distribution Services, and the SecondLook Wizard.\\nComplete the information in the following tabs:\\nPrimary Criteria\\nInclude Filters\\nExclude Filters\\nDay and Time Criteria\\nLog Source Criteria\\nAggregation\\nSettings\\nNotify\\nActions\\nInformation\\nPrimary Criteria\\nInclude Filters\\nExclude Filters\\nDay and Time Criteria\\nLog Source Criteria\\nAggregation\\nSettings\\nNotify\\nActions\\nInformation\\nClick\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nAlarm Rules\\n/\\nAlarm Notification Policies\\n', 'Create Group Notifications for Alarms': 'You can use the Notification and Collaboration Group Manager to add, modify, or delete an alarm notification group. All group members defined in an alarm notification configuration receive Simple Mail Transport Protocol (SMTP) or Simple Network Management Protocol (SNMP) alert notifications.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nDistribution, Notifications and Collaboration\\n, and then click\\nNotifications and Collaboration Group Manager\\n.\\nThe Notification and Collaboration Group Manager window appears. You can add, modify, or delete groups.\\nOn the File menu, click\\nNew\\nto open the Alarm Notification Group Properties window.\\nEnter a Notification Group Name.\\nIn the Brief Description text box, enter any necessary details.\\nIn the middle of the window, click\\nAdd\\n.\\nThe Person Selector window appears.\\nSelect the person or role to add.\\nClick\\nOK\\n.\\nYou return to the Alarm Notification Group Properties window.\\n(Optional)\\nTo remove a person or role, select the entry in the list and click\\nRemove\\n.\\nTo save your changes, click\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nAlarm Rules\\n/\\nAlarm Notification Policies\\n', 'Create New Email Alarm Notification Policies': '\\nTo create a new, private email notification policy:\\nDo one of the following to access the\\xa0Notification Policy Manager:\\nAdministrators\\n. On the main toolbar, click\\nDeployment Manager\\n. On the Tools menu, click\\nDistribution\\n, click\\nNotifications and Collaboration\\n, and then click\\nNotification Policy Manager\\nfrom the main menu.\\nNon-Administrators\\n. On the My LogRhythm menu, click\\nMy Notification Policies.\\nAdministrators\\n. On the main toolbar, click\\nDeployment Manager\\n. On the Tools menu, click\\nDistribution\\n, click\\nNotifications and Collaboration\\n, and then click\\nNotification Policy Manager\\nfrom the main menu.\\nNon-Administrators\\n. On the My LogRhythm menu, click\\nMy Notification Policies.\\nIn the Policy Name field, enter a name for your policy.\\n(Optional)\\nOn the Additional Info tab, enter a Brief Description and more details or notes.\\nEnter a Notification Email Subject Prefix. The default is \"LogRhythm Alarm - \".\\nIn the Notification Period in Minutes and Maximum Notifications Per Period settings, set the amount of notifications to be sent in a specific amount of time.\\nSetting Notification Period in Minutes to 0 results in all alarms being sent in individual notifications as shown in this example:\\nWHEN\\nNotification Period in Minutes = 60\\nMaximum Notifications Per Period = 10\\n15 alarms are received in 60 minutes\\nRESULT\\nThe first 10 alarms notify individually.\\nThe last 5 alarms are sent in a batch notification at the end of 60 minutes.\\nIn the Notification Period in Minutes and Maximum Notifications Per Period settings, set the amount of notifications to be sent in a specific amount of time.\\nSetting Notification Period in Minutes to 0 results in all alarms being sent in individual notifications as shown in this example:\\nWHEN\\nNotification Period in Minutes = 60\\nMaximum Notifications Per Period = 10\\n15 alarms are received in 60 minutes\\nRESULT\\nThe first 10 alarms notify individually.\\nThe last 5 alarms are sent in a batch notification at the end of 60 minutes.\\nDecide whether to include N/A fields. If Include N/A Fields is selected, the email includes headers for all selected items, even if they are blank. If Include N/A Fields is cleared, selected items that are blank are omitted completely.\\nSelect a Notification Format. The default is HTML.\\nThe AIE Drill Down Cache feature must be enabled for HTML notifications. Note that this feature should only be enabled if you have an average of 10,000 daily alarms or fewer. If your deployment processes more than 10,000 alarms per day, AIE Drilldown Cache performance, as well as overall deployment performance, could be degraded.\\nFor XMs and\\nsingle node Linux clusters,\\nthe\\xa0maximum alarm rate should be 5,000.\\nYou can check your alarm rate in the Client Console\\'s Deployment Monitor. If your alarm rate exceeds 10,000 per day, it is recommended that you disable the AIE Drill Down Cache API in the LogRhythm Configuration Manager or reduce your alarm volume by adjusting your AIE rules.\\nSelect a Notification Format. The default is HTML.\\nThe AIE Drill Down Cache feature must be enabled for HTML notifications. Note that this feature should only be enabled if you have an average of 10,000 daily alarms or fewer. If your deployment processes more than 10,000 alarms per day, AIE Drilldown Cache performance, as well as overall deployment performance, could be degraded.\\nFor XMs and\\nsingle node Linux clusters,\\nthe\\xa0maximum alarm rate should be 5,000.\\nYou can check your alarm rate in the Client Console\\'s Deployment Monitor. If your alarm rate exceeds 10,000 per day, it is recommended that you disable the AIE Drill Down Cache API in the LogRhythm Configuration Manager or reduce your alarm volume by adjusting your AIE rules.\\nIn the Information Included in Email section, select the items to include in the notification. You can right-click anywhere in the list to display a menu that allows you to Select All or Unselect All.\\nThe selected items appear in the email in the same order that they appear in this list.\\nTo reorder them, select an item and use the Field Order arrows at the top of the list. Arrows with lines above or below move an item to the top or bottom of the list. The other arrows move an item up or down one line at a time. In HTML notifications, the Rule Block Section and Origin/Impacted Section fields are not affected by reordering.\\nClick\\nOK\\n.\\nA new private policy is created. To create a group policy that can be used by others, see\\nCreate Group Notifications for Alarms\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nData Archives and Restoration\\n', 'SecondLook': \"The LogRhythm SIEM solution, like other SIEMs, attempts to strike a balance between the relatively high cost and performance of online storage of useful log data for quick retrieval, and the more cost-effective method of storing flat archived log data. The SIEM processes log data and writes data to both\\xa0the Data Indexer and the archiver concurrently. However, after log data is made available online, it expires out of the indexed persistence layer in somewhere between 30 and 90 days, depending on your configuration, and then the only option for recovery and analysis of older log data is to perform a SecondLook Restore from the LogRhythm SIEM. This process reads in relevant archive files and processes the contents based upon the filters set in the SecondLook search initiated by the end user. The pertinent log data is then stored in the archive indexer for search and analysis.\\nSecondLook is always available for LogRhythm Administrators. For other users, SecondLook is only available if Allow use of SecondLook is selected in the user's profile.\\n\", 'The SecondLook Process': 'The SecondLook Restore is launched from a LogRhythm Client Console, which performs all the disk retrieval of archive files, log processing of raw log data, and indexer inserts of retrieved data. The actual SecondLook Restore process consists of the following underlying steps:\\nAfter the parameters of the SecondLook Restore are defined and the restore job is executed, the Client Console starts a new instance of the Message Processing Engine (MPE) that uses the selected MPE policy selected for each target log source.\\nThe Client Console searches the provided archive paths for relevant archive files, based on the chosen log source and date/time parameters of the restore.\\nWhen the SecondLook Restore job finds a matching archive file, the Client Console performs the following:\\nRuns a SHA1 hash verification of the archive file (if applicable) to cross reference against the hash value of that archive file stored in the EMDB. This is to ensure that the archive file has not been tampered with since it was sealed by the archiver.\\nDecompresses the raw log contents of the file.\\nSubmits the raw log contents to the MPE instance.\\nProcesses the raw log with the selected MPE policy.\\nInserts any raw log matches for provided filters (user, host, etc) to the archive indexer.\\nRuns a SHA1 hash verification of the archive file (if applicable) to cross reference against the hash value of that archive file stored in the EMDB. This is to ensure that the archive file has not been tampered with since it was sealed by the archiver.\\nDecompresses the raw log contents of the file.\\nSubmits the raw log contents to the MPE instance.\\nProcesses the raw log with the selected MPE policy.\\nInserts any raw log matches for provided filters (user, host, etc) to the archive indexer.\\nThe previous step repeats until the client console has identified ALL archive files that meet the date/time and log source criteria.\\nThe SecondLook Restore job will terminate and display relevant statistics surrounding the restore job, including number of archive files accessed, raw logs processed, and logs restored that met criteria, plus any failures encountered throughout the job.\\n', 'SecondLook Best Practices': 'The following list are best practices for utilizing the SecondLook Wizard to minimize time it takes to restore the logs needed.\\nA SecondLook Restore should not be performed on an existing Data Processor server. When it is, the two MPE instances compete for CPU resources.\\nInitialize the SecondLook Restore with the most precise date/time range and log source list as possible that will meet your search criteria.\\nThe process must search though all archive paths and files using date range and log source ID as a primary filter.\\nInclude/Exclude Filters such as user or host information only filter what logs are restored to the archive indexer, but they must still be processed by the MPE, which also happens to be the most expensive step of the SecondLook Restore process.\\nThe process must search though all archive paths and files using date range and log source ID as a primary filter.\\nInclude/Exclude Filters such as user or host information only filter what logs are restored to the archive indexer, but they must still be processed by the MPE, which also happens to be the most expensive step of the SecondLook Restore process.\\nCopy the Inactive Archive files (.LCA files) for the time period you want to the server that will be used for the SecondLook restore.\\nLocal storage yields faster retrieval of archive files than searching archive files across a network drive, especially when the search scope includes several hundreds of thousands of potential matches.\\nLocal storage yields faster retrieval of archive files than searching archive files across a network drive, especially when the search scope includes several hundreds of thousands of potential matches.\\nUse the name of the file/folder for the timestamp of the relevant logs and NOT the date/time of the file itself. The file/folder name contains the normalized datetime of the logs within that file.\\nLog in to the Client Console as LogRhythmAdmin or another user with the role of GlobalAdmin when performing the SecondLook restore, and ensure that the Windows user account under which the LogRhythm Client Console was launched is a local administrator.\\nDoing so ensures that the Client Console has adequate access to all local files/paths that contain archive files.\\nDoing so ensures that the Client Console has adequate access to all local files/paths that contain archive files.\\nIf the restore period is longer than a week\\'s worth of data, perform multiple SecondLook restores with concurrent date ranges.\\nThis range recommendation is variable in nature, and is directly related to the amount of log data that must be searched.\\nDoing so keeps the process from running over several hours or days even, and raises the chance of completion so that the process does not have to be restarted.\\nCurrently, there is no way to \"restart\" a SecondLook restore, so if it does not run to completion, then there is no way to guarantee that log data was found by the previous SecondLook Restore attempt.\\nThis range recommendation is variable in nature, and is directly related to the amount of log data that must be searched.\\nDoing so keeps the process from running over several hours or days even, and raises the chance of completion so that the process does not have to be restarted.\\nCurrently, there is no way to \"restart\" a SecondLook restore, so if it does not run to completion, then there is no way to guarantee that log data was found by the previous SecondLook Restore attempt.\\nRun extremely high volume deployments and/or large SecondLook timeframes, or multiple concurrent SecondLook Restores, on separate servers.\\nDoing so provides increased throughput of the SecondLook restore process. The workloads can be divided using log sources, date/time range, or both.\\nThis approach works best when both SecondLook instances are pointed to the same archive file location. While this point does contradict previous the suggestion of copying archive files for local access, this approach yields more throughput at the MPE processing stage of a SecondLook Restores, which is more of a performance bottleneck than the file search process.\\nDoing so provides increased throughput of the SecondLook restore process. The workloads can be divided using log sources, date/time range, or both.\\nThis approach works best when both SecondLook instances are pointed to the same archive file location. While this point does contradict previous the suggestion of copying archive files for local access, this approach yields more throughput at the MPE processing stage of a SecondLook Restores, which is more of a performance bottleneck than the file search process.\\nTune the MPE settings of the Archive Data Processsor to use the following enhancements: LogProcessingThreads = # of physical cores minus 2 (a 32 core system would yield a thread count of 30)\\nThe MPE policy used for a SecondLook Restore should be as \"skinny\" as possible.\\nThe SecondLook Restore process is mostly constrained by the MPE processing of the LogRhythm client console.\\nMPE policy should contain as few rules as needed to identify the logs that are the target of the SecondLook Restore. This keeps the MPE performance high by not utilizing unnecessary MPE rules that do not match on relevant logs.\\nIndividual MPE rules should parse as few data elements as possible while still yielding useful and indexed results. For instance, if the SecondLook Restore is meant to find user accounts, then the MPE rule should only parse perhaps the Event ID and the user field from the raw log message.\\nThe SecondLook Restore process is mostly constrained by the MPE processing of the LogRhythm client console.\\nMPE policy should contain as few rules as needed to identify the logs that are the target of the SecondLook Restore. This keeps the MPE performance high by not utilizing unnecessary MPE rules that do not match on relevant logs.\\nIndividual MPE rules should parse as few data elements as possible while still yielding useful and indexed results. For instance, if the SecondLook Restore is meant to find user accounts, then the MPE rule should only parse perhaps the Event ID and the user field from the raw log message.\\nDisk I/O, both network shares and local disk arrays, did not come into play as evidenced by performance counters, and should be considered a secondary performance consideration behind MPE optimization.\\nPerform parallel restores using separate servers with dedicated resources for MPE processing, with restore jobs logically segmented by timeframe yields scalable results.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nData Archives and Restoration\\n', 'Use Intelligent Indexing': 'Only Global Admins or Restricted Admins with elevated View and Manage privileges can take this action.\\nIntelligent archiving is part of the Mediator/Message Processing Engine. It prevents logs, events, and LogMart data that do not conform to the TTL values set in Global Maintenance Settings from being added to the online databases. Instead, if your system is configured appropriately, this data is archived.\\nWhen Intelligent Archiving evaluates logs, it applies the following logic:\\nIf an event is older than the TTL_Event value plus one day, it is not inserted into the LogRhythm_Events database. The log is archived if the system is configured to do so.\\nIf a log is older than the TTL_LogMart value plus one week, it is not inserted into the LogRhythm_LogMart database. The log is archived if the system is configured to do so.\\nThere are two TTL Global Data Management settings that work with Intelligent Archiving: TTL_LogMart and TTL_Event.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nPlatform Manager\\ntab.\\nClick\\nGlobal System Settings\\n.\\nYou can modify any of the values evaluated and used by Intelligent Archiving:\\nTTL_LogMart\\n. The number of days the Log Mart info is available online before being removed by the maintenance process. This is the time to live value used by the Log Mart. Min=1, Max=3660.\\nTTL_Event\\n. The number of days the event info is available online before being removed by the maintenance process. This is the time to live value used by the events. Min=30, Max=3660\\nTTL_LogMart\\n. The number of days the Log Mart info is available online before being removed by the maintenance process. This is the time to live value used by the Log Mart. Min=1, Max=3660.\\nTTL_Event\\n. The number of days the event info is available online before being removed by the maintenance process. This is the time to live value used by the events. Min=30, Max=3660\\nClick\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nData Processor\\n', 'Modify Data Processor Advanced Properties': \"\\nMake changes to the Data Processor Advanced Properties with extreme care! LogRhythm recommends that the Data Processor Advanced Properties only be modified with the assistance of LogRhythm Support, or by advanced users who have attended LogRhythm training.\\n\\nTo modify the advanced properties of a data processor:\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nData Processors\\ntab.\\nDouble-click the Data Processor you want to configure.\\nClick the\\nAdvanced\\nbutton at the lower-left corner.\\nThe Advanced Properties window appears.\\nClick the\\nAdvanced\\nbutton at the lower-left corner.\\nThe Advanced Properties window appears.\\nFind the component you want to configure and adjust the settings in the Value column according to the information in the following table.\\nProperty\\nRange\\nDefault\\nDescription\\nAIE Provider: Provider\\nClientAddress\\nIPv4/IPv6 address the AI Engine Data Provider will use to connect to the AI Communication Manager for data/management communications. Only use a static IP address. Do not use DHCP.\\nDefault is blank (recommended.)\\nLocalLogLifeTime\\n1-30\\n7\\nTime to keep AI\\xa0Engine Data Provider application logs (in days).\\nLogLevel\\nWarning\\nSets the AI\\xa0Engine Data Provider logging level. The log is written to the lraiedp.log file.\\nAIE Provider: Sending\\nCompressionStrength\\n0-10\\n5\\nThe compression level to use when sending logs to the AI Engine Communication Manager. Values from 1-10 indicate the compression strength where 0 is off/no compression. Stronger compression requires more CPU\\xa0to compress and uncompress the data.\\nFlushBatch\\n1000-10000\\n1000\\nThe (maximum) number of logs that should be batched and sent to the AI\\xa0Engine Communication Manager during each socket send.\\nMaxDataQueueSize\\n10-2048\\n256\\nThe maximum size of the AI Engine Data Provider's in-memory data queue (in MB). When the queue size exceeds this amount, incoming logs will be buffered into spool files until the queue size is reduced.\\nMaxSpoolStorage\\n0-1024\\n20\\nThe maximum amount of storage available to hold AI Engine Data Provider spooled data filed (in GB). When the amount of space the spool files occupy exceeds this amount, the oldest spool files will be deleted.\\nSendAfterXLogsQueued\\n1-100000\\n100\\nThe threshold number of logs in the queue required to send logs to the AI Engine Communication Manager, independent of time.\\nSendAfterXSecondsElapsed\\n1-3600\\n10\\nThe threshold number of records required to send logs to the AI Engine Communication Manager, independent of number of logs.\\nAIE Provider: TCP/IP\\nSocketConnectionTimeout\\n1-300\\n120\\nAI Engine Data Provider socket connection timeout (in seconds).\\nSocketDontLinger\\nEnabled\\nAI Engine Data Provider don't linger socket option. Close the socket gracefully without lingering.\\nSocketNoDelay\\nEnabled\\nAI Engine Data Provider no delay socket option. Disable the Nagle algorithm for send coalescing.\\nSocketReceiveBuffer\\n16384-65535\\n65535\\nAI Engine Data Provider socket receiver buffer (in bytes).\\nSocketReceiveTimeout\\n1-300\\n60\\nAI Engine Data Provider socket receive timeout (in seconds).\\nSocketReuseAddress\\nEnabled\\nAI Engine Data Provider reuse address socket option. Allow the socket to be bound to an address that is already in use.\\nSocketSendBuffer\\n16384-65535\\n65535\\nAI Engine Data Provider socket send buffer (in bytes).\\nSocketSendTimeout\\n1-300\\n60\\nAI Engine Data Provider socket send timeout (in seconds).\\nAIE Provider: TLS\\xa0Security\\nAIEComMgrTLSCertOCSPURL\\nOCSP URL for AIE ComMgr TLS certificate revocation checking.\\nAIEDPTLSCertLocation\\nLocalMachine\\nAI Engine Data Provider TLS\\xa0certificate location. Values: LocalMachine or CurrentUser\\nAIEDPTCertStore\\nMY\\nAI Engine Data Provider TLS\\xa0certificate store. Values: MY or Root\\nAIEDPTLSCertSubject\\nAI Engine Data Provider TLS\\xa0certificate subject. Example values: CN=10.1.0.79 or CN=lr-0872ed-msa or CN=lr-0872ed-msa.exampledomain.com.\\nEnforceAIEComMgrTLSCertRevocation\\nDisabled\\nEnforce AI Engine Communication Manager TLS certificate revocation check.\\nEnforceAIEComMgrTLSCertTrust\\nDisabled\\nEnforce AI\\xa0Engine Communication Manager TLS certificate trusted authority check.\\nUseAIEDPTLSCert\\nDisabled\\nEnable AI\\xa0Engine Data Provider client TLS certificate.\\nMediator: DataIndexerProvider\\nDataLingerTimeoutMiliSec\\n1-10000\\n1000\\nThe data socket linger timeout (in milliseconds).\\nDataQueueHighWaterMark\\n10000-100000\\n100000\\nThe high water mark for the Data Indexer data queue.\\nDataSendTimeoutMilliSec\\n0-10000\\n250\\nThe data socket send timeout (in milliseconds).\\nParseQueueThreadCount\\n1-25\\n3\\nThe maximum number of unparsed messages that will be serialized concurrently.\\nStatsLingerTimeoutMilliSec\\n1-10000\\n1000\\nThe data socket linger timeout (in milliseconds).\\nStatsQueueHighWaterMark\\n10000-100000\\n10000\\nThe high water mark for the Data Indexer stats queue.\\nStatsSendTimeoutMilliSec\\n0-10000\\n0\\nThe stats socket send timeout (in milliseconds).\\nThreadJoinTimeoutMilliSec\\n1000-10000\\n5000\\nThe maximum amount of time to wait for the Data Indexer provider threads to exit on shutdown.\\nUnparsedItemsQueueSize\\n10000-10000000\\n250000\\nThe number of unparsed reliable messages allowed to accumulate in memory before the Mediator goes into a Suspend state.\\nMediator: General\\nActiveArchivePath\\nC:\\\\LogRhythmArchives \\\\Active\\nArchiving directory path (full path to the directory in which archive files are written). If the requested directory does not exist, it is created.\\nActiveArchiveProtection\\nFile size and last modification date tracking\\nActive archive protection mode\\nFile size and last modification date tracking\\nNo Protections\\nFull SHA1 hashing of archive files\\nArchiveAge\\n1-7\\n7\\nMaximum days an archive can live in active directory (in days).\\nArchiveBatch\\n1000-10000000\\n102400\\nThe number of logs that are allowed to build up in the archive queue before being processed by the archiver.\\nArchiveByEntity\\nDisabled\\nStores inactive archives according to entity structure.\\nArchiveCompression\\nEnabled\\nDetermines if inactive archive files are gzip compressed\\nArchiveSize\\n1024-131072\\n10240\\nMaximum size for archive before moving to inactive directory (in KB).\\nArchiveWriteThreadCount\\n1-20\\n3\\nThe maximum number of archives that will be serialized and written to disk concurrently.\\nAutomaticLogSource ConfigurationNetflow\\nDisabled\\nAutomatic Log Source Configuration (Netflow/J-Flow Sources). When enabled, the Data Processor automatically registers new message sources for NetFlow/J-Flow sending devices which can be automatically identified.\\nAutomaticLogSource ConfigurationsFlow\\nDisabled\\nAutomatic Log Source Configuration (sFlow Sources). When enabled, the Data Processor automatically registers new message sources for sFlow sending devices which can be automatically identified.\\nAutomaticLogSource ConfigurationSNMPTimeout\\n1-120\\n10\\nAutomatic Log Source Configuration (SNMP Discovery). Defines the timeout value (in seconds) for SNMP communications used in SNMP Device Identification.\\nAutomaticLogSource ConfigurationSNMPTrap\\nDisabled\\nAutomatic Log Source Configuration (SNMP Trap Sources). When enabled, the Data Processor automatically registers new message sources for SNMP trap sending devices which can be automatically identified.\\nAutomaticLogSource ConfigurationSyslog\\nDisabled\\nAutomatic Log Source Configuration (Syslog Sources). When enabled the Data Processor\\xa0 automatically registers new message sources for syslog sending devices which can be automatically identified.\\nClientSocket ReceiveTimeout\\n1000-7200000\\n60000\\nClient socket receive timeout for Agent socket connections (in ms).\\nClientSocketSendTimeout\\n1000-7200000\\n60000\\nClient socket send timeout for Agent socket connections (in ms).\\nComponentVersion\\nThe version of this LogRhythm component\\nConnectionTimeout\\n3-7200\\n120\\nConnection timeout for Agent socket connections (in seconds).\\nInactiveArchivePath\\nC:\\\\LogRhythmArchives \\\\Inactive\\nDirectory (full path) where the inactive archive files are written. If the requested directory does not exist, it is created.\\nInactiveArchiveProtection\\nFull SHA1 hashing of archive files\\nInactive archive protection mode\\nFile size and last modification date tracking\\nNo Protections\\nFull SHA1 hashing of archive files\\nInactiveSubdirectory FileCount\\n100-10000\\n10000\\nInactive archive subdirectory maximum file count.\\nLocalLogLifetime\\n1-30\\n7\\nThe number of days to keep Mediator and MPE\\xa0log files.\\nLogLevel\\nVERBOSE\\nSets the Data Processor logging level (log written to scmedsvr.log)\\nMaxAgentUpdates\\n1-10000\\n10\\nThe maximum number of concurrent Agent updates that can be delivered.\\nMaxConnections\\n0-10000\\n100\\nMaximum number of Agent connections to allow.\\nMaxLogArchivingRate\\n0-10000\\n0\\nMaximum rate at which logs can be archived.\\nMaxLogProcessingRate\\n0-100000\\n0\\nMaximum rate at which logs can be processed.\\nMaxLogReceiveRate\\n0-100000\\n0\\nMaximum rate at which logs can be received.\\nMaxServiceMemory\\n512-65536\\n1024\\nMaximum memory allowed for the Data Processor process (in MB).\\nMaxUnprocessed\\nDiskQueueSpace\\n0-1000\\n100\\nThe maximum amount of space (in GB) to be used by the Unprocessed Log Disk Queue. A value of 0 indicates no maximum.\\nA warning event is written when 80% of the specified space is used. If the maximum is reached, the mediator goes into suspend mode.\\nMinAgentSocketSecurity\\nTLS 1.0\\nSets the minimum encryption standard to be used for Agent connections.\\nIf set to TLS 1.0, the Mediator generates a 1024-bit key.\\nIf set to TLS 1.2, the Mediator generates a 2048-bit key.\\nMinUnprocessed\\nDiskQueueSpace\\n1-1000\\n1\\nThe minimum amount of space (in GB) that must be available on the volume that the Unprocessed Log Disk Queue spool files are being written to.\\nIf the minimum is reached, the mediator goes into suspend mode.\\nProcessPriority\\nNormal\\nProcess priority for the Data Processor process.\\nQueueSize\\n10000-500000\\n20000\\nThe maximum size of the archive queue and the unprocessed log queue.\\nSecondaryServerIP\\nAn external facing IP address that an Agent can use to connect to the Mediator. This IP address will be used by Agents when they can't connect using the Primary Server IP address (ServerIP). The Secondary Server IP/Port must be forwarded to the Primary Server IP/Port by a firewall or router.\\nThis parameter must be a static IP v4/v6 address with a maximum length of 45 or a DNS name with a maximum length of 255. DNS names are only supported for version 6.x System Monitors and later.\\nYou must configure your firewall or router to forward this IP/Port to the Primary Server. This is important for deployments that use NAT.\\nSecondaryServerSSLPort\\n1-65535\\n443\\nThe external facing IP port to use with the Secondary Server IP address. The Secondary Server IP/Port must be forwarded to the Primary Server IP/Port by a firewall or router.\\nServerDNS\\nDNS address that agents will use to connect to this Data Processor. If this parameter is not specified, Agents uses the ServerIP address to connect to this Data Processor.\\nIf you created custom certificates for the Mediator, this must match the DNS name specified in the custom certificate.\\nServerIP\\nIPv4 address that the Data Processor listens on for Agent communications. This parameter must be a static IPv4 address with a maximum length of 16\\nServerIPv6\\nIPv6 address that the Data Processor listens on for Agent communications. This parameter must be a static IPv6 address with a maximum length of 45.\\nServerSSLPort\\n1-65535\\n443\\nPort that the Data Processor listens on for Agent communications.\\nTertiaryServerIP\\nAn external facing IP address or DNS name that an Agent outside the network can use to connect to the Mediator. This IP address will be used by Agents when they can't connect using the Primary or Secondary Server IP addresses (ServerIP/SecondaryServerIP). The Tertiary Server IP/Port must be forwarded to the Primary Server IP/Port by a firewall or router. This parameter must be a static IP v4/v6 address with a maximum length of 45 or a DNS name with a maximum length of 255. DNS names are only supported for version 6.x System Monitors and later.\\nYou must configure your firewall or router to forward this IP/Port to the Tertiary Server. This is important for deployments that use NAT.\\nTertiaryServerSSLPort\\n1-65535\\n443\\nThe external facing IP port to use with the Tertiary Server IP address. The Tertiary Server IP/Port must be forwarded to the Primary Server IP/Port by a firewall or router.\\nUnprocessed\\nDiskQueueLocation\\nThe directory where Data Processor unprocessed log disk queue spool files are written.\\nThe default directory is the mediator state folder. After changing the directory location, any remaining spool files must be manually moved to the new location.\\nMediator: InsertManagerEM\\nAllowAutomaticRateOverride\\nEnabled\\nEnable/disable automatic event insert rate override.\\nBatchInterval\\n1-300\\n5\\nThis value determines how often (in seconds) batches are submitted to the Platform Manager database for insertion.\\nMax Insert Batch is determined at startup by the Max Insert Rate and Batch Interval.\\nDiskQueueLocation\\nThe directory where Platform Manager Insert Manager disk queue spool files are written.\\nThe default directory is the mediator state folder. After changing the directory location, any remaining spool files must be manually moved to the new location.\\nMaxAutomaticInsert\\nRateOverridePercent\\n10-100\\n50\\nThe maximum override percentage that is applied to Max Insert Rate throttling level.\\nMaxEMInsert\\nDiskQueueSpace\\n0-1000\\n100\\nThe maximum amount of space (in GB) to be used by the PM Insert Manager Disk Queue. A value of 0 indicates no maximum.\\nA warning event is written when 80% of the specified space is used. If the maximum is reached, the oldest spool files are deleted until the space used by the spool files is less than the specified maximum.\\nMaxInsertRate\\n1-100000\\n3000\\nThis value determines the maximum number of Platform Manager logs that will be inserted per second. The insertion rate will not exceed this value. Note that this value is based on the performance profile of the system.\\nMinEMInsert\\nDiskQueueSpace\\n1-1000\\n1\\nThe minimum of amount of space (in GB) that must be available on the volume that the PM Insert Disk Queue spool files are being written to.\\nIf the minimum is reached, the oldest spool files are deleted until the space used by the spool files is above the specified minimum.\\nSystemMaxInsertBatch\\n100-100000\\n50000\\nThis is a fixed constant that determines the maximum number of inserts the system will process in a single batch.\\nMediator:\\xa0LDS\\nLDSDistributionQueueSize\\n1000-100000\\n10000\\nSpecify the size for each log distribution receiver queue. Every receiver has its own queue. If this queue reaches maximum size, logs will be dropped. However setting queue size too high could result in excessive memory utilization.\\nLDSDistributionThreadCount\\n1-100\\n10\\nSpecify the number of threads to use for the log distribution receiver process.\\nLDSEngineQueueSize\\n1000-500000\\n60000\\nSpecify the size of primary log distribution queue. If this queue reaches maximum size, logs will be dropped. However setting queue size too high could result in excessive memory utilization.\\nLDSEngineThreadCount\\n1-100\\n5\\nSpecify the number of threads to use for the primary log distribution process.\\nMediator: TLSCertificates\\nAgentTLSCertOCSPURL\\nThe OCSP URL for Agent certificate revocation checking.\\nEnforceAgentTLSCert Revocation\\nDisabled\\nEnforce Agent Certificate Revocation Check. If this fails, the Mediator will disconnect from the Agent and logs will be written to the scmedsvr.log.\\nEnforceAgentTLSCertTrust\\nDisabled\\nEnforce Agent certificate Trusted Authority Check. If this fails, the Mediator will disconnect from the Agent and logs will be written to the scmedsvr.log.\\nMediatorTLSCertLocation\\nThe location of the Windows certificate where the Mediator server certificates are installed--can be LocalMachine or CurrentUser.\\nMediatorTLSCertStore\\nThe Windows certificate store where the Mediator server certificate is installed--can be MY or ROOT.\\nMediatorTLSCertSubject\\nThe Subject of the server certificate that the Mediator should use (e.g., CN=190.1.2.123 or CN=lr-0870eds-msa or CN=\\nlr-0870eds-msa.secious.com\\n).\\nRequireAgentTLSCert\\nDisabled\\nRequire agents to present a client certificate when connecting.\\nUseMediatorTLSCert\\nDisabled\\nIf checked, the Mediator will use the specified server certificate when connecting with Agents; otherwise, the Mediator will use a self-generated/signed certificate (default).\\nMediator: Unidirectional Agent\\nEnabled\\nDisabled\\nCheck to enable unidirectional Agent communications with the Data Processor.\\nMediator Port\\n1-65535\\n40000\\nSpecifies the Data Processor port to use when running in Unidirectional Agent mode.\\nMPE:\\xa0Engine\\nCacheSize_Dimension\\n1000-1000000\\n10000\\nSpecify the size for the unique metadata value cache. There are nine metadata caches containing unique metadata values for processed log messages. The larger the queue size the more unique values will be stored in memory resulting in more efficient log processing. However setting queue size too high could result in excessive memory utilization.\\nCacheSize_Msg\\n100000-5000000\\n200000\\nSpecify the size for the unique log message cache. The larger the queue size, the more unique log messages will be stored in memory resulting in more efficient online log storage. However setting queue size too high could result in excessive memory utilization.\\nDataAndIndexCompression\\nNone\\nSpecifies the level of compression to apply to data and indices.\\nThis is obsolete in the current version and changing its value has no impact on indexing and compression.\\nDenormalizeLogMetadata\\nTrue\\nSetting this property to false reduces data transmission volume at the cost of normalizing enumerable values. Metadata fields such as Log Source Type and Common Event will be presented as ID numbers instead of readable text. Disabling this feature decreases the usability of downstream features such as Log Distribution Service and full text search.\\nDNSCachedRecordTTL\\n5-1440\\n15\\nThe time to live for cached DNS\\xa0Name to Known Host to IP\\xa0host resolution records (in minutes).\\nDNSCacheMaintCycle\\n1-60\\n5\\nThe frequency to launch DNS cache maintenance (in minutes).\\nDNSCacheRecord ExternalIPToNameTTL\\n5-1440\\n15\\nThe time to live for cached DNS external IP to Name host resolution records (in minutes).\\nDNSCacheRecord InternalIPToNameTTL\\n5-1440\\n5\\nThe time to live for cached DNS private/internal IP to Name host resolution records (in minutes).\\nDNSIPToName\\nOff\\nIP\\xa0to Name DNS\\xa0resolution mode.\\nValues: Off, Resolve All, Resolve Internal\\nResolve IP\\xa0addresses to their associated DNS\\xa0names.\\nDNSLogLevel\\nError\\nThe logging level for the DNS\\xa0resolution engine.\\nDNSNameToIP\\nDisabled\\nResolve\\xa0DNS\\xa0names to their associated IP\\xa0addresses.\\nDNSResolveMsgSourceHostIP\\nEnabled\\nResolve host IP\\xa0addresses when logs match a rule where the source or destination is assigned to the message source host.\\nGeoIPResolutionMode\\nNone\\nThe level of detail to resolve for Geographic IP lookup.\\nOptions = None, Country, Region, and City. If this is left set to None, GeoIP location will not be resolved for logs or Network Visualization.\\nLogProcessingThreads\\n1-50\\n10\\nThe number of log processing threads.\\nPerfOptimizedLogIndexing\\nDisabled\\nEnables or disables performance-optimized indexing of logs.\\nRulePerfLogSampleSize\\n1-1000\\n10\\nThe minimum number of logs that must be processed before a rule will be disabled due to not meeting the minimum logs per second requirement.\\nRulePerfMinLogsPerSecond\\n1-1000\\n50\\nThe minimum allowed average logs per second a rule must meet.\\nMPE:\\xa0General\\nIdentityInference\\nEnabled\\nEnables or disables Identity Inference for the MPE (as long as Globally disabled).\\nLogLevel\\nWARNING\\nSets the MPE\\xa0logging level (log written to scmpe.log).\\nOptions: Off, Error, Warning, Info, Verbose,\\xa0Debug\\nMaintenanceInterval\\n1-120\\n60\\nHow often to perform internal process maintenance (in seconds).\\nRulePerformanceStatsMode\\nOff\\nRule performance statistics mode:\\nOff - no not write report (lps_detail.log) or data file (lps_stats.dat) locally or submit to LogRhythm (default).\\nLocal - write the report (lps_detail.log) and data file (lps_stats.dat) locally.\\nLocal and Send - write the Report (lps_detail.log) and data file (lps_stats.dat) locally and submit to LogRhythm.\\nRulePerformanceStats\\nSubmitInterval\\n1-24\\n24\\nHow often to submit rule performance information to LogRhythm (in hours). The latest lps_detail.log and lps_stats.dat files will be submitted each interval.\\nMPE:\\xa0LogMart\\nLogMartCommitInterval\\n1-120\\n60\\nHow often (in seconds) the LogMart is updated with new data.\\nLogMartCommitTimeout\\n1-120\\n40\\nHow long (in seconds)\\xa0a single commit operation can take before timing out.\\nMPE: StatKeeper\\nStatkeeperCommitInterval HeartbeatInfo\\n1-300\\n10\\nHow often (in seconds) heartbeat information is committed to the database.\\nStatKeeperCommitIntervalLogInfo\\n1-300\\n60\\nHow often (in seconds)\\xa0log collection statistics are committed to the database.\\nStatKeeperCommitTimeout\\n30-120\\n30\\nHow long (in seconds)\\xa0a single commit operation can take before timing out\\nStatKeeperEnabled\\nEnabled\\nSpecify if StatKeeper should be enabled.\\nFind the component you want to configure and adjust the settings in the Value column according to the information in the following table.\\nProperty, Range, Default, Description\\nAIE Provider: Provider\\nClientAddress, , , IPv4/IPv6 address the AI Engine Data Provider will use to connect to the AI Communication Manager for data/management communications. Only use a static IP address. Do not use DHCP.Default is blank (recommended.)\\nLocalLogLifeTime, 1-30, 7, Time to keep AI\\xa0Engine Data Provider application logs (in days).\\nLogLevel, , Warning, Sets the AI\\xa0Engine Data Provider logging level. The log is written to the lraiedp.log file.\\nAIE Provider: Sending\\nCompressionStrength, 0-10, 5, The compression level to use when sending logs to the AI Engine Communication Manager. Values from 1-10 indicate the compression strength where 0 is off/no compression. Stronger compression requires more CPU\\xa0to compress and uncompress the data.\\nFlushBatch, 1000-10000, 1000, The (maximum) number of logs that should be batched and sent to the AI\\xa0Engine Communication Manager during each socket send.\\nMaxDataQueueSize, 10-2048, 256, The maximum size of the AI Engine Data Provider's in-memory data queue (in MB). When the queue size exceeds this amount, incoming logs will be buffered into spool files until the queue size is reduced.\\nMaxSpoolStorage, 0-1024, 20, The maximum amount of storage available to hold AI Engine Data Provider spooled data filed (in GB). When the amount of space the spool files occupy exceeds this amount, the oldest spool files will be deleted.\\nSendAfterXLogsQueued, 1-100000, 100, The threshold number of logs in the queue required to send logs to the AI Engine Communication Manager, independent of time.\\nSendAfterXSecondsElapsed, 1-3600, 10, The threshold number of records required to send logs to the AI Engine Communication Manager, independent of number of logs.\\nAIE Provider: TCP/IP\\nSocketConnectionTimeout, 1-300, 120, AI Engine Data Provider socket connection timeout (in seconds).\\nSocketDontLinger, , Enabled, AI Engine Data Provider don't linger socket option. Close the socket gracefully without lingering.\\nSocketNoDelay, , Enabled, AI Engine Data Provider no delay socket option. Disable the Nagle algorithm for send coalescing.\\nSocketReceiveBuffer, 16384-65535, 65535, AI Engine Data Provider socket receiver buffer (in bytes).\\nSocketReceiveTimeout, 1-300, 60, AI Engine Data Provider socket receive timeout (in seconds).\\nSocketReuseAddress, , Enabled, AI Engine Data Provider reuse address socket option. Allow the socket to be bound to an address that is already in use.\\nSocketSendBuffer, 16384-65535, 65535, AI Engine Data Provider socket send buffer (in bytes).\\nSocketSendTimeout, 1-300, 60, AI Engine Data Provider socket send timeout (in seconds).\\nAIE Provider: TLS\\xa0Security\\nAIEComMgrTLSCertOCSPURL, , , OCSP URL for AIE ComMgr TLS certificate revocation checking.\\nAIEDPTLSCertLocation, , LocalMachine, AI Engine Data Provider TLS\\xa0certificate location. Values: LocalMachine or CurrentUser\\nAIEDPTCertStore, , MY, AI Engine Data Provider TLS\\xa0certificate store. Values: MY or Root\\nAIEDPTLSCertSubject, , , AI Engine Data Provider TLS\\xa0certificate subject. Example values: CN=10.1.0.79 or CN=lr-0872ed-msa or CN=lr-0872ed-msa.exampledomain.com.\\nEnforceAIEComMgrTLSCertRevocation, , Disabled, Enforce AI Engine Communication Manager TLS certificate revocation check.\\nEnforceAIEComMgrTLSCertTrust, , Disabled, Enforce AI\\xa0Engine Communication Manager TLS certificate trusted authority check.\\nUseAIEDPTLSCert, , Disabled, Enable AI\\xa0Engine Data Provider client TLS certificate.\\nMediator: DataIndexerProvider\\nDataLingerTimeoutMiliSec, 1-10000, 1000, The data socket linger timeout (in milliseconds).\\nDataQueueHighWaterMark, 10000-100000, 100000, The high water mark for the Data Indexer data queue.\\nDataSendTimeoutMilliSec, 0-10000, 250, The data socket send timeout (in milliseconds).\\nParseQueueThreadCount, 1-25, 3, The maximum number of unparsed messages that will be serialized concurrently.\\nStatsLingerTimeoutMilliSec, 1-10000, 1000, The data socket linger timeout (in milliseconds).\\nStatsQueueHighWaterMark, 10000-100000, 10000, The high water mark for the Data Indexer stats queue.\\nStatsSendTimeoutMilliSec, 0-10000, 0, The stats socket send timeout (in milliseconds).\\nThreadJoinTimeoutMilliSec, 1000-10000, 5000, The maximum amount of time to wait for the Data Indexer provider threads to exit on shutdown.\\nUnparsedItemsQueueSize, 10000-10000000, 250000, The number of unparsed reliable messages allowed to accumulate in memory before the Mediator goes into a Suspend state.\\nMediator: General\\nActiveArchivePath, , C:\\\\LogRhythmArchives \\\\Active, Archiving directory path (full path to the directory in which archive files are written). If the requested directory does not exist, it is created.\\nActiveArchiveProtection, , File size and last modification date tracking, Active archive protection modeFile size and last modification date trackingNo ProtectionsFull SHA1 hashing of archive files\\nArchiveAge, 1-7, 7, Maximum days an archive can live in active directory (in days).\\nArchiveBatch, 1000-10000000, 102400, The number of logs that are allowed to build up in the archive queue before being processed by the archiver.\\nArchiveByEntity, , Disabled, Stores inactive archives according to entity structure.\\nArchiveCompression, , Enabled, Determines if inactive archive files are gzip compressed\\nArchiveSize, 1024-131072, 10240, Maximum size for archive before moving to inactive directory (in KB).\\nArchiveWriteThreadCount, 1-20, 3, The maximum number of archives that will be serialized and written to disk concurrently.\\nAutomaticLogSource ConfigurationNetflow, , Disabled, Automatic Log Source Configuration (Netflow/J-Flow Sources). When enabled, the Data Processor automatically registers new message sources for NetFlow/J-Flow sending devices which can be automatically identified.\\nAutomaticLogSource ConfigurationsFlow, , Disabled, Automatic Log Source Configuration (sFlow Sources). When enabled, the Data Processor automatically registers new message sources for sFlow sending devices which can be automatically identified.\\nAutomaticLogSource ConfigurationSNMPTimeout, 1-120, 10, Automatic Log Source Configuration (SNMP Discovery). Defines the timeout value (in seconds) for SNMP communications used in SNMP Device Identification.\\nAutomaticLogSource ConfigurationSNMPTrap, , Disabled, Automatic Log Source Configuration (SNMP Trap Sources). When enabled, the Data Processor automatically registers new message sources for SNMP trap sending devices which can be automatically identified.\\nAutomaticLogSource ConfigurationSyslog, , Disabled, Automatic Log Source Configuration (Syslog Sources). When enabled the Data Processor\\xa0 automatically registers new message sources for syslog sending devices which can be automatically identified.\\nClientSocket ReceiveTimeout, 1000-7200000, 60000, Client socket receive timeout for Agent socket connections (in ms).\\nClientSocketSendTimeout, 1000-7200000, 60000, Client socket send timeout for Agent socket connections (in ms).\\nComponentVersion, , , The version of this LogRhythm component\\nConnectionTimeout, 3-7200, 120, Connection timeout for Agent socket connections (in seconds).\\nInactiveArchivePath, , C:\\\\LogRhythmArchives \\\\Inactive, Directory (full path) where the inactive archive files are written. If the requested directory does not exist, it is created.\\nInactiveArchiveProtection, , Full SHA1 hashing of archive files, Inactive archive protection modeFile size and last modification date trackingNo ProtectionsFull SHA1 hashing of archive files\\nInactiveSubdirectory FileCount, 100-10000, 10000, Inactive archive subdirectory maximum file count.\\nLocalLogLifetime, 1-30, 7, The number of days to keep Mediator and MPE\\xa0log files.\\nLogLevel, , VERBOSE, Sets the Data Processor logging level (log written to scmedsvr.log)\\nMaxAgentUpdates, 1-10000, 10, The maximum number of concurrent Agent updates that can be delivered.\\nMaxConnections, 0-10000, 100, Maximum number of Agent connections to allow.\\nMaxLogArchivingRate, 0-10000, 0, Maximum rate at which logs can be archived.\\nMaxLogProcessingRate, 0-100000, 0, Maximum rate at which logs can be processed.\\nMaxLogReceiveRate, 0-100000, 0, Maximum rate at which logs can be received.\\nMaxServiceMemory, 512-65536, 1024, Maximum memory allowed for the Data Processor process (in MB).\\nMaxUnprocessedDiskQueueSpace, 0-1000, 100, The maximum amount of space (in GB) to be used by the Unprocessed Log Disk Queue. A value of 0 indicates no maximum.A warning event is written when 80% of the specified space is used. If the maximum is reached, the mediator goes into suspend mode.\\nMinAgentSocketSecurity, , TLS 1.0, Sets the minimum encryption standard to be used for Agent connections.If set to TLS 1.0, the Mediator generates a 1024-bit key.If set to TLS 1.2, the Mediator generates a 2048-bit key.\\nMinUnprocessedDiskQueueSpace, 1-1000, 1, The minimum amount of space (in GB) that must be available on the volume that the Unprocessed Log Disk Queue spool files are being written to.If the minimum is reached, the mediator goes into suspend mode.\\nProcessPriority, , Normal, Process priority for the Data Processor process.\\nQueueSize, 10000-500000, 20000, The maximum size of the archive queue and the unprocessed log queue.\\nSecondaryServerIP, , , An external facing IP address that an Agent can use to connect to the Mediator. This IP address will be used by Agents when they can't connect using the Primary Server IP address (ServerIP). The Secondary Server IP/Port must be forwarded to the Primary Server IP/Port by a firewall or router.This parameter must be a static IP v4/v6 address with a maximum length of 45 or a DNS name with a maximum length of 255. DNS names are only supported for version 6.x System Monitors and later.You must configure your firewall or router to forward this IP/Port to the Primary Server. This is important for deployments that use NAT.\\nSecondaryServerSSLPort, 1-65535, 443, The external facing IP port to use with the Secondary Server IP address. The Secondary Server IP/Port must be forwarded to the Primary Server IP/Port by a firewall or router.\\nServerDNS, , , DNS address that agents will use to connect to this Data Processor. If this parameter is not specified, Agents uses the ServerIP address to connect to this Data Processor.If you created custom certificates for the Mediator, this must match the DNS name specified in the custom certificate.\\nServerIP, , , IPv4 address that the Data Processor listens on for Agent communications. This parameter must be a static IPv4 address with a maximum length of 16\\nServerIPv6, , , IPv6 address that the Data Processor listens on for Agent communications. This parameter must be a static IPv6 address with a maximum length of 45.\\nServerSSLPort, 1-65535, 443, Port that the Data Processor listens on for Agent communications.\\nTertiaryServerIP, , , An external facing IP address or DNS name that an Agent outside the network can use to connect to the Mediator. This IP address will be used by Agents when they can't connect using the Primary or Secondary Server IP addresses (ServerIP/SecondaryServerIP). The Tertiary Server IP/Port must be forwarded to the Primary Server IP/Port by a firewall or router. This parameter must be a static IP v4/v6 address with a maximum length of 45 or a DNS name with a maximum length of 255. DNS names are only supported for version 6.x System Monitors and later.You must configure your firewall or router to forward this IP/Port to the Tertiary Server. This is important for deployments that use NAT.\\nTertiaryServerSSLPort, 1-65535, 443, The external facing IP port to use with the Tertiary Server IP address. The Tertiary Server IP/Port must be forwarded to the Primary Server IP/Port by a firewall or router.\\nUnprocessedDiskQueueLocation, , , The directory where Data Processor unprocessed log disk queue spool files are written.The default directory is the mediator state folder. After changing the directory location, any remaining spool files must be manually moved to the new location.\\nMediator: InsertManagerEM\\nAllowAutomaticRateOverride, , Enabled, Enable/disable automatic event insert rate override.\\nBatchInterval, 1-300, 5, This value determines how often (in seconds) batches are submitted to the Platform Manager database for insertion.Max Insert Batch is determined at startup by the Max Insert Rate and Batch Interval.\\nDiskQueueLocation, , , The directory where Platform Manager Insert Manager disk queue spool files are written.The default directory is the mediator state folder. After changing the directory location, any remaining spool files must be manually moved to the new location.\\nMaxAutomaticInsertRateOverridePercent, 10-100, 50, The maximum override percentage that is applied to Max Insert Rate throttling level.\\nMaxEMInsertDiskQueueSpace, 0-1000, 100, The maximum amount of space (in GB) to be used by the PM Insert Manager Disk Queue. A value of 0 indicates no maximum.A warning event is written when 80% of the specified space is used. If the maximum is reached, the oldest spool files are deleted until the space used by the spool files is less than the specified maximum.\\nMaxInsertRate, 1-100000, 3000, This value determines the maximum number of Platform Manager logs that will be inserted per second. The insertion rate will not exceed this value. Note that this value is based on the performance profile of the system.\\nMinEMInsertDiskQueueSpace, 1-1000, 1, The minimum of amount of space (in GB) that must be available on the volume that the PM Insert Disk Queue spool files are being written to.If the minimum is reached, the oldest spool files are deleted until the space used by the spool files is above the specified minimum.\\nSystemMaxInsertBatch, 100-100000, 50000, This is a fixed constant that determines the maximum number of inserts the system will process in a single batch.\\nMediator:\\xa0LDS\\nLDSDistributionQueueSize, 1000-100000, 10000, Specify the size for each log distribution receiver queue. Every receiver has its own queue. If this queue reaches maximum size, logs will be dropped. However setting queue size too high could result in excessive memory utilization.\\nLDSDistributionThreadCount, 1-100, 10, Specify the number of threads to use for the log distribution receiver process.\\nLDSEngineQueueSize, 1000-500000, 60000, Specify the size of primary log distribution queue. If this queue reaches maximum size, logs will be dropped. However setting queue size too high could result in excessive memory utilization.\\nLDSEngineThreadCount, 1-100, 5, Specify the number of threads to use for the primary log distribution process.\\nMediator: TLSCertificates\\nAgentTLSCertOCSPURL, , , The OCSP URL for Agent certificate revocation checking.\\nEnforceAgentTLSCert Revocation, , Disabled, Enforce Agent Certificate Revocation Check. If this fails, the Mediator will disconnect from the Agent and logs will be written to the scmedsvr.log.\\nEnforceAgentTLSCertTrust, , Disabled, Enforce Agent certificate Trusted Authority Check. If this fails, the Mediator will disconnect from the Agent and logs will be written to the scmedsvr.log.\\nMediatorTLSCertLocation, , , The location of the Windows certificate where the Mediator server certificates are installed--can be LocalMachine or CurrentUser.\\nMediatorTLSCertStore, , , The Windows certificate store where the Mediator server certificate is installed--can be MY or ROOT.\\nMediatorTLSCertSubject, , , The Subject of the server certificate that the Mediator should use (e.g., CN=190.1.2.123 or CN=lr-0870eds-msa or CN=lr-0870eds-msa.secious.com).\\nRequireAgentTLSCert, , Disabled, Require agents to present a client certificate when connecting.\\nUseMediatorTLSCert, , Disabled, If checked, the Mediator will use the specified server certificate when connecting with Agents; otherwise, the Mediator will use a self-generated/signed certificate (default).\\nMediator: Unidirectional Agent\\nEnabled, , Disabled, Check to enable unidirectional Agent communications with the Data Processor.\\nMediator Port, 1-65535, 40000, Specifies the Data Processor port to use when running in Unidirectional Agent mode.\\nMPE:\\xa0Engine\\nCacheSize_Dimension, 1000-1000000, 10000, Specify the size for the unique metadata value cache. There are nine metadata caches containing unique metadata values for processed log messages. The larger the queue size the more unique values will be stored in memory resulting in more efficient log processing. However setting queue size too high could result in excessive memory utilization.\\nCacheSize_Msg, 100000-5000000, 200000, Specify the size for the unique log message cache. The larger the queue size, the more unique log messages will be stored in memory resulting in more efficient online log storage. However setting queue size too high could result in excessive memory utilization.\\nDataAndIndexCompression, , None, Specifies the level of compression to apply to data and indices.This is obsolete in the current version and changing its value has no impact on indexing and compression.\\nDenormalizeLogMetadata, , True, Setting this property to false reduces data transmission volume at the cost of normalizing enumerable values. Metadata fields such as Log Source Type and Common Event will be presented as ID numbers instead of readable text. Disabling this feature decreases the usability of downstream features such as Log Distribution Service and full text search.\\nDNSCachedRecordTTL, 5-1440, 15, The time to live for cached DNS\\xa0Name to Known Host to IP\\xa0host resolution records (in minutes).\\nDNSCacheMaintCycle, 1-60, 5, The frequency to launch DNS cache maintenance (in minutes).\\nDNSCacheRecord ExternalIPToNameTTL, 5-1440, 15, The time to live for cached DNS external IP to Name host resolution records (in minutes).\\nDNSCacheRecord InternalIPToNameTTL, 5-1440, 5, The time to live for cached DNS private/internal IP to Name host resolution records (in minutes).\\nDNSIPToName, , Off, IP\\xa0to Name DNS\\xa0resolution mode.Values: Off, Resolve All, Resolve InternalResolve IP\\xa0addresses to their associated DNS\\xa0names.\\nDNSLogLevel, , Error, The logging level for the DNS\\xa0resolution engine.\\nDNSNameToIP, , Disabled, Resolve\\xa0DNS\\xa0names to their associated IP\\xa0addresses.\\nDNSResolveMsgSourceHostIP, , Enabled, Resolve host IP\\xa0addresses when logs match a rule where the source or destination is assigned to the message source host.\\nGeoIPResolutionMode, , None, The level of detail to resolve for Geographic IP lookup.Options = None, Country, Region, and City. If this is left set to None, GeoIP location will not be resolved for logs or Network Visualization.\\nLogProcessingThreads, 1-50, 10, The number of log processing threads.\\nPerfOptimizedLogIndexing, , Disabled, Enables or disables performance-optimized indexing of logs.\\nRulePerfLogSampleSize, 1-1000, 10, The minimum number of logs that must be processed before a rule will be disabled due to not meeting the minimum logs per second requirement.\\nRulePerfMinLogsPerSecond, 1-1000, 50, The minimum allowed average logs per second a rule must meet.\\nMPE:\\xa0General\\nIdentityInference, , Enabled, Enables or disables Identity Inference for the MPE (as long as Globally disabled).\\nLogLevel, , WARNING, Sets the MPE\\xa0logging level (log written to scmpe.log).Options: Off, Error, Warning, Info, Verbose,\\xa0Debug\\nMaintenanceInterval, 1-120, 60, How often to perform internal process maintenance (in seconds).\\nRulePerformanceStatsMode, , Off, Rule performance statistics mode:Off - no not write report (lps_detail.log) or data file (lps_stats.dat) locally or submit to LogRhythm (default).Local - write the report (lps_detail.log) and data file (lps_stats.dat) locally.Local and Send - write the Report (lps_detail.log) and data file (lps_stats.dat) locally and submit to LogRhythm.\\nRulePerformanceStatsSubmitInterval, 1-24, 24, How often to submit rule performance information to LogRhythm (in hours). The latest lps_detail.log and lps_stats.dat files will be submitted each interval.\\nMPE:\\xa0LogMart\\nLogMartCommitInterval, 1-120, 60, How often (in seconds) the LogMart is updated with new data.\\nLogMartCommitTimeout, 1-120, 40, How long (in seconds)\\xa0a single commit operation can take before timing out.\\nMPE: StatKeeper\\nStatkeeperCommitInterval HeartbeatInfo, 1-300, 10, How often (in seconds) heartbeat information is committed to the database.\\nStatKeeperCommitIntervalLogInfo, 1-300, 60, How often (in seconds)\\xa0log collection statistics are committed to the database.\\nStatKeeperCommitTimeout, 30-120, 30, How long (in seconds)\\xa0a single commit operation can take before timing out\\nStatKeeperEnabled, , Enabled, Specify if StatKeeper should be enabled.\\nProperty\\n\\nIPv4/IPv6 address the AI Engine Data Provider will use to connect to the AI Communication Manager for data/management communications. Only use a static IP address. Do not use DHCP.\\nDefault is blank (recommended.)\\n1-30\\n7\\nWarning\\n0-10\\n5\\n1000-10000\\n1000\\n10-2048\\n256\\n0-1024\\n20\\n1-100000\\n100\\n1-3600\\n1-300\\n120\\nEnabled\\nEnabled\\n16384-65535\\n65535\\n1-300\\n60\\nEnabled\\n16384-65535\\n65535\\n1-300\\n60\\n\\nLocalMachine\\nMY\\n\\nDisabled\\nDisabled\\n1-10000\\n10000-100000\\n0-10000\\n1-25\\n1-10000\\n10000-100000\\n1000-10000\\n10000-10000000\\nC:\\\\LogRhythmArchives \\\\Active\\nActive archive protection mode\\nFile size and last modification date tracking\\nNo Protections\\nFull SHA1 hashing of archive files\\n1000-10000000\\n1024-131072\\n1-20\\nAutomatic Log Source Configuration (sFlow Sources). When enabled, the Data Processor automatically registers new message sources for sFlow sending devices which can be automatically identified.\\nAutomaticLogSource ConfigurationSNMPTimeout\\n1-120\\nAutomatic Log Source Configuration (SNMP Trap Sources). When enabled, the Data Processor automatically registers new message sources for SNMP trap sending devices which can be automatically identified.\\nAutomatic Log Source Configuration (Syslog Sources). When enabled the Data Processor\\xa0 automatically registers new message sources for syslog sending devices which can be automatically identified.\\nDirectory (full path) where the inactive archive files are written. If the requested directory does not exist, it is created.\\nInactive archive protection mode\\nFile size and last modification date tracking\\nNo Protections\\nFull SHA1 hashing of archive files\\nThe maximum amount of space (in GB) to be used by the Unprocessed Log Disk Queue. A value of 0 indicates no maximum.\\nA warning event is written when 80% of the specified space is used. If the maximum is reached, the mediator goes into suspend mode.\\nIf set to TLS 1.0, the Mediator generates a 1024-bit key.\\nIf set to TLS 1.2, the Mediator generates a 2048-bit key.\\nThe minimum amount of space (in GB) that must be available on the volume that the Unprocessed Log Disk Queue spool files are being written to.\\nIf the minimum is reached, the mediator goes into suspend mode.\\nAn external facing IP address that an Agent can use to connect to the Mediator. This IP address will be used by Agents when they can't connect using the Primary Server IP address (ServerIP). The Secondary Server IP/Port must be forwarded to the Primary Server IP/Port by a firewall or router.\\nThis parameter must be a static IP v4/v6 address with a maximum length of 45 or a DNS name with a maximum length of 255. DNS names are only supported for version 6.x System Monitors and later.\\nYou must configure your firewall or router to forward this IP/Port to the Primary Server. This is important for deployments that use NAT.\\nThe external facing IP port to use with the Secondary Server IP address. The Secondary Server IP/Port must be forwarded to the Primary Server IP/Port by a firewall or router.\\nDNS address that agents will use to connect to this Data Processor. If this parameter is not specified, Agents uses the ServerIP address to connect to this Data Processor.\\nIf you created custom certificates for the Mediator, this must match the DNS name specified in the custom certificate.\\nAn external facing IP address or DNS name that an Agent outside the network can use to connect to the Mediator. This IP address will be used by Agents when they can't connect using the Primary or Secondary Server IP addresses (ServerIP/SecondaryServerIP). The Tertiary Server IP/Port must be forwarded to the Primary Server IP/Port by a firewall or router. This parameter must be a static IP v4/v6 address with a maximum length of 45 or a DNS name with a maximum length of 255. DNS names are only supported for version 6.x System Monitors and later.\\nYou must configure your firewall or router to forward this IP/Port to the Tertiary Server. This is important for deployments that use NAT.\\nThe external facing IP port to use with the Tertiary Server IP address. The Tertiary Server IP/Port must be forwarded to the Primary Server IP/Port by a firewall or router.\\nThe directory where Data Processor unprocessed log disk queue spool files are written.\\nThe default directory is the mediator state folder. After changing the directory location, any remaining spool files must be manually moved to the new location.\\nThis value determines how often (in seconds) batches are submitted to the Platform Manager database for insertion.\\nMax Insert Batch is determined at startup by the Max Insert Rate and Batch Interval.\\nThe directory where Platform Manager Insert Manager disk queue spool files are written.\\nThe default directory is the mediator state folder. After changing the directory location, any remaining spool files must be manually moved to the new location.\\nThe maximum amount of space (in GB) to be used by the PM Insert Manager Disk Queue. A value of 0 indicates no maximum.\\nA warning event is written when 80% of the specified space is used. If the maximum is reached, the oldest spool files are deleted until the space used by the spool files is less than the specified maximum.\\nThis value determines the maximum number of Platform Manager logs that will be inserted per second. The insertion rate will not exceed this value. Note that this value is based on the performance profile of the system.\\nThe minimum of amount of space (in GB) that must be available on the volume that the PM Insert Disk Queue spool files are being written to.\\nIf the minimum is reached, the oldest spool files are deleted until the space used by the spool files is above the specified minimum.\\nSpecify the size for each log distribution receiver queue. Every receiver has its own queue. If this queue reaches maximum size, logs will be dropped. However setting queue size too high could result in excessive memory utilization.\\nSpecify the size of primary log distribution queue. If this queue reaches maximum size, logs will be dropped. However setting queue size too high could result in excessive memory utilization.\\nEnforce Agent Certificate Revocation Check. If this fails, the Mediator will disconnect from the Agent and logs will be written to the scmedsvr.log.\\nEnforce Agent certificate Trusted Authority Check. If this fails, the Mediator will disconnect from the Agent and logs will be written to the scmedsvr.log.\\nSpecifies the level of compression to apply to data and indices.\\nThis is obsolete in the current version and changing its value has no impact on indexing and compression.\\nSetting this property to false reduces data transmission volume at the cost of normalizing enumerable values. Metadata fields such as Log Source Type and Common Event will be presented as ID numbers instead of readable text. Disabling this feature decreases the usability of downstream features such as Log Distribution Service and full text search.\\nIP\\xa0to Name DNS\\xa0resolution mode.\\nValues: Off, Resolve All, Resolve Internal\\nResolve IP\\xa0addresses to their associated DNS\\xa0names.\\nDNSResolveMsgSourceHostIP\\nThe level of detail to resolve for Geographic IP lookup.\\nOptions = None, Country, Region, and City. If this is left set to None, GeoIP location will not be resolved for logs or Network Visualization.\\nSets the MPE\\xa0logging level (log written to scmpe.log).\\nOptions: Off, Error, Warning, Info, Verbose,\\xa0Debug\\nStatkeeperCommitInterval HeartbeatInfo\\nStatKeeperCommitIntervalLogInfo\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nData Processor\\n', 'Modify Data Processor Basic Properties': 'To modify the basic properties of a data processor:\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nData Processors\\ntab.\\nDouble-click the Data Processor you want to configure.\\nFind the component you want to configure and adjust the settings in the Value column according to the information in the following table.\\nProperty\\nDescription\\nHost\\nThe host where the Data Processor software physically resides.\\nTo select a different host, click the selector icon to the right of the Host box. Select the host, and then click\\nOK\\n.\\nPlatform\\nThe platform for the Data Processor.\\nTo select a different platform, click the selector icon to the right of the Platform box. Select the platform, and then click\\nOK\\n.\\nGen6 hardware platforms are available in KB versions greater than 7.1.679.0.\\nData Processor Name\\nA unique name for the Data Processor. The name cannot be the same as an existing or previously deleted Data Processor. If you are connecting to an existing host with a Data Processor, the Data Processor field is populated.\\nCluster Name\\nIf this is the first machine in the cluster, enter a name for the cluster.\\nIf this is not the first machine in the cluster, select a cluster name from the list.\\nData Processor Pool Name\\nIf the Data Processor is in a DP Pool, select the DP Pool from the list. For more information, see\\nData Processor Pooling\\n.\\nOperating Mode\\nOffline\\n. The Data Processor is unavailable for use.\\nOnline Active\\n. The Data Processor is online for active log data collection and analysis. (Default)\\nOnline Archive\\n. The Data Processor is online for use in archive restoration and analysis.\\nMessage Processing Engine Settings\\nEnabled by default\\n:\\xa0This tells the MPE to actively process logs coming from this Data Processor.\\nDisabled by default\\n: This value is used by the Message Processing Engine to determine whether the MPE should forward messages to the Platform Manager. If checked, the MPE does not forward any events to the Platform Manager, regardless of the MPE Rule configuration. This setting can be used to disable all event forwarding.\\nHeartbeat Warning Interval\\nThe number of seconds that a heartbeat signal from this Agent can be late by, before a Missing Heartbeat Warning event is generated. Warnings continue to be generated, at this interval, until a heartbeat is successfully received. Default: 60\\nThis property must have a different setting than the AE_HeartbeatMonitorInterval property set in Modify Platform Manager Advanced Properties to prevent unpredictable behaviour.\\nLicense Status\\nThe current status of licensing for the selected Data Processor.\\nFind the component you want to configure and adjust the settings in the Value column according to the information in the following table.\\nProperty, Description\\nHost, The host where the Data Processor software physically resides.To select a different host, click the selector icon to the right of the Host box. Select the host, and then clickOK.\\nPlatform, The platform for the Data Processor.To select a different platform, click the selector icon to the right of the Platform box. Select the platform, and then clickOK.Gen6 hardware platforms are available in KB versions greater than 7.1.679.0.\\nData Processor Name, A unique name for the Data Processor. The name cannot be the same as an existing or previously deleted Data Processor. If you are connecting to an existing host with a Data Processor, the Data Processor field is populated.\\nCluster Name, If this is the first machine in the cluster, enter a name for the cluster.If this is not the first machine in the cluster, select a cluster name from the list.\\nData Processor Pool Name, If the Data Processor is in a DP Pool, select the DP Pool from the list. For more information, seeData Processor Pooling.\\nOperating Mode, Offline. The Data Processor is unavailable for use.Online Active. The Data Processor is online for active log data collection and analysis. (Default)Online Archive. The Data Processor is online for use in archive restoration and analysis.\\nMessage Processing Engine Settings, Enabled by default:\\xa0This tells the MPE to actively process logs coming from this Data Processor.Disabled by default: This value is used by the Message Processing Engine to determine whether the MPE should forward messages to the Platform Manager. If checked, the MPE does not forward any events to the Platform Manager, regardless of the MPE Rule configuration. This setting can be used to disable all event forwarding.\\nHeartbeat Warning Interval, The number of seconds that a heartbeat signal from this Agent can be late by, before a Missing Heartbeat Warning event is generated. Warnings continue to be generated, at this interval, until a heartbeat is successfully received. Default: 60This property must have a different setting than the AE_HeartbeatMonitorInterval property set in Modify Platform Manager Advanced Properties to prevent unpredictable behaviour.\\nLicense Status, The current status of licensing for the selected Data Processor.\\nThe host where the Data Processor software physically resides.\\nTo select a different host, click the selector icon to the right of the Host box. Select the host, and then click\\nOK\\n.\\nThe platform for the Data Processor.\\nTo select a different platform, click the selector icon to the right of the Platform box. Select the platform, and then click\\nOK\\n.\\n\\nGen6 hardware platforms are available in KB versions greater than 7.1.679.0.\\nData Processor Name\\nA unique name for the Data Processor. The name cannot be the same as an existing or previously deleted Data Processor. If you are connecting to an existing host with a Data Processor, the Data Processor field is populated.\\nIf this is the first machine in the cluster, enter a name for the cluster.\\nIf this is not the first machine in the cluster, select a cluster name from the list.\\nOffline\\n. The Data Processor is unavailable for use.\\nOnline Active\\n. The Data Processor is online for active log data collection and analysis. (Default)\\nOnline Archive\\n. The Data Processor is online for use in archive restoration and analysis.\\nEnabled by default\\n:\\xa0This tells the MPE to actively process logs coming from this Data Processor.\\nDisabled by default\\n: This value is used by the Message Processing Engine to determine whether the MPE should forward messages to the Platform Manager. If checked, the MPE does not forward any events to the Platform Manager, regardless of the MPE Rule configuration. This setting can be used to disable all event forwarding.\\nThe number of seconds that a heartbeat signal from this Agent can be late by, before a Missing Heartbeat Warning event is generated. Warnings continue to be generated, at this interval, until a heartbeat is successfully received. Default: 60\\nThis property must have a different setting than the AE_HeartbeatMonitorInterval property set in Modify Platform Manager Advanced Properties to prevent unpredictable behaviour.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nDeployment Health\\n', 'Centralized Service Metrics': '\\nCustomers can now tell when their services are down, memory is too high, and CPU is spiking for each system in their deployment or for their deployment as a whole. Using Kapacitor, an alerting engine that works with InfluxDB, customers can set up alerts to let them know when their LogRhythm system is not performing well.\\nThis feature is enabled by default as part of the Common Components installation. The Metrics Collection service are installed on all components you wish to collect metrics from. The Metrics Database and Metrics Web UI services are installed on only one server in the deployment, the Platform Manager.\\nThis feature was created to give us an out-of-band solution to display health of the LogRhythm deployment. It will speed up troubleshooting on issues because we can look at the deployment as a whole rather than individual pieces of it.\\n', 'LogRhythm Services': 'There are three services associated with Metrics Collection. The Metrics Collection service is pushed out as part of the Common Components installation. The Metrics Database and Metrics Web UI services are installed on the Platform Manager. Metrics Collection is the service that gathers all the metrics from the server it is installed on and sends them to the Metrics Database to store. The Metrics Database stores the data for a default length of seven days and the Metrics Web UI retrieves the data when a dashboard is configured to view the metrics.\\n', 'Metrics Collection': 'The Metrics Collection service utilizes Telegraf to collect performance metrics from the system it runs on. It listens for StatsD formatted metrics on the local host over UDP port 8125 for Windows servers only. It collects system information such as Disk, RAM, CPU, and Port metrics on all systems. It then forwards these metrics to the Metrics Database over TCP port 8076.\\n', 'Metrics Database': 'The Metrics Database service listens externally on port 8076 for the traffic coming from the Metrics Collection service. It utilizes InfluxDB as a persistence layer for time-series metrics and stores them for a default of seven days in 8.0.0. This storage amount may be increased in a future release.\\n', 'Metrics Web UI': 'The Metrics Web UI shows all the gathered data. It utilizes Grafana to display and explore the data.\\n', 'Dashboards': 'The LogRhythm Metrics Services provides dashboards for the following components and services:\\nAIE\\nCase API\\nCase API Endpoints\\nHardware Usage\\nCase API Endpoints\\nHardware Usage\\nCommon\\nDeployment View\\nSingle Host View\\nMetrics Health Service\\nDeployment View\\nSingle Host View\\nMetrics Health Service\\nOpen Collector\\nPipeline\\nLog Distribution Services\\nMediator\\nLog Distribution Services\\nMediator\\nPlatform Manager\\nAIE Auto Cache Drill Down\\nNotification Service\\nAIE Auto Cache Drill Down\\nNotification Service\\nWeb Indexer\\n', 'Logs': 'The logs for all Common Components are handled by procman-beta so old log files are cleaned up. The most you should have on a system per service is 50MB.\\nLogs for Metrics Collection are located in C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Common\\\\logs. The LogRhythm Metrics Collection.log is available on all LogRhythm appliances.\\nLogs for LogRhythm Metrics services are located at C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Metrics\\\\logs. The LogRhythm Metrics Database.log and LogRhythm Metrics Web UI.log are only available on one server in your deployment, usually the Platform Manager.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nDeployment Health\\n', 'Deployment Monitor': '\\nThe Deployment Monitor provides Global Administrators with a near-real-time view of the performance of LogRhythm and the hosts where its components run.\\nEach LogRhythm Deployment panel tab contains a grid that displays descriptive, statistical, and status information for the deployment or the specific component type. The contents of each grid are refreshed every 30 seconds. The tabs are:\\nComponent Status\\n. The Component Status tab shows the health of each component in a LogRhythm deployment. It always lists systems running Data Processor and Platform Manager services as part of this deployment.\\nData Processors\\n. The Data Processors tab shows the health of the Data Processors.\\nAI Engines\\n. The AI Engines tab shows the health of the AI Engines.\\nCollectors\\n. The Collectors tab shows the health of the Collectors. Collectors are Agents which act as an aggregation point for log collection. These Agents collect data from remote, non-local log sources.\\nSystem Monitors\\n. The System Monitors tab shows the health System Monitor Agents and Hosts. These Agents only collect data from their local host. An Agent which is not a Collector is referred to as a Host or System Monitor.\\nLog Sources\\n. The Log Sources tab shows the health of the Log Sources.\\nClusters\\n. The Clusters tab shows the names of the cluster in the deployment and their status.\\nNodes\\n. The Nodes tab shows the nodes associated with this deployment and information related to them.\\n', 'Component Status': 'The Component Status tab shows the health of each component in a LogRhythm deployment. It always lists systems running Data Processor and Platform Manager services as part of this deployment. By default, the Hosts pane shows any hosts running a System Monitor Agent with a status of Critical, Warning, Notice, or Normal.\\n', 'Missing Heartbeat Detection': \"The Data Processor, Agent, AI Engine, and AI Comm Manager actively monitor themselves and Agents for a heartbeat signal at regular intervals. After receiving the signal, the database is updated with a time stamp of the last successful signal from that component. The Job Manager service regularly checks the amount of time that passed since the last successful heartbeat from each component and compares it with the component's unique Heartbeat Warning Interval setting.\\nIf a Heartbeat is not received for one full Heartbeat Warning Interval, the Last Heartbeat field is yellow.\\nIf a Heartbeat is not received for two full Heartbeat Warning Intervals, the Last Heartbeat field is red.\\nFor some components, the Heartbeat Warning Interval can be modified:\\nData Processor\\n. The Heartbeat Warning Interval can be set between 60 seconds and 86,400 seconds (1 day). To learn how to change this, see\\nModify Data Processor Basic Properties\\n.\\nPlatform Manager\\n. The Heartbeat Warning Interval cannot be changed. The default is 60 seconds.\\nSystem Monitor Agent\\n. The Heartbeat Warning Interval can be set between 1 minute and 30 days. To learn how to change this, see\\nModify System Monitor Basic Properties\\n.\\nAI Engine and AI Comm Manager\\n. The Heartbeat Warning Interval cannot be changed. The default is 60 seconds.\\nLog Sources\\n. These do not have heartbeats. Instead, they use Silent Log Message Source Detection.\\nIf the expected reporting time is greater than the Heartbeat Warning Interval, a Missing Heartbeat Warning event is generated. The warnings continue to be generated each time an additional Heartbeat Warning Interval passes without a signal. After a heartbeat is received from the component, a Heartbeat Returned event is generated and the system again waits for a missing heartbeat condition.\\nSet a reasonable Heartbeat Warning Interval. Take special notice of systems that reside on non-persistent connections or are removable from the network, such as notebook computers.\\n\", 'Alarms': 'In order to receive an Alarm on missing heartbeats, you must\\nCreate Alarm Rules\\n. There are several predefined rules that are part of the LogRhythm Diagnostics module to alarm on missed heartbeats for the AI Comm Manager, AI Engine, Data Processor, and Agent.\\n', 'LogRhythm System Metrics': 'This chart shows the System Metrics by Data Processor.\\nPlatform Manager Database Util %\\nEMDB Utilization\\nEventDB Utilization\\nAlarmDB Utilization\\nLogMartDB Utilization\\nCMDB Utilization\\nEMDB Utilization\\nEventDB Utilization\\nAlarmDB Utilization\\nLogMartDB Utilization\\nCMDB Utilization\\nSystem Metrics by Data Processor\\nUnprocessed Queue % Full\\nLog Processing Queue % Full\\nArchive Queue % Full\\nGLPRs Hit %\\nEM Realtime Insert Queue % Full\\nEM Disk Insert Queue % Full\\nLogMart Heap % Full\\nUnprocessed Queue % Full\\nLog Processing Queue % Full\\nArchive Queue % Full\\nGLPRs Hit %\\nEM Realtime Insert Queue % Full\\nEM Disk Insert Queue % Full\\nLogMart Heap % Full\\n', 'Log Volume by Day': 'This chart shows Log Volume Statistics by Day for the Past Month.\\nEach graph shows the following types of logs:\\nProcessed Logs\\nArchived Logs\\nIndexed Logs: Online Logs\\nEvents: logs that have been promoted to events\\nAlarms\\nLogMart\\nBy default the graph is in a logarithmic scale, which helps compress the graph in deployments that fluctuate log volume greatly.\\nUse the context menu to display:\\nIndexed Logs\\nEvent Data\\nUnidentified Logs\\nLogMart\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nDeployment Health\\n', 'Log Processing Reports': '\\nThe MPE, a component of the Mediator Server service, keeps a record of how many times a rule has been compared to a log message and the total amount of time spent processing logs against each rule. This is accomplished by writing two logs: lps_detail.log which generates detailed statistics for a log processing policy for a given period of time; lps_policysortingstats.log which compiles a log per second rate of the policy over time. These reports give valuable input into system performance and the efficiency of rules being used in processing.\\nTo send your report to LogRhythm automatically, configure the following parameters in the MPE component, and General group, of the\\nModify Data Processor Advanced Properties\\n.\\nComponent, Group, Parameter Name, Value Type, Description\\nMPE, General, LogLevel, VerboseDebug, Sets the MPE\\xa0logging level (log written to scmpe.log).Options: Off, Error, Warning, Info, Verbose,\\xa0DebugFor lps_detail.log only, set LogLevel toVerbose.For both reports, set LogLevel toDebug.\\nMPE, General, SubmitDiagnosticsInterval, Integer, How often to submit diagnostic information to LogRhythm (in hours). Enter0to disable sendingdiagnostic information or1-24to send diagnosticinformation. Default:0\\nMPE, General, RulePerformanceStatsMode, OffLocalLocal and Send, Default: OffRule performance statistics mode:Off. Do not write report (lps_detail.log or lps_policysortingstats.log) or data file (lps_stats.dat) locally or submit to LogRhythm (default).Local. Write the report (lps_detail.log or lps_policysortingstats.log) and data file (lps_stats.dat) locally.Local and Send. Write the Report (lps_detail.log or lps_policysortingstats.log) and data file (lps_stats.dat) locally and submit to LogRhythm.The MPE LogLevel must also be set.\\nMPE, General, RulePerformanceStatsSubmitInterval, 1-24, Default: 12How often to submit rule performance information to LogRhythm (in hours). The latest lps_detail.log and lps_stats.dat files are submitted each interval.\\nDescription\\nVerbose\\nDebug\\nSets the MPE\\xa0logging level (log written to scmpe.log).\\nOptions: Off, Error, Warning, Info, Verbose,\\xa0Debug\\nFor lps_detail.log only, set LogLevel to\\nVerbose\\n.\\nFor both reports, set LogLevel to\\nDebug\\n.\\nInteger\\nHow often to submit diagnostic information to LogRhythm (in hours). Enter\\n0\\nto disable sending\\ndiagnostic information or\\n1\\n-\\n24\\nto send diagnostic\\ninformation. Default:\\n0\\nOff\\nLocal\\nLocal and Send\\nDefault: Off\\nRule performance statistics mode:\\nOff\\n. Do not write report (lps_detail.log or lps_policysortingstats.log) or data file (lps_stats.dat) locally or submit to LogRhythm (default).\\nLocal\\n. Write the report (lps_detail.log or lps_policysortingstats.log) and data file (lps_stats.dat) locally.\\nLocal and Send\\n. Write the Report (lps_detail.log or lps_policysortingstats.log) and data file (lps_stats.dat) locally and submit to LogRhythm.\\nThe MPE LogLevel must also be set.\\nDefault: 12\\nHow often to submit rule performance information to LogRhythm (in hours). The latest lps_detail.log and lps_stats.dat files are submitted each interval.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nDeployment Health\\n', 'Performance Counters': '\\nLogRhythm has implemented performance counters within its Windows service components to provide visibility into their performance. This topic includes descriptions for the performance counters and guidance in how to interpret them to evaluate component performance.\\nWindows performance counters provide parameters within a Microsoft Windows operating system or Windows applications / services that can be monitored in real-time. Typically, the Microsoft Performance Monitor application is used to monitor and chart performance counter data in real-time. The data is also frequently used by third party monitoring systems to gauge the health of computer systems and the applications running on them\\nPerformance Monitoring can be accessed via Administrative Tools or by typing perfmon at the command prompt.\\n', 'Performance Monitoring': 'You use performance counters primarily for diagnosing application performance or a specific error.\\nWindows performance counters allow you to monitor specific parameters in a Microsoft Windows operating system or Windows applications / services in real-time. Typically, the Microsoft Performance Monitor application is used to monitor and chart performance counter data in real-time. Performance counter data is also frequently used by third party monitoring systems to gauge the health of computer systems and the applications running on them.\\nLogRhythm implemented performance counters within its Windows service components to provide visibility into their performance.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nDeployment Security\\n', 'Enhanced Auditing': 'Enhanced Auditing is a shadow table with a system of triggers and tables that can be implemented to track all database table inserts, updates, and deletions. The system captures the name of the user, the type of update, the date and time of the update, and changes to the data in each record. Auditing is done at the record level.\\nLogRhythm Enhanced Auditing is enabled and supported by default for a particular group of tables that monitor administrative actions in LogRhythm.\\xa0 A setup to collect data from each shadow table to log the audit information directly into the SIEM must be established. Users can create dashboards, reports, and alarms around LogRhythm Administrative actions with the data collected from shadow tables.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nDeployment Security\\n', 'Least Privileged User': 'Current best practices dictate that all software be deployed with minimal user/account privileges. The Least-Privileged User approach helps reduce the potential impact if an attacker were to compromise a particular system or user account. This document describes the privilege footprint for typical LogRhythm deployments and provides guidance on how to restrict user permissions.\\nThe LogRhythm SIEM runs as a set of services to support scalability and process isolation. Each service can run under a unique security context to enable greater flexibility in tuning privileges.\\n', 'Software Version': 'This document applies to the LogRhythm SIEM version 7.14.x. Future versions of LogRhythm may require additional changes or configuration settings based on new features.\\nUnless otherwise stated, settings may also be applicable for 6.3.8 and 6.3.3 installations. Earlier installations may have slight variations or may not have specific features in the System Monitors.\\n', 'LogRhythm Security Certifications': 'The LogRhythm SIEM runs as a set of independent services to support process isolation and scalability. Each service can run under a unique security context. This provides granularity of privilege assignment, along with the assurance that the service can only perform the functions for which it has been granted permission.\\nBoth LogRhythm SIEM appliances and LogRhythm Software Solutions (LRSS) have a certified security policy applied during the build process as part of the standard LogRhythm hardening process. LogRhythm is also proud to hold the following certifications:\\n', 'Version 6.3.4': 'Defense Information System Agency (DISA) Security Technical Implementation Guide (STIG)\\nCommon Criteria EAL2+ (VID#10389)\\nFIPS 140-2\\nU.S. Army Certificate of Networthiness (CoN)\\n', 'Version 7.1.X': 'Although certifications have not been attained at this time, LogRhythm still provides guidance and configuration to support evaluation against each of the certifications listed in the previous section.\\n', 'Version 7.2': 'Defense Information System Agency (DISA) Security Technical Implementation Guide (STIG)\\nCommon Criteria EAL2+ (VID#10389)\\nFIPS 140-2\\nU.S. Army Certificate of Networthiness (CoN)\\nSeveral of these security standards have a direct impact on user privilege and may meet the needs of your enterprise without further changes. If you have questions about any of these certifications, contact LogRhythm for the current guidelines and certification statements.\\n', 'LogRhythm Account Types': 'A LogRhythm SIEM deployment contains the following types of user contexts:\\nPlatform Manager (PM) Version 7 (Formerly Event Manager)\\n. The Platform Manager provides alarming, notifications, case and security incident management, workflow automation, and centralized administration for a LogRhythm deployment. The Platform Manager can include an embedded AI Engine instance, a Web Console, or both. The Platform Manager is a required component in the LogRhythm solution, and each deployment has a single Platform Manager.\\nData Processor (DP) Version 7 (Formerly Log Manager)\\n. The Data Processor provides high-performance, distributed, and highly available processing of machine and forensic data. Data Processors receive machine and forensic data from collectors and forensic sensors. The Data Processor archives data and distributes both the original copy and the structured copy to other LogRhythm components for indexing, machine-based analytics, and alarming.\\nData Indexer (DX) Version 7 (Formerly Log Manager)\\n. The Data Indexer provides high-performance, distributed, and highly scalable indexing and searching of machine and forensic data. Data Indexers store both the original and structured copies of data to enable search-based analytics.\\nIn LogRhythm 7.1.4, the communication between the Data Processor and Data Indexer was improved, resulting in increased resiliency to data spikes and reliability of message delivery. These changes impact least privilege, as extra services were created and ports were changed.\\nSystem Monitor Agents\\n. LogRhythm System Monitor Agents are deployed on systems that require forensic monitoring, or to read logs from target systems in a scalable fashion. Agents are more difficult to lock down, as the privilege footprint can vary depending on which endpoint areas are being monitored and how the Agent is configured to collect data.\\nLogRhythm Users\\n. Users who access the LogRhythm SIEM are already configured to have minimal privileges on any LogRhythm-related system. These users are also already linked to LogRhythm-generated security roles in the LogRhythm data stores.\\n', 'LogRhythm Security/Trust Boundaries': 'When evaluating least privilege, it often helps to understand the security zones or trust boundaries from a system perspective. For the LogRhythm SIEM, boundaries can vary by deployment footprint, but can be generalized.\\nDepending on the exact deployment footprint, the zones can collapse onto a single server (including the Agent), or be distributed across many servers, networks, and endpoint devices. In a large deployment, multiple appliances may be used, and certain data stores (for example, Report Archives or Inactive Log Archives) may be offloaded to separate storage systems not shown in Figure 1.\\nIn terms of securing permissions, user privilege must be considered both within a zone and between zones. If permission is required to leave a security zone, then the privilege must be considered a higher threat, as it may enable the expansion of an attack if a malicious user has compromised a particular account.\\n', 'Map Accounts to Security Boundaries': 'Services deployed on a Platform Manager, Data Processor, or Data Indexer (or colocated on an XM) are considered to be inside a LogRhythm-specific security zone. This zone is usually a set of one or more appliance devices provided by LogRhythm. Agents can be deployed on a wide variety of systems outside the XM zone, and, depending on the network topography, may be in multiple, differing security contexts. Based on feature usage and deployment pattern, some LogRhythm services may require access to remote hosts or other systems that have no LogRhythm software installed.\\nAccount, XM, System Monitor Agent Host, Remote Host, Other\\nPlatform Manager, Data Indexer, Data Processor\\nJob Manager, Local Files Registry EMDBs, Report Archive, N/A, Log Database, N/A, N/A, Report Archive1ADSync2\\nARM, Local Files Registry EMDBs, N/A, N/A, N/A, SmartResponse2, SmartResponse2\\nAIE, Local Files Registry EMDBs, N/A, Mediator, N/A, N/A, N/A\\nAIE Communication, Local Files Registry EMDBs, N/A, Mediator, N/A, N/A, N/A\\nClient Console, Local Files Registry EMDBs, Columbo, Mediator Log Databases, N/A, N/A, N/A\\nWeb Console, Local Files Registry EMDBs, Columbo, Mediator Log Databases, N/A, N/A, N/A\\nMediator Server, AIE EMDBs, , Local Files Registry Log Databases Archives, N/A, N/A, Archives1\\nSystem Monitor Agent (all platforms), N/A, N/A, N/A, Local Files Registry End Point Protection, Log Files2, Third-Party Systems2\\nData Indexer Services, Columbo, Bulldozer, Carpenter, All services, , N/A, N/A, N/A\\n1 Applies only if function is offloaded from DP/PM/LM/EM environment\\n2 Applies only if enabled\\n', 'Privilege Types': 'Each user context requires access to certain resources. To run in a Least-Privileged mode, each context should be locked down to only allow access to named resources. This section provides an overview of the types of resources required by LogRhythm services.\\n', 'Shared Resource Access': 'Various LogRhythm components read and/or write to file locations or UNC paths on local machines, and, in some cases, to remote machines or remote file shares. In certain cases (for example, SmartResponse), the component may even need to execute scripts or software stored in the file share. Shared resource permissions are defined as a combination of the explicit file path and six standard permissions for Windows folders:\\nRead\\n. Grants permission to list the contents of the directory and read the contents of any files in the directory.\\nWrite\\n. Grants permission to add files to the directory and write to files.\\nRead and Execute\\n. Grants permission to read and execute files in the directory. Note that, depending on the nature of the executable files, this may cause privilege escalation.\\nModify\\n. Grants permission to modify the folder structure by creating, renaming, or removing subfolders.\\nFull Control\\n. Grants the account full control (all permissions) over the resource.\\nChildren Inherit\\n. Determines that child folders should inherit the permissions of the parent.\\nAlmost every LogRhythm service that requires shared resource access has a configurable path for the resource. By default, the resources are placed in a local installation directory. You can change the locations using either the service-specific configuration tool or the Advanced Properties options in the Console’s Deployment Manager.\\n', 'Windows Registry Access': 'For LogRhythm components that require local or remote Windows Registry access, the permissions are defined by the registry key name and the 11 different standard Windows Registry permissions:\\nRead Control\\n. Grants permission to read the DACL (Discretionary Access Control List), which is generally required to identify which users have permissions.\\nWrite Owner\\n. Grants permission to modify the container’s owner.\\nWrite DAC\\n. Grants permission to change the permissions on the DACL. Delete – Grants permission to delete a key.\\nCreate Link\\n. Generally not applicable; reserved by the operating system.\\nNotify\\n. Grants permission to request change notifications for registry keys or subkeys.\\nEnumerate SubKeys\\n. Grants permission to iterate through any subkeys.\\nSet Value\\n. Grants permission to set a value on the current object.\\nQuery Value\\n. Grants permission to query a value on the current object.\\nFull Control\\n. Grants full control (all permissions) over registry key.\\nChildren Inherit\\n. Determines that child keys should inherit the permissions.\\nIf you are not familiar with setting advanced registry permissions, you can reach the settings by performing the following actions:\\nStart Registry Editor (note: Admin permissions are required to make changes).\\nFind the target key.\\nRight-click the key, and then click\\nPermissions\\n.\\nIn the Permissions dialog box, click\\nAdvanced\\n.\\nIn the Advanced Security Settings panel, click the\\nEffective Permissions\\ntab.\\n', 'Database Access': 'LogRhythm accounts only access the LogRhythm databases (EMDB, Data Indexer, etc.). By default, all database access is controlled through database accounts created during the installation and configuration of the LogRhythm software. Each account is tied to a database role that is defined in the setup scripts.\\nAll LogRhythm database access requires the default SQL Server port 1433.\\nIt is imperative to change all default passwords on initial deployment.\\n', 'Communication (Ports)': 'LogRhythm services communicate with each other through a combination of reading/writing database values, and also through encrypted communication via network ports. If per-user, port-level security is required, permissions can be defined for each account based on the types and targets of communication and the default port numbers.\\n', 'Other Resources': 'In certain cases, LogRhythm services may require elevated or extra permissions to access other resources such as third-party applications or specific system services. These requirements are noted as “Other Resources.”\\nFor example, Agents can be configured to perform remote event log collection. This access may require creating accounts or adjusting privileges on the third-party system and linking the Agent security context to those accounts.\\n', 'Prerequisites': 'LogRhythm runs on software and systems provided by third parties, including Microsoft, Oracle, and others. Each of these systems may have additional privilege or requirements not explicitly discussed in this document.\\nOf special note, all Windows-based services require access to the .NET Framework. However, none of the services use custom assemblies stored in the GAC.\\n', 'Approaches to Least Privilege': 'As with all security policies, choosing the right balance of risk, functionality, and complexity depends heavily on the risk tolerance and standard policies of your company or agency. The approaches listed here are recommendations only, and they may or may not be appropriate given your particular policies, risk tolerance, deployment architecture, and IT staff levels\\n', 'Define Required Functionality': 'As a general rule, if a function is not absolutely required, consider configuring all systems to block that function. With this in mind, the first step of any least-privilege setup is to determine which features are required to meet your business requirements. With regard to LogRhythm, the main questions will include:\\nCore Services\\nDo you need core services configured for high availability or disaster recovery?\\nDo you offload log storage, reports, or any other state information from the application servers?\\nDo you require a file-based notification system?\\nDo you leverage SmartResponse? If so, do you execute from the Platform Manager or through the System Monitors?\\nData Processors\\nDo you require offloaded archives?\\nDoes your Data Processor provide Log Distribution Services (LDS)?\\nAgents\\nWhich log sources will each Agent collect from?\\nWill any Agent collect logs from remote sources?\\n', 'Isolate LogRhythm': 'As shown in Table 3, all LogRhythm components except for Agents can be deployed in an isolated security zone. The default appliance-based deployment uses local system accounts for this reason, as none of the services require access to non-LogRhythm equipment.\\nAgents can be deployed under a user context that is as restrictive as possible based on the type of information collected. See the Agent section for your specific operating system details.\\n', 'Leverage Active Directory Accounts': 'If your environment requires the use of service accounts managed by Active Directory, best practice is to lock down the permissions for each service according to the guidance provided later in this document.\\n', 'UNIX/Linux Agents': 'The *nix-based systems require different permissions because of the underlying operating system. By default, the *nix Agents are deployed to run under root because of the requirement to access port 514 to gather Syslog data.\\nTo run a *nix Agent with non-root privileges, see the current instructions in the\\xa0LogRhythm SIEM Help.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nDeployment Security\\n', 'Public Key Infrastructure (PKI) Support': 'LogRhythm is Public Key Enabled (PKE) and supports Public Key Infrastructures (PKI). The application supports Common Access Cards (CAC) so users can log in to the LogRhythm Client Console using CAC windows credentials and run the LogRhythm services using CAC certificates for client/server TLS communications.\\n', 'LogRhythm Component Mutual TLS Authentication': 'LogRhythm services can operate in several modes that allow for increasing levels of security. By default, the SIEM server services (for example, Mediator Server, AIE Communications Manager, SQL Server) use a self-generated server certificate to authenticate themselves to the client components that connect to them — System Monitors, AIE Data Providers, SQL Server clients). By default, the client components do not provide a client certificate to the servers – they are unauthenticated (one-way authentication). A better authentication method employs user-provided server certificates for these server services. The best authentication method employs user-provided server certificates AND user-provided client certificates for the client services — mutual authentication.\\n', 'SIEM Component Default Behavior': 'Server services (LogRhythm and Microsoft SQL Server) use self-generated, self-signed server certificates:\\nThe Mediator service generates a self-signed server certificate at process start-up and uses that to establish TLS connections with System Monitor Agents. The key size depends on the value set for\\nMinAgentSocketSecurity\\nin the\\nData Processor Advanced Properties\\n:\\n2048-bit key, if\\nMinAgentSocketSecurity\\nis set to TLS 1.2\\n1024-bit key, if\\nMinAgentSocketSecurity\\nis set to TLS 1.0\\n2048-bit key, if\\nMinAgentSocketSecurity\\nis set to TLS 1.2\\n1024-bit key, if\\nMinAgentSocketSecurity\\nis set to TLS 1.0\\nThe AIE Communication Manager service generates a self-signed server certificate at start-up and uses that to establish TLS connections with AIE Data Providers.\\nThe Web UI Server service generates a self-signed server certificate at start-up and uses that to establish TLS connections with web clients.\\nThe Common bundle generates a self-signed sever certificate at start-up for TLS connections with LR components.\\nThe SQL Server service generates a self-signed server certificate at process start-up and uses that to establish TLS connections with the LogRhythm components.\\nClient services (System Monitor, AIE Data Provider, SQL Server clients) do NOT present a client certificate when connecting to the server services.\\n', 'User Certificate-based Mutual Authentication': 'Support for user-specified TLS certificates for Windows/UNIX System Monitor Agent (client) and Mediator (server) communications (one- and two-way authentication).\\nSupport for user-specified TLS certificates for AIE Data Provider (client, in the Mediator) and AIE Communication Manager (server) communications (one- and two-way authentication).\\nSupport for user-specified TLS certificates for the Web UI Server (server, nginx) and web clients (browsers).\\nSupport for user-specified TLS certificates for the Data Indexer server.\\nSupport for user-specified TLS certificates for SQL Server (server). This certificate is used to authenticate and encrypt communications between SQL Server and the LogRhythm components: Client and Web Consoles, Mediator, ARM, Job Manager, and AIE Engine. Note that SQL Server does not support client certificates (one-way authentication only).\\n\\nRed\\ncertificates are server certificates and\\nblue\\ncertificates are client certificates.\\n', 'Certificate Deployment Options for SIEM Service TLS Communications': 'Software Component, Client/Server, No Certificate, Self-Generated Certificate, User Certificate\\nSystem Monitor Agent, Client, X, , X\\nMediator Server, Server, , X, X\\nAI Engine Data Provider, Client, X, , X\\nAI Engine Communication Manager, Server, , X, X\\nSQL Server, Server, , X, X\\nData Indexer Server, Server, , X, X\\nTrueIdentity Sync Client, Server/Client, X (Client), , X (server)\\nUser Certificate\\nX\\nX\\nThe certificates need to use the same name as the default certificates.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nDeployment Security\\n/\\nPublic Key Infrastructure (PKI) Support\\n', 'Certificate Configuration for LogRhythm Component Connections': 'LogRhythm and SQL Server support any certificates that the Windows operating system can support, including certificates using SHA1 through SHA512 for the signature algorithm.\\nThis topic provides information about configuring certificate information for LogRhythm components. Please note the following:\\nFor LogRhythm client and server certificates, the Subject name can be the FQDN, short name, or IP address of the host machine.\\nServer certificates must contain the Server Authentication enhanced key usage value (–eku 1.3.6.1.5.5.7.3.1) as well as the key exchange attribute (-sky exchange).\\nBe sure to use a ‘CN=’ before the FQDN or IP address of the Subject for all certificates (SQL Server and LogRhythm client/server). For example: CN=LRDPX1.logrhythm.com\\nEnsure there are no spaces surrounding — or in between — the ‘CN’ and ‘=’ and the Subject (FQDN/Name/IP).\\nEnsure there are no spaces surrounding — or in between — the ‘CN’ and ‘=’ and the Subject (FQDN/Name/IP).\\nEnsure that the client and server certificates have their signing certificate — the Root CA of the certificate — in the Trusted Root Certification Authorities store.\\nEnsure that the client and server certificates have their signing certificate — the Root CA of the certificate — in the Trusted Root Certification Authorities store.\\nPassword-protected certificates are not supported at this time.\\n', 'LogRhythm Mediator Server': 'Mediator Server Certificate Specification Settings\\n. Use the specified server certificate instead of the certificate the Mediator service self-generates and self-signs when the service starts.\\nSystem Monitor Agent Client Certificate Enforcement Settings\\n. Specify whether to require Agents to have certificates when they connect. This is applied to all Agents that connect to the Mediator.\\n', 'AI Engine Data Provider': 'AI Engine Data Provider Client Certificate Specification Settings\\n. This is the client certificate used by the AIE Data Provider (in the Mediator) to authenticate with the AIE Communication Manager (running on AI Engine machine).\\nAI Engine Communication Manager Server Certificate Enforcement Settings.\\n', 'LogRhythm AI Engine Communication Manager': 'AIE Communication Manager Server Certificate Specification Settings\\n. Use the specified server certificate instead of the certificate the AIE Communication Manager self-generates and self-signs when the service starts.\\nAI Engine Data Provider Client Certificate Enforcement Settings.\\n', 'System Monitor': 'Mediator Server Certificate Enforcement Settings.\\nS\\nystem Monitor Client Certificate Specification Settings\\n. This is the client certificate used by the Agent to authenticate with the Mediator Server.\\n', 'LogRhythm Web UI': 'To specify a server certificate for the Web UI Server to use for incoming browser connections on a single Web Console\\nTo open the LogRhythm Configuration Manager, go to\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Configuration Manager\\n.\\nGo to the\\nWeb Console UI\\nsection.\\nClick\\nChoose file\\n.\\nSelect the certificate you want to use.\\nClick\\nSave\\n.\\nFor more information on creating certificates for the Web Console, see Complete Additional LogRhythm Installation Tasks in the\\nLogRhythm Installation Guide\\n.\\nTo specify a server certificate for the Web UI Server to use for incoming browser connections on multiple Web Consoles, specify separate keys for each.\\nGo to\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Web Services\\n.\\nOpen the\\nnginx.conf\\nand\\nnginx.conf.ejs\\nfiles.\\nSpecify both the ssl_certificate and ssl_certificate_key file values:\\nserver {\\nlisten\\n443 ssl;\\nserver_name\\nwww.logrhythm.com;\\nssl_certificate\\nwww.logrhythm.com.crt;\\nssl_certificate_key\\nwww.logrhythm.com.key;\\nssl_protocols\\nTLSv1.2;\\nssl_ciphers\\nAES128-SHA;\\n...\\n}\\nSpecify both the ssl_certificate and ssl_certificate_key file values:\\n, server {, \\n, , listen, 443 ssl;\\n, , server_name, www.logrhythm.com;\\n, , ssl_certificate, www.logrhythm.com.crt;\\n, , ssl_certificate_key, www.logrhythm.com.key;\\n, , ssl_protocols, TLSv1.2;\\n, , ssl_ciphers, AES128-SHA;\\n, , ..., \\n, }, , \\nwww.logrhythm.com.key;\\nTLSv1.2;\\nAES128-SHA;\\n...\\n}\\nRestart the\\nLogRhythm Services Host Service\\nfor the changes to take effect.\\nThe server certificate file is sent to every client that connects to the server. The private key file is a secure object and should be stored with restricted access.\\n', 'Common Components': 'To specify a server certificate for the Common Components, complete the following steps on each node in a cluster.\\nCreate the certificates\\n.\\nThe certificates need to use the same name as the default certificates.\\nCreate the certificates\\n.\\nThe certificates need to use the same name as the default certificates.\\nOn the Platform Manager, go to\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Common\\\\LogRhythm API Gateway\\\\tls.\\nComplete the following steps on server.crt and server.key.\\nDouble-click\\nserver.crt\\n.\\nClick\\nInstall Certificate\\n.\\nClick\\nLocal Machine\\n.\\nClick\\nNext\\n.\\nClick\\nPlace all certificates in the following store\\n: Trusted Root Certification Authorities.\\nClick\\nOK\\n.\\nClick\\nFinish\\n.\\nDouble-click\\nserver.crt\\n.\\nClick\\nInstall Certificate\\n.\\nClick\\nLocal Machine\\n.\\nClick\\nNext\\n.\\nClick\\nPlace all certificates in the following store\\n: Trusted Root Certification Authorities.\\nClick\\nOK\\n.\\nClick\\nFinish\\n.\\n', 'Common Access Card (CAC) Use': \"Work with your Administrator to get details about your organization's certificate authority and client certificates.\\nThe setup of certificates and common access card use must be done by an authorized administrator who understands your organization's network system infrastructure and has the proficiency to set it up correctly.\\nKey Considerations:\\nWhen creating a server certificate for the Mediator, AIE ComMgr, and SQL Server using your ‘root’ certificate, you must run the command with the ‘-sky exchange –eku 1.3.6.1.5.5.7.3.1’ parameter. This enables the certificate to perform Server Authentication which is required for all server certificates including those for the Mediator, AIE ComMgr, and SQL Server. If you don’t create the server certificate with the key exchange attribute specified (-sky exchange –eku 1.3.6.1.5.5.7.3.1) it does not work for the Mediator and the certificate does not show up in the SQL Server configuration Certificates menu. The SQL Server Configuration Manager looks in both LocalMachine and CurrentUser MY stores for certificates to use.\\nWhen creating a server certificate for SQL Server using your ‘root’ certificate, you MUST use the machine FQDN for the Subject. The short hostname or IP address WILL NOT WORK.\\nThe user the Agent service is running under MUST have the LogRhythm Root CA certificate in the LocalMachine’s trusted store (v). This allows the Agent to verify the server certificate presented by the Mediator, AIE ComMgr, and SQL Server.\\nThe user the LogRhythm service (e.g. Agent) is running on MUST have read permissions to the certificate store and certificate(s).\\n\", 'LogRhythm TrueIdentity Sync Client Remote Server': '', 'Create Custom Certificates': 'Create new custom or self-signed certificates. For more information, see\\nCreate Client and Server Certificates\\n. If you are using the self-signed certificates, complete the following using the existing certificates located C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Common\\\\LogRhythm API Gateway\\\\tls.\\n', 'Trust Certificates': 'On the Platform Manager, trust the newly generated certificates.\\nAdd the certificate as a new file to /etc/pki/ca-trust/source/anchors/:\\nCODE\\nsudo cp foo.crt /etc/pki/ca-trust/source/anchors/\\nAdd the certificate as a new file to /etc/pki/ca-trust/source/anchors/:\\nRun\\nCODE\\nsudo update-ca-trust\\nRun\\nTo restart the Sync Client, run\\nCODE\\nsudo systemctl restart LogRhythmTrueIdentitySyncClient\\nTo restart the Sync Client, run\\nGo to\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Common\\\\LogRhythm API Gateway\\\\tls\\n.\\nEnsure the certificates use the same name as the default certificates: server.crt and server.key.\\nDouble-click\\nserver.crt\\n.\\nClick\\nInstall Certificate...\\n, and then click\\nLocal Machine\\n.\\nThis is not the default.\\nClick\\nInstall Certificate...\\n, and then click\\nLocal Machine\\n.\\nThis is not the default.\\nClick\\nNext\\n, and then click\\nPlace all certificates in the following store\\n.\\nSelect\\nTrusted Root Certification Authorities\\n, and then click\\nOK\\n.\\nClick\\nFinish\\n.\\nFor both Windows and Linux, if you have different certificates for your Active Directory, you must add those certificates to the same directory as above and trust the certificates.\\nThe following error messages appear if the certificates are not properly trusted:\\nlevel=warning msg=\"LDAP TLS connection failed, make sure your machine trusts the LDAP Domain Controller\\'s root CA certificate.\"\\nlevel=warning msg=\"TrueIdentity request failed with TLS verification on, make sure your machine trusts the APIG\\'s root CA.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nDeployment Security\\n/\\nPublic Key Infrastructure (PKI) Support\\n', 'Create Client and Server Certificates': 'This topic provides information about creating client and server certificates. Please note the following:\\nFor SQL Server server certificates, the Subject name must be the FQDN of the host machine — IP addresses are not allowed.\\nFor LogRhythm client and server certificates, the Subject name can be the FQDN of the host machine or its IP address.\\nBe sure to put a ‘CN=’ before the FQDN or IP address of the Subject for all certificates (SQL Server and LogRhythm client/server).\\nEnsure there are no spaces surrounding or in between the ‘CN’ and ‘=’ and the Subject (FQDN/IP).\\nEnsure that the client and server certificates have their signing certificate — the Root CA of the certificate — in the Trusted Root Certification Authorities store.\\nIf the LogRhythm TrueIdentity Sync Client is on a remote host, you must generate and trust custom or self-signed certificates on the PM before continuing with configuration.\\nIf you are using the self-signed certificates located in C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Common\\\\LogRhythm API Gateway\\\\tls, follow instructions to trust the certificates. Note that it is recommended you create custom certificates.\\nThe instructions below are examples using openSSL to create certifications in a Windows command prompt.\\nLog onto the machine where your LogRhythm Platform Manager is installed.\\nGo to C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Infrastructure Installer\\\\ssl, and copy the openssl.cfg to this directory.\\nThe openssl.cfg can be found here\\nopenssl.cfg\\n.\\nGo to C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Infrastructure Installer\\\\ssl, and copy the openssl.cfg to this directory.\\nThe openssl.cfg can be found here\\nopenssl.cfg\\n.\\nOpen a command prompt from this location and complete the following:\\nTo create CSR, run\\nCODE\\nopenssl req -out CSR.csr -new -newkey rsa:2048 -nodes -sha256 -keyout privateKey.key -config openssl.cfg\\nTo create a public certificate from CSR and a private certificate, run\\nCODE\\nopenssl x509 -req -days 365 -in CSR.csr -signkey privateKey.key -out LogRhythmSSL.crt -extensions extended -extfile openssl.cfg\\nTo create PFX from the public and private certificates, run\\nCODE\\nopenssl pkcs12 -export -out certificate.pfx -inkey privateKey.key -in LogRhythmSSL.crt\\nTo export the two certificates from PFX, run\\nCODE\\nopenssl pkcs12 -in <certname>.pfx -nocerts -out privateKey.key -nodes\\nopenssl pkcs12 -in <certname>.pfx -nokeys -out LogRhythmSSL.crt\\nTo remove the passphrase from the private key, run\\nCODE\\nopenssl rsa -in privateKey.key -out LogRhythmSSL.pem\\nTo convert p7b format to the certificate, run\\nCODE\\nopenssl pkcs7 -inform (DER|PEM) -print_certs –in <pkcs7_certname>.p7b -out LogRhythmSSL.crt\\nRun the following to ensure all MD5 checksums match\\nCODE\\nopenssl rsa -noout -modulus -in privateKey.key | openssl md5\\nopenssl x509 -noout -modulus -in LogRhythmSSL.crt | openssl md5\\nTo create CSR, run\\nCODE\\nopenssl req -out CSR.csr -new -newkey rsa:2048 -nodes -sha256 -keyout privateKey.key -config openssl.cfg\\nTo create CSR, run\\nTo create a public certificate from CSR and a private certificate, run\\nCODE\\nopenssl x509 -req -days 365 -in CSR.csr -signkey privateKey.key -out LogRhythmSSL.crt -extensions extended -extfile openssl.cfg\\nTo create a public certificate from CSR and a private certificate, run\\nTo create PFX from the public and private certificates, run\\nCODE\\nopenssl pkcs12 -export -out certificate.pfx -inkey privateKey.key -in LogRhythmSSL.crt\\nTo create PFX from the public and private certificates, run\\nTo export the two certificates from PFX, run\\nCODE\\nopenssl pkcs12 -in <certname>.pfx -nocerts -out privateKey.key -nodes\\nopenssl pkcs12 -in <certname>.pfx -nokeys -out LogRhythmSSL.crt\\nTo export the two certificates from PFX, run\\nTo remove the passphrase from the private key, run\\nCODE\\nopenssl rsa -in privateKey.key -out LogRhythmSSL.pem\\nTo remove the passphrase from the private key, run\\nTo convert p7b format to the certificate, run\\nCODE\\nopenssl pkcs7 -inform (DER|PEM) -print_certs –in <pkcs7_certname>.p7b -out LogRhythmSSL.crt\\nTo convert p7b format to the certificate, run\\nRun the following to ensure all MD5 checksums match\\nCODE\\nopenssl rsa -noout -modulus -in privateKey.key | openssl md5\\nopenssl x509 -noout -modulus -in LogRhythmSSL.crt | openssl md5\\nRun the following to ensure all MD5 checksums match\\n\\nThe new certificates are generated.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nEndpoint Monitoring\\n', 'Data Loss Defender (DLD)': 'The Data Loss Defender (DLD) feature of the Windows System Monitor Agent independently monitors and logs the connection and disconnection of external data devices to the host computer where the Agent is running. It also monitors and logs the transmission of files to an external storage device. You can configure DLD to protect against external data device connections by ejecting specified devices upon detection. External USB drive storage devices include Flash/RAM drives and CD/DVD drives.\\nYou must configure Data Loss Defender from both these locations:\\nThe Data Loss Defender Policy Manager\\nSystem Monitor Agent DLD Properties\\nA LogRhythm DLD log message source type is automatically created for each agent on first connection to the Mediator. The Log Message Source Name is WinDataDefender. It is associated with the LogRhythm Default policy which contains all available MPE rules. For information on accessing and modifying the log source type, see\\nModify a Single Log Source\\n.\\nA LogRhythm Default policy exists for Data Loss Defender in the Knowledge Base file. To access the Log Processing Policy and its associated MPE Rules, see\\nModify Log Processing Policies\\n.\\nMPE Rules exist for DLD in the MPE Rule Builder. Specific settings can be viewed and modified from within the DLD Log Processing Policy.\\nDLD logs can be queried using Investigator, monitored in Personal Dashboard and Tail, and restored using LogRhythm’s Archive Restoration tool SecondLook.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nEndpoint Monitoring\\n', 'File Integrity Monitor (FIM)': 'FIM provides independent auditing of access to and modification of files and directories. It is intended for monitoring operating system files and other limited, critical files that, when changed, suggest systems have been compromised.\\nThe purpose of FIM is to monitor integrity (not activity) though mechanisms, such independent hash verification, that tend to be resource intensive, which is why FIM has limited use.\\nFor example, customers using Windows may want to monitor .exe and .dll files in\\nC:\\\\Windows\\\\System32\\nand\\nC:\\\\Windows\\\\SysWOW64\\n. FIM is not suitable for use on large directories with thousands of files that are modified frequently. Enabling FIM on directories with tens of GB of data results in poor performance. Customers may want to filter for a\\nccounts such as localsystem, network service, and trustedinstaller to prevent FIM from logging normal system behavior and Windows Updates. However, FIM configuration should always be based on your organizational need and auditing requirements.\\nThe recommended file limits for FIM usage are as follows:\\n10 files of 1 Gb each\\n1,000 files of 1Mb each\\n98,990 files of 1 Kb each\\n', 'LogRhythm and FIM': 'When FIM detects a change, a System Monitor Agent generates a log and sends it to the Data Processor where you can manage it like any other log. Logs can be forwarded to LogMart and the Platform Manager, can generate alarms, and can be included in reports.\\nA LogRhythm File Integrity Monitor log message source type is automatically created for each agent on first connection to the Mediator.\\xa0There are\\nGeneric System Log Sources\\nfor Windows and *NIX agents, and they are associated with the LogRhythm Default policy which contains all available MPE rules. For information on accessing and modifying the log source type, see\\nModify a Single Log Source\\n.\\nA LogRhythm Default policy exists for File Integrity Monitor in the Knowledge Base file. To access the Log Processing Policy and its associated MPE Rules, see\\nModify Log Processing Policies\\n.\\nMPE Rules exist for File Integrity Monitor in the MPE Rule Builder. Specific settings can be viewed and modified from within the File Integrity Monitor Log Processing Policy.\\nFile Integrity Monitor logs can be queried using Investigator, monitored in Personal Dashboard and Tail, and restored using LogRhythm’s Archive Restoration tool SecondLook.\\n', 'Types of File Integrity Monitoring': 'There are two types of File Integrity Monitoring: Standard (FIM) and Realtime (Realtime FIM). Standard and Realtime FIM are both included with the System Monitor Lite license for desktop operating systems only. Server operating systems require System Monitor Pro or Collector. For more information about specific operating system support, see the\\nRealtime File Integrity Monitor (FIM) Support by Operating System\\ntopic in the LogRhythm Compatibility and System Monitor Functionality Guide.\\n, Standard FIM, Realtime FIM\\nMonitors files and directories, X, X\\nScans at configured intervals, X, \\nMonitors in realtime (event-driven), , X\\nIdentifies Process and User, , X\\nIdentifies additional changes in permissions types\\nAccess Control Lists (ACLs), , X\\nFile Attributes (Read-only/Hidden/System), , X\\nRealtime FIM\\nAccess Control Lists (ACLs)\\nFile Attributes (Read-only/Hidden/System)\\n', 'Standard FIM': 'To use standard FIM, you need to:\\nInstall a System Monitor Lite Agent on a desktop operating system or a System Monitor Pro or Collector Agent on a server operating system\\nCreate the File Integrity Monitor Policy\\nor\\nModify the File Integrity Monitor Policy\\nConfigure the System Monitor Agent Properties\\n', 'Realtime FIM': 'Realtime File Integrity Monitoring (Realtime FIM) is an event-driven model that provides real-time accuracy and enables precise user identification. This feature provides exact identification of the process that performed the change, enabling precise identification of the user as well. Standard FIM scans the directories on an interval and then alarms when a change to a file\\'s hash is detected. Depending on how many directories are being monitored, it may even take slightly longer than the configured interval for the Agent to hash all your files and alert you of a change.\\nTo use Realtime FIM, you need to:\\nInstall a System Monitor Lite Agent on a desktop operating system or a System Monitor Pro or Collector Agent on a server operating system\\nCreate the File Integrity Monitor Policy\\nor\\nModify the File Integrity Monitor Policy\\nConfigure the System Monitor Agent Properties\\nRealtime FIM cannot monitor files on a network drive using a UNC path.\\nOn recent versions of Windows, the Last Access timestamp may be disabled by default, and it is required to ensure that read events trigger a Realtime FIM event. To check this setting, run\\nfsutil behavior query disablelastaccess\\nin an elevated command prompt. If DisableLastAccess is set to 1, you will need to enable it by running\\nfsutil behavior set disablelastaccess 0\\nin the same elevated command prompt.\\nTo ensure that Realtime FIM works as expected on Linux and AIX operating systems, please note the following prerequisites.\\nThe audit subsystem needs to be enabled for the LogRhythm System Monitor to correctly perform Realtime FIM on Linux. You can query the status of the subsystem by running the following command: auditctl –s\\nThe \"e\" value indicates if audit is enabled. A value of 1 indicates that audit is enabled, and 0 is disabled.\\nIf needed, you can enable audit by running the following command: auditctl –e 1\\nEnsure that the audit subsystem is enabled at startup on the system where the System Monitor is running.\\nRealTimeFIM feature on AgentU uses the system auditd service to collect logs for monitoring. Due to an architectural limitation on Linux, only one instance of auditd can be active. Therefore, if RealTimeFIM is enabled, /var/log/audit/audit.log won\\'t be collected.\\nTo ensure proper operation of Realtime FIM on AIX, please note the following:\\nlibstdc++ 4.8.3 or newer must be installed for the System Monitor to start.\\nIf needed, modify /etc/security/audit/config to be sure that it contains the following:\\nclasses:\\nfiles = FILE_Open,FILE_Read,FILE_Write,FILE_Close,FILE_Link,FILE_Unlink,FILE_Rename,FILE_Owner,FILE_Mode,FILE_Acl,FILE_Privilege,DEV_Create\\nusers:\\n[for every user] = general,files\\nAfter modifying /etc/security/audit/config, restart the audit service and verify the audit object section has been updated permanently.\\nclasses:\\nfiles = FILE_Open,FILE_Read,FILE_Write,FILE_Close,FILE_Link,FILE_Unlink,FILE_Rename,FILE_Owner,FILE_Mode,FILE_Acl,FILE_Privilege,DEV_Create\\nusers:\\n[for every user] = general,files\\nAfter modifying /etc/security/audit/config, restart the audit service and verify the audit object section has been updated permanently.\\nusers:\\n[for every user] = general,files\\nAfter modifying /etc/security/audit/config, restart the audit service and verify the audit object section has been updated permanently.\\nThere can be many entries under the users section, one for each user. If a user entry does not contain the files parameter, file activity by that user cannot be monitored.\\n', 'FIM Triggers': 'The modifications that trigger FIM logs depend on the operating system where the host agent is installed. FIM is available on all operating systems supported by the LogRhythm *NIX and Windows System Monitor Agents. Realtime FIM is supported on desktop and server platforms with the appropriate license. The following table provides details.\\nType of Change, Standard FIM, Realtime FIM\\nWindows, *NIX, Windows, *NIX1\\nFiles and Directories, , , , \\nPermissions: Permissions (attributes), , X, X, X\\nPermissions: Owner, X, X, X, X\\nPermissions: ACLs, , , X, X\\nAdd, X, X, X, X\\nDelete, X2, X, X2, X\\nFiles, , , , \\nRead, X, X, X, X\\nWrite, X, X, X, X\\nPermissions: Permissions (attributes)\\nPermissions: Owner\\nPermissions: ACLs\\nAdd\\nDelete\\nRead\\nWrite\\n1\\nFor a full list of Realtime FIM\\xa0support by Agent operating system, see\\nRealtime File Integrity Monitor (FIM) Support by Operating System\\n.\\n2\\nOn Windows systems, FIM\\xa0categorizes files sent to the Recycle Bin (for example, by right-clicking the file and clicking\\nDelete\\n)\\xa0as renamed instead of deleted. If you bypass the recycle bin when deleting a file (for example, press\\nShift\\n+\\nDelete\\n), FIM\\xa0logs the DELETE\\xa0change.\\nFIM is centrally managed from the LogRhythm Console. The defined monitoring policy can be used by multiple agents; thus,\\nfilemon.cfg\\nno longer needs to be edited for each agent host.\\nDue to limitations in the Windows Cache Manager, reads performed by applications that use Memory-mapped files are not always seen by file system filters such as the one used by Realtime FIM in the Windows System Monitor Agent. Notepad and WordPad are two such applications. Consequently, some reads by these applications, and other applications that use Memory-mapped files, are not reported.\\nIn some cases, Linux realtime FIM reports a large number of events for a single operation. If there is an operation on a very large file, the Linux realtime FIM module may report each read and write as the file is being processed for an operation. The agent may seem to be reporting a large number of events, but the agent is reporting each and every file system access performed by the operation.\\nThe MODIFY events that are reported by Linux realtime FIM indicate content changes to that file. A single application operation (wget, scp, etc) may generate multiple MODIFY events that indicate that Linux is updating the file multiple times.\\n', 'FIM Event Descriptions': 'There are four categories of Agent Event(s): Discrete, Cumulative, Multiple Change, and Anomaly. Discrete Events have a one to one correspondence with the RealTime FIM Records which cause them to be generated. Cumulative Events are multiple RealTime FIM Records combined into a single Event. Multiple Change Events are multiple Agent Events generated by a single RealTime FIM Record. Anomaly Events can occur independently of RealTime FIM Records. Multiple Change and Anomaly Events are SubTyped Events.\\n', 'Discrete Events': 'Discrete Events have a one to one correspondence with the RealTime FIM Records which cause them to be generated. All Event types that aren’t Cumulative, Multiple Change, or Anomaly Events are Discrete Events.\\nAn evCreate record for a file that didn’t previously exist will generate a CreateOpEvent which has the Event ID “EVENT=ADD”.\\nREALTIME FILEMON EVENT=ADD OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Bar.tmp USER=DOMAIN\\\\john.doe PROCESS=cmd SIZE=1184 DETAILS=lastaccess=5/20/2011 11:35:07 AM -0600 lastwrite=5/20/2011 11:08:09 AM -0600 create=5/20/2011 11:35:07 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=2692\\nAn evSetInformation record with the FileInfoClass value of evFileRenameInformation will generate a RenameEvent which has the Event ID “EVENT=RENAME”.\\nREALTIME FILEMON EVENT=RENAME OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Bar.tmp USER=DOMAIN\\\\john.doe PROCESS=cmd SIZE=1184 DETAILS=lastaccess=5/20/2011 11:35:07 AM -0600 lastwrite=5/20/2011 11:08:09 AM -0600 create=5/20/2011 11:35:07 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=2692 newname=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Bar.tmp\\nAn evClose on a file which has had the delete flag set will result in a test for the existence of the file. If the file no longer exists, a DeleteEvent is generated, which has the Event ID “EVENT=DELETE”.\\nREALTIME FILEMON EVENT=DELETE OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Bar.tmp USER=DOMAIN\\\\john.doe PROCESS=cmd SIZE=1184 DETAILS=lastaccess=5/20/2011 11:35:07 AM -0600 lastwrite=5/20/2011 11:08:09 AM -0600 create=5/20/2011 11:35:07 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=2692\\nAn evClose on a file which has had the delete flag set will result in a test for the existence of the file. If the file still exists, a DeleteFailedEvent is generated, which has the Event ID “EVENT=DELETE_FAILED”.\\nREALTIME FILEMON EVENT=DELETE_FAILED OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Bar.tmp USER=DOMAIN\\\\john.doe PROCESS=cmd SIZE=1184 DETAILS=lastaccess=5/20/2011 11:51:32 AM -0600 lastwrite=5/20/2011 11:08:09 AM -0600 create=5/20/2011 11:51:31 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=2692\\n', 'Cumulative Events': 'Cumulative Events are multiple RealTime FIM Records combined into a single Event. ReadWriteEvent and its derivatives are currently the only Cumulative Events.\\nA ReadEvent, derived from ReadWriteEvent, has the Event ID “EVENT=READ”. The first evRead Record following a non-Read Record generates a ReadEvent, but the Event is not forwarded, in order to coalesce any subsequent adjacent evRead Records. Until there is a record that is not evRead, each subsequent record is checked for adjacency with the previous Read Record(s) and coalesced with the previous one(s) by adding the length from the current record to the cumulative length for the pending ReadEvent. A non-Read Record or a Read Record with a non-adjacent location will cause the ReadEvent to be forwarded to the Mediator and processing to resume on the next Record as the initial Record in a new Event.\\nREALTIME FILEMON EVENT=READ OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Foo.tmp USER=DOMAIN\\\\john.doe PROCESS=System OFFSET=0 LENGTH=1184 SIZE=1184 DETAILS=lastaccess=5/19/2011 11:51:27 AM -0600 lastwrite=5/20/2011 11:08:09 AM -0600 create=5/19/2011 11:51:27 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=4\\nA WriteEvent, derived from ReadWriteEvent, has the Event ID “EVENT=MODIFY”. The first evWrite Record following a non-Write Record generates a WriteEvent, but the Event is not forwarded, in order to coalesce any subsequent adjacent evWrite Records. Until there is a record that is not evWrite, each subsequent record is check for adjacency with the previous Write Record(s) and coalesced with the previous one(s) by adding the length from the current record to the cumulative length for the pending WriteEvent. A non-Write Record or a Write Record with a non-adjacent location will cause the WriteEvent to be forwarded to the Mediator and processing to resume on the next Record as the initial Record in a new Event.\\nREALTIME FILEMON EVENT=MODIFY OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Foo.tmp USER=DOMAIN\\\\john.doe PROCESS=System OFFSET=0 LENGTH=1184 SIZE=1184 DETAILS=lastaccess=5/19/2011 11:51:27 AM -0600 lastwrite=5/20/2011 11:08:09 AM -0600 create=5/19/2011 11:51:27 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=4 oldsize=1184 hash=(0xbdfa30ad4e5884aa1874c095fae3a28aa35f5156)->(0x8926907a474becf728a8fbdd2258cbb7bd652991)\\n', 'SubTyped Events': 'SubTyped Events are multiple Event definitions with a single Event ID. They contain Type and Description fields that other Events do not have.\\n', 'Multiple Change Events': 'Multiple Change Events are multiple Events generated by a single RealTime FIM Record. Multiple Change Events have a CHANGESET field that is unique to the RealTime FIM Record that generated them. PermissionsChangeEvent and AttributeChangeEvent and their derivatives are Multiple Change Events. Multiple Change Events are SubTyped Events, with Type and Description fields.\\nThe Attribute Change Event is a Multiple Change Event due to the fact that multiple Attributes can be changed with a single operation on the File System, which will show up as a single RealTime FIM Record, but it is desirable to have them appear as separate Event messages. An AttributeChangeEvent has the Event ID “EVENT=ATTRIB”. The AttributeChangeEvent is a SubTyped Event. The label for the Type field is “ATTRIB_TYPE”. The label for the Description field is “ATTRIB_DESC”. The supported Attributes are Read-only, Hidden, and System. There are separate events for Set and Clear of each Attribute.\\nA ReadOnlyAttributeSetEvent has the Event ID “EVENT=ATTRIB”. The ATTRIB_TYPE field is 001, and the ATTRIB_DESC field is “Read-only Attribute Set”.\\nREALTIME FILEMON EVENT=ATTRIB OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Foo.tmp ATTRIB_TYPE=001 ATTRIB_DESC=Read-only Attribute Set USER=DOMAIN\\\\john.doe PROCESS= SIZE=51703603 CHANGESET=20110520170707-93019 DETAILS=lastaccess=5/19/2011 11:51:27 AM -0600 lastwrite=5/20/2011 10:34:07 AM -0600 create=5/19/2011 11:51:27 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=1108\\nA ReadOnlyAttributeClearEvent has the Event ID “EVENT=ATTRIB”. The ATTRIB_TYPE field is 002, and the ATTRIB_DESC field is “Read-only Attribute Clear”.\\nREALTIME FILEMON EVENT=ATTRIB OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Foo.tmp ATTRIB_TYPE=002 ATTRIB_DESC=Read-only Attribute Clear USER=DOMAIN\\\\john.doe PROCESS= SIZE=51703603 CHANGESET=20110520170707-93259 DETAILS=lastaccess=5/19/2011 11:51:27 AM -0600 lastwrite=5/20/2011 10:34:07 AM -0600 create=5/19/2011 11:51:27 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=796\\nA HiddenAttributeSetEvent has the Event ID “EVENT=ATTRIB”. The ATTRIB_TYPE field is 003, and the ATTRIB_DESC field is “Hidden Attribute Set”.\\nREALTIME FILEMON EVENT=ATTRIB OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Foo.tmp ATTRIB_TYPE=003 ATTRIB_DESC=Hidden Attribute Set USER=DOMAIN\\\\john.doe PROCESS= SIZE=51703603 CHANGESET=20110520170707-93019 DETAILS=lastaccess=5/19/2011 11:51:27 AM -0600 lastwrite=5/20/2011 10:34:07 AM -0600 create=5/19/2011 11:51:27 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=1108\\nA HiddenAttributeClearEvent has the Event ID “EVENT=ATTRIB”. The ATTRIB_TYPE field is 004, and the ATTRIB_DESC field is “Hidden Attribute Clear”.\\nREALTIME FILEMON EVENT=ATTRIB OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Foo.tmp ATTRIB_TYPE=004 ATTRIB_DESC=Hidden Attribute Clear USER=DOMAIN\\\\john.doe PROCESS= SIZE=51703603 CHANGESET=20110520170707-93259 DETAILS=lastaccess=5/19/2011 11:51:27 AM -0600 lastwrite=5/20/2011 10:34:07 AM -0600 create=5/19/2011 11:51:27 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=796\\nA SystemAttributeSetEvent has the Event ID “EVENT=ATTRIB”. The ATTRIB_TYPE field is 005, and the ATTRIB_DESC field is “System Attribute Set”.\\nREALTIME FILEMON EVENT=ATTRIB OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Foo.tmp ATTRIB_TYPE=005 ATTRIB_DESC=System Attribute Set USER=DOMAIN\\\\john.doe PROCESS= SIZE=51703603 CHANGESET=20110520170707-93019 DETAILS=lastaccess=5/19/2011 11:51:27 AM -0600 lastwrite=5/20/2011 10:34:07 AM -0600 create=5/19/2011 11:51:27 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=1108\\nA SystemAttributeClearEvent has the Event ID “EVENT=ATTRIB”. The ATTRIB_TYPE field is 006, and the ATTRIB_DESC field is “System Attribute Clear”.\\nREALTIME FILEMON EVENT=ATTRIB OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Foo.tmp ATTRIB_TYPE=006 ATTRIB_DESC=System Attribute Clear USER=DOMAIN\\\\john.doe PROCESS= SIZE=51703603 CHANGESET=20110520170707-93259 DETAILS=lastaccess=5/19/2011 11:51:27 AM -0600 lastwrite=5/20/2011 10:34:07 AM -0600 create=5/19/2011 11:51:27 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=796\\nThe Permission Change Event is a Multiple Change Event due to the fact that multiple Permissions can be changed with a single operation on the File System, which will show up as a single RealTime FIM Record, but it is desirable to have them appear as separate Event messages. A PermissionChangeEvent has the Event ID “EVENT=PERMS”. The PermissionChangeEvent is a SubTyped Event. The label for the Type field is “PERMS_TYPE”. The label for the Description field is “PERMS_DESC”. The supported Permissions are Owner, Group, Discretionary ACL, and System ACL. There is a single Event for each Permission type.\\nAn OwnerChangeEvent has the Event ID “EVENT=PERMS”. The PERMS_TYPE field is 001, and the PERMS_DESC field is “Owner changed”.\\nREALTIME FILEMON EVENT=PERMS OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Foo.tmp PERMS_TYPE=001 PERMS_DESC=Owner changed USER=DOMAIN\\\\john.doe PROCESS=explorer SIZE=1184 OWNER=()->(DOMAIN\\\\john.doe) CHANGESET=20110520171237-167336 DETAILS=lastaccess=5/19/2011 11:51:27 AM -0600 lastwrite=5/20/2011 11:08:09 AM -0600 create=5/19/2011 11:51:27 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=2640\\nA GroupChangeEvent has the Event ID “EVENT=PERMS”. The PERMS_TYPE field is 002, and the PERMS_DESC field is “Group changed”.\\nREALTIME FILEMON EVENT=PERMS OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Foo.tmp PERMS_TYPE=002 PERMS_DESC=Group changed USER=DOMAIN\\\\john.doe PROCESS=explorer SIZE=1184 GROUP=()->(DOMAIN\\\\Domain Users) CHANGESET=20110520171237-167336 DETAILS=lastaccess=5/19/2011 11:51:27 AM -0600 lastwrite=5/20/2011 11:08:09 AM -0600 create=5/19/2011 11:51:27 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=2640\\nA GroupChangeEvent has the Event ID “EVENT=PERMS”. The PERMS_TYPE field is 002, and the PERMS_DESC field is “Group changed”.\\nREALTIME FILEMON EVENT=PERMS OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Foo.tmp PERMS_TYPE=002 PERMS_DESC=Group changed USER=DOMAIN\\\\john.doe PROCESS=explorer SIZE=1184 GROUP=()->(DOMAIN\\\\Domain Users) CHANGESET=20110520171237-167336 DETAILS=lastaccess=5/19/2011 11:51:27 AM -0600 lastwrite=5/20/2011 11:08:09 AM -0600 create=5/19/2011 11:51:27 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=2640\\nA DaclChangeEvent has the Event ID “EVENT=PERMS”. The PERMS_TYPE field is 003, and the PERMS_DESC field is “Discretionary ACL changed”.\\nREALTIME FILEMON EVENT=PERMS OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Foo.tmp PERMS_TYPE=003 PERMS_DESC=Discretionary ACL changed USER=DOMAIN\\\\john.doe PROCESS=explorer SIZE=1184 CHANGESET=20110520171237-167336 DETAILS=lastaccess=5/19/2011 11:51:27 AM -0600 lastwrite=5/20/2011 11:08:09 AM -0600 create=5/19/2011 11:51:27 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=2640\\nA SaclChangeEvent has the Event ID “EVENT=PERMISSIONS”. The PERMS_TYPE field is 004, and the PERMS_DESC field is “System ACL changed”.\\nREALTIME FILEMON EVENT=PERMS OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Foo.tmp PERMS_TYPE=004 PERMS_DESC=System ACL changed USER=DOMAIN\\\\john.doe PROCESS=explorer SIZE=1184 CHANGESET=20110520171237-167336 DETAILS=lastaccess=5/19/2011 11:51:27 AM -0600 lastwrite=5/20/2011 11:08:09 AM -0600 create=5/19/2011 11:51:27 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=2640\\n', 'Anomaly Events': 'Anomaly Events can be generated independently of any RealTime FIM Records, or in conjunction with one or more Records. The AnomalyEvent has the Event ID “EVENT=ANOMALY”. Anomaly Events are SubTyped Events. The label for the Type field is “ANOMALY_TYPE”. The label for the Description field is “ANOMALY_DESC”. The supported Anomaly types are Hash Equal and Missed Modify Anomalies.\\nA HashEqualAnomalyEvent has the Event ID “EVENT=ANOMALY”. The ANOMALY_TYPE is 001. The ANOMALY_DESC is “Modification observed with unchanged file hash”.\\nREALTIME FILEMON EVENT=ANOMALY OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Foo.tmp ANOMALY_TYPE=001 ANOMALY_DESC=Modification observed with unchanged file hash USER=DOMAIN\\\\john.doe PROCESS=System SIZE=1184 DETAILS=lastaccess=5/19/2011 11:51:27 AM -0600 lastwrite=5/20/2011 11:08:09 AM -0600 create=5/19/2011 11:51:27 AM -0600 usersid=S-1-5-21-1760952874-2610146993-1928205901-4870 pid=4 hash=0x8926907a474becf728a8fbdd2258cbb7bd652991\\nA MissedModifyAnomalyEvent has the Event ID “EVENT=ANOMALY”. The ANOMALY_TYPE is 002. The ANOMALY_DESC is “No MODIFY observed with changed file hash”.\\nREALTIME FILEMON EVENT=ANOMALY OBJECT=F:\\\\Users\\\\john.doe\\\\AppData\\\\Local\\\\Temp\\\\Foo.tmp ANOMALY_TYPE=002 ANOMALY_DESC=No MODIFY observed with changed file hash SIZE=1025 DETAILS=lastaccess=5/19/2011 11:51:27 AM -0600 lastwrite=5/20/2011 12:56:54 PM -0600 create=5/19/2011 11:51:27 AM -0600 oldsize=1024 hash=(0xf462535686c7922fed4df8d5fbd7ea8e8b848b68)->(0xb53f12025175614596948646fa7782dcfbeb67f5)\\n', 'Discretionary Access Control List (ACL) Changes': 'When file or folder permissions are added, modified, or deleted, Realtime FIM logs the following details:\\nOrigin Logon\\n. The account ID\\xa0of the user who made the change.\\nChange Made\\n. The type of access that was granted (for example, read, write, full, etc.).\\nAffected File or Folder\\n. The file or folder upon which permissions were changed (for example, C:\\\\users\\\\john.doe\\\\file.tmp).\\nUser or Group Granted Access\\n. The user ID\\xa0or user group that was granted access.\\nWithin the Realtime FIM logs, associated permissions are comma-delimited, a separate log is generated for each account impacted by the change, and each log contains a RESULT\\xa0field that describes the file permissions resulting from the change. The following examples illustrate how Realtime FIM logs added, deleted, or changed permissions.\\nREALTIME FILEMON EVENT=PERMS OBJECT=C:\\\\windows\\\\regedit.exe PERMS_TYPE=003 PERMS_DESC=\\nDiscretionary ACL changed\\nUSER=domain\\\\user.one PROCESS=DllHost.exe SIZE=7 CHANGESET=20161130175122-3555943 DETAILS=lastaccess=11/30/2016 8:08:21 AM -0800 lastwrite=1/22/2016 2:25:47 PM -0800 create=11/30/2016 8:08:21 AM -0800 usersid=S-1-5-21-1760952874-2610146993-1928205901-12996 pid=2955764 Policy=User1 c:\\\\windows COMMAND=ADD domain\\\\user.two AccessAllowed Write, ReadAndExecute, Synchronize RESULT=BUILTIN\\\\Users AccessAllowed Write, ReadAndExecute, Synchronize;domain\\\\user.two AccessAllowed Write, ReadAndExecute, Synchronize;NT AUTHORITY\\\\SYSTEM AccessAllowed FullControl;BUILTIN\\\\Administrators AccessAllowed FullControl;BUILTIN\\\\Users AccessAllowed ReadAndExecute, Synchronize;APPLICATION PACKAGE AUTHORITY\\\\ALL APPLICATION PACKAGES AccessAllowed ReadAndExecute, Synchronize\\nREALTIME FILEMON EVENT=PERMS OBJECT=C:\\\\windows\\\\regedit.exe PERMS_TYPE=003 PERMS_DESC=\\nDiscretionary ACL changed\\nUSER=domain\\\\user.one PROCESS=DllHost.exe SIZE=7 CHANGESET=20161130175145-3872518 DETAILS=lastaccess=11/30/2016 8:08:21 AM -0800 lastwrite=1/22/2016 2:25:47 PM -0800 create=11/30/2016 8:08:21 AM -0800 usersid=S-1-5-21-1760952874-2610146993-1928205901-12996 pid=2186084 Policy=User1 c:\\\\windows COMMAND=MODIFY domain\\\\user.two AccessAllowed Write, ReadAndExecute, Synchronize -> FullControl RESULT=BUILTIN\\\\Users AccessAllowed Write, ReadAndExecute, Synchronize;domain\\\\user.two AccessAllowed FullControl;NT AUTHORITY\\\\SYSTEM AccessAllowed FullControl;BUILTIN\\\\Administrators AccessAllowed FullControl;BUILTIN\\\\Users AccessAllowed ReadAndExecute, Synchronize;APPLICATION PACKAGE AUTHORITY\\\\ALL APPLICATION PACKAGES AccessAllowed ReadAndExecute, Synchronize\\nREALTIME FILEMON EVENT=PERMS OBJECT=C:\\\\windows\\\\regedit.exe PERMS_TYPE=003 PERMS_DESC=\\nDiscretionary ACL changed\\nUSER=domain\\\\user.one PROCESS=DllHost.exe SIZE=7 CHANGESET=20161130175225-4491589 DETAILS=lastaccess=11/30/2016 8:08:21 AM -0800 lastwrite=1/22/2016 2:25:47 PM -0800 create=11/30/2016 8:08:21 AM -0800 usersid=S-1-5-21-1760952874-2610146993-1928205901-12996 pid=1762608 Policy=User1 c:\\\\windows COMMAND=DELETE domain\\\\user.two AccessAllowed RESULT=BUILTIN\\\\Users AccessAllowed Write, ReadAndExecute, Synchronize;NT AUTHORITY\\\\SYSTEM AccessAllowed FullControl;BUILTIN\\\\Administrators AccessAllowed FullControl;BUILTIN\\\\Users AccessAllowed ReadAndExecute, Synchronize;APPLICATION PACKAGE AUTHORITY\\\\ALL APPLICATION PACKAGES AccessAllowed ReadAndExecute, Synchronize\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nEndpoint Monitoring\\n', 'Registry Integrity Monitor (RIM)': 'The Registry Integrity Monitor (RIM) provides independent, realtime auditing of modifications to Windows registries. When RIM detects a change, the System Monitor Agent generates a log and sends it to the Data Processor where it can manage it like any other log. The logs can be forwarded to LogMart and to the Platform Manager so alarms can be generated and included in reports.\\nTo configure RIM for a Windows Agent, four steps must be completed:\\nCreate a Registry Integrity Monitor Policy\\n.\\nConfigure Registry Integrity Monitor Policy Items\\n.\\nAssociate Registry Integrity Monitor Policy Items to a Policy\\n.\\nAssociate a Registry Integrity Monitor Policy to a Windows System Monitor Agent\\n.\\nNote the following considerations regarding RIM:\\nRIM is available for both Pro and Lite Desktop Windows Agents but only available on Pro Windows Server Agents. RIM is supported on Windows Vista/2008 and above.\\nRIM requires the installation of the Realtime File Integrity Monitor driver. For more information, see System Monitor Agent Installation.\\nDue to a known Windows limitation, the following may be observed with RENAME event handling:When a RENAME event is reported by RIM (for example, a key is renamed), it is reported properly with the old name and new name populated with the correct values. Subsequent operations on the renamed key, however, may be reported with the old name.\\nRIM events are not reported as HKEY_CURRENT_USER. They are always reported as HKEY_USERS\\\\<User_SID>\\\\. HKEY_CURRENT_USER is a symbolic link to the current user’s branch in the \\\\Registry\\\\User hive. For this reason, events reported from \\\\Registry\\\\User\\\\<User_SID\\\\ will be translated to HKEY_USERS\\\\<User_SID>\\\\.\\nRecurse Subkeys and Registry Integrity Monitor: If you have not enabled the Recurse Subkeys option on a RIM Policy item, the key value is reported but no events are reported on parent keys. To avoid this issue, ensure that Recurse Subkeys is enabled when adding a RIM Policy item.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nEndpoint Monitoring\\n/\\nFile Integrity Monitor (FIM)\\n', 'Associate a File Integrity Monitor Policy With an Agent': 'You must be logged in as an Administrator to take this action.\\nIn the System Monitor Agent Properties dialog box, the Endpoint Monitoring tab contains the File Integrity Monitor sub-tab. On this tab you assign FIM polices to the agent and tab to enable monitoring for that agent and to assign FIM policies.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nSystem Monitors\\ntab.\\nDouble-click an agent to display the System Monitor Agent Properties dialog box.\\nClick the\\nEndpoint Monitoring\\ntab, and then click the\\nFile Integrity Monitor\\nsub-tab.\\nSelect the\\nEnable File Integrity Monitor\\ncheck box.\\nSelect\\nStandard\\nor\\nRealtime\\nmonitoring.\\nIn Standard mode, and if User Activity Monitor is enabled, you can select the Include User Activity Monitor Data (Requires UAM) option. When enabled, user log on information is included in the FIM logs. This option is disabled by default.\\nIn Realtime mode, you can select the Enable Realtime Mode Anomaly Detection option. If an active FIM Policy is monitoring for Modify events, the Realtime FIM engine recomputes the hash for monitored items after every Modify. If Realtime Mode Anomaly Detection is enabled, the Realtime FIM engine recomputes the hash for each file once every 24 hours. If the hash value has changed since it was last computed, FIM generates a \"missed\" modify event (MissedModifyAnomalyEvent). If you\\'re monitoring for READ, it will report that when an application reads the file, but will not recompute the hash for that event.\\nStandard and Realtime FIM are included with the System Monitor Lite license for desktop operating systems only. Server operating systems require System Monitor Pro or Collector. For more information about specific operating system support, see the\\nRealtime File Integrity Monitor (FIM) Support by Operating System\\n.\\nIn Standard mode, and if User Activity Monitor is enabled, you can select the Include User Activity Monitor Data (Requires UAM) option. When enabled, user log on information is included in the FIM logs. This option is disabled by default.\\nIn Standard mode, and if User Activity Monitor is enabled, you can select the Include User Activity Monitor Data (Requires UAM) option. When enabled, user log on information is included in the FIM logs. This option is disabled by default.\\nIn Realtime mode, you can select the Enable Realtime Mode Anomaly Detection option. If an active FIM Policy is monitoring for Modify events, the Realtime FIM engine recomputes the hash for monitored items after every Modify. If Realtime Mode Anomaly Detection is enabled, the Realtime FIM engine recomputes the hash for each file once every 24 hours. If the hash value has changed since it was last computed, FIM generates a \"missed\" modify event (MissedModifyAnomalyEvent). If you\\'re monitoring for READ, it will report that when an application reads the file, but will not recompute the hash for that event.\\nIn Realtime mode, you can select the Enable Realtime Mode Anomaly Detection option. If an active FIM Policy is monitoring for Modify events, the Realtime FIM engine recomputes the hash for monitored items after every Modify. If Realtime Mode Anomaly Detection is enabled, the Realtime FIM engine recomputes the hash for each file once every 24 hours. If the hash value has changed since it was last computed, FIM generates a \"missed\" modify event (MissedModifyAnomalyEvent). If you\\'re monitoring for READ, it will report that when an application reads the file, but will not recompute the hash for that event.\\nStandard and Realtime FIM are included with the System Monitor Lite license for desktop operating systems only. Server operating systems require System Monitor Pro or Collector. For more information about specific operating system support, see the\\nRealtime File Integrity Monitor (FIM) Support by Operating System\\n.\\nIn the Policy list, select one or more policies to apply to the agent.\\nThe policies are applied consecutively. Each selected policy is applied to the agent.\\nIn the Policy list, select one or more policies to apply to the agent.\\nThe policies are applied consecutively. Each selected policy is applied to the agent.\\n(Optional)\\nTo display the Directories Monitored With Selected Policies window, click\\nPreview\\n. This windows displays the directories and files being monitored by the selected policies. To close the window, click\\nOK\\n.\\n(Optional)\\nTo display the Directories Monitored With Selected Policies window, click\\nPreview\\n. This windows displays the directories and files being monitored by the selected policies. To close the window, click\\nOK\\n.\\nTo associate the policies to the Agent, click\\nApply\\n, and then click\\nOK\\nto close the dialog box.\\nTo associate the policies to the Agent, click\\nApply\\n, and then click\\nOK\\nto close the dialog box.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nEndpoint Monitoring\\n/\\nFile Integrity Monitor (FIM)\\n', 'Create File Integrity Monitor Policies': \"Only Global Admins or Restricted Admins with elevated View and Manage privileges can take this action.\\nYou can create new FIM policies using the File Integrity Monitor Policy Manager. The LogRhythm deployment also includes default policy templates for each supported operating system. These templates are examples of policies that can be created. Using them without modifying them to fit your specific needs is not recommended. For more information, see\\nModify File Integrity Monitor Policies\\n.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nFile Integrity Monitor Policy Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nFile Integrity Monitor Policy Manager\\n.\\nOn the File menu, click\\nNew\\n.\\nThe File Integrity Monitor Policy Properties window appears.\\nOn the File menu, click\\nNew\\n.\\nThe File Integrity Monitor Policy Properties window appears.\\nEnter a policy name and description.\\nEnter a policy name and description.\\nRight-click in the Monitoring Configurations grid, and then click\\nNew\\n.\\nRight-click in the Monitoring Configurations grid, and then click\\nNew\\n.\\nEnter a configuration name.\\nEnter a configuration name.\\nSelect the configuration properties you want.\\nField/Button\\nDescription\\nName\\nThe name of the configuration. It must be unique.\\nEnable Start/Stop Time\\nSelect the check box to set monitoring to start and stop at the time specified every day.\\nStart Time\\nSelect the hour and minute that monitoring should start each day. This field cannot be edited unless the Enable Start/Stop Time check box is selected.\\nStop Time\\nSelect the hour and minute that monitoring should stop each day. This field cannot be edited unless the Enable Start/Stop Time check box is selected.\\nInterval\\nSet the frequency, in minutes, of the monitoring interval. Range is 1 - 10080 minutes.\\nMax Hashed File Bytes\\nSet the maximum file size, in kilobytes, that FIM reviews for changes. If the files being monitored are over 1MB, using this value can save time by specifying how much of each file to view. For example, if Max Hashed File Bytes is set to 1024, only the first 1024 KBytes of the file will be checked for changes.\\nMax Depth\\nApplies only when the monitored item is a directory and controls the number of subdirectories the monitor descends to detect changes. Max Depth specifies how many subdirectories below a monitored directory to look for FIM events.\\nEXAMPLE\\nThe monitored directory is C:\\\\DirA\\nThe Max Depth =2\\nHost directory structure is C:\\\\DirA\\\\DirB\\\\DirC\\nThe Agent travels two directories below C:\\\\DirA looking for FIM events. Files in:\\nC:\\\\DirA are at depth 0\\nC:\\\\DirA\\\\DirB are at depth 1\\nC:\\\\DirA\\\\DirB\\\\DirC are at depth 2\\nMonitoring Flags\\nIndicates when FIM logs are generated:\\nRead\\n. Monitored item is read. This option may generate a large number of logs.\\nModify\\n. Monitored item is modified.\\nWhen FIM\\xa0is monitoring for Modify events, the HashEqualAnomalyEvent is generated if a monitored file is modified and the file's hash value is unchanged.\\nPermissions\\n. Permissions are changed on a monitored item.\\nAdd\\n. Item is added to the monitored directory. The Add option cannot be disabled.\\nDelete\\n. Monitored item is deleted. The Delete option cannot be disabled.\\nOK\\nSaves the record, closes the window, and displays the record in the File Integrity Monitor Policy Manager grid\\nCancel\\nCancels the process, closes the window, and does not create the record.\\nSelect the configuration properties you want.\\nField/Button, Description\\nName, The name of the configuration. It must be unique.\\nEnable Start/Stop Time, Select the check box to set monitoring to start and stop at the time specified every day.\\nStart Time, Select the hour and minute that monitoring should start each day. This field cannot be edited unless the Enable Start/Stop Time check box is selected.\\nStop Time, Select the hour and minute that monitoring should stop each day. This field cannot be edited unless the Enable Start/Stop Time check box is selected.\\nInterval, Set the frequency, in minutes, of the monitoring interval. Range is 1 - 10080 minutes.\\nMax Hashed File Bytes, Set the maximum file size, in kilobytes, that FIM reviews for changes. If the files being monitored are over 1MB, using this value can save time by specifying how much of each file to view. For example, if Max Hashed File Bytes is set to 1024, only the first 1024 KBytes of the file will be checked for changes.\\nMax Depth, Applies only when the monitored item is a directory and controls the number of subdirectories the monitor descends to detect changes. Max Depth specifies how many subdirectories below a monitored directory to look for FIM events.EXAMPLEThe monitored directory is C:\\\\DirAThe Max Depth =2Host directory structure is C:\\\\DirA\\\\DirB\\\\DirCThe Agent travels two directories below C:\\\\DirA looking for FIM events. Files in:C:\\\\DirA are at depth 0C:\\\\DirA\\\\DirB are at depth 1C:\\\\DirA\\\\DirB\\\\DirC are at depth 2\\nMonitoring Flags, Indicates when FIM logs are generated:Read. Monitored item is read. This option may generate a large number of logs.Modify. Monitored item is modified.When FIM\\xa0is monitoring for Modify events, the HashEqualAnomalyEvent is generated if a monitored file is modified and the file's hash value is unchanged.Permissions. Permissions are changed on a monitored item.Add. Item is added to the monitored directory. The Add option cannot be disabled.Delete. Monitored item is deleted. The Delete option cannot be disabled.\\nOK, Saves the record, closes the window, and displays the record in the File Integrity Monitor Policy Manager grid\\nCancel, Cancels the process, closes the window, and does not create the record.\\nApplies only when the monitored item is a directory and controls the number of subdirectories the monitor descends to detect changes. Max Depth specifies how many subdirectories below a monitored directory to look for FIM events.\\nEXAMPLE\\nThe monitored directory is C:\\\\DirA\\nThe Max Depth =2\\nHost directory structure is C:\\\\DirA\\\\DirB\\\\DirC\\nThe Agent travels two directories below C:\\\\DirA looking for FIM events. Files in:\\nC:\\\\DirA are at depth 0\\nC:\\\\DirA\\\\DirB are at depth 1\\nC:\\\\DirA\\\\DirB\\\\DirC are at depth 2\\nRead\\n. Monitored item is read. This option may generate a large number of logs.\\nModify\\n. Monitored item is modified.\\nWhen FIM\\xa0is monitoring for Modify events, the HashEqualAnomalyEvent is generated if a monitored file is modified and the file's hash value is unchanged.\\nPermissions\\n. Permissions are changed on a monitored item.\\nAdd\\n. Item is added to the monitored directory. The Add option cannot be disabled.\\nDelete\\n. Monitored item is deleted. The Delete option cannot be disabled.\\nClick\\nOK\\n.\\nRight-click the Monitored Items grid, and then click\\nNew\\n.\\nSelect the configuration properties you want.\\nField/Button\\nDescription\\nType\\nSelect File or Directory\\nPath\\nSpecify the path of the directory or the location and file name of the file to monitor. Cannot include a wildcard.\\nConfiguration\\nSelect from the monitoring configurations created for this policy.\\nInclusions\\nA comma-separated list of files and directories to include in monitoring. If nothing is specified, all files and directories are monitored. Applies only to directories to define what is monitored and triggers FIM logs.\\nTo determine your inclusions:\\nIdentify the files and directories that should be monitored within your network. LogRhythm supports file names and directory paths up to approximately 32,000 characters in length.\\nFile Integrity Monitor is not suitable for use on large directories with thousands of files that are modified frequently. It is intended for monitoring operating system files and other limited, critical files. Enabling FIM on directories with tens of GB of data results in poor performance. The default policies, shown in the templates in the FIM Policy Manager, are limited to Windows system files, which are fairly static.\\nDetermine which changes are important to monitor for files:\\nREAD. When a file is accessed.\\nThe File Integrity Monitor does not always capture Read events on monitored files for Windows 2008 R2, Vista, or Windows 2003 Server\\nMODIFY. When a file is edited.\\nPERMISSIONS:\\nFor Windows, when a file owner, group, or ACL changes.\\nFor UNIX, when a file owner is changed or file permissions are changed.\\nDELETE. When a file is deleted. This setting is automatic and cannot be canceled.\\nDetermine which changes are important to monitor for directories:\\nPERMISSIONS:\\nFor Windows, when a directory has an owner change or when a file within the directory has an owner change.\\nFor UNIX, when a directory has an owner or permissions change or a file within a directory has an owner or permissions change.\\nDELETE. When a file is deleted from a directory. The setting is automatic and cannot be canceled.\\nADD. When a file is added to a directory. This setting is automatic and cannot be canceled.\\nIf you are running Windows 2008 or Windows 2008 R2 and want to monitor the C:\\\\Documents and Settings directory, changes are not seen because it is a junction point to C:\\\\Users. Instead, enter the folder C:\\\\Users when setting up the directory monitoring.\\nIf you want to monitor a type of file created by an application that creates temporary files (such as Microsoft Word documents .docx), you need to monitor the parent directory of the modified file directory instead of the specific file type.\\nExclusions\\nA comma-separated list of files and directories to include in monitoring. Applies only to directories to define what is monitored and triggers FIM logs. If both include and exclude filters are specified, only include files that match the include filter and not matching the exclude filter.\\nExclusions take precedence over Inclusions. If you mistakenly put the same file type in both categories, the file type is excluded from the monitoring process.\\nIt is important to identify resource-taxing FIM objects and create exclusions for them. For example, you want to identify automated scripting objects that are constantly changing.\\nFor more information, see\\nCreate Inclusions and Exclusions for FIM\\n.\\nOK\\nSaves the record, closes the window, and displays the record in the File Integrity Monitor Policy Manager grid\\nCancel\\nCancels the process, closes the window, and does not create the record.\\nSelect the configuration properties you want.\\nField/Button, Description\\nType, Select File or Directory\\nPath, Specify the path of the directory or the location and file name of the file to monitor. Cannot include a wildcard.\\nConfiguration, Select from the monitoring configurations created for this policy.\\nInclusions, A comma-separated list of files and directories to include in monitoring. If nothing is specified, all files and directories are monitored. Applies only to directories to define what is monitored and triggers FIM logs.To determine your inclusions:Identify the files and directories that should be monitored within your network. LogRhythm supports file names and directory paths up to approximately 32,000 characters in length.File Integrity Monitor is not suitable for use on large directories with thousands of files that are modified frequently. It is intended for monitoring operating system files and other limited, critical files. Enabling FIM on directories with tens of GB of data results in poor performance. The default policies, shown in the templates in the FIM Policy Manager, are limited to Windows system files, which are fairly static.Determine which changes are important to monitor for files:READ. When a file is accessed.The File Integrity Monitor does not always capture Read events on monitored files for Windows 2008 R2, Vista, or Windows 2003 ServerMODIFY. When a file is edited.PERMISSIONS:For Windows, when a file owner, group, or ACL changes.For UNIX, when a file owner is changed or file permissions are changed.DELETE. When a file is deleted. This setting is automatic and cannot be canceled.Determine which changes are important to monitor for directories:PERMISSIONS:For Windows, when a directory has an owner change or when a file within the directory has an owner change.For UNIX, when a directory has an owner or permissions change or a file within a directory has an owner or permissions change.DELETE. When a file is deleted from a directory. The setting is automatic and cannot be canceled.ADD. When a file is added to a directory. This setting is automatic and cannot be canceled.If you are running Windows 2008 or Windows 2008 R2 and want to monitor the C:\\\\Documents and Settings directory, changes are not seen because it is a junction point to C:\\\\Users. Instead, enter the folder C:\\\\Users when setting up the directory monitoring.If you want to monitor a type of file created by an application that creates temporary files (such as Microsoft Word documents .docx), you need to monitor the parent directory of the modified file directory instead of the specific file type.\\nExclusions, A comma-separated list of files and directories to include in monitoring. Applies only to directories to define what is monitored and triggers FIM logs. If both include and exclude filters are specified, only include files that match the include filter and not matching the exclude filter.Exclusions take precedence over Inclusions. If you mistakenly put the same file type in both categories, the file type is excluded from the monitoring process.It is important to identify resource-taxing FIM objects and create exclusions for them. For example, you want to identify automated scripting objects that are constantly changing.For more information, seeCreate Inclusions and Exclusions for FIM.\\nOK, Saves the record, closes the window, and displays the record in the File Integrity Monitor Policy Manager grid\\nCancel, Cancels the process, closes the window, and does not create the record.\\nType\\nSelect File or Directory\\nPath\\nSpecify the path of the directory or the location and file name of the file to monitor. Cannot include a wildcard.\\nConfiguration\\nSelect from the monitoring configurations created for this policy.\\nInclusions\\nA comma-separated list of files and directories to include in monitoring. If nothing is specified, all files and directories are monitored. Applies only to directories to define what is monitored and triggers FIM logs.\\nTo determine your inclusions:\\nIdentify the files and directories that should be monitored within your network. LogRhythm supports file names and directory paths up to approximately 32,000 characters in length.\\nFile Integrity Monitor is not suitable for use on large directories with thousands of files that are modified frequently. It is intended for monitoring operating system files and other limited, critical files. Enabling FIM on directories with tens of GB of data results in poor performance. The default policies, shown in the templates in the FIM Policy Manager, are limited to Windows system files, which are fairly static.\\nIdentify the files and directories that should be monitored within your network. LogRhythm supports file names and directory paths up to approximately 32,000 characters in length.\\nDetermine which changes are important to monitor for files:\\nREAD. When a file is accessed.\\nThe File Integrity Monitor does not always capture Read events on monitored files for Windows 2008 R2, Vista, or Windows 2003 Server\\nMODIFY. When a file is edited.\\nPERMISSIONS:\\nFor Windows, when a file owner, group, or ACL changes.\\nFor UNIX, when a file owner is changed or file permissions are changed.\\nDELETE. When a file is deleted. This setting is automatic and cannot be canceled.\\nREAD. When a file is accessed.\\nThe File Integrity Monitor does not always capture Read events on monitored files for Windows 2008 R2, Vista, or Windows 2003 Server\\nREAD. When a file is accessed.\\nThe File Integrity Monitor does not always capture Read events on monitored files for Windows 2008 R2, Vista, or Windows 2003 Server\\nMODIFY. When a file is edited.\\nMODIFY. When a file is edited.\\nPERMISSIONS:\\nFor Windows, when a file owner, group, or ACL changes.\\nFor UNIX, when a file owner is changed or file permissions are changed.\\nPERMISSIONS:\\nFor Windows, when a file owner, group, or ACL changes.\\nFor Windows, when a file owner, group, or ACL changes.\\nFor UNIX, when a file owner is changed or file permissions are changed.\\nFor UNIX, when a file owner is changed or file permissions are changed.\\nDELETE. When a file is deleted. This setting is automatic and cannot be canceled.\\nDELETE. When a file is deleted. This setting is automatic and cannot be canceled.\\nDetermine which changes are important to monitor for directories:\\nPERMISSIONS:\\nFor Windows, when a directory has an owner change or when a file within the directory has an owner change.\\nFor UNIX, when a directory has an owner or permissions change or a file within a directory has an owner or permissions change.\\nDELETE. When a file is deleted from a directory. The setting is automatic and cannot be canceled.\\nADD. When a file is added to a directory. This setting is automatic and cannot be canceled.\\nDetermine which changes are important to monitor for directories:\\nPERMISSIONS:\\nFor Windows, when a directory has an owner change or when a file within the directory has an owner change.\\nFor UNIX, when a directory has an owner or permissions change or a file within a directory has an owner or permissions change.\\nPERMISSIONS:\\nFor Windows, when a directory has an owner change or when a file within the directory has an owner change.\\nFor Windows, when a directory has an owner change or when a file within the directory has an owner change.\\nFor UNIX, when a directory has an owner or permissions change or a file within a directory has an owner or permissions change.\\nFor UNIX, when a directory has an owner or permissions change or a file within a directory has an owner or permissions change.\\nDELETE. When a file is deleted from a directory. The setting is automatic and cannot be canceled.\\nDELETE. When a file is deleted from a directory. The setting is automatic and cannot be canceled.\\nADD. When a file is added to a directory. This setting is automatic and cannot be canceled.\\nADD. When a file is added to a directory. This setting is automatic and cannot be canceled.\\nIf you are running Windows 2008 or Windows 2008 R2 and want to monitor the C:\\\\Documents and Settings directory, changes are not seen because it is a junction point to C:\\\\Users. Instead, enter the folder C:\\\\Users when setting up the directory monitoring.\\nIf you want to monitor a type of file created by an application that creates temporary files (such as Microsoft Word documents .docx), you need to monitor the parent directory of the modified file directory instead of the specific file type.\\nExclusions\\nA comma-separated list of files and directories to include in monitoring. Applies only to directories to define what is monitored and triggers FIM logs. If both include and exclude filters are specified, only include files that match the include filter and not matching the exclude filter.\\nExclusions take precedence over Inclusions. If you mistakenly put the same file type in both categories, the file type is excluded from the monitoring process.\\nIt is important to identify resource-taxing FIM objects and create exclusions for them. For example, you want to identify automated scripting objects that are constantly changing.\\nFor more information, see\\nCreate Inclusions and Exclusions for FIM\\n.\\nOK\\nSaves the record, closes the window, and displays the record in the File Integrity Monitor Policy Manager grid\\nCancel\\nCancels the process, closes the window, and does not create the record.\\nClick\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nEndpoint Monitoring\\n/\\nFile Integrity Monitor (FIM)\\n', 'Create Inclusions and Exclusions for FIM': '\\nA monitored item that is a directory has inclusions and exclusions that are applied to the files within it.\\nA monitored item that is a file cannot have inclusions and exclusions. Individual files cannot have filters applied to them.\\nWhen an include filter is applied to a directory, the filter is applied to the parent directory and all the child directories and files within those directories. For example, if an include filter is applied to the Documents directory to monitor document files, FIM monitors all the files in the Document directory and the subdirectories whether those files are document files or files of other types, as long as they match an include filter and don’t match an exclude filter.\\nIf a subdirectory of the Document directory has an exclude filter applied to it, that directory and its child directories are ignored.\\nIn the graphic below, all the directories highlighted in green are affected by the included filter; they are monitored. When the LogRhythm Agent encounters an exclude filter for a subdirectory (represented by the red highlight), the files in the subdirectory and its child directories are ignored.\\n\\n\\n', 'Syntax': 'Wildcard Required\\nA wildcard is always required and can appear multiple times in Inclusions and Exclusions lists. The only wildcard allowed in a filter is the asterisk (*), as shown in these examples:\\n*.exe\\n*access*.log\\n*/logs/\\ndata.*\\n*\\\\$NtUninstallKB*$\\\\\\nC:\\\\Windows\\\\$NtUninstall*\\\\\\nA wildcard is always required and can appear multiple times in Inclusions and Exclusions lists. The only wildcard allowed in a filter is the asterisk (*), as shown in these examples:\\n*.exe\\n*access*.log\\n*/logs/\\ndata.*\\n*\\\\$NtUninstallKB*$\\\\\\nC:\\\\Windows\\\\$NtUninstall*\\\\\\nLists\\nThe list items must be separated with either commas or semicolons and cannot contain spaces.\\nFor example:\\n*.txt,access.*,$NtUninstall*$,*access*.log,*.*\\n*.txt,access.*;$NtUninstall*$;*access*.log,*.*\\nThe list items must be separated with either commas or semicolons and cannot contain spaces.\\nFor example:\\n*.txt,access.*,$NtUninstall*$,*access*.log,*.*\\n*.txt,access.*;$NtUninstall*$;*access*.log,*.*\\n', 'Evaluating Filters': 'Each file and directory and fully qualified path is evaluated against the include and exclude filters independently. When the directory monitored item has a Max Depth greater than 0, each subdirectory level is evaluated before traveling deeper into the directory structure. Additionally, the LogRhythm Agent appends a backslash (\\\\) to all Windows directories or a forward slash (/) to all UNIX directories before applying the filters.\\nFor example, if you want to exclude all subdirectories ending with debug under the root monitored directory C:\\\\Temp, the exclude filter to use is:\\n(Note the trailing backslash.)\\nrather than\\nFilters are applied to the fully qualified path, not just the right-most element of the path.\\n', 'Filter Precedence': 'If only an include filter is specified, the results include only the files and directories matching the include filter.\\nIf only an exclude filter is specified, the results include only the files and directories\\nnot\\nmatching the exclude filter.\\nIf both include and exclude filters are specified, files and directories that match the exclude filter are excluded regardless of whether they match the include filter.\\nIf a directory matches an include filter, then all files directly within that directory are monitored, regardless of whether they also match the include filter. If those files then match an exclude filter, they are excluded.\\nIf a file matches an include filter, but its directory does not match the filter, the file is monitored, unless the file also matches an exclude filter.\\nIf a directory matches an exclude filter, then that directory and all its files and subdirectories are excluded.\\nYou have the following directory structure and Max Depth = 1:\\n\\nResults for stated filters are:\\nFilter, Result\\nExclusionC:\\\\DirA\\\\item*or*\\\\item*, Included:C:\\\\DirA\\\\DirBC:\\\\DirA\\\\DirB\\\\fileA.iniC:\\\\DirA\\\\file1.datExcluded:C:\\\\DirA\\\\itemA.txtC:\\\\DirA\\\\itemCC:\\\\DirA\\\\itemC\\\\odbc.dllC:\\\\DirA\\\\itemD\\\\vacation.bmp\\nInclusion:C:\\\\DirA\\\\*.dator*\\\\DirA\\\\*dator*.dat, Included:C:\\\\DirA\\\\file1.datExcluded:C:\\\\DirA\\\\DirBC:\\\\DirA\\\\DirB\\\\fileA.iniC:\\\\DirA\\\\itemA.txtC:\\\\DirA\\\\itemCC:\\\\DirA\\\\itemC\\\\odbc.dllC:\\\\DirA\\\\itemDC:\\\\DirA\\\\itemD\\\\vacation.bmp\\nInclusion:*\\\\item*\\\\, Included:C:\\\\DirA\\\\itemCC:\\\\DirA\\\\itemC\\\\odbc.dllC:\\\\DirA\\\\itemDC:\\\\DirA\\\\itemD\\\\vacation.bmpExcluded:C:\\\\DirA\\\\file1.datC:\\\\DirA\\\\DirBC:\\\\DirA\\\\DirB\\\\fileA.iniC:\\\\DirA\\\\itemA.txt\\nExclusion\\nC:\\\\DirA\\\\item*\\nor\\n*\\\\item*\\nIncluded\\n:\\nC:\\\\DirA\\\\DirB\\nC:\\\\DirA\\\\DirB\\\\fileA.ini\\nC:\\\\DirA\\\\file1.dat\\nExcluded\\n:\\nC:\\\\DirA\\\\itemA.txt\\nC:\\\\DirA\\\\itemC\\nC:\\\\DirA\\\\itemC\\\\odbc.dll\\nC:\\\\DirA\\\\itemD\\\\vacation.bmp\\nInclusion:\\nC:\\\\DirA\\\\*.dat\\nor\\n*\\\\DirA\\\\*dat\\nor\\n*.dat\\nIncluded:\\nC:\\\\DirA\\\\file1.dat\\nExcluded:\\nC:\\\\DirA\\\\DirB\\nC:\\\\DirA\\\\DirB\\\\fileA.ini\\nC:\\\\DirA\\\\itemA.txt\\nC:\\\\DirA\\\\itemC\\nC:\\\\DirA\\\\itemC\\\\odbc.dll\\nC:\\\\DirA\\\\itemD\\nC:\\\\DirA\\\\itemD\\\\vacation.bmp\\nInclusion:\\n*\\\\item*\\\\\\n\\nIncluded:\\nC:\\\\DirA\\\\itemC\\nC:\\\\DirA\\\\itemC\\\\odbc.dll\\nC:\\\\DirA\\\\itemD\\nC:\\\\DirA\\\\itemD\\\\vacation.bmp\\nExcluded:\\nC:\\\\DirA\\\\file1.dat\\nC:\\\\DirA\\\\DirB\\nC:\\\\DirA\\\\DirB\\\\fileA.ini\\nC:\\\\DirA\\\\itemA.txt\\nMonitored directory is C:\\\\temp, monitor flags are MRP (MODIFY, READ, PERMISSIONS)\\nInclude filter of *.exe\\nDepth = 3\\nChanges to any file matching *.exe are recorded. Files are monitored for whatever the root monitored item is configured for. Files matching the include filter are monitored based on the monitored items configuration flags (MODIFY, READ, PERMISSIONS).\\nFile match: C:\\\\temp\\\\apps\\\\notepad.exe – will be monitored for MRP.\\nMonitored directory is C:\\\\temp, monitor flags are MRP (MODIFY, READ, PERMISSIONS)\\nInclude filter of *.exe\\nDepth = 3\\nChanges to any file matching *.exe are recorded. Files are monitored for whatever the root monitored item is configured for. Files matching the include filter are monitored based on the monitored items configuration flags (MODIFY, READ, PERMISSIONS).\\nFile match: C:\\\\temp\\\\apps\\\\notepad.exe – will be monitored for MRP.\\nMonitored directory is C:\\\\temp, monitor flags are MRP (MODIFY, READ, PERMISSIONS)\\nInclude filter of *.exe\\nDepth = 3\\nChanges to any file matching *.exe are recorded. Files are monitored for whatever the root monitored item is configured for. Files matching the include filter are monitored based on the monitored items configuration flags (MODIFY, READ, PERMISSIONS).\\nFile match: C:\\\\temp\\\\apps\\\\notepad.exe – will be monitored for MRP.\\nMonitored directory is C:\\\\temp, monitor flags are MRP (MODIFY, READ, PERMISSIONS).\\nInclude filter of *.exe\\\\\\nDepth = 3\\nIf any directory matches *.exe\\\\ - for example, C:\\\\temp\\\\mydir.exe - then all files and directories immediately within it are monitored for MRP, even if they do not match the filter.\\nFile match: C:\\\\temp\\\\mydir.exe\\\\notepad.exe – will be monitored for MRP.\\nFile match: C:\\\\temp\\\\mydir.exe\\\\data.log – will be monitored for MRP.\\nFile match: C:\\\\temp\\\\mydir.exe\\\\notes.txt– will be monitored for MRP.\\nMonitored directory is C:\\\\temp, monitor flags are MRP (MODIFY, READ, PERMISSIONS).\\nInclude filter of *.exe\\\\\\nDepth = 3\\nIf any directory matches *.exe\\\\ - for example, C:\\\\temp\\\\mydir.exe - then all files and directories immediately within it are monitored for MRP, even if they do not match the filter.\\nFile match: C:\\\\temp\\\\mydir.exe\\\\notepad.exe – will be monitored for MRP.\\nFile match: C:\\\\temp\\\\mydir.exe\\\\data.log – will be monitored for MRP.\\nFile match: C:\\\\temp\\\\mydir.exe\\\\notes.txt– will be monitored for MRP.\\nMonitored directory is C:\\\\temp, monitor flags are MRP (MODIFY, READ, PERMISSIONS).\\nInclude filter of *.exe\\\\\\nDepth = 3\\nIf any directory matches *.exe\\\\ - for example, C:\\\\temp\\\\mydir.exe - then all files and directories immediately within it are monitored for MRP, even if they do not match the filter.\\nFile match: C:\\\\temp\\\\mydir.exe\\\\notepad.exe – will be monitored for MRP.\\nFile match: C:\\\\temp\\\\mydir.exe\\\\data.log – will be monitored for MRP.\\nFile match: C:\\\\temp\\\\mydir.exe\\\\notes.txt– will be monitored for MRP.\\nMonitored directory is C:\\\\temp, monitor flags are MRP (MODIFY, READ, PERMISSIONS).\\nExclude filter of *.log\\nDepth = 3\\nChanges to any file not matching *.log are recorded.\\nMonitored directory is C:\\\\temp, monitor flags are MRP (MODIFY, READ, PERMISSIONS).\\nExclude filter of *.log\\nDepth = 3\\nChanges to any file not matching *.log are recorded.\\nMonitored directory is C:\\\\temp, monitor flags are MRP (MODIFY, READ, PERMISSIONS).\\nExclude filter of *.log\\nDepth = 3\\nChanges to any file not matching *.log are recorded.\\nMonitored directory is C:\\\\temp, monitor flags are MRP (MODIFY, READ, PERMISSIONS).\\nInclude filter of *.exe.\\nExclude filter of *debug*.\\nDepth = 3.\\nChanges to any file matching *.exe and not matching *debug* are recorded. If the file is C:\\\\temp\\\\foo.exe, it is included. If the file is C:\\\\debugdir\\\\notepad.exe, then it is excluded, because the directory\\nC:\\\\debugdir and all its files and subdirectories are excluded. Any subdirectory matching *.exe is included in monitoring and all files and subdirectories directly within it are monitored unless they match the *debug* exclude filter.\\nMonitored directory is C:\\\\temp, monitor flags are MRP (MODIFY, READ, PERMISSIONS).\\nInclude filter of *.exe.\\nExclude filter of *debug*.\\nDepth = 3.\\nChanges to any file matching *.exe and not matching *debug* are recorded. If the file is C:\\\\temp\\\\foo.exe, it is included. If the file is C:\\\\debugdir\\\\notepad.exe, then it is excluded, because the directory\\nC:\\\\debugdir and all its files and subdirectories are excluded. Any subdirectory matching *.exe is included in monitoring and all files and subdirectories directly within it are monitored unless they match the *debug* exclude filter.\\nMonitored directory is C:\\\\temp, monitor flags are MRP (MODIFY, READ, PERMISSIONS).\\nInclude filter of *.exe.\\nExclude filter of *debug*.\\nDepth = 3.\\nChanges to any file matching *.exe and not matching *debug* are recorded. If the file is C:\\\\temp\\\\foo.exe, it is included. If the file is C:\\\\debugdir\\\\notepad.exe, then it is excluded, because the directory\\nC:\\\\debugdir and all its files and subdirectories are excluded. Any subdirectory matching *.exe is included in monitoring and all files and subdirectories directly within it are monitored unless they match the *debug* exclude filter.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nEndpoint Monitoring\\n/\\nFile Integrity Monitor (FIM)\\n', 'Modify File Integrity Monitor Policies': 'The LogRhythm deployment includes default policy templates for each supported operating system. These templates are examples of policies that can be created. Using them without modifying them to fit your specific needs is not recommended. You can also use the File Integrity Policy Manager to modify policies you have created.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nFile Integrity Monitor Policy Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nFile Integrity Monitor Policy Manager\\n.\\nSelect an existing policy.\\nSelect an existing policy.\\nOn the File menu, click\\nProperties\\n.\\nThe File Integrity Monitor Policy Properties window appears.\\nOn the File menu, click\\nProperties\\n.\\nThe File Integrity Monitor Policy Properties window appears.\\nMake any changes you want to Description, Monitoring Configurations, or Monitored Items.\\nMake any changes you want to Description, Monitoring Configurations, or Monitored Items.\\nTo save your changes and close the window, click\\nOK\\n.\\nTo save your changes and close the window, click\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nEndpoint Monitoring\\n/\\nRegistry Integrity Monitor (RIM)\\n', 'Associate Items to RIM Policies': 'Items are Registry Keys that have been configured in the Registry Integrity Monitor Policy Item Manager.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, then click\\nRegistry Integrity Policy Manager\\n.\\nThe Registry Integrity Monitor Policy Manager window appears.\\nSelect the\\nAction\\ncheck box, right-click the Registry Integrity Monitor Policy, and then click\\nProperties\\n.\\nThe Registry Integrity Monitor Policy Properties windows appears.\\nClick the Associate Policy Item button at the bottom of the window.\\nThe Registry Integrity Monitor Policy Item Selector window appears.\\nThe Registry Integrity Monitor Policy Item Selector window appears.\\nSelect the Action check box of the items to be included in the policy.\\nSelect the Action check box of the items to be included in the policy.\\nClick\\nOK\\n.\\nThe selected items appear in the Monitored Keys section of the Registry Integrity Monitor Policy Properties window.\\nClick\\nOK\\n.\\nThe selected items appear in the Monitored Keys section of the Registry Integrity Monitor Policy Properties window.\\nTo save the policy, click\\nOK\\n.\\nTo save the policy, click\\nOK\\n.\\nTo clear the Registry Integrity Monitor Policy Manager window, click\\nClose\\n.\\nTo clear the Registry Integrity Monitor Policy Manager window, click\\nClose\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nEndpoint Monitoring\\n/\\nRegistry Integrity Monitor (RIM)\\n', 'Associate RIM Policies to Windows System Monitor Agents': 'Registry Integrity Monitor Policies must be associated to a Windows Agent to have the Registry Keys listed in them monitored.\\nMore than one Registry Integrity Monitor Policy can be associated to a Windows System Monitor Agent.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nSystem Monitors\\ntab.\\nSelect a\\nWindows System Monitor Agent\\n.\\nRight-click the Windows Agent, and then click\\nProperties\\n.\\nThe System Monitor Agent Properties window appears.\\nSelect the\\nEndpoint Monitoring\\ntab.\\nSelect the\\nEndpoint Monitoring\\ntab.\\nSelect the\\nRegistry Integrity Monitor\\nsub tab.\\nSelect the\\nRegistry Integrity Monitor\\nsub tab.\\nTo activate the Policy section, select the\\nEnable Registry Integrity Monitor\\ncheck box.\\nTo activate the Policy section, select the\\nEnable Registry Integrity Monitor\\ncheck box.\\nIn the Policy section, select the policies to be associated to the Windows Agent.\\nIn the Policy section, select the policies to be associated to the Windows Agent.\\nClick\\nOK\\n.\\nThe selected policies are associated to the selected Windows System Monitor Agent.\\nClick\\nOK\\n.\\nThe selected policies are associated to the selected Windows System Monitor Agent.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nEndpoint Monitoring\\n/\\nRegistry Integrity Monitor (RIM)\\n', 'Configure RIM Policy Items': '\\nBefore you begin these instructions, be sure to have the list of Registry Keys to be monitored on hand.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, then click\\nRegistry Integrity Policy Manager\\n.\\nThe Registry Integrity Monitor Policy Manager window appears.\\nClick the\\nLaunch Policy Item Manager\\nbutton.\\nThe Registry Integrity Monitor Policy Item Manager window appears.\\nRight-click inside the window, and then click\\nNew\\n.\\nThe Registry Integrity Monitor Policy Item window appears.\\nComplete the following fields:\\nRegistry Key\\n. Enter the Registry Key to be monitored, for example, you can enter HKEY_LOCAL_MACHINE or HKLM.\\nRecurse Subkeys\\n. (Optional) Select the Recurse Subkeys check box to have the policy monitor all of the subkeys under the initial Registry Key.\\nComplete the following fields:\\nRegistry Key\\n. Enter the Registry Key to be monitored, for example, you can enter HKEY_LOCAL_MACHINE or HKLM.\\nRegistry Key\\n. Enter the Registry Key to be monitored, for example, you can enter HKEY_LOCAL_MACHINE or HKLM.\\nRecurse Subkeys\\n. (Optional) Select the Recurse Subkeys check box to have the policy monitor all of the subkeys under the initial Registry Key.\\nRecurse Subkeys\\n. (Optional) Select the Recurse Subkeys check box to have the policy monitor all of the subkeys under the initial Registry Key.\\nTo save the item, click\\nOK\\n.\\nThe window closes and the item appears in the Registry Integrity Monitor Policy Item Manager window.\\nTo save the item, click\\nOK\\n.\\nThe window closes and the item appears in the Registry Integrity Monitor Policy Item Manager window.\\nRepeat steps 3 through 5 to configure more Registry Keys for the Registry Integrity Monitor Policy.\\nRepeat steps 3 through 5 to configure more Registry Keys for the Registry Integrity Monitor Policy.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nEndpoint Monitoring\\n/\\nRegistry Integrity Monitor (RIM)\\n', 'Create RIM Policies': 'A Registry Integrity Monitor Policy is a container that holds the registry keys to be monitored.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, then click\\nRegistry Integrity Policy Manager\\n.\\nOn the File menu, click\\nNew\\n.\\nThe Registry Integrity Monitor Policy Properties window appears.\\nOn the File menu, click\\nNew\\n.\\nThe Registry Integrity Monitor Policy Properties window appears.\\nComplete the following fields:\\nName\\n. Enter a name for the policy.\\nDescription\\n.\\n(Optional)\\nEnter a description for the policy.\\nComplete the following fields:\\nName\\n. Enter a name for the policy.\\nName\\n. Enter a name for the policy.\\nDescription\\n.\\n(Optional)\\nEnter a description for the policy.\\nDescription\\n.\\n(Optional)\\nEnter a description for the policy.\\nTo save the policy, click\\nOK\\n.\\nThe Registry Integrity Monitor Policy Manager window appears with the newly created policy listed.\\nTo save the policy, click\\nOK\\n.\\nThe Registry Integrity Monitor Policy Manager window appears with the newly created policy listed.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nEntities\\n', 'Run the Entities Reorganization Wizard': 'Only Global Admins or Restricted Admins with elevated View and Manage privileges can take this action.\\nTo migrate Host and Network records between Entities\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nEntities\\ntab.\\nOn the Edit menu, click\\nReorganization Wizard\\n.\\nThe Entity Move Wizard appears.\\nOn the Edit menu, click\\nReorganization Wizard\\n.\\nSelect the Entity to which you want to move existing network and host records, and then click\\nNext\\n.\\nThe wizard displays the Network and Host records that can be moved.\\nSelect the Entity to which you want to move existing network and host records, and then click\\nNext\\n.\\nSelect the\\nMove\\ncheck box next to the Network and Host records that you want to move, and then click\\nNext\\n.\\nSelect the\\nMove\\ncheck box next to the Network and Host records that you want to move, and then click\\nNext\\n.\\nReview the pending moves in the Review Items list.\\nReview the pending moves in the Review Items list.\\nIf you want to make any changes, click\\nBack\\nto return to the selection window, revise your selections, and then click\\nNext\\nto return to the Review Items list.\\nIf you want to make any changes, click\\nBack\\nto return to the selection window, revise your selections, and then click\\nNext\\nto return to the Review Items list.\\nWhen you are ready to move the pending items, click\\nOK\\n.\\nThe status of the selected records is updated in the Review Items list.\\nWhen you are ready to move the pending items, click\\nOK\\n.\\nThe status of the selected records is updated in the Review Items list.\\nClick\\nClose\\nto exit the wizard.\\nYou must close the Client Console and log back in before any changes are applied.\\nClick\\nClose\\nto exit the wizard.\\nYou must close the Client Console and log back in before any changes are applied.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nGlobal Log Processing Rules\\n', 'Create Global Log Processing Rules': \"You can create a GLPR using the Global Log Processing Rule Manager or using a log message that is returned by a Tail or an Investigation. The process of defining the rule criteria is the same for each method.\\nIf a log does not match GLPR filter criteria, it is processed according to the Classification Based Data Management (CBDM) or standard Data Management settings.\\nExample 1: Create a GLPR to override indexing, and the override specifies Don't Index:\\nA log does not match the GLPR filter criteria.\\nThe classification is set to index based on a Global Classification setting in CBDM.\\nIn this case, the log will be indexed.\\nExample 2: Create a GLPR to override indexing, and the override specifies Don't Index:\\nA log matches the GLPR filter criteria.\\nThe classification is set to index based on a Global Classification setting in CBDM.\\nIn this case, the log will not be indexed.\\nTo create a rule from a Tail or an Investigation, right-click one of the logs or events, and then click\\nCreate Global Log Processing Rule\\n. You will be prompted to define some of the rule criteria using most of the metadata in the log message or a limited set of the metadata. After selecting the metadata option for the rule criteria, the Global Log Processing Rule Wizard appears. Skip to step 4 in the following procedure.\\nTo create a GLPR:\\nOn the main toolbar, click\\nDeployment Manage\\nr.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nGlobal Log Processing Rule Manager\\n.\\nThe Global Log Processing Rule Manager appears.\\nClick the\\nNew Rule\\nicon.\\nThe Global Log Processing Rule Wizard opens to the Classification tab.\\nClick\\nAdd Item\\n.\\nThe Classification Selector appears.\\nSelect an option from the Classification Type Filter list.\\nThe Classification list populates.\\nSelect one or more items from the Classification list.\\nClick\\nOK\\nto return to the Global Log Processing Rule Wizard.\\nRepeat the process to add as many additional filters as needed.\\nUnder Risk Based Priority (RBP) Criteria, specify a minimum Risk Based Priority (RBP) log messages must meet to match the rule.\\nClick\\nNext\\n.\\nYou move to the Include Filters tab. For more information, see\\nFilters—Include Filter\\n.\\nClick\\nNext\\n.\\nYou move to the Exclude Filters tab. For more information, see\\nFilters—Exclude Filter\\n.\\nAn Include or Exclude Filter is required.\\nClick\\nNext\\n.\\nYou move to the Exclude Filters tab. For more information, see\\nFilters—Exclude Filter\\n.\\nAn Include or Exclude Filter is required.\\nClick\\nNext\\n.\\nYou move to the Log Source Criteria.\\nSelect one of the following:\\nInclude All Log Sources\\n. This is the default.\\nInclude Log Sources from the Selected Lists\\n. Selecting this option populates the grid below, where you can select the lists you want.\\nInclude the Selected Log Sources\\n. Selecting this option populates the grid below, where you can select the log sources you want.\\nInclude All Log Sources\\n. This is the default.\\nInclude Log Sources from the Selected Lists\\n. Selecting this option populates the grid below, where you can select the lists you want.\\nInclude the Selected Log Sources\\n. Selecting this option populates the grid below, where you can select the log sources you want.\\nClick\\nNext\\nto proceed to the Settings tab.\\nSelect the overrides you want according to the information in the following table.\\nYou must configure at least one override setting when creating a GLPR.\\nOverride Settings\\nSetting\\nDescription\\nLog Data Management Settings\\nOverride Archiving\\nArchive\\nor\\nDon't Archive\\nDetermines whether matching logs should be stored in offline archive files.\\nOverride Index\\nIndex\\nor\\nDon't Index\\nDetermines whether matching logs should be indexed in the online repository (also referred to as ‘Drop Whole Log’ in other areas of the product).\\nOverride Drop Raw Log\\nStore Raw Log\\nor\\nDon't Store Raw Log\\nDetermines whether raw logs should be stored.\\nOverride Common Event\\nSelect this option and then select an alternate Common Event to forward to the Data Indexer, Platform Manager, or LogMart.\\nWhen this option is enabled, the Override Common Event option under Event Management Settings is selected as read-only, and its value will be updated.\\nExample: To configure LogRhythm to watch for Dropped Packet logs that are outbound and on a specific port that you suspect have been recruited into a botnet, change the Common Event to Dropped Packet: BotNet Traffic.\\nEvent Management Settings\\nOverride Event Forwarding\\nForward as Event\\n,\\nDon't Forward as Event\\n, or\\nIgnore Global Risk Based (RBP) Criteria\\nDetermines whether matching logs should be forwarded as an Event and stored in the Platform Manager Database.\\nOverride RBP Value Assigned\\nOverrides the assigned RBP value. Specify a value between 0 and 100.\\nOverride Risk Rating\\nAllows you to apply a custom Risk Rating to matching logs.\\nOverride False Alarm Rating\\nAllows you to apply a custom False Alarm Rating to matching logs.\\nOverride Common Event\\nSelect this option and then select an alternate Common Event to forward to the Platform Manager.\\nThis does not change the log's Common Event. To do this, you must enable the Override Common Event option under Log Data Management Settings.\\nExample: To configure LogRhythm to watch for Dropped Packet logs that are outbound and on a specific port that you suspect have been recruited into a botnet, change the Common Event to Dropped Packet: BotNet Traffic.\\nLogMart Settings\\nOverride LogMart Forwarding\\nForward to LogMart\\nor\\nDon't Forward to LogMart\\nDetermines whether matching logs should be forwarded to the LogMart database.\\nOverride LogMart Aggregation\\nDetermines whether matching logs should be grouped together using customizable LogMart Record Fields. Click Settings to specify the optional fields that will be stored as part of every LogMart record.\\nAdvanced Intelligence (AI) Engine Settings\\nDon't Forward Logs to AI Engine\\nOverrides the option to forward logs to AI\\xa0Engine.\\nSelect the overrides you want according to the information in the following table.\\nYou must configure at least one override setting when creating a GLPR.\\nOverride Settings\\nSetting, Description\\nLog Data Management Settings\\nOverride Archiving, ArchiveorDon't ArchiveDetermines whether matching logs should be stored in offline archive files.\\nOverride Index, IndexorDon't IndexDetermines whether matching logs should be indexed in the online repository (also referred to as ‘Drop Whole Log’ in other areas of the product).\\nOverride Drop Raw Log, Store Raw LogorDon't Store Raw LogDetermines whether raw logs should be stored.\\nOverride Common Event, Select this option and then select an alternate Common Event to forward to the Data Indexer, Platform Manager, or LogMart.When this option is enabled, the Override Common Event option under Event Management Settings is selected as read-only, and its value will be updated.Example: To configure LogRhythm to watch for Dropped Packet logs that are outbound and on a specific port that you suspect have been recruited into a botnet, change the Common Event to Dropped Packet: BotNet Traffic.\\nEvent Management Settings\\nOverride Event Forwarding, Forward as Event,Don't Forward as Event, orIgnore Global Risk Based (RBP) CriteriaDetermines whether matching logs should be forwarded as an Event and stored in the Platform Manager Database.\\nOverride RBP Value Assigned, Overrides the assigned RBP value. Specify a value between 0 and 100.\\nOverride Risk Rating, Allows you to apply a custom Risk Rating to matching logs.\\nOverride False Alarm Rating, Allows you to apply a custom False Alarm Rating to matching logs.\\nOverride Common Event, Select this option and then select an alternate Common Event to forward to the Platform Manager.This does not change the log's Common Event. To do this, you must enable the Override Common Event option under Log Data Management Settings.Example: To configure LogRhythm to watch for Dropped Packet logs that are outbound and on a specific port that you suspect have been recruited into a botnet, change the Common Event to Dropped Packet: BotNet Traffic.\\nLogMart Settings\\nOverride LogMart Forwarding, Forward to LogMartorDon't Forward to LogMartDetermines whether matching logs should be forwarded to the LogMart database.\\nOverride LogMart Aggregation, Determines whether matching logs should be grouped together using customizable LogMart Record Fields. Click Settings to specify the optional fields that will be stored as part of every LogMart record.\\nAdvanced Intelligence (AI) Engine Settings\\nDon't Forward Logs to AI Engine, Overrides the option to forward logs to AI\\xa0Engine.\\nArchive\\nor\\nDon't Archive\\nDetermines whether matching logs should be stored in offline archive files.\\nIndex\\nor\\nDon't Index\\nDetermines whether matching logs should be indexed in the online repository (also referred to as ‘Drop Whole Log’ in other areas of the product).\\nStore Raw Log\\nor\\nDon't Store Raw Log\\nDetermines whether raw logs should be stored.\\nSelect this option and then select an alternate Common Event to forward to the Data Indexer, Platform Manager, or LogMart.\\nWhen this option is enabled, the Override Common Event option under Event Management Settings is selected as read-only, and its value will be updated.\\nExample: To configure LogRhythm to watch for Dropped Packet logs that are outbound and on a specific port that you suspect have been recruited into a botnet, change the Common Event to Dropped Packet: BotNet Traffic.\\nForward as Event\\n,\\nDon't Forward as Event\\n, or\\nIgnore Global Risk Based (RBP) Criteria\\nDetermines whether matching logs should be forwarded as an Event and stored in the Platform Manager Database.\\nSelect this option and then select an alternate Common Event to forward to the Platform Manager.\\nThis does not change the log's Common Event. To do this, you must enable the Override Common Event option under Log Data Management Settings.\\nExample: To configure LogRhythm to watch for Dropped Packet logs that are outbound and on a specific port that you suspect have been recruited into a botnet, change the Common Event to Dropped Packet: BotNet Traffic.\\nForward to LogMart\\nor\\nDon't Forward to LogMart\\nDetermines whether matching logs should be forwarded to the LogMart database.\\nDetermines whether matching logs should be grouped together using customizable LogMart Record Fields. Click Settings to specify the optional fields that will be stored as part of every LogMart record.\\nClick\\nNext\\nto proceed to the Information tab.\\nEnter a name for the rule (required) and an optional description.\\nIf you want to set an expiration date for the rule, select the\\nConfigure Expiration Date\\ncheck box and specify the date and time when the rule should expire.\\nClick\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nHost Records\\n', 'Add Host Records Manually': 'You must be logged in as an Administrator to take this action.\\nOn the main toolbar, click\\nDeployment Manager.\\nClick the\\nEntities\\ntab, and then select the Entity to which you want to assign the Host.\\nIn the Entity Hosts pane at the lower-right, click\\nNew\\n.\\nThe Host dialog box appears.\\nOn the Basic Information tab, enter the following details:\\nField\\nDescription\\nName (required)\\nThe name to assign to the new host.\\nLogRhythm does not support hostnames that include spaces.\\nHost Zone (required)\\nInternal, DMZ, or External\\nOperating System\\nThe operating system of the new host. Click the ellipsis [...] button next to the Operating System box. In the Operating System Selector window, click your operating system in the list, and then click\\nOK\\n.\\nOperating System Version\\nThe version of the selected operating system that is running on the new host.\\nHost Location\\nThe geographic location of the new host. Click the ellipsis [...] button next to the Host Location box. In the Location Selector window, select the country, region, and city where the host is located.\\nBrief Description\\nAn optional description of the new host.\\nHost Risk Level (required)\\nRepresents the amount of risk developed if the system were to become compromised or the subject of some other issue. A value of 0 indicates that no risk is involved in the loss of this system. A value of 9 indicates the most risk would be incurred if the system were compromised. The risk level is relevant when the host is the impacted system, target, or is acted upon by external forces.\\nWindows Event Log Credentials\\nWhen the operating system is Windows, if you want the Agent to use different credentials for each host in the deployment when collecting Event Logs, select the\\nUse specified credentials\\ncheck box and provide the username and password to be used. If you do not select this option, the Agent uses its own service credentials.\\nMulti-domain event log collection is only supported on Windows Vista, 7, 8, 2008, or 2012. Windows XP, 2000, and 2003 are not supported.\\nOn the Basic Information tab, enter the following details:\\nField, Description\\nName (required), The name to assign to the new host.LogRhythm does not support hostnames that include spaces.\\nHost Zone (required), Internal, DMZ, or External\\nOperating System, The operating system of the new host. Click the ellipsis [...] button next to the Operating System box. In the Operating System Selector window, click your operating system in the list, and then clickOK.\\nOperating System Version, The version of the selected operating system that is running on the new host.\\nHost Location, The geographic location of the new host. Click the ellipsis [...] button next to the Host Location box. In the Location Selector window, select the country, region, and city where the host is located.\\nBrief Description, An optional description of the new host.\\nHost Risk Level (required), Represents the amount of risk developed if the system were to become compromised or the subject of some other issue. A value of 0 indicates that no risk is involved in the loss of this system. A value of 9 indicates the most risk would be incurred if the system were compromised. The risk level is relevant when the host is the impacted system, target, or is acted upon by external forces.\\nWindows Event Log Credentials, When the operating system is Windows, if you want the Agent to use different credentials for each host in the deployment when collecting Event Logs, select theUse specified credentialscheck box and provide the username and password to be used. If you do not select this option, the Agent uses its own service credentials.Multi-domain event log collection is only supported on Windows Vista, 7, 8, 2008, or 2012. Windows XP, 2000, and 2003 are not supported.\\nThe name to assign to the new host.\\nLogRhythm does not support hostnames that include spaces.\\nWhen the operating system is Windows, if you want the Agent to use different credentials for each host in the deployment when collecting Event Logs, select the\\nUse specified credentials\\ncheck box and provide the username and password to be used. If you do not select this option, the Agent uses its own service credentials.\\nMulti-domain event log collection is only supported on Windows Vista, 7, 8, 2008, or 2012. Windows XP, 2000, and 2003 are not supported.\\nOn the Identifiers tab, enter Host Identifiers. Identifiers are used by the MPE to associate values in a log message to the correct host record. Available identifiers include static IP addresses, Windows names, and DNS names. Enter all aliases a host may have, but do not enter aliases that are subject to change. For example, a current IP that is assigned by DHCP could lead to misidentified logs because it changes.\\nOn the Host Roles tab, enter key contacts.\\nOn the Threat Level tab, designate the amount of threat that is developed if the system were to be the origin of actions. Select the\\nAdd to Global Source Threat List\\ncheck box if there is any treat level other than 0 (none/no risk). A value of 1 (low-low (lowest threat)) means that actions originating from this host are of little cause for alarm or are possibly commonplace, and a value of 9 (high-high (highest threat)) means that this system should not be the source of outgoing actions and that there is the greatest threat to security if such events are observed.\\nOn the Additional Information tab, add any other useful information.\\nClick\\nOK\\n.\\nYou can add an origin or impacted Host as the known Host from a log returned in search results. For more information, see the information on\\nContext Menus\\n.\\nClick\\nOK\\n.\\nYou can add an origin or impacted Host as the known Host from a log returned in search results. For more information, see the information on\\nContext Menus\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nHost Records\\n', 'Windows Host Wizard': 'The Windows Host Wizard connects to Active Directory to find Windows systems on the domain. Eligible systems returned by the scan can be selected for remote log collection. Correctly defined permissions are essential to identify systems and collect logs.\\nThe wizard can only scan domains that have the Include in Scan option selected in the domain properties under Windows Host Wizard. For more information, see\\nConfigure Initial Host Settings (Domain, Entity, and Log Source Types)\\n.\\n', 'Requirements for Scanning': 'The Remote Registry service on Agent-less systems must be started for machines to be identified in the scan.\\nThe user logged in to the machine where the scan is taking place must be a domain user on the domain being scanned or the scan will fail to run.\\n', 'Requirements for Firewall Settings': 'If firewalls are used on systems in your network:\\nTo allow for remote log collection, an exception for port 443 must be added to the Windows Firewall settings on the Agent-less systems.\\nThe Client Console machine should also have an exception for port 443.\\nTo allow the host machine to be identified, the Remote Admin exception must be added to the Windows Firewall settings on the Agent-less systems. If it does not appear in the list of Programs and Services within Windows firewall exceptions tab, add it from a command prompt by typing the following command:\\nCODE\\nnetsh firewall set service remoteadmin enable\\nTo confirm it is enabled, type the following:\\nCODE\\nnetsh firewall show state\\nTo allow the host machine to be identified, the Remote Admin exception must be added to the Windows Firewall settings on the Agent-less systems. If it does not appear in the list of Programs and Services within Windows firewall exceptions tab, add it from a command prompt by typing the following command:\\nTo confirm it is enabled, type the following:\\n', 'Requirements for Remote Collection': 'To collect logs remotely from another system, the collecting Agent’s service must be running under an account that is in the Event Log Readers group. For more information, refer to the\\nLogRhythm Guide: Least-Privileged User\\n.\\n', 'Requirements for Security Event Logs': 'The user running the scan must have administrator privileges on the system that is running the Client Console and for the systems on the domain from which logs will be collected. This can be achieved by setting up local users with Administrator rights or by using users with domain administrator privileges.\\n', 'Miscellaneous Requirements': 'Any other settings on the systems related to firewall, permissions, or security may impact scanning, identification, or collection of event logs.\\n', 'Allowable Platforms for Remote Log Collection': 'The following is a table of the allowable combinations for collection setup. The table provides the following parameters:\\nAgent Operating System\\n. Operating system of the machine where the agent is installed.\\nLog Message Source Host\\n. Machine from which the MS Event Logs will be collected.\\nLog Message Source Type\\n. Log Message Source Type selected for the Log Message Source Host.\\nLocal Event Log Collection Allowed?\\nWhether the agent can collect the Log Message Source locally.\\nRemote Event Log Collection Allowed?\\nWhether the agent can collect the Log Message Source remotely.\\n\\nAgent Operating System, Log Message Source Host System, Log Message Source Type, Local Event Log Collection Allowed?, Remote Event Log Collection Allowed?\\nXP/2003, 2000, MS Event Log for XP/2000/2003, n/a, Yes\\nXP/2003, XP/2003, MS Event Log for XP/2000/2003, Yes, Yes\\nXP/2003, 2008/Vista, MS Windows Event Logging, n/a, No\\nXP/2003, Win7/2008R2, MS Windows Event Logging, n/a, No\\nXP/2003, Win8/2012, MS Windows Event Logging, n/a, No\\n2008, 2000, MS Event Log for XP/2000/2003, n/a, Yes\\n2008, XP/2003, MS Event Log for XP/2000/2003, n/a, Yes\\n2008, 2008/Vista, MS Windows Event Logging, Yes, Yes\\n2008, Win7/2008R2, MS Windows Event Logging, n/a, Yes\\n2008, Win8/2012, MS Windows Event Logging, n/a, Yes\\nWin7/2008R2, 2000, MS Event Log for XP/2000/2003, n/a, Yes\\nWin7/2008R2, XP/2003, MS Event Log for XP/2000/2003, n/a, Yes\\nWin7/2008R2, 2008/Vista, MS Windows Event Logging, n/a, Yes\\nWin7/2008R2, Win7/2008R2, MS Windows Event Logging, Yes, Yes\\nWin7/2008R2, Win8/2012, MS Windows Event Logging, n/a, Yes\\nWin8/2012, 2000, MS Event Log for XP/2000/2003, n/a, Yes\\nWin8/2012, XP/2003, MS Event Log for XP/2000/2003, n/a, Yes\\nWin8/2012, 2008/Vista, MS Windows Event Logging, n/a, Yes\\nWin8/2012, Win7/2008R2, MS Windows Event Logging, n/a, Yes\\nWin8/2012, Win8/2012, MS Windows Event Logging, Yes, Yes\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nHost Records\\n/\\nWindows Host Wizard\\n', 'Configure Initial Host Settings in Windows Host Wizard': '\\nOnly Global Admins or Restricted Admins with elevated View and Manage privileges can take this action.\\nDuring a deployment, the first step is to configure the initial settings of the domains, entities, and log source types that will be used during scanning. The configuration is saved so the wizard does not need to be configured each time.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nWindows Host Wizard\\n.\\nThe Windows Host Wizard appears.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nWindows Host Wizard\\n.\\nThe Windows Host Wizard appears.\\nThe first time the Windows Host Wizard opens, the Settings dialog box is automatically opened. On subsequent occasions, click\\nSettings\\n.\\nThe Settings window appears with the Domains tab.\\nThe first time the Windows Host Wizard opens, the Settings dialog box is automatically opened. On subsequent occasions, click\\nSettings\\n.\\nThe Settings window appears with the Domains tab.\\nFrom the context menu, select\\nNew\\nto specify a new domain to include in the scans.\\nEnter the New Domain Properties as directed.\\nDomain Name\\n. A required field.\\nOrganizational Unit\\n. An optional field.\\nUser Name\\nand\\nPassword\\n. Can be used to provide alternate credentials. Otherwise, the login account will be used for authentication by Active Directory. These credentials only apply to Scan Domains. They are not used by Query Computers.\\nInclude in Scan\\n. Check box selected by default.\\nDefault LogRhythm Entity\\n. A required field.\\nScan Sub Units\\n. An optional field. When checked, all OU units are recursively scanned for all OU units below the one specified in Organizational Unit.\\nInclude in Active Directory Synchronization\\n. This check box is unavailable.\\nInclude in Active Directory Group Based Authorization\\n. This check box is unavailable.\\nBrief Description\\n. An optional field.\\nDomain Name\\n. A required field.\\nOrganizational Unit\\n. An optional field.\\nUser Name\\nand\\nPassword\\n. Can be used to provide alternate credentials. Otherwise, the login account will be used for authentication by Active Directory. These credentials only apply to Scan Domains. They are not used by Query Computers.\\nInclude in Scan\\n. Check box selected by default.\\nDefault LogRhythm Entity\\n. A required field.\\nScan Sub Units\\n. An optional field. When checked, all OU units are recursively scanned for all OU units below the one specified in Organizational Unit.\\nInclude in Active Directory Synchronization\\n. This check box is unavailable.\\nInclude in Active Directory Group Based Authorization\\n. This check box is unavailable.\\nBrief Description\\n. An optional field.\\nTo validate the domain using Active Directory and refresh the domain details, click the\\nDetails\\ntab and click\\nValidate.\\nTo validate the domain using Active Directory and refresh the domain details, click the\\nDetails\\ntab and click\\nValidate.\\nClick\\nOK\\n.\\nOn the Domains tab, review the domains to be scanned and select or clear the check box in the Include In Scan column, if necessary. At least one domain must be selected to scan the domains for computers.\\nOn the Domains tab, review the domains to be scanned and select or clear the check box in the Include In Scan column, if necessary. At least one domain must be selected to scan the domains for computers.\\nClick\\nOK\\n.\\nClick the\\nLog Source Types\\ntab.\\nSelect the types of log sources to detect when scanning and querying hosts. To select or clear all log source types, right-click and select\\nCheck All\\nor\\nUncheck All\\n.\\nThe Security, Sysmon, and System Legacy Windows Event log source types cannot be selected on this step. Those log source types can be added after the Windows Host Wizard scans in new hosts, if needed.\\nSelect the types of log sources to detect when scanning and querying hosts. To select or clear all log source types, right-click and select\\nCheck All\\nor\\nUncheck All\\n.\\nThe Security, Sysmon, and System Legacy Windows Event log source types cannot be selected on this step. Those log source types can be added after the Windows Host Wizard scans in new hosts, if needed.\\nTo modify the properties of an individual log source, highlight the log source, and then click\\nProperties\\n.\\nChange the MPE Processing Mode and MPE Policy, if necessary.\\nTo begin log collection at the beginning of the log, select\\nStart Collection\\nfrom the beginning of the log check box.\\nBatch editing of properties is not permitted.\\nTo modify the properties of an individual log source, highlight the log source, and then click\\nProperties\\n.\\nChange the MPE Processing Mode and MPE Policy, if necessary.\\nTo begin log collection at the beginning of the log, select\\nStart Collection\\nfrom the beginning of the log check box.\\nBatch editing of properties is not permitted.\\nTo begin log collection at the beginning of the log, select\\nStart Collection\\nfrom the beginning of the log check box.\\nBatch editing of properties is not permitted.\\nClick\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nKnowledge Base\\n', 'Configure Knowledge Base Synchronization Settings': '\\nK\\nnowledge Base Synchronization Settings can affect the status of\\nAI Engine Rules\\nafter a Knowledge Base synchronization. Before\\nsyncing the Knowledge Base,\\nreview your settings on the Synchronize Additional System Properties tab in the AI Engine Rule Properties section and verify that the Enable Advanced Synchronization Settings check box is unchecked. For a detailed explanation of these settings, see\\nA\\nI Engine Rule Properties\\n.\\nKnowledge Base Automatic Synchronization Settings allow you to set the Synchronization Mode, Schedule, and Synchronize Additional System Properties. These settings are accessed via the Automatic Synchronization Settings button.\\nSet Synchronization Mode.\\nOn the Synchronization Mode tab, determine the Knowledge Base Automatic Synchronization Mode settings.\\nSelect the\\nEnable Automatic Knowledge Base Download\\ncheck box. When enabled, you can choose to enable the Knowledge Base Core synchronization, enable Knowledge Base Module synchronization, or stop synchronization when Common Event migrations are detected.\\nOn the Synchronization Mode tab, determine the Knowledge Base Automatic Synchronization Mode settings.\\nSelect the\\nEnable Automatic Knowledge Base Download\\ncheck box. When enabled, you can choose to enable the Knowledge Base Core synchronization, enable Knowledge Base Module synchronization, or stop synchronization when Common Event migrations are detected.\\nSet Schedule. On the Schedule tab, set the schedule to check for Knowledge Base updates. Set the frequency (in days), time, and start date.\\nSet Proxy Settings. On the Proxy Settings tab, set the following items:\\nProxy Server Address\\n. You must use the format http://<address> (for example,\\nhttp://123.4.5.6/\\n).\\nProxy Server Port\\n. If necessary, select the Proxy Server Requires Authentication check box and then provide the appropriate credentials.\\nProxy Server Address\\n. You must use the format http://<address> (for example,\\nhttp://123.4.5.6/\\n).\\nProxy Server Port\\n. If necessary, select the Proxy Server Requires Authentication check box and then provide the appropriate credentials.\\nSet Synchronize Additional System Properties. When you have made customizations to filter criteria for System Reports, Investigations, or Tails, you must verify that the Advanced Settings are configured so as not to overwrite your customizations during import.\\nIf you are not familiar with the customizations that have been made to your deployment, obtain this knowledge and/or contact\\nLogRhythm Support\\nfor assistance.\\nSynchronize Additional System Properties\\nDescription\\nLog Processing Properties\\nCommon Events (Recommended)\\nSynchronize all customizable Common Event properties; Classification, Risk Rating, and Description.\\nLog Processing Policies\\nSynchronize all system log processing policies, replacing any customized log and event management settings.\\nPort and Protocol Application and Mappings (Recommended)\\nSynchronize all system port and protocol application mappings. Custom mappings that conflict with system mappings will be replaced. Custom mappings that do not conflict with system mappings will be retained.\\nReport Properties\\nLog Source List Criteria\\nSynchronize the Log Source Criteria for all system reports that use Log Source Lists.\\nFilter Criteria\\nSynchronize the Filter Criteria for all system reports.\\nInvestigation Properties\\nLog Source List Criteria\\nSynchronize the Log Source Criteria for all system Investigations that use Log Source Lists.\\nFilter Criteria\\nSynchronize the Filter Criteria for all system Investigations.\\nTail Properties\\nLog Source List Criteria\\nSynchronize the Log Source Criteria for all system Tails that use Log Source Lists.\\nFilter Criteria\\nSynchronize the Filter Criteria for all system Tails.\\nAI Engine Rule Properties\\nFor a detailed explanation of these settings, see\\nAI Engine Rule Properties\\n.\\nLog Source List Criteria\\nSynchronize the Log Source Criteria for all system\\nAI Engine\\nRules that use Log Source Lists. The check box is unchecked by default (recommended setting).\\nEnable Advanced Synchronization Settings\\nSynchronize user editable rule evaluation settings for all system\\nAI Engine\\nRules. This includes all Rule Block Time Limit settings, Unique Value Rule Block occurrences, and Threshold Rule Block values.\\nThe check box is unchecked by default (recommended setting).\\nOnly Sync Additional Properties for Disabled Rules\\nOnly synchronize advanced settings when the\\nAI Engine\\nRule is disabled.\\nDisable Dynamic Sync Settings Universally\\nManage all dynamic sync rules manually instead of allowing LogRhythm to update them for you as the module content changes. Manual settings persist after Knowledge Base synchronization. Deselecting this setting does not change settings on existing modules. This feature is turned on by default, but most modules are not configured for Dynamic Sync. Modules that are configured to allow Dynamic Sync are determined by LogRhythm.\\nAlarm Rule Properties\\nLog Source List Criteria\\nSynchronize the Log Source Criteria for all system Alarm Rules that use Log Source Lists.\\nPrimary Criteria and Filter Criteria\\nSynchronize the Primary Criteria, Include Filters and Exclude Filters for all Alarm Rules with System: Global Admin permission.\\nGlobal Log Processing Rule Properties\\nLog Source List Criteria\\nSynchronize the Log Source Criteria for all system GLPRs that use Log Source Lists.\\nSet Synchronize Additional System Properties. When you have made customizations to filter criteria for System Reports, Investigations, or Tails, you must verify that the Advanced Settings are configured so as not to overwrite your customizations during import.\\nSynchronize Additional System Properties, Description\\nLog Processing Properties\\nCommon Events (Recommended), Synchronize all customizable Common Event properties; Classification, Risk Rating, and Description.\\nLog Processing Policies, Synchronize all system log processing policies, replacing any customized log and event management settings.\\nPort and Protocol Application and Mappings (Recommended), Synchronize all system port and protocol application mappings. Custom mappings that conflict with system mappings will be replaced. Custom mappings that do not conflict with system mappings will be retained.\\nReport Properties\\nLog Source List Criteria, Synchronize the Log Source Criteria for all system reports that use Log Source Lists.\\nFilter Criteria, Synchronize the Filter Criteria for all system reports.\\nInvestigation Properties, \\nLog Source List Criteria, Synchronize the Log Source Criteria for all system Investigations that use Log Source Lists.\\nFilter Criteria, Synchronize the Filter Criteria for all system Investigations.\\nTail Properties\\nLog Source List Criteria, Synchronize the Log Source Criteria for all system Tails that use Log Source Lists.\\nFilter Criteria, Synchronize the Filter Criteria for all system Tails.\\nAI Engine Rule PropertiesFor a detailed explanation of these settings, seeAI Engine Rule Properties.\\nLog Source List Criteria, Synchronize the Log Source Criteria for all systemAI EngineRules that use Log Source Lists. The check box is unchecked by default (recommended setting).\\nEnable Advanced Synchronization Settings, Synchronize user editable rule evaluation settings for all systemAI EngineRules. This includes all Rule Block Time Limit settings, Unique Value Rule Block occurrences, and Threshold Rule Block values.The check box is unchecked by default (recommended setting).\\nOnly Sync Additional Properties for Disabled Rules, Only synchronize advanced settings when theAI EngineRule is disabled.\\nDisable Dynamic Sync Settings Universally, Manage all dynamic sync rules manually instead of allowing LogRhythm to update them for you as the module content changes. Manual settings persist after Knowledge Base synchronization. Deselecting this setting does not change settings on existing modules. This feature is turned on by default, but most modules are not configured for Dynamic Sync. Modules that are configured to allow Dynamic Sync are determined by LogRhythm.\\nAlarm Rule Properties\\nLog Source List Criteria, Synchronize the Log Source Criteria for all system Alarm Rules that use Log Source Lists.\\nPrimary Criteria and Filter Criteria, Synchronize the Primary Criteria, Include Filters and Exclude Filters for all Alarm Rules with System: Global Admin permission.\\nGlobal Log Processing Rule Properties\\nLog Source List Criteria, Synchronize the Log Source Criteria for all system GLPRs that use Log Source Lists.\\nCommon Events (Recommended)\\nLog Source List Criteria\\nLog Source List Criteria\\nAI Engine Rule Properties\\nFor a detailed explanation of these settings, see\\nAI Engine Rule Properties\\n.\\n', 'AI Engine Rule Properties': '', 'Log Source List Criteria': 'By default, the List Source List Criteria check box is unchecked. The following table explains the synchronization behavior for each check box option.\\nCheck Box, Behavior\\nUnchecked (default), The Log Sources and Log Source Lists are not synchronized from the Knowledge Base (wherever Log Source List and Log Source is used) and keep the current values.This is the recommended setting.\\nChecked, The Log Sources and Log Source Lists are synchronized from theKnowledge Baseinto the rules filter.\\nThe Log Sources and Log Source Lists are not synchronized from the Knowledge Base (wherever Log Source List and Log Source is used) and keep the current values.\\n', 'Enable Advanced Synchronization Settings': \"The Enable Advanced Synchronization Settings check box controls\\xa0an AI Engine Rule's advanced settings on the Settings tab in the AI Engine Rule Wizard, including:\\nExpiration Date\\nRule Group\\nPermissions\\nRun Time Priority\\nRule Set ID\\nSuppression Seconds\\nFalse Positive Probability\\nData Segregation Mode\\nEnable Event Forwarding\\n\\nBy default, the\\xa0Enable Advanced Synchronization Settings check box is unchecked. Also by default, the\\nOnly sync additional properties for disabled setting is grayed out and not applied. The following table explains the synchronization behavior for the available check box combinations.\\nEnable Advanced Synchronization Settings, Only sync additional properties for disabled, Behavior\\nUnchecked (default), Grayed out (default), All user advanced settings for system rules are preserved.This is the recommended setting.\\nChecked, Checked, Only disabled system rules are updated to match the advanced settings for those rules in the Knowledge Base. Enabled system rules are not updated and retain their advanced settings.\\nChecked, Unchecked, All system rules are updated to match the advanced settings in the Knowledge Base.This setting is not recommended on an active deployment because the Rule Set ID will be reset to the default value of 0. This can cause rules to be unassigned from an AI Engine, which causes rules to be disabled.Use this setting only if you want to intentionally reset all rules to match the Knowledge Base.\\nAll user advanced settings for system rules are preserved.\\nAll system rules are updated to match the advanced settings in the Knowledge Base.\\nThis setting is not recommended on an active deployment because the Rule Set ID will be reset to the default value of 0. This can cause rules to be unassigned from an AI Engine, which causes rules to be disabled.\\nUse this setting only if you want to intentionally reset all rules to match the Knowledge Base.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nKnowledge Base\\n', 'Import a Knowledge Base': '\\nIf you are not familiar with the customizations that have been made to your deployment, you should not proceed with the import until such knowledge is acquired, or you should contact\\nLogRhythm Support\\nfor assistance.\\n', 'Import Phase 1: Automatically Download or Select the Knowledge Base File': 'On the Tools menu, click\\nKnowledge\\n, and then click\\nKnowledge Base Manager\\n.\\nThe Deployment Manager must be closed to access the Knowledge Base Manager.\\nThe Knowledge Base Manager appears.\\nOn the Tools menu, click\\nKnowledge\\n, and then click\\nKnowledge Base Manager\\n.\\nThe Deployment Manager must be closed to access the Knowledge Base Manager.\\nThe Knowledge Base Manager appears.\\nDo one of the following:\\nIf you want to automatically download the Knowledge Base, click\\nCheck for Knowledge Base Updates\\nand then click\\nSynchronize Stored Knowledge Base,\\nif necessary.\\nIf you manually downloaded the Knowledge Base file:\\nFrom the Knowledge Base Manager, click\\nFile\\n, then click\\nImport Knowledge Base File\\n.\\nSelect the Knowledge Base File, and then click\\nOK\\n.\\nThe Knowledge Base Import Wizard appears and starts unpacking and validating the Knowledge Base file. The file is checked for compatibility with your current deployment and is prepared for import. This may take several minutes. Upon completion, the Unpack Progress: Knowledge Base unpacked message appears.\\nIf you want to automatically download the Knowledge Base, click\\nCheck for Knowledge Base Updates\\nand then click\\nSynchronize Stored Knowledge Base,\\nif necessary.\\nIf you manually downloaded the Knowledge Base file:\\nFrom the Knowledge Base Manager, click\\nFile\\n, then click\\nImport Knowledge Base File\\n.\\nSelect the Knowledge Base File, and then click\\nOK\\n.\\nThe Knowledge Base Import Wizard appears and starts unpacking and validating the Knowledge Base file. The file is checked for compatibility with your current deployment and is prepared for import. This may take several minutes. Upon completion, the Unpack Progress: Knowledge Base unpacked message appears.\\nFrom the Knowledge Base Manager, click\\nFile\\n, then click\\nImport Knowledge Base File\\n.\\nSelect the Knowledge Base File, and then click\\nOK\\n.\\nThe Knowledge Base Import Wizard appears and starts unpacking and validating the Knowledge Base file. The file is checked for compatibility with your current deployment and is prepared for import. This may take several minutes. Upon completion, the Unpack Progress: Knowledge Base unpacked message appears.\\nTo import the Knowledge Base, click\\nNext\\n.\\nUpon completion, the Import Progress Import Completed message appears.\\nClick\\nOK\\n.\\nThe Knowledge Base Updated message appears.\\nClick\\nOK\\n.\\nOn the Knowledge Base Import Wizard, click\\nClose\\n.\\n', 'Import Phase 2: Enable Knowledge Base Modules and Synchronize': 'Select the\\nAction\\ncheck boxes next to the modules you want.\\nThe Enable Selected Modules message box appears.\\nRight-click the module you want, click\\nActions\\n, and then click\\nEnable Module\\n.\\nIf you want Reports, Report Packages, Tails, and Investigations to have their log data indexed, select the\\nEnable Intelligent Indexing on Module Objects\\ncheck box. For more information, see\\nUse Intelligent Indexing\\n.\\nTo start the synchronization, click\\nOK\\n.\\nWhen complete, click\\nClose\\nto complete the process.\\n', 'Import Phase 3: Migrate Common Event Changes': 'When importing a Knowledge Base with Common Event changes, you are given the opportunity to preview any objects that are affected by the Common Event changes and that require Common Event migration work. These changes can impact the behavior of existing Objects, both System and Custom, as currently deployed. Some Knowledge Base updates include Common Event migration changes, which are changes to the Common Event metadata filters used by LogRhythm. For more information about Common Event Manager, see\\nCommon Event Manager\\n.\\nIf an Action Required message appears, some items need to be updated due to Common Event migration changes. Click\\nCommon Event Change Manager\\n.\\nDo one of the following:\\nTo migrate a Common Event with a preview, select the\\nAction\\ncheck box for the item. Right-click the grid, select\\nMigrate With Preview\\n, and then select either\\nCommon Event To Common Event\\nor\\nCommon Event To MPE Rule\\n.\\nTo migrate a Common Event without a preview, select the\\nAction\\ncheck box for the item. Right-click the grid, select\\nAction\\n, and then select either\\nMigrate Common Event to Common Event\\nor\\nMigrate Common Event To MPE Rule\\n.\\nTo migrate a Common Event with a preview, select the\\nAction\\ncheck box for the item. Right-click the grid, select\\nMigrate With Preview\\n, and then select either\\nCommon Event To Common Event\\nor\\nCommon Event To MPE Rule\\n.\\nTo migrate a Common Event without a preview, select the\\nAction\\ncheck box for the item. Right-click the grid, select\\nAction\\n, and then select either\\nMigrate Common Event to Common Event\\nor\\nMigrate Common Event To MPE Rule\\n.\\nClick\\nClose\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nKnowledge Base\\n', 'Knowledge Base Manager': 'The Knowledge Base Manager is a tool for managing Knowledge Base Modules and their associated objects. Modules and their associated objects are imported with a Knowledge Base. For details regarding the import process, see\\nImport a Knowledge Base\\n.\\nThe Knowledge Base Manager can only be accessed when all other windows in the Client Console are closed.\\n', 'Knowledge Base Modules and Objects Overview': 'The Knowledge Base Module and Objects architecture provides administrators flexibility and ease in managing objects within their deployment, including:\\nThe flexibility to import and synchronize only those modules (and their associated objects) that are relevant to the organization. This is managed through the enable and disable functionality of the module.\\nThe flexibility for administrators to choose if the module should be updated based on the latest LogRhythm module and objects (import by default), or if the module should remain as it is in the current deployment (do not import by default).\\nEase in identifying which modules are out of sync with LogRhythm’s latest version by viewing the Latest and Loaded version values for the module.\\nEase in identifying the specific LogRhythm objects as well as providing others the list of objects for a given module.\\nAbility to modify the modules that are enabled and imported and synchronized from within the Knowledge Base Importer before the import begins.\\n\\n', 'Knowledge Base Modules': \"Knowledge Base Modules are prepackaged, customizable content applicable to a specific regulation or need, such as reports, investigations, alerts, AI Engine rules, or other applicable product areas. For example, the module named Compliance: NERC CIP contains objects for Alarm Rules, Investigations, Lists, Reports, and Report Packages that are useful in providing information necessary to meet NERC CIP requirements.\\nThe LogRhythm Required Objects module is a module that is required for every deployment to function properly. Required modules are always imported and synchronized with every Knowledge Base import and are not editable by administrators.\\nThe Knowledge Base Modules grid allows you to review existing KB modules and modify their status and synchronization settings. In this grid, you can perform the following actions:\\nView and edit properties for a module\\nEnable or disable a module\\nExport the grid information to a file, including:\\nPrimary objects in the module\\nDependent objects in the module\\nPrimary and dependent objects in the module\\nPrimary objects in the module\\nDependent objects in the module\\nPrimary and dependent objects in the module\\nThe Knowledge Base Modules grid contains the columns described in the following table.\\nColumn, Description\\nName, The name of the module\\nDescription, The description for the module\\nLatest Version, The latest version of the module from the last Knowledge Base that was imported\\nLoaded Version, The version that is loaded in the deployment\\nEnabled, The indicator if the module is enabled in the deployment. This means that the module's objects are in the deployment (available to users). The module was imported and synchronized at one point.\\nIntelligent Indexing, Reports, Report Packages, Tails, and Investigations will have their log data indexed (in other words, brought online) into the applicable data source (Data Processor, LogMart, or both). The Global Log Processing Rules supersede Intelligent Indexing settings and can be used to take specific data offline.\\nRequired, The indicator if the module is required and must be enabled, and therefore must be imported and synchronized.\\nSync by Default, The indicator that this module should be imported and synchronized by default for any new Knowledge Base imports. This should be set if you want future versions of the module to be updated in your deployment. Unchecking this value is useful when you don’t want to import a newer version of the module because you have your objects set up in a specific manner and do not want anything to be over written.\\nDate Updated, The date the module was last updated\\nRecord Status, The status of the record (either Active or Retired)\\nKB Module ID, The unique identifier for the module\\n\", 'Knowledge Base Module Objects': 'Knowledge Base Objects are the specific LogRhythm objects associated with a module. Any updated or new objects related to a module can be imported and synchronized at the next Knowledge Base import based on settings applied by an administrator.\\nThe following objects can be contained within a module:\\nAI Engine Rules\\nAlarm Rules\\nFIM Policies\\nGLPRs\\nInvestigations\\nLists\\nReports\\nReport Packages\\nReport Templates\\nTails\\nA primary object is an object that is intentionally associated with a module.\\nA dependent object is an object that is part of a primary object, but is not a primary object for the module. This could be a list that is part of an Alarm Rule, or it could be a report template that is associated with a report.\\nFrom the Module Objects grid, you can view the list of objects for the selected module. The grid contains the fields described in the following table.\\nColumn Name, Description\\nObject Type, The type of object: AI Engine Rule, Alarm Rule, FIM Policy, GLPR, Investigation, List, Report, Report Package, Report Template, Tail\\nName, The name of the object\\nDependent Object, The indicator for an object that is a dependent object for the module. This column only appears if View > Dependent Objects is selected.\\nDescription, The description for the object\\nDate Updated, The date last updated\\nRecord Status, The record status is either active or retired\\nObject ID, The unique identifier for the object\\n', 'Knowledge Base Manager Options': 'The following options are available on the Knowledge Base Manager toolbar.\\nOption, Description\\nSynchronization Settings, Set the Synchronization Mode, Schedule, and Synchronize Additional System Properties. For more information, seeConfigure Knowledge Base Synchronization Settings.\\nCheck for Knowledge Base Updates, Manually check for updates before the next scheduled update.\\nSynchronize Stored Knowledge Base, Synchronize the current knowledge base with the newly downloaded one. For more information, seeMigrate Common Events.\\nCommon Event Change Manager, Assist in the migration of the Common Events in your affected objects. For more information, seeCommon Event Change Managerbelow.\\nView Synchronization History, View a history of Knowledge Base synchronization activity, including the date, account, and a description of activity.\\n', 'Knowledge Base File': 'The Knowledge Base file contains the modules and their associated objects.\\nWhen LogRhythm Labs sends out periodic updates or new content for the Knowledge Base, administrators can choose when or if a module should be updated. There is a step within the import process that permits changes to the modules prior to importing. For more information, see\\nImport a Knowledge Base\\n.\\n', 'Common Event Change Manager': 'The Common Event Change Manager is a tool that enables you to make the appropriate updates based on user input for common events that have been modified. If custom objects reference a consolidated common event, that object may no longer function properly. Impacted custom objects include: Saved Investigations, Saved Tails, Personal Dashboard Filters, Reports, Alarm Rules, GLPRs, AI Engine Rules.\\n', 'Pre-Knowledge Base Import Inspection': 'When you start to load a new Knowledge Base (KB), a migration inspection is performed to determine what objects contained within the user environment will be affected by importing the selected KB. If objects that will be affected are identified, the CE migration manager opens in a read-only mode and allows you to view the items that will be affected. At that point, you have the option to proceed with the Import a Knowledge Base (Version 7.3.x) or cancel.\\n', 'Post-Knowledge Base Import and User Launches Migration Manager': 'The Common Event Change Manager runs automatically prior to a Knowledge Base import in which migration affected objects were detected during the pre-Knowledge Base Import Inspection. You are also prompted to open this tool each time the Deployment Manager is opened as long as affected objects remain in the database.\\nThe Common Event Change Manager consists primarily of a grid which displays all analytic objects that are affected by migrated common events. The grid contains controls for the user to select migration options for the objects and commit the selected changes.\\n', 'Common Event Change Preview': 'The preview appears prior to a Knowledge Base import. Normally, the Common Event Change Preview and the Common Event Change Manager display identical items. However, in some instances, the items in the Common Event Change Preview may be slightly different than the items shown in the Common Event Change Manager. Some items that are affected may not show up and some items that are not affected may show up. One case is when custom MPE rules use completely migrated common events.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nKnowledge Base\\n/\\nKnowledge Base Manager\\n', 'Migrate Common Events': 'The purpose of the Common Event Change Manager is to assist in the migration of the Common Events in your affected objects. There are two types of objects you need to migrate if they contain changed Common Events:\\nSystem Objects with Custom filters: Primary, Include, and/or Exclude filters\\nCustom objects\\nLogRhythm recommends that you choose the Common Event to MPE Rule migration option for System Objects to retain the behavior of the initial object.\\nIf you migrate Common Event to Common Event, multiple Common Events may result where there was previously only one.\\nIf you migrate Common Event to MPE Rule, a large list of MPE Rules may result. This list may be harder to maintain in the future, but may also more accurately reflect the old filter behavior.\\n', 'Migrate Common Events With a Preview': 'Right-click the\\nCommon Event Change Manager\\ngrid, and then click\\nMigrate With Preview\\n.\\nClick either\\nCommon Event To Common Event\\nor\\nCommon Event To MPE Rule\\n.\\n', 'Migrate Common Events Without a Preview': 'Right-click the\\nCommon Event Change Manager\\ngrid, and then click\\nAction\\n.\\nClick either\\nMigrate Common Event To Common Event\\nor\\nMigrate Common Event To MPE Rule\\n.\\nA confirmation dialog box appears.\\nTo confirm your selection, click\\nYes\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Distribution Services\\n', 'Log Distribution Policy Manager': 'A Log Distribution Services policy identifies which logs to distribute to a selected Log Distribution Receiver.\\nUse the Log Distribution Policy Manager to select:\\nThe log sources or log source lists that should be distributed.\\nThe LDS receivers that will forward the selected logs.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Distribution Services\\n', 'Log Distribution Receiver Manager': 'A Log Distribution Services policy identifies which logs to distribute to a selected Log Distribution Receiver.\\nUse the Log Distribution Receiver Manager to define:\\nNetwork Settings including the external syslog receivers Host IP and Port, TCP or UDP network protocol, and ASCII, UTF-8, or Windows-1252 text encoding.\\nThe syslog and non-syslog message format to use when forwarding them to the external syslog receiver.\\nA priority (PRI) value to use in the log messages for non-syslog sources.\\nThe host identifier value to use in the log messages for syslog and non-syslog sources.\\nThe timestamp value to use in the log messages for syslog and non-syslog sources.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Processing Policies\\n', 'Modify Log Processing Policies': 'You must be logged in as an Administrator to take this action.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nLog Processing Policies\\ntab.\\nSelect the Log Processing Policy you want to modify.\\nRight-click the selection and then click\\nEdit\\n.\\nThe MPE Policy Editor appears.\\nIf you want to modify the timeout for policy rules, type the new timeout period (in milliseconds) in the MPE Rule Timeout box.\\nSelect the\\nEnabled\\ncheck box for each rule to include in the policy.\\nTo override the default aging and event settings, select the\\nEdit\\ncheck box of the rule to edit, right-click the selection, and then select\\nProperties\\n.\\nThe MPE Policy Rule Editor appears.\\nMake your changes.\\nThe edits you make apply to all the rules that are currently selected.\\nMake your changes.\\nThe edits you make apply to all the rules that are currently selected.\\nTo return to the MPE Policy Editor, click\\nOK\\n.\\nTo close the MPE Policy Editor, click\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n', 'Data Masking': 'There are times when information within a log message needs to be transformed into a more useable format or masked to hide sensitive or regulated data. LogRhythm allows you to set up Data Masking Rules to transform, redact, or substitute text on a global or log message source basis.\\nUsers must monitor the processing rates in their solution for a period of time to ensure their system can support the processing requirements.\\nData Masking Rules allow you to perform multiple types of data transformation and masking. The Archives continue to contain the original raw log in its original collected state. The Data Indexer contains the transformed raw log and any associated transformed metadata.\\nThe following are the types of data masking:\\n', 'Transform Text': 'Transform specific text within a log message into a specified usable format where the input text is used to create the output text and the output can contain new characters and formatting.\\nFor example, transform (3)www(9)microsoft(3)com(0) to\\xa0www.microsoft.com.\\n', 'Redact Sensitive Text': 'Redact specific text within a log message where all or part of the input text is replaced with a specified masking character or string.\\nFor example, redact a Social Security Number SSN: 123-45-6789 to SSN: XXX-XX-XXXX.\\n', 'Substitute Sensitive Text': 'Substitute specific text within a log message into a consistent unique value. The value is hashed into a new unique value where the same input value always results in the same output value across different log messages.\\nFor example, transform SSN: 123-45-6789 to SSN: bfda2b7_579e_b1dc_3cba_e0df31fa8ff0.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n', 'Flat File Collection': 'LogRhythm can collect logs from compressed flat files on Windows and UNIX systems. The Agent decompresses the file, collects its logs like any other flat file, and then deletes the decompressed file when it has been fully collected.\\nOnly static compressed files are supported. Single compressed files and multiple files within a single directory are supported. The following are not supported: Multi-part, encrypted, password-protected, and compressed files containing more than one file.\\nThe following compression types are supported:\\ngzip\\ntar\\ntargzip (UNIX only)\\nzip\\nbzip (UNIX only)\\nbzip2 (UNIX only)\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n', 'Log Source Identification and Acceptance': '\\nNew Log Sources are saved in a separate Acceptance table (the New Log Sources grid) pending a direct action on the part of the user. This includes the following log source types:\\nSyslog (TCP/UDP)\\nCisco NetFlow\\nIPFIX\\nJuniper J-Flow\\nsFlow\\nSNMP Traps\\nAdditionally, two configurable identification process, Automatic Log Source Configuration and Log Source Preregistration, are available to allow LogRhythm to identify the source for you.\\nOn the Log Sources tab, the New/Pending Log Sources can be viewed in the New Log Sources upper grid. The lower grid includes the active Log Sources that have already been accepted.\\nIn the New Log Source tab, the following columns appear:\\nColumn, Description\\nAction, Batch actions operate on all checked rows.\\nStatus, Incomplete. The new log source has not been identified by the system yet. The user can act on the record now, or wait for the system to finish identifying it. When finished, the record status will be changed to Pending; however, the user will have to manually refresh the list to see the latest values from the database.Pending. The new log source is waiting for the user to accept or reject it.Rejected. The user has rejected the new log source. You should disable transmission of logs from the sending device prior to deleting the acceptance record or another pending log source will be generated.\\nSearch Scope, The search scope associated with the search result. For example, if duplicates were found at the Root Entity level, then this field would display Root Entity, even though the System Monitor might be configured for Global search scope. For information on changing the search scope of a System Monitor, seeSet the Log Source Identification Search Scope.\\nSearch Result, The reason the Log Source search failed and a new log source acceptance record was created. There are two possible values: No matching log source found, or multiple matching log sources found.\\nLog Interface, This is the interface associated with the log, such as Syslog.\\nDevice IP\\xa0Address, The IP address that was either parsed out of the log message or determined by the message origin. May be IPv4 or IPv6, but never both. May be blank; however, either the log host or the IP address must be known. They cannot both be blank.\\nLog Host Name, The computer or device name that was either parsed out of the log message or determined by the message origin. May be blank.Hostnames with a space are not supported by LogRhythm software.\\nLog Source Host, This lets the user know if a new host record will be created for this log source or it will use an existing host record. Must be resolved via the context menu.If the host has never been resolved, the resolved known host column will display blank values. When the user Resolves Known Host, the value will be populated.If a matching host is found, it appears.If matching host is not found, then the New Host – [entity]:[hostname] appears.\\nLog Source Type, If the log source type cannot be identified, then the user will have to assign a log source type before the record can be accepted.\\nMPE Policy, The policy, if any, this is applied to this log source.\\nLog Source Name, Default value is [host name] [log source type abbreviation], but the user can edit the name.\\nCollection Host, Host performing the collection.\\nLast Time Seen, The most recent time a request for this log source was received. Used to verify that requests are no longer being received prior to deleting the record. This value must be manually refreshed.\\nIncomplete\\n. The new log source has not been identified by the system yet. The user can act on the record now, or wait for the system to finish identifying it. When finished, the record status will be changed to Pending; however, the user will have to manually refresh the list to see the latest values from the database.\\nPending\\n. The new log source is waiting for the user to accept or reject it.\\nRejected\\n. The user has rejected the new log source. You should disable transmission of logs from the sending device prior to deleting the acceptance record or another pending log source will be generated.\\nThe computer or device name that was either parsed out of the log message or determined by the message origin. May be blank.\\nHostnames with a space are not supported by LogRhythm software.\\nThis lets the user know if a new host record will be created for this log source or it will use an existing host record. Must be resolved via the context menu.\\nIf the host has never been resolved, the resolved known host column will display blank values. When the user Resolves Known Host, the value will be populated.\\nIf a matching host is found, it appears.\\nIf matching host is not found, then the New Host – [entity]:[hostname] appears.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n', 'Log Source Types': 'Log Source Types are used to classify logs that come from common hardware or have the same data format and operate under the same processing rules. Using a Log Source Type improves processing performance because logs are only processed against rules for that type. Rules for other Log Sources Types are automatically skipped.\\nExamples of a Log Source Type:\\nAn in-house software application\\nThe Windows Application Event Log\\nOne Log Source Type is assigned to each Log Message Source and to collections of rules defined in Log Processing Policies. That way, LogRhythm knows which rules can be assigned to which Log Message Sources.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n', 'Log Source Virtualization': '\\nLog Source Virtualization is supported on Windows agents and on Linux agents\\nfrom System Monitor 7.5.1.8001 and later.\\nLog Source Virtualization makes it possible to consume all the available intelligence within individual log source files that contain multiple records from different sources. When virtualization is enabled on a log source, it is referred to as a “parent” log source, and the different records inside it are referred to as either “virtual” or “child” log sources (when referencing log sources, the terms “virtual” and “child” are often used interchangeably).\\nVirtual log sources are treated in the same way as other log sources. They are processed in accordance with their assigned MPE policies and they appear in the same lists as the other log sources within the deployment. In contrast to Syslog Virtualization, which applies only to syslog relay logs received by the System Monitor syslog server, Log Source Virtualization can be applied to syslog relay sources, Windows Event Logs, flat files, and any other log source within your deployment that contains multiple records.\\nTo begin Log Source Virtualization, you need to apply properly configured Log Source Virtualization templates to the parent log sources at the agent level. Virtualization templates contain one or more virtual log sources that include identifier regular expressions (also called “regexes”) to run against and parse data in the parent sources. When one of the records matches a particular regex, a child log is created and assigned to the virtual log source associated with that regex. Records that do not match any of the regexes are assigned to the Catch-All log source.\\nVirtual log sources cannot be edited to the same extent as their non-virtual counterparts because certain properties (including their lifecycle) remain tied to their parent sources. For example, if a parent log source is retired or has its virtualization disabled, all of its child log sources are retired or disabled as well. You can, however, edit the name, regex, MPE policy, and log source type properties for virtual log sources.\\nYou can add, modify, and delete both virtual log sources and virtualization templates from the Log Source Virtualization Template Manager. As you create or modify templates and virtual log sources, you can check their regex parsing and distribution accuracy by pasting sample logs into the testing tool. Keep in mind that changes you make to the properties of either virtual log sources or virtualization templates only affect the future child log sources created by them (existing child sources are unaffected).\\n', 'Load Balanced Virtual Log Sources': 'Load balanced virtual log sources let you specify the log sources that are being sent to a load balancer and the System Monitors to which the load balancer is sending log messages. These options enable deployments with larger volumes to utilize load balanced log sources without data loss.\\nIn LogRhythm, you can designate one or more System Monitors and one or more Log Sources as \"load balancing.\" After doing this, all load balancing System Monitors must be made aware of all load balanced Log Sources, regardless of where the Log Sources originated. As more System Monitors or Log Sources are created, the updated configuration is pushed out to all load balancing System Monitors.\\nSystem Monitors are designated under the Syslog and Flow Settings tab of the System Monitor Agent Properties dialog box.\\nLog Sources are designated under the Additional Settings tab of the Log Message Source Properties dialog box or the Log Source Settings dialog box (when adding in batch).\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n', 'UDLA Collection': 'You can configure the Windows System Monitor Pro or Collector Agent to collect data from database tables, usually targeting tables that contain database audit or log data. LogRhythm stores the data from a table row as a log to allow analysis tools such as Investigator or Tail to review the information. Universal Database Log Adapter (UDLA) logs are treated as any other log types; they can be forwarded as events, associated with alarms, and archived.\\n', 'UDLA Data Collection Prerequisites': '', 'Database Table': 'Two database table prerequisites must be met before LogRhythm can collect data. The table must have:\\nEither a primary key column or a concatenation of columns that creates a unique identifier for each row.\\nA column with an incrementing integer or a date/time stamp so that the table order can be determined.\\nA single column may be able to satisfy both requirements. The System Monitor Pro or Collector Agent uses the concept of state to know which rows of data have been collected from a table by tracking table sequence and by using the unique identifier. If a column is an auto-incrementing number for each row, and therefore unique in the table, it both defines the order of the data and provides the unique identifier. It can be used in the Unique Identifier Field and in the State Field of the UDLA settings.\\nFor example, when a table has a primary key column which contains a unique, increasing value, this column can be used for the Unique Identifier Field and the State Field.\\nThis sample contains one day of log traffic, where an event was logged every six hours.\\nKey, Date, Time, Log\\n1, 01/01/2009, 01:01:01, An event has occurred.\\n2, 01/01/2009, 07:01:01, An event has occurred.\\n3, 01/01/2009, 13:01:01, An event has occurred.\\n4, 01/01/2009, 19:01:01, An event has occurred.\\n5, 01/01/2009, 01:01:01, An event has occurred.\\n1\\n01/01/2009\\n01:01:01\\nAn event has occurred.\\n2\\n01/01/2009\\n07:01:01\\nAn event has occurred.\\n3\\n01/01/2009\\n13:01:01\\nAn event has occurred.\\n4\\n01/01/2009\\n19:01:01\\nAn event has occurred.\\n5\\n01/01/2009\\n01:01:01\\nAn event has occurred.\\nCorresponding UDLA Settings:\\nUDLA Settings, Column(s)\\nUnique Identifier Field, Key\\nState Field, Key\\nState Field Type, Increment\\nUnique Identifier Field\\nKey\\nState Field\\nKey\\nState Field Type\\nIncrement\\nWhen there is no primary key column, a concatenation of columns can be used if doing so uniquely identifies all rows. Here, the System Monitor Pro or Collector Agent tracks collection state by using the unique identifier plus the State Field, which must either be an increasing integer or date/time stamp.\\nFor example, given the table below with the columns Date, Time, and Log, the concatenation of the Date and Time columns meet the prerequisite for a unique identifier. The State Field must always either be an incrementing integer or a date/time stamp, so the Date column meets the other requirement.\\nThis sample contains one day of log traffic, where an event was logged every six hours.\\nDate, Time, Log\\n01/01/2009, 01:01:01, An event has occurred.\\n01/01/2009, 07:01:01, An event has occurred.\\n01/01/2009, 13:01:01, An event has occurred.\\n01/01/2009, 19:01:01, An event has occurred.\\n01/02/2009, 01:01:01, An event has occurred.\\n01/01/2009\\n01:01:01\\nAn event has occurred.\\n01/01/2009\\n07:01:01\\nAn event has occurred.\\n01/01/2009\\n13:01:01\\nAn event has occurred.\\n01/01/2009\\n19:01:01\\nAn event has occurred.\\n01/02/2009\\n01:01:01\\nAn event has occurred.\\nCorresponding UDLA Settings:\\nUDLA Setting Name, Column(s)\\nUnique Identifier Field, Date, Time\\nState Field, Date\\nState Field Type, Timestamp\\nUnique Identifier Field\\nDate, Time\\nState Field\\nDate\\nState Field Type\\nTimestamp\\n', 'ODBC and OLE DB Drivers Availability': 'ODBC/OLE DB drivers must be installed and configured prior to data collection. They are available from the website of each supported database vendor:\\nMicrosoft SQL Server 2016 SP2\\nOracle 9i, 10g, 11g\\nOracle does not support Windows Server 2008 R2.\\nOracle 9i, 10g, 11g\\nOracle does not support Windows Server 2008 R2.\\nIBM DB2 v9\\nIBM DB2 v8\\nMySQL\\n', 'System Monitor Pro or Collector Agent Host': 'The System Monitor Pro or Collector Agent requires that an OLE DB or ODBC driver be installed on the Agent host to connect to the specified Database Management System. A 64-bit System Monitor Agent is required.\\n', 'Test Feature': 'The Test feature requires that the appropriate ODBC or OLE DB driver be installed on the Client Console host.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n', 'Work With Log Sources': '\\nGeneric system log sources are registered by default in the LogRhythm configuration database the first time an agent connects to a Data Processor. They are used either to log File Integrity Monitor (FIM) information or as collection sources as described in the following table.\\nFIM is available only for System Monitor Pro or Collector Agents.\\n\\nLog Source, Description\\nAIXFileMon, Registered by an AIX System Monitor Pro or Collector Agent the first time it connects to a Data Processor. It contains all logs generated by the AIX agent FIM. It can have a Message Processing Engine Policy assigned to process FIM generated logs.\\nHPUXFileMon, Registered by a HP-UX System Monitor Pro or Collector Agent on first connection to a Data Processor. It contains all logs generated by the HP-UX agent FIM. It can have a Message Processing Engine Policy assigned to process FIM generated logs.\\nLinuxFileMon, Registered by a Linux System Monitor Pro or Collector Agent the first time it connects to a Data Processor. It contains all logs generated by the Linux agent FIM. It can have a Message Processing Engine Policy assigned to process FIM generated logs.\\nLogRhythmDXMonitor, Registered by a Windows System Monitor Agent on first connection to a Data Processor. It contains all diagnostic logs generated by the Data Indexer. Only collects logs when the System Monitor is installed on a Data Indexer.\\nNetworkConnectionMonitor, Registered by a Windows System Monitor Agent the first time it connects to a Data Processor. It contains all logs generated by the Windows Agent Network Connection Monitor (NCM), and it can have a Message Processing Engine Policy assigned to process NCM generated logsSelect from types Windows, Linux, Solaris, AIX, and HP-UX.\\nProcessMonitor, Registered by a Windows System Monitor Agent the first time it connects to a Data Processor. It contains all logs generated by the Windows Agent Process Monitor (PM) and it can have a Message Processing. Engine Policy assigned to process PM generated logsSelect from types Windows, Linux, Solaris, AIX, and HP-UX.\\nSolarisFileMon, Registered by a Solaris System Monitor Pro or Collector Agent the first time it connects to a Data Processor. It contains all logs generated by the Solaris agent FIM. It can have a Message Processing Engine Policy assigned to process FIM generated logs.\\nUserActivityMonitor, Registered by a Windows System Monitor Agent the first time it connects to a Data Processor. It contains all logs generated by the Windows Agent User Activity Monitor (UAM), and it can have a Message Processing. Engine Policy assigned to process UAM generated logs. Select from types Windows, Linux, Solaris, AIX, or HP-UX:\\nWinDataDefender, Registered by a Windows System Monitor Agent the first time it connects to a Data Processor. It contains all logs generated by the Windows Agent Data Loss Defender (DLD). It can have a Message Processing Engine Policy assigned to process DLD generated logs.\\nWinFileMon, Registered by a Windows System Monitor Pro or Collector Agent on first connection to a Data Processor. It contains all logs generated by Windows agent FIM. It can have a Message Processing Engine Policy assigned to process FIM generated logs.\\nRegistered by a Windows System Monitor Agent the first time it connects to a Data Processor. It contains all logs generated by the Windows Agent Network Connection Monitor (NCM), and it can have a Message Processing Engine Policy assigned to process NCM generated logs\\nSelect from types Windows, Linux, Solaris, AIX, and HP-UX.\\nRegistered by a Windows System Monitor Agent the first time it connects to a Data Processor. It contains all logs generated by the Windows Agent Process Monitor (PM) and it can have a Message Processing. Engine Policy assigned to process PM generated logs\\nSelect from types Windows, Linux, Solaris, AIX, and HP-UX.\\nRegistered by a Windows System Monitor Agent the first time it connects to a Data Processor. It contains all logs generated by the Windows Agent User Activity Monitor (UAM), and it can have a Message Processing. Engine Policy assigned to process UAM generated logs. Select from types Windows, Linux, Solaris, AIX, or HP-UX:\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n/\\nData Masking\\n', 'Add New Data Masking Rules': 'You must be logged in as an Administrator to take this action.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nData Masking Rule Manager\\n.\\nThe Data Masking Rule Manager appears.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nData Masking Rule Manager\\n.\\nThe Data Masking Rule Manager appears.\\nOn the menu bar, click\\nNew\\n.\\nThe Data Masking Rule Properties window appears.\\nOn the menu bar, click\\nNew\\n.\\nThe Data Masking Rule Properties window appears.\\nEnter Name.\\nEnter Name.\\nEnter Description.\\nEnter Description.\\nSelect the Scope.\\nIf the rule applies to all Message Source Types, select\\nGlobal\\n.\\nIf the rule applies to a specific Message Source Type, click the\\nBrowse\\nbutton and select the applicable Message Source Type.\\nSelect the Scope.\\nIf the rule applies to all Message Source Types, select\\nGlobal\\n.\\nIf the rule applies to all Message Source Types, select\\nGlobal\\n.\\nIf the rule applies to a specific Message Source Type, click the\\nBrowse\\nbutton and select the applicable Message Source Type.\\nIf the rule applies to a specific Message Source Type, click the\\nBrowse\\nbutton and select the applicable Message Source Type.\\nTo enable the rule, select the\\nEnable Data Masking Rule\\ncheck box.\\nTo enable the rule, select the\\nEnable Data Masking Rule\\ncheck box.\\nType the match regex.\\nIf left blank, the transformation find/replace pairs are applied to all logs in the specified scope.\\nMetadata\\nExample Regex Patterns\\nExample Replacement Strings\\nDomain Name\\n\\\\s(?<Domain>[\\\\w@][\\\\w.:@]+)\\\\(\\\\w+\\\\)\\\\w+\\\\(\\\\w+\\\\)\\\\w+\\\\s\\nOriginal:\\nwww(dot)microsoft(dot)com\\nTransformed:\\nwww.microsoft.com\\n. (period)\\nDomain Name\\n(?<Domain>[\\\\w@][\\\\w.:@]+)\\\\(\\\\w+\\\\)\\\\w+\\\\(\\\\w+\\\\)\\\\w+\\nOriginal:\\n(3)www(9)microsoft(3)com(0)\\nTransformed:\\nwww.microsoft.com\\n. (period)\\nE-mail Address\\n(([a-zA-Z0-9_\\\\-\\\\.]+)@((\\\\[[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.)|(([a-zA-Z0-9\\\\-]+\\\\.)+))([a-zA-Z]{2,4}|[0-9]{1,3}))\\nOriginal:\\n04/24/2014 21:34:51.937154 NAME:\\nMary Moore\\nEMAIL:\\nmmoore@recordflow.com\\nTransformed:\\n04/24/2014 21:34:51.937154 NAME:\\nMary Moore\\nEMAIL: user@company.com\\nuser@company.com\\nE-mail Address\\n(([a-zA-Z0-9_\\\\-\\\\.]+)@((\\\\[[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.)|(([a-zA-Z0-9\\\\-]+\\\\.)+))([a-zA-Z]{2,4}|[0-9]{1,3}))\\nOriginal:\\n04/24/2014 21:34:51.937154 NAME: Mary Moore EMAIL: mmoore@recordflow.com\\nTransformed:\\n04/24/2014 21:34:51.937154 NAME:\\nMary Moore\\nEMAIL: f3ce9f0f_937a_590e_64df_6f3b36eff1e3\\n<hash_string>\\nPhone Number\\n(\\\\((?<AreaCode>\\\\d{3})\\\\)\\\\s*(?<Number>\\\\d{3}(?:-|\\\\s*)\\\\d{4}))\\nOriginal: 04/24/2014 21:34:51.937154 NAME:\\nMary Moore\\nPHONE: (202) 111-2222\\nTransform: 04/24/2014 21:34:51.937154 NAME:\\nMary Moore\\nPHONE: (nnn) nnn-nnnn\\n(nnn) nnn-nnnn\\nSocial Security Number\\nSSN: (\\\\d{3}-\\\\d{2}-\\\\d{4})\\nOriginal:\\n04/24/2014 21:34:51.937154 NAME: Mary SSN: 111-22-3333 PHONE: (202) 111-2222\\nTransformed:\\n04/24/2014 21:34:51.937154 NAME: Mary SSN: XXX-XX-XXXX PHONE: (202) 111-2222\\nXXX-XX-XXX\\nURL\\n(?<Protocol>\\\\w+):\\\\/\\\\/[\\\\w@][\\\\w.:@]+\\nOriginal:\\n04/24/2014 21:34:51.937154 NAME:\\nMary\\nURL:\\nhttps://www.recordflow.com/\\nPHONE: (202) 111-2222\\nTransformed:\\n04/24/2014 21:34:51.937154 NAME:\\nMary\\nURL: f3ce9f0f_937a_590e_64df_6f3b36eff1e3 PHONE: (202) 111-2222\\n<hash_string>\\nUser Names\\nUID: (\\\\w+)\\nOriginal:\\n04/24/2014 21:34:51.937154 NAME:\\nMary\\nUID: mmoore PHONE: (202) 111-2222\\nTransformed:\\n04/24/2014 21:34:51.937154 NAME:\\nMary\\nUID: XXXXXXX PHONE: (202) 111-2222\\nXXXXXXX\\nType the match regex.\\nIf left blank, the transformation find/replace pairs are applied to all logs in the specified scope.\\nMetadata, Example Regex Patterns, Example Replacement Strings\\nDomain Name, \\\\s(?<Domain>[\\\\w@][\\\\w.:@]+)\\\\(\\\\w+\\\\)\\\\w+\\\\(\\\\w+\\\\)\\\\w+\\\\sOriginal:www(dot)microsoft(dot)comTransformed:www.microsoft.com, . (period)\\nDomain Name, (?<Domain>[\\\\w@][\\\\w.:@]+)\\\\(\\\\w+\\\\)\\\\w+\\\\(\\\\w+\\\\)\\\\w+Original:(3)www(9)microsoft(3)com(0)Transformed:www.microsoft.com, . (period)\\nE-mail Address, (([a-zA-Z0-9_\\\\-\\\\.]+)@((\\\\[[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.)|(([a-zA-Z0-9\\\\-]+\\\\.)+))([a-zA-Z]{2,4}|[0-9]{1,3}))Original:04/24/2014 21:34:51.937154 NAME:Mary MooreEMAIL:mmoore@recordflow.comTransformed:04/24/2014 21:34:51.937154 NAME:Mary MooreEMAIL: user@company.com, user@company.com\\nE-mail Address, (([a-zA-Z0-9_\\\\-\\\\.]+)@((\\\\[[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.)|(([a-zA-Z0-9\\\\-]+\\\\.)+))([a-zA-Z]{2,4}|[0-9]{1,3}))Original:04/24/2014 21:34:51.937154 NAME: Mary Moore EMAIL: mmoore@recordflow.comTransformed:04/24/2014 21:34:51.937154 NAME:Mary MooreEMAIL: f3ce9f0f_937a_590e_64df_6f3b36eff1e3, <hash_string>\\nPhone Number, (\\\\((?<AreaCode>\\\\d{3})\\\\)\\\\s*(?<Number>\\\\d{3}(?:-|\\\\s*)\\\\d{4}))Original: 04/24/2014 21:34:51.937154 NAME:Mary MoorePHONE: (202) 111-2222Transform: 04/24/2014 21:34:51.937154 NAME:Mary MoorePHONE: (nnn) nnn-nnnn, (nnn) nnn-nnnn\\nSocial Security Number, SSN: (\\\\d{3}-\\\\d{2}-\\\\d{4})Original:04/24/2014 21:34:51.937154 NAME: Mary SSN: 111-22-3333 PHONE: (202) 111-2222Transformed:04/24/2014 21:34:51.937154 NAME: Mary SSN: XXX-XX-XXXX PHONE: (202) 111-2222, XXX-XX-XXX\\nURL, (?<Protocol>\\\\w+):\\\\/\\\\/[\\\\w@][\\\\w.:@]+Original:04/24/2014 21:34:51.937154 NAME:MaryURL:https://www.recordflow.com/PHONE: (202) 111-2222Transformed:04/24/2014 21:34:51.937154 NAME:MaryURL: f3ce9f0f_937a_590e_64df_6f3b36eff1e3 PHONE: (202) 111-2222, <hash_string>\\nUser Names, UID: (\\\\w+)Original:04/24/2014 21:34:51.937154 NAME:MaryUID: mmoore PHONE: (202) 111-2222Transformed:04/24/2014 21:34:51.937154 NAME:MaryUID: XXXXXXX PHONE: (202) 111-2222, XXXXXXX\\nOriginal:\\nwww(dot)microsoft(dot)com\\nTransformed:\\nwww.microsoft.com\\nOriginal:\\n(3)www(9)microsoft(3)com(0)\\nTransformed:\\nwww.microsoft.com\\nOriginal:\\n04/24/2014 21:34:51.937154 NAME:\\nMary Moore\\nEMAIL:\\nmmoore@recordflow.com\\nTransformed:\\n04/24/2014 21:34:51.937154 NAME:\\nMary Moore\\nEMAIL: user@company.com\\nOriginal:\\n04/24/2014 21:34:51.937154 NAME: Mary Moore EMAIL: mmoore@recordflow.com\\nTransformed:\\n04/24/2014 21:34:51.937154 NAME:\\nMary Moore\\nEMAIL: f3ce9f0f_937a_590e_64df_6f3b36eff1e3\\nOriginal: 04/24/2014 21:34:51.937154 NAME:\\nMary Moore\\nPHONE: (202) 111-2222\\nTransform: 04/24/2014 21:34:51.937154 NAME:\\nMary Moore\\nPHONE: (nnn) nnn-nnnn\\nOriginal:\\n04/24/2014 21:34:51.937154 NAME: Mary SSN: 111-22-3333 PHONE: (202) 111-2222\\nTransformed:\\n04/24/2014 21:34:51.937154 NAME: Mary SSN: XXX-XX-XXXX PHONE: (202) 111-2222\\nOriginal:\\n04/24/2014 21:34:51.937154 NAME:\\nMary\\nURL:\\nhttps://www.recordflow.com/\\nPHONE: (202) 111-2222\\nTransformed:\\n04/24/2014 21:34:51.937154 NAME:\\nMary\\nURL: f3ce9f0f_937a_590e_64df_6f3b36eff1e3 PHONE: (202) 111-2222\\nOriginal:\\n04/24/2014 21:34:51.937154 NAME:\\nMary\\nUID: mmoore PHONE: (202) 111-2222\\nTransformed:\\n04/24/2014 21:34:51.937154 NAME:\\nMary\\nUID: XXXXXXX PHONE: (202) 111-2222\\nAdd a find/replace pair.\\nClick Add\\nNew\\n.\\nThe Find/Replace Properties window appears.\\nIn the Find Regex box, type the expression you want to transform.\\nIn the Replacement String box, enter text you want to replace the expression with.\\nEnter <hash_string> to generate a consistent hash where the same input value always results in the same output value.\\nIf blank, the matching text is replaced by a blank message.\\nClick\\nOK\\n.\\n(Optional)\\nAdd additional pairs.\\nAdd a find/replace pair.\\nClick Add\\nNew\\n.\\nThe Find/Replace Properties window appears.\\nClick Add\\nNew\\n.\\nThe Find/Replace Properties window appears.\\nIn the Find Regex box, type the expression you want to transform.\\nIn the Find Regex box, type the expression you want to transform.\\nIn the Replacement String box, enter text you want to replace the expression with.\\nIn the Replacement String box, enter text you want to replace the expression with.\\nEnter <hash_string> to generate a consistent hash where the same input value always results in the same output value.\\nEnter <hash_string> to generate a consistent hash where the same input value always results in the same output value.\\nIf blank, the matching text is replaced by a blank message.\\nIf blank, the matching text is replaced by a blank message.\\nClick\\nOK\\n.\\nClick\\nOK\\n.\\n(Optional)\\nAdd additional pairs.\\n(Optional)\\nAdd additional pairs.\\n(Optional)\\nIf necessary, use the Up and Down arrows to reorder the Find/Replace pairs. The transformations are applied in the order listed.\\n(Optional)\\nIf necessary, use the Up and Down arrows to reorder the Find/Replace pairs. The transformations are applied in the order listed.\\nType a Log Sample. When text is entered into the Log Sample text box, the Test button is enabled.\\nType a Log Sample. When text is entered into the Log Sample text box, the Test button is enabled.\\nTo validate the regex, click\\nTest\\n. The Match Regex and Find/Replace pairs are run against the Log Sample. A result dialog box appears and indicates one of the following:\\nMatch Regex Success.\\nThe Match Regex matched the log sample.\\nMatch Regex Failure.\\nTo validate the regex, click\\nTest\\n. The Match Regex and Find/Replace pairs are run against the Log Sample. A result dialog box appears and indicates one of the following:\\nMatch Regex Success.\\nMatch Regex Success.\\nThe Match Regex matched the log sample.\\nThe Match Regex matched the log sample.\\nMatch Regex Failure.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n/\\nFlat File Collection\\n', 'Configure a Host for Local Flat File Collection': \"\\nCreate a host record for the system. For more information, see\\nAdd Host Records Manually\\n.\\nInstall and configure a System Monitor Agent on the server. For more information, see\\nSet Up an Initial System Monitor Agent\\n.\\nEstablish a Log Processing (MPE) Policy for the Log Source Type, or use the default (if available).\\nAdd a Log Message Source to the host's System Monitor Agent. For more information, see\\nAdd a Single Log Source\\n.\\nConfigure the server's local System Monitor Agent to collect the logs.\\nConfigure the message source.\\nOn the Basic Configuration tab, select the\\nLog Message Processing Settings\\n.\\nClick the\\nAdditional Settings\\ntab, and then select the\\nStart collection from the beginning of the log\\ncheck box.\\nClick the\\nFlat File Settings\\ntab and enter the following information:\\nFile Path - For multiple files, use a wildcard pattern.\\nDate Parsing Format\\nMultiline Log Message Settings\\nDirectory Collection\\nDays to watch modified files: Specify the number of days to monitor the directory for changes or new files.\\nThe default value for this setting is 0, which means the agent collects from the entire directory. The maximum value is 128 days.\\nCompression Type: none, gzip, tar, targzip, zip, bzip (UNIX only), bzip2 (UNIX only)\\nLog formats with blank lines between each message are considered multi-line messages, and require the Log Message Start Regex to be populated. The following regex enables the Agent to read more than one such log per cycle to keep up with the configured number of logs for collection: \\\\d{1,2}\\\\/\\\\d{1,2}\\\\/\\\\d{4}\\\\s\\\\d{1,2}:\\\\d{1,2}:\\\\d{1,2}\\\\s(AM|PM)\\\\s\\\\d+\\nFile Path - For multiple files, use a wildcard pattern.\\nDate Parsing Format\\nMultiline Log Message Settings\\nDirectory Collection\\nDays to watch modified files: Specify the number of days to monitor the directory for changes or new files.\\nThe default value for this setting is 0, which means the agent collects from the entire directory. The maximum value is 128 days.\\nDays to watch modified files: Specify the number of days to monitor the directory for changes or new files.\\nThe default value for this setting is 0, which means the agent collects from the entire directory. The maximum value is 128 days.\\nCompression Type: none, gzip, tar, targzip, zip, bzip (UNIX only), bzip2 (UNIX only)\\nLog formats with blank lines between each message are considered multi-line messages, and require the Log Message Start Regex to be populated. The following regex enables the Agent to read more than one such log per cycle to keep up with the configured number of logs for collection: \\\\d{1,2}\\\\/\\\\d{1,2}\\\\/\\\\d{4}\\\\s\\\\d{1,2}:\\\\d{1,2}:\\\\d{1,2}\\\\s(AM|PM)\\\\s\\\\d+\\nClick\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n/\\nLog Source Identification and Acceptance\\n', 'Accept New Log Sources Automatically': '\\nIn deployments where the number of new Log Sources is high, administrators can configure various levels of automatic Log Source acceptance, as follows:\\nAutomatically Resolve Log Source Host\\nAutomatically Identify the Log Source Type\\nAutomatically Accept the Log Source (includes host resolution and identification of Log Source type)\\nYou can create one or more rules to be used to evaluate incoming Log Sources. Acceptance can be based on the IP address of a new Log Source, or on regular expression pattern matching. You can have multiple rules enabled, and you can use the Log Source Acceptance Rule Manager to enable or disable rules, or change the priority of rules.\\n', 'Auto-Acceptance and Search Scope': \"When the Target Entity is specified for an automatic log source acceptance rule, it is important to ensure the log source search scope is set appropriately for the System Monitor that initiates the auto-acceptance. The log source is processed as follows:\\nIf the Target Entity is in the System Monitor's search scope, the log source and host are created in the Target Entity.\\nIf the Target Entity is not in the System Monitor’s search scope, the log source goes into\\nthe acceptance table\\nwhere it can be manually accepted.\\xa0 An ERROR log is written to the scmedsvr.log file indicating what the scope problem is and how to remedy it.\\nIf the System Monitor’s search scope is set to\\nSystem Monitor\\n, an ERROR log is written to the scmedsvr.log file indicating what the scope problem is and how to remedy it. The\\nSystem Monitor\\nsearch scope only provides access to the log sources that System Monitor owns. Therefore, it cannot verify that there is no other host or log source with that IP address, so the auto-acceptance is rejected to prevent creating duplicates in the Target Entity.\\nFor information on changing the search scope of a System Monitor, see\\nSet the Log Source Identification Search Scope\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n/\\nLog Source Identification and Acceptance\\n', 'Set the Log Source Identification Search Scope': 'There is a System Monitor configuration parameter named Log Source Identification Search Scope that is set within the System Monitor Agent advanced properties. It determines how existing (possible matching) log sources are searched within the deployment. The Log Search Identification Search Scope appears in the lower grid of the System Monitor Agents. You must scroll to the right to see this value.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nSystem Monitors\\ntab.\\nSelect the\\nAction\\ncheck box of a System Monitor Agent.\\nRight-click the selection, click\\nActions\\n, and then click\\nChange Log Source Identification Search Scope\\nand choose one of the following:\\nSystem Monitor Scope\\n. This is the default value set for existing and/or upgraded system monitor agents. If the user selects this option, the system searches for a unique matching log source across all active Log Sources associated with the collection System Monitor Agent.\\nRoot Entity Scope\\n. This is the default value set for new System Monitor Agents. If the user selects this option, a unique matching log source is searched for across all active Log Sources within the deployment in the following order of precedence:\\nLog Sources associated with the collection System Monitor Agent.\\nLog Sources having the same Root Entity as the collection System Monitor Agent.\\nRoot Entity Searches are composed of the following sub-searches:\\nSearch for Log Sources within the Entity of the System Monitor Agent.\\nIf the System Monitor is attached to a Child Entity,\\nSearch for Log Sources within the Root Entity (that the child belongs to).\\nSearch for Log Sources within the Other Child Entities (under the root entity the child entity belongs to).\\nIf the System Monitor is attached to a Root Entity,\\nSearch for Log Sources within the Child Entities of the Root Entity.\\nGlobal Scope\\n. If you select this option, a unique matching log source will be searched for across all active Log Sources within the deployment in the following order of precedence:\\nLog Sources associated with the collection System Monitor Agent.\\nLog Sources having the same Root Entity as the collection System Monitor Agent.\\nAll other Log Sources.\\nSystem Monitor Scope\\n. This is the default value set for existing and/or upgraded system monitor agents. If the user selects this option, the system searches for a unique matching log source across all active Log Sources associated with the collection System Monitor Agent.\\nSystem Monitor Scope\\n. This is the default value set for existing and/or upgraded system monitor agents. If the user selects this option, the system searches for a unique matching log source across all active Log Sources associated with the collection System Monitor Agent.\\nRoot Entity Scope\\n. This is the default value set for new System Monitor Agents. If the user selects this option, a unique matching log source is searched for across all active Log Sources within the deployment in the following order of precedence:\\nLog Sources associated with the collection System Monitor Agent.\\nLog Sources having the same Root Entity as the collection System Monitor Agent.\\nRoot Entity Searches are composed of the following sub-searches:\\nSearch for Log Sources within the Entity of the System Monitor Agent.\\nIf the System Monitor is attached to a Child Entity,\\nSearch for Log Sources within the Root Entity (that the child belongs to).\\nSearch for Log Sources within the Other Child Entities (under the root entity the child entity belongs to).\\nIf the System Monitor is attached to a Root Entity,\\nSearch for Log Sources within the Child Entities of the Root Entity.\\nRoot Entity Scope\\n. This is the default value set for new System Monitor Agents. If the user selects this option, a unique matching log source is searched for across all active Log Sources within the deployment in the following order of precedence:\\nLog Sources associated with the collection System Monitor Agent.\\nLog Sources associated with the collection System Monitor Agent.\\nLog Sources having the same Root Entity as the collection System Monitor Agent.\\nLog Sources having the same Root Entity as the collection System Monitor Agent.\\nSearch for Log Sources within the Entity of the System Monitor Agent.\\nSearch for Log Sources within the Entity of the System Monitor Agent.\\nIf the System Monitor is attached to a Child Entity,\\nSearch for Log Sources within the Root Entity (that the child belongs to).\\nSearch for Log Sources within the Other Child Entities (under the root entity the child entity belongs to).\\nIf the System Monitor is attached to a Child Entity,\\nSearch for Log Sources within the Root Entity (that the child belongs to).\\nSearch for Log Sources within the Root Entity (that the child belongs to).\\nSearch for Log Sources within the Other Child Entities (under the root entity the child entity belongs to).\\nSearch for Log Sources within the Other Child Entities (under the root entity the child entity belongs to).\\nIf the System Monitor is attached to a Root Entity,\\nSearch for Log Sources within the Child Entities of the Root Entity.\\nIf the System Monitor is attached to a Root Entity,\\nSearch for Log Sources within the Child Entities of the Root Entity.\\nSearch for Log Sources within the Child Entities of the Root Entity.\\nGlobal Scope\\n. If you select this option, a unique matching log source will be searched for across all active Log Sources within the deployment in the following order of precedence:\\nLog Sources associated with the collection System Monitor Agent.\\nLog Sources having the same Root Entity as the collection System Monitor Agent.\\nAll other Log Sources.\\nGlobal Scope\\n. If you select this option, a unique matching log source will be searched for across all active Log Sources within the deployment in the following order of precedence:\\nLog Sources associated with the collection System Monitor Agent.\\nLog Sources associated with the collection System Monitor Agent.\\nLog Sources having the same Root Entity as the collection System Monitor Agent.\\nLog Sources having the same Root Entity as the collection System Monitor Agent.\\nAll other Log Sources.\\nAll other Log Sources.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n/\\nLog Source Identification and Acceptance\\n/\\nAccept New Log Sources Automatically\\n', 'Create IP Range Log Source Acceptance Rules': 'Only Global Admins or Restricted Admins with elevated View and Manage privileges can take this action.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nAutomatic Log Source Acceptance Rule Manager\\n.\\nThe Automatic Log Source Acceptance Rule Manager appears.\\nClick\\nNew\\n, and then click\\nIP Range Rule\\n.\\nThe Automatic Log Source Acceptance Configuration dialog box appears.\\nClick\\nNew\\n, and then click\\nIP Range Rule\\n.\\nThe Automatic Log Source Acceptance Configuration dialog box appears.\\nModify the available configuration parameters for the new rule, as follows.\\nParameter\\nDescription\\nRule Name\\nA\\xa0descriptive name for the rule.\\nBeginning IP\\xa0Address\\nAn IP\\xa0address that represents the first IP\\xa0in a defined range.\\nEnding IP\\xa0Address\\nAn IP\\xa0address that represents the last IP\\xa0in a defined range.\\nLog Interface Type\\nSelect a Log Interface Type from the following values: Syslog, Netflow, SNMP\\xa0TrapReceiver, or sFlow.\\nYour selection filters the Log Source types that are available in the Log Message Source Type list.\\nLog Message Source Type\\nIf the Automatically Identify Log Source Type option is enabled, select the specific Log Message Source Type to apply to Log Sources that match this rule. If you know the name of the log message source, begin typing it to filter the available options. Otherwise, click the arrow to scroll through all options.\\nLog Message Processing Engine (MPE) Policy\\nSelect the MPE\\xa0Policy to be applied to Log Sources that match with this rule.\\nSystem Monitor Entity\\nClick the ellipses\\n[...]\\nbutton to select the System Monitor Entity from which the log sources can originate. To allow multiple entities, press\\nCtrl\\nand select each entity you want. If you have one entity selected and want to add another, click the ellipses\\n[...]\\nbutton, and then select all entities you want, including the original.\\nTarget Entity for Automatically Accepted Log Sources\\nClick the ellipses\\n[...]\\nbutton to select the host entity to which the new log source will be assigned. Note the following conditions:\\nThe default is the Collection System Monitor Entity. If you select a different entity and then want to restore the default, click the ellipses\\n[...]\\nbutton, do not select any options, and then click\\nOK.\\nYou can only select one target entity. Using the Select All options in the Edit menu will not have any result.\\nMake sure you understand\\nhow search scope works\\nso that you select an appropriate target entity.\\nAutomatically Resolve Host\\nSelect this check box if you want to perform automatic host resolution on Log Sources that match this rule.\\nEnabling this option does not automatically accept matching Log Sources.\\nAutomatically Identify Log Source Type\\nSelect this check box if you want to apply the Log Source type that is selected in the\\nLog Message Source Type\\nlist.\\nEnabling this option does not automatically accept matching Log Sources.\\nAutomatically Accept Sources\\nSelect this check box if you want to automatically accept Log Sources that match this rule.\\nModify the available configuration parameters for the new rule, as follows.\\nParameter, Description\\nRule Name, A\\xa0descriptive name for the rule.\\nBeginning IP\\xa0Address, An IP\\xa0address that represents the first IP\\xa0in a defined range.\\nEnding IP\\xa0Address, An IP\\xa0address that represents the last IP\\xa0in a defined range.\\nLog Interface Type, Select a Log Interface Type from the following values: Syslog, Netflow, SNMP\\xa0TrapReceiver, or sFlow.Your selection filters the Log Source types that are available in the Log Message Source Type list.\\nLog Message Source Type, If the Automatically Identify Log Source Type option is enabled, select the specific Log Message Source Type to apply to Log Sources that match this rule. If you know the name of the log message source, begin typing it to filter the available options. Otherwise, click the arrow to scroll through all options.\\nLog Message Processing Engine (MPE) Policy, Select the MPE\\xa0Policy to be applied to Log Sources that match with this rule.\\nSystem Monitor Entity, Click the ellipses[...]button to select the System Monitor Entity from which the log sources can originate. To allow multiple entities, pressCtrland select each entity you want. If you have one entity selected and want to add another, click the ellipses[...]button, and then select all entities you want, including the original.\\nTarget Entity for Automatically Accepted Log Sources, Click the ellipses[...]button to select the host entity to which the new log source will be assigned. Note the following conditions:The default is the Collection System Monitor Entity. If you select a different entity and then want to restore the default, click the ellipses[...]button, do not select any options, and then clickOK.You can only select one target entity. Using the Select All options in the Edit menu will not have any result.Make sure you understandhow search scope worksso that you select an appropriate target entity.\\nAutomatically Resolve Host, Select this check box if you want to perform automatic host resolution on Log Sources that match this rule.Enabling this option does not automatically accept matching Log Sources.\\nAutomatically Identify Log Source Type, Select this check box if you want to apply the Log Source type that is selected in theLog Message Source Typelist.Enabling this option does not automatically accept matching Log Sources.\\nAutomatically Accept Sources, Select this check box if you want to automatically accept Log Sources that match this rule.\\nSelect a Log Interface Type from the following values: Syslog, Netflow, SNMP\\xa0TrapReceiver, or sFlow.\\nYour selection filters the Log Source types that are available in the Log Message Source Type list.\\nThe default is the Collection System Monitor Entity. If you select a different entity and then want to restore the default, click the ellipses\\n[...]\\nbutton, do not select any options, and then click\\nOK.\\nYou can only select one target entity. Using the Select All options in the Edit menu will not have any result.\\nMake sure you understand\\nhow search scope works\\nso that you select an appropriate target entity.\\nSelect this check box if you want to perform automatic host resolution on Log Sources that match this rule.\\nEnabling this option does not automatically accept matching Log Sources.\\nSelect this check box if you want to apply the Log Source type that is selected in the\\nLog Message Source Type\\nlist.\\nEnabling this option does not automatically accept matching Log Sources.\\nSelect this check box if you want to automatically accept Log Sources that match this rule.\\nWhen you are finished configuring the rule, click\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n/\\nLog Source Identification and Acceptance\\n/\\nAccept New Log Sources Automatically\\n', 'Create Pattern Match Log Source Acceptance Rules': 'Only Global Admins or Restricted Admins with elevated View and Manage privileges can take this action.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nAutomatic Log Source Acceptance Rule Manager\\n.\\nThe Automatic Log Source Acceptance Rule Manager appears.\\nClick\\nNew\\n, and then click\\nLog Message Pattern Match Rule\\n.\\nThe Automatic Log Source Acceptance Configuration dialog box appears.\\nClick\\nNew\\n, and then click\\nLog Message Pattern Match Rule\\n.\\nThe Automatic Log Source Acceptance Configuration dialog box appears.\\nIn the Rule Name box, type a descriptive name for the rule.\\nIn the Rule Name box, type a descriptive name for the rule.\\nTo add a new regex pattern, click\\nAdd\\n.\\nTo add a new regex pattern, click\\nAdd\\n.\\nType or paste the regex to use for matching log messages in the box that appears, and then click\\nSave\\n.\\nType or paste the regex to use for matching log messages in the box that appears, and then click\\nSave\\n.\\nRepeat steps 5 and 6 to add more regex patterns.\\nThere is no limit to the number of patters you can add, but performance is best when using no more than three. Messages are evaluated against all regex patterns, top to bottom, until a match is found or until all patterns have been evaluated.\\nTo modify an existing pattern, double-click the pattern, modify it in the box that appears below the grid, and then click\\nUpdate\\n. Alternatively, select the\\nAction\\ncheck box to the left of the pattern, right-click the grid, and then click\\nUpdate\\n. To delete an existing pattern, select the\\nAction\\ncheck box to the left of the pattern, right-click the grid, and then click\\nDelete\\n.\\nRepeat steps 5 and 6 to add more regex patterns.\\nThere is no limit to the number of patters you can add, but performance is best when using no more than three. Messages are evaluated against all regex patterns, top to bottom, until a match is found or until all patterns have been evaluated.\\nTo modify an existing pattern, double-click the pattern, modify it in the box that appears below the grid, and then click\\nUpdate\\n. Alternatively, select the\\nAction\\ncheck box to the left of the pattern, right-click the grid, and then click\\nUpdate\\n. To delete an existing pattern, select the\\nAction\\ncheck box to the left of the pattern, right-click the grid, and then click\\nDelete\\n.\\nModify the remaining configuration parameters for the new rule, as follows:\\nParameter\\nDescription\\nLog Interface Type\\nSelect a Log Interface Type from the following values: Syslog, Netflow, SNMP\\xa0TrapReceiver, or sFlow.\\nYour selection filters the Log Source types that are available in the Log Message Source Type list.\\nLog Message Source Type\\nIf the Automatically Identify Log Source Type option is enabled, select the specific Log Message Source Type to apply to Log Sources that match this rule. If you know the name of the log message source, begin typing it to filter the available options. Otherwise, click the arrow to scroll through all options.\\nLog Message Processing Engine (MPE) Policy\\nSelect the MPE\\xa0Policy to be applied to Log Sources that match with this rule.\\nSystem Monitor Entity\\nClick the ellipses\\n[...]\\nbutton to select the\\xa0System Monitor Entity from which the log sources can originate.\\xa0To allow multiple entities, press\\nCtrl\\nand select each entity you want. If you have one entity selected and want to add another, click the ellipses\\n[...]\\nbutton, and then select all entities you want, including the original.\\nTarget Entity for Automatically Accepted Sources\\nClick the ellipses\\n[...]\\nbutton to select the host entity to which the new log source will be assigned. Note the following conditions:\\nThe default is the Collection System Monitor Entity. If you select a different entity and then want to restore the default, click the ellipses\\n[...]\\nbutton, do not select any options, and then click\\nOK.\\nYou can only select one target entity. Using the Select All options in the Edit menu will not have any result.\\nMake sure you understand\\nhow search scope works\\nso that you select an appropriate target entity.\\nAutomatically Resolve Host\\nSelect this check box if you want to perform automatic host resolution on Log Sources that match this rule.\\nEnabling this option does not automatically accept matching Log Sources.\\nAutomatically Identify Log Source Type\\nSelect this check box if you want to apply the Log Source type that is selected in the\\nLog Message Source Type\\nlist.\\nEnabling this option does not automatically accept matching Log Sources.\\nAutomatically Accept Sources\\nSelect this check box if you want to automatically accept Log Sources that match this rule.\\nModify the remaining configuration parameters for the new rule, as follows:\\nParameter, Description\\nLog Interface Type, Select a Log Interface Type from the following values: Syslog, Netflow, SNMP\\xa0TrapReceiver, or sFlow.Your selection filters the Log Source types that are available in the Log Message Source Type list.\\nLog Message Source Type, If the Automatically Identify Log Source Type option is enabled, select the specific Log Message Source Type to apply to Log Sources that match this rule. If you know the name of the log message source, begin typing it to filter the available options. Otherwise, click the arrow to scroll through all options.\\nLog Message Processing Engine (MPE) Policy, Select the MPE\\xa0Policy to be applied to Log Sources that match with this rule.\\nSystem Monitor Entity, Click the ellipses[...]button to select the\\xa0System Monitor Entity from which the log sources can originate.\\xa0To allow multiple entities, pressCtrland select each entity you want. If you have one entity selected and want to add another, click the ellipses[...]button, and then select all entities you want, including the original.\\nTarget Entity for Automatically Accepted Sources, Click the ellipses[...]button to select the host entity to which the new log source will be assigned. Note the following conditions:The default is the Collection System Monitor Entity. If you select a different entity and then want to restore the default, click the ellipses[...]button, do not select any options, and then clickOK.You can only select one target entity. Using the Select All options in the Edit menu will not have any result.Make sure you understandhow search scope worksso that you select an appropriate target entity.\\nAutomatically Resolve Host, Select this check box if you want to perform automatic host resolution on Log Sources that match this rule.Enabling this option does not automatically accept matching Log Sources.\\nAutomatically Identify Log Source Type, Select this check box if you want to apply the Log Source type that is selected in theLog Message Source Typelist.Enabling this option does not automatically accept matching Log Sources.\\nAutomatically Accept Sources, Select this check box if you want to automatically accept Log Sources that match this rule.\\nSelect a Log Interface Type from the following values: Syslog, Netflow, SNMP\\xa0TrapReceiver, or sFlow.\\nYour selection filters the Log Source types that are available in the Log Message Source Type list.\\nThe default is the Collection System Monitor Entity. If you select a different entity and then want to restore the default, click the ellipses\\n[...]\\nbutton, do not select any options, and then click\\nOK.\\nYou can only select one target entity. Using the Select All options in the Edit menu will not have any result.\\nMake sure you understand\\nhow search scope works\\nso that you select an appropriate target entity.\\nSelect this check box if you want to perform automatic host resolution on Log Sources that match this rule.\\nEnabling this option does not automatically accept matching Log Sources.\\nSelect this check box if you want to apply the Log Source type that is selected in the\\nLog Message Source Type\\nlist.\\nEnabling this option does not automatically accept matching Log Sources.\\nSelect this check box if you want to automatically accept Log Sources that match this rule.\\nWhen you are finished configuring the rule, click\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n/\\nLog Source Identification and Acceptance\\n/\\nAccept New Log Sources Automatically\\n', 'Manage Automatic Log Source Acceptance Rules': 'Only Global Admins or Restricted Admins with elevated View and Manage privileges can take this action.\\nWhen new Log Message Sources come in to a deployment, they are evaluated against all enabled Log Source Acceptance rules in the order that the rules appear in the Automatic Log Source Acceptance Rule Manager. If a Log Message Source matches one of the enabled rules, it is no longer evaluated against any remaining rules. To ensure that you are applying the right number of rules in the right order, you can enable or disable rules, or change their order of processing (priority).\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nAutomatic Log Source Acceptance Rule Manager\\n.\\nThe Entity column in the grid shows the value in the System Monitor Entity field.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nAutomatic Log Source Acceptance Rule Manager\\n.\\nThe Entity column in the grid shows the value in the System Monitor Entity field.\\nDo one of the following:\\nView or Modify Existing Rules\\nClick an existing rule to select it.\\nDo one of the following:\\nDouble-click the rule.\\nClick the\\nProperties\\nbutton on the toolbar.\\nRight-click within the rule grid, and then click\\nProperties\\n.\\nFor more information about modifying an existing rule, see\\nCreate an IP Range Log Source Acceptance Rule\\nor\\nCreate a Pattern Match Log Source Acceptance Rule\\n.\\nEnable or Disable Rules\\nSelect the\\nAction\\ncheck box to the left of one or more rules.\\nDo one of the following:\\nRight-click within the rule grid, click\\nAction\\n, and then click\\nEnable\\nor\\nDisable\\n.\\nClick the\\nAction\\nmenu, and then click\\nEnable\\nor\\nDisable.\\nDelete Rules\\nSelect the\\nAction\\ncheck box to the left of one or more rules.\\nRight-click within the rule grid, click\\nAction\\n, and then click\\nDelete\\n.\\nChange the Priority of Rules\\nSelect the\\nAction\\ncheck box to the left of one rule.\\nClick one of the move buttons in the toolbar:\\nMoveTop\\n. Move the selected rule to the top of the list.\\nMoveUp\\n. Move the selected rule up one spot in the list.\\nMoveDown\\n. Move the selected rule down one spot in the list.\\nMoveBottom\\n. Move the selected rule to the bottom of the list.\\nView or Modify Existing Rules\\nClick an existing rule to select it.\\nDo one of the following:\\nDouble-click the rule.\\nClick the\\nProperties\\nbutton on the toolbar.\\nRight-click within the rule grid, and then click\\nProperties\\n.\\nFor more information about modifying an existing rule, see\\nCreate an IP Range Log Source Acceptance Rule\\nor\\nCreate a Pattern Match Log Source Acceptance Rule\\n.\\nClick an existing rule to select it.\\nClick an existing rule to select it.\\nDo one of the following:\\nDouble-click the rule.\\nClick the\\nProperties\\nbutton on the toolbar.\\nRight-click within the rule grid, and then click\\nProperties\\n.\\nFor more information about modifying an existing rule, see\\nCreate an IP Range Log Source Acceptance Rule\\nor\\nCreate a Pattern Match Log Source Acceptance Rule\\n.\\nDo one of the following:\\nDouble-click the rule.\\nDouble-click the rule.\\nClick the\\nProperties\\nbutton on the toolbar.\\nClick the\\nProperties\\nbutton on the toolbar.\\nRight-click within the rule grid, and then click\\nProperties\\n.\\nRight-click within the rule grid, and then click\\nProperties\\n.\\nFor more information about modifying an existing rule, see\\nCreate an IP Range Log Source Acceptance Rule\\nor\\nCreate a Pattern Match Log Source Acceptance Rule\\n.\\nEnable or Disable Rules\\nSelect the\\nAction\\ncheck box to the left of one or more rules.\\nDo one of the following:\\nRight-click within the rule grid, click\\nAction\\n, and then click\\nEnable\\nor\\nDisable\\n.\\nClick the\\nAction\\nmenu, and then click\\nEnable\\nor\\nDisable.\\nEnable or Disable Rules\\nSelect the\\nAction\\ncheck box to the left of one or more rules.\\nSelect the\\nAction\\ncheck box to the left of one or more rules.\\nDo one of the following:\\nRight-click within the rule grid, click\\nAction\\n, and then click\\nEnable\\nor\\nDisable\\n.\\nClick the\\nAction\\nmenu, and then click\\nEnable\\nor\\nDisable.\\nDo one of the following:\\nRight-click within the rule grid, click\\nAction\\n, and then click\\nEnable\\nor\\nDisable\\n.\\nRight-click within the rule grid, click\\nAction\\n, and then click\\nEnable\\nor\\nDisable\\n.\\nClick the\\nAction\\nmenu, and then click\\nEnable\\nor\\nDisable.\\nClick the\\nAction\\nmenu, and then click\\nEnable\\nor\\nDisable.\\nDelete Rules\\nSelect the\\nAction\\ncheck box to the left of one or more rules.\\nRight-click within the rule grid, click\\nAction\\n, and then click\\nDelete\\n.\\nSelect the\\nAction\\ncheck box to the left of one or more rules.\\nSelect the\\nAction\\ncheck box to the left of one or more rules.\\nRight-click within the rule grid, click\\nAction\\n, and then click\\nDelete\\n.\\nRight-click within the rule grid, click\\nAction\\n, and then click\\nDelete\\n.\\nChange the Priority of Rules\\nSelect the\\nAction\\ncheck box to the left of one rule.\\nClick one of the move buttons in the toolbar:\\nMoveTop\\n. Move the selected rule to the top of the list.\\nMoveUp\\n. Move the selected rule up one spot in the list.\\nMoveDown\\n. Move the selected rule down one spot in the list.\\nMoveBottom\\n. Move the selected rule to the bottom of the list.\\nChange the Priority of Rules\\nSelect the\\nAction\\ncheck box to the left of one rule.\\nSelect the\\nAction\\ncheck box to the left of one rule.\\nClick one of the move buttons in the toolbar:\\nMoveTop\\n. Move the selected rule to the top of the list.\\nMoveUp\\n. Move the selected rule up one spot in the list.\\nMoveDown\\n. Move the selected rule down one spot in the list.\\nMoveBottom\\n. Move the selected rule to the bottom of the list.\\nClick one of the move buttons in the toolbar:\\nMoveTop\\n. Move the selected rule to the top of the list.\\nMoveTop\\n. Move the selected rule to the top of the list.\\nMoveUp\\n. Move the selected rule up one spot in the list.\\nMoveUp\\n. Move the selected rule up one spot in the list.\\nMoveDown\\n. Move the selected rule down one spot in the list.\\nMoveDown\\n. Move the selected rule down one spot in the list.\\nMoveBottom\\n. Move the selected rule to the bottom of the list.\\nMoveBottom\\n. Move the selected rule to the bottom of the list.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n/\\nLog Source Types\\n', 'Modify Custom Log Source Type': 'You must be logged in as an Administrator to take this action.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nKnowledge\\n, and then click\\nLog Source Type Manager\\n.\\nThe Log Source Type Manager appears.\\nOn the Tools menu, click\\nKnowledge\\n, and then click\\nLog Source Type Manager\\n.\\nThe Log Source Type Manager appears.\\nDouble-click a Log Source Type in the list.\\nThe Log Source Type Source Properties window appears.\\nDouble-click a Log Source Type in the list.\\nThe Log Source Type Source Properties window appears.\\nEdit the information as needed.\\nIf Log Source Type = System, it has been defined by LogRhythm and cannot be modified or removed.\\nEdit the information as needed.\\nIf Log Source Type = System, it has been defined by LogRhythm and cannot be modified or removed.\\nClick\\nOK\\n.\\nClick\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n/\\nLog Source Virtualization\\n', 'Create Virtual Log Sources': 'Before beginning these instructions, record the Regex of the original log source.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nLog Source Virtualization Template Manager\\n.\\nAt the bottom of the dialog box, click the\\nVirtual Log Source Manager\\nbutton.\\nThe Virtual Log Source Manager appears.\\nAt the bottom of the dialog box, click the\\nVirtual Log Source Manager\\nbutton.\\nThe Virtual Log Source Manager appears.\\nOn the upper-left side of the Virtual Log Source Manager dialog box, click the\\nNew Template Item\\nicon.\\nOn the upper-left side of the Virtual Log Source Manager dialog box, click the\\nNew Template Item\\nicon.\\nIn the Virtual Log Source Name field, type a name.\\nIn the Virtual Log Source Name field, type a name.\\nIn the Identifier Regex text box, specify a regex pattern that identifies the virtual (child) log source.\\nThe Identifier Regex is a regular expression to match the log message.\\xa0For example, you might want to split Office 365 Management Activity API logs into one log source per service (Exchange, Sharepoint, Azure Active Directory). For a log like:\\nTS=2018-05-01T15:27:14 SESSID=123 COMMAND=MailboxLogin USERTYPE=Regular USERKEY=123 WORKLOAD=Exchange RESULTCODE=Succeeded\\nthe Identifier Regex for Exchange would be:\\nWorkload=Exchange\\nThe Identifier Regex that matches both Sharepoint and OneDrive would be:\\nWorkload=(Sharepoint|Onedrive)\\nIn the Identifier Regex text box, specify a regex pattern that identifies the virtual (child) log source.\\nthe Identifier Regex for Exchange would be:\\nThe Identifier Regex that matches both Sharepoint and OneDrive would be:\\n\\n(Optional)\\nIf you want to drop all logs matching the specified regex, select the\\nDrop Logs\\ncheck box.\\nIf you enable the Drop Logs option, you cannot select a Log Message Source Type or MPE Policy. The Log Source Type is LogRhythm Filter, and the LogRhythm Default MPE policy is applied. At this point, you can save the virtual log source.\\n(Optional)\\nIf you want to drop all logs matching the specified regex, select the\\nDrop Logs\\ncheck box.\\nIf you enable the Drop Logs option, you cannot select a Log Message Source Type or MPE Policy. The Log Source Type is LogRhythm Filter, and the LogRhythm Default MPE policy is applied. At this point, you can save the virtual log source.\\nTo search for a log source type, click the\\nLog Message Source Type\\nicon.\\nThe Log Source Type Selector dialog box appears.\\nTo narrow the list of log source types, select a Record Type Filter and/or type a Text Filter.\\nTo include retired log source types in the list, select the\\nShow Retired\\ncheck box in the lower-left corner of the dialog box.\\nIn the Log Source Type list box, select the appropriate log source type, and then click\\nOK\\n.\\nTo search for a log source type, click the\\nLog Message Source Type\\nicon.\\nThe Log Source Type Selector dialog box appears.\\nTo narrow the list of log source types, select a Record Type Filter and/or type a Text Filter.\\nTo narrow the list of log source types, select a Record Type Filter and/or type a Text Filter.\\nTo include retired log source types in the list, select the\\nShow Retired\\ncheck box in the lower-left corner of the dialog box.\\nTo include retired log source types in the list, select the\\nShow Retired\\ncheck box in the lower-left corner of the dialog box.\\nIn the Log Source Type list box, select the appropriate log source type, and then click\\nOK\\n.\\nIn the Log Source Type list box, select the appropriate log source type, and then click\\nOK\\n.\\nOn the Log Processing Message Engine (MPE) Policy menu, click an MPE policy.\\nOn the Log Processing Message Engine (MPE) Policy menu, click an MPE policy.\\nClick\\nSave\\n.\\nThe virtual log source is created and ready to use.\\nClick\\nSave\\n.\\nThe virtual log source is created and ready to use.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n/\\nWork With Log Sources\\n', 'Add a Single Log Source': \"You must be logged in as an Administrator to take this action.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nSystem Monitors\\ntab.\\nSelect the Agent where you want to add a Log Source.\\nRight-click the selection and click\\nProperties\\n.\\nThe System Monitor Agent Properties window opens.\\nRight-click in the lower pane and select\\nNew\\nto open the Log Message Source Properties window.\\nIn the Basic Configuration tab, enter the appropriate information.\\nProperty\\nDescription\\nBasic Configuration Tab\\nLog Source Host\\nThe Host for the log file.\\nCollection Agent\\nThe System Monitor Agent performing the log collection.\\nLog Message Source Type\\nThe type of source of the log data. Example, Microsoft Event Log - Security. The Log Source Type Selector lets you choose between System Log Sources and Custom Log Sources that you have created. For more information, see\\nLog Source Types\\n.\\nYou must create parsing rules for the new, custom log sources before data can be parsed from the logs. Contact\\nLogRhythm Support\\nto submit a request for parsing rules for a new Log Source Type. Users who attended LogRhythm Rule Building training can create their own custom parsing rules.\\nLog Message Source Name\\nThe name of the log source being configured.\\nBrief\\nDescription\\nDescription of the log source being configured.\\nLog Message\\nProcessing Mode\\nEnable or disable processing or event forwarding.\\nLog Message Processing Engine (MPE) Policy\\nSelect the MPE Policy to assign to the log source being configured.\\nForward Logs to LogRhythm LogMart\\nSelect to enable log forwarding to LogMart.\\nA GLPR can override log forwarding to LogMart.\\nIn the Basic Configuration tab, enter the appropriate information.\\nProperty, Description\\nBasic Configuration Tab\\nLog Source Host, The Host for the log file.\\nCollection Agent, The System Monitor Agent performing the log collection.\\nLog Message Source Type, The type of source of the log data. Example, Microsoft Event Log - Security. The Log Source Type Selector lets you choose between System Log Sources and Custom Log Sources that you have created. For more information, seeLog Source Types.You must create parsing rules for the new, custom log sources before data can be parsed from the logs. ContactLogRhythm Supportto submit a request for parsing rules for a new Log Source Type. Users who attended LogRhythm Rule Building training can create their own custom parsing rules.\\nLog Message Source Name, The name of the log source being configured.\\nBriefDescription, Description of the log source being configured.\\nLog MessageProcessing Mode, Enable or disable processing or event forwarding.\\nLog Message Processing Engine (MPE) Policy, Select the MPE Policy to assign to the log source being configured.\\nForward Logs to LogRhythm LogMart, Select to enable log forwarding to LogMart.A GLPR can override log forwarding to LogMart.\\nLog Source Host\\nThe Host for the log file.\\nThe type of source of the log data. Example, Microsoft Event Log - Security. The Log Source Type Selector lets you choose between System Log Sources and Custom Log Sources that you have created. For more information, see\\nLog Source Types\\n.\\nYou must create parsing rules for the new, custom log sources before data can be parsed from the logs. Contact\\nLogRhythm Support\\nto submit a request for parsing rules for a new Log Source Type. Users who attended LogRhythm Rule Building training can create their own custom parsing rules.\\nSelect to enable log forwarding to LogMart.\\nA GLPR can override log forwarding to LogMart.\\nIn the Additional Settings tab, enter the appropriate information.\\nProperty\\nDescription\\nAdditional Settings Tab\\nVirtualization Settings\\nA virtualized Log Source collects logs from more than one real source (multiple switches, access points, etc.) via the Agent's syslog. The identifiers are data that would trigger the Agent to assign the log to this virtual Log Source.\\nSelect the check box for the identifier you want.\\nLog Data Management and Processing Settings\\nDon't Archive\\n. A copy of the logs is not written to archive.\\nDrop Whole Log\\n. Log messages are not indexed or written to the Events DB or LogMart. Logs are archived unless\\nDon't Archive\\nis selected.\\nDrop Raw Log\\n. Only log metadata is indexed. Logs are archived unless\\nDon't Archive\\nis selected.\\nSilent Log Message Source Settings\\nEnable Silent Log Message\\xa0Source\\xa0Detection\\n. Select to begin detecting Silent Log Message Sources.\\nIssue Warning After\\nn\\nhours and\\nn\\nminutes\\n. Set time frame before a Warning is issued due to a log source not being received.\\nIssue Error After\\nn\\nhours and\\nn\\nminutes\\n. Set time frame before an Error is issued due to a log source not being received.\\nStart Collection from the Beginning of the Log\\nWhen enabled, the System Monitor Agent starts the log collection at the beginning of the log to obtain all historical Event Logs. Collecting historical data can be time intensive lasting hours to days to catch up with real-time data.\\nWhen disabled, the log collection starts real-time at the current time and date.\\nLoad Balanced Log Source\\nEnable this setting when using\\nLoad Balanced Agent Groups\\nand\\nDP Pooling\\n. When enabled the Log Source is a load balanced Log Source. Be sure the Agents that receive load balanced log sources are configured to communicate with all Mediators that are used for load balancing for that set of Agents. Configuring these Agents to communicate with only some of the Mediators in the set will result in errors. For more information, see\\nLoad Balancing\\n.\\nIn the Additional Settings tab, enter the appropriate information.\\nProperty, Description\\nAdditional Settings Tab\\nVirtualization Settings, A virtualized Log Source collects logs from more than one real source (multiple switches, access points, etc.) via the Agent's syslog. The identifiers are data that would trigger the Agent to assign the log to this virtual Log Source.Select the check box for the identifier you want.\\nLog Data Management and Processing Settings, Don't Archive. A copy of the logs is not written to archive.Drop Whole Log. Log messages are not indexed or written to the Events DB or LogMart. Logs are archived unlessDon't Archiveis selected.Drop Raw Log. Only log metadata is indexed. Logs are archived unlessDon't Archiveis selected.\\nSilent Log Message Source Settings, Enable Silent Log Message\\xa0Source\\xa0Detection. Select to begin detecting Silent Log Message Sources.Issue Warning Afternhours andnminutes. Set time frame before a Warning is issued due to a log source not being received.Issue Error Afternhours andnminutes. Set time frame before an Error is issued due to a log source not being received.\\nStart Collection from the Beginning of the Log, When enabled, the System Monitor Agent starts the log collection at the beginning of the log to obtain all historical Event Logs. Collecting historical data can be time intensive lasting hours to days to catch up with real-time data.When disabled, the log collection starts real-time at the current time and date.\\nLoad Balanced Log Source, Enable this setting when usingLoad Balanced Agent GroupsandDP Pooling. When enabled the Log Source is a load balanced Log Source. Be sure the Agents that receive load balanced log sources are configured to communicate with all Mediators that are used for load balancing for that set of Agents. Configuring these Agents to communicate with only some of the Mediators in the set will result in errors. For more information, seeLoad Balancing.\\nVirtualization Settings\\nSelect the check box for the identifier you want.\\nDon't Archive\\n. A copy of the logs is not written to archive.\\nDrop Whole Log\\n. Log messages are not indexed or written to the Events DB or LogMart. Logs are archived unless\\nDon't Archive\\nis selected.\\nDrop Raw Log\\n. Only log metadata is indexed. Logs are archived unless\\nDon't Archive\\nis selected.\\nEnable Silent Log Message\\xa0Source\\xa0Detection\\n. Select to begin detecting Silent Log Message Sources.\\nIssue Warning After\\nn\\nhours and\\nn\\nminutes\\n. Set time frame before a Warning is issued due to a log source not being received.\\nIssue Error After\\nn\\nhours and\\nn\\nminutes\\n. Set time frame before an Error is issued due to a log source not being received.\\nEnable this setting when using\\nLoad Balanced Agent Groups\\nand\\nDP Pooling\\n. When enabled the Log Source is a load balanced Log Source. Be sure the Agents that receive load balanced log sources are configured to communicate with all Mediators that are used for load balancing for that set of Agents. Configuring these Agents to communicate with only some of the Mediators in the set will result in errors. For more information, see\\nLoad Balancing\\n.\\nIn the Flat File Settings tab, enter the appropriate information. For additional information on collecting local flat files and Windows Extended Event log, see\\nConfigure a Host for Local Flat File Collection\\n.\\nProperty\\nDescription\\nFlat File Settings Tab\\nFile Path\\nDefine the path to the directory or log file.\\nExamples: Directory path = C:\\\\Logs; Log file path = C:\\\\Logs\\\\error.log\\nIf you enter a directory path, you must enable the\\nIs Directory\\nfield.\\nIf you enter a log file path, you cannot enable the\\nIs Directory\\nfield.\\nDate Parsing\\nFormat\\nDefine regular expression (Regex) patterns to be used by a System Monitor Agent for parsing date information from log files.\\nTo open the\\nDate Format Manager\\n, click the ellipsis\\n[...]\\nbutton after the\\nDate Parsing Format\\nfield. Select an existing date parsing format or create a new one by clicking\\nFile\\n, and then clicking\\nNew\\n.\\nMultiline Log Message Settings\\nLog Message Start Regex\\n. Serves to indicate the start of a multiline log entry. If a line read for a log file matches this Regex string, it indicates the beginning of a new log entry.\\nLog Message Delimiter Regex\\n. Serves to indicate that the current line delimits log entries. When the line matches the Regex string, it indicates that the previous entry is complete and a new log entry follows on the next line. The line matched by the Log Message Delimiter Regex is discarded and not included in any log entry.\\nLog Message End Regex\\n. Serves to indicate the end of a multi-line log entry. If a line read from a log file matches this Regex string, it indicates the end of the current log entry. The line matched is included in the log entry.\\nUsually, only one of the three parameters is necessary, dependent upon which configuration parameter offers the most simplistic Regex.\\nFor additional information, see Multi-Line Log Collection.\\nDirectory Collection\\nIs Directory\\nSelect to indicate that the file path entered above is a directory. Selecting this box allows files to be collected recursively through the directory and enables the other fields in the Directory Collection area.\\nWatch File Rename On Rollover\\nCheck this box when collecting log files that are renamed on rollover. Uncheck this box when collecting logs that do not get renamed on rollover.\\nRecursion Depth\\nSelect a number to indicate the number of folder levels relative to the File Path entry.\\nExample: When the path = C:\\\\Logs\\nThe depth for files in C:\\\\Logs = 0\\nThe depth for files in C:\\\\Logs\\\\20100430 = 1\\nInclusions\\nIf you do not want to collect logs from all files, add the inclusions required.\\nInclusion is extremely flexible and allows a complex use of wildcards. It is based on the model used in File Integrity Monitor. If you are not familiar with how Inclusion functions in FIM, read the FIM section Inclusion and Exclusion Filters for detailed information before you complete this field.\\nExclusions\\nIf you do not want to collect logs from all files, add the exclusions required.\\nExclusion is extremely flexible and allows a complex use of wildcards. It is based on the model used in File Integrity Monitor. If you are not familiar with how Exclusion functions in FIM, read the FIM section Inclusion and Exclusion Filters for detailed information before you complete this field.\\nCompression Type\\nSelect the type of compression (for example, gzip, tar, targzip, bzip2, zip, or none).\\nFile Path\\nDate Parsing Format\\nOpen the Date Format Manager by clicking the ellipsis [...] button after the Date Parsing Format field.\\nTo select a system date format or create a new one, click the\\nFile\\nmenu, and then click\\nNew\\n.\\nMultiline Log Message Settings\\nDirectory Collection\\nCompression Type\\nIn the Flat File Settings tab, enter the appropriate information. For additional information on collecting local flat files and Windows Extended Event log, see\\nConfigure a Host for Local Flat File Collection\\n.\\nProperty, Description\\nFlat File Settings Tab\\nFile Path, Define the path to the directory or log file.Examples: Directory path = C:\\\\Logs; Log file path = C:\\\\Logs\\\\error.logIf you enter a directory path, you must enable theIs Directoryfield.If you enter a log file path, you cannot enable theIs Directoryfield.\\nDate ParsingFormat, Define regular expression (Regex) patterns to be used by a System Monitor Agent for parsing date information from log files.To open theDate Format Manager, click the ellipsis[...]button after theDate Parsing Formatfield. Select an existing date parsing format or create a new one by clickingFile, and then clickingNew.\\nMultiline Log Message Settings, Log Message Start Regex. Serves to indicate the start of a multiline log entry. If a line read for a log file matches this Regex string, it indicates the beginning of a new log entry.Log Message Delimiter Regex. Serves to indicate that the current line delimits log entries. When the line matches the Regex string, it indicates that the previous entry is complete and a new log entry follows on the next line. The line matched by the Log Message Delimiter Regex is discarded and not included in any log entry.Log Message End Regex. Serves to indicate the end of a multi-line log entry. If a line read from a log file matches this Regex string, it indicates the end of the current log entry. The line matched is included in the log entry.Usually, only one of the three parameters is necessary, dependent upon which configuration parameter offers the most simplistic Regex.For additional information, see Multi-Line Log Collection.\\nDirectory CollectionIs Directory, Select to indicate that the file path entered above is a directory. Selecting this box allows files to be collected recursively through the directory and enables the other fields in the Directory Collection area.\\nWatch File Rename On Rollover, Check this box when collecting log files that are renamed on rollover. Uncheck this box when collecting logs that do not get renamed on rollover.\\nRecursion Depth, Select a number to indicate the number of folder levels relative to the File Path entry.Example: When the path = C:\\\\LogsThe depth for files in C:\\\\Logs = 0The depth for files in C:\\\\Logs\\\\20100430 = 1\\nInclusions, If you do not want to collect logs from all files, add the inclusions required.Inclusion is extremely flexible and allows a complex use of wildcards. It is based on the model used in File Integrity Monitor. If you are not familiar with how Inclusion functions in FIM, read the FIM section Inclusion and Exclusion Filters for detailed information before you complete this field.\\nExclusions, If you do not want to collect logs from all files, add the exclusions required.Exclusion is extremely flexible and allows a complex use of wildcards. It is based on the model used in File Integrity Monitor. If you are not familiar with how Exclusion functions in FIM, read the FIM section Inclusion and Exclusion Filters for detailed information before you complete this field.\\nCompression Type, Select the type of compression (for example, gzip, tar, targzip, bzip2, zip, or none).\\nDefine the path to the directory or log file.\\nExamples: Directory path = C:\\\\Logs; Log file path = C:\\\\Logs\\\\error.log\\nIf you enter a directory path, you must enable the\\nIs Directory\\nfield.\\nIf you enter a log file path, you cannot enable the\\nIs Directory\\nfield.\\nDefine regular expression (Regex) patterns to be used by a System Monitor Agent for parsing date information from log files.\\nTo open the\\nDate Format Manager\\n, click the ellipsis\\n[...]\\nbutton after the\\nDate Parsing Format\\nfield. Select an existing date parsing format or create a new one by clicking\\nFile\\n, and then clicking\\nNew\\n.\\nMultiline Log Message Settings\\nLog Message Start Regex\\n. Serves to indicate the start of a multiline log entry. If a line read for a log file matches this Regex string, it indicates the beginning of a new log entry.\\nLog Message Delimiter Regex\\n. Serves to indicate that the current line delimits log entries. When the line matches the Regex string, it indicates that the previous entry is complete and a new log entry follows on the next line. The line matched by the Log Message Delimiter Regex is discarded and not included in any log entry.\\nLog Message End Regex\\n. Serves to indicate the end of a multi-line log entry. If a line read from a log file matches this Regex string, it indicates the end of the current log entry. The line matched is included in the log entry.\\nUsually, only one of the three parameters is necessary, dependent upon which configuration parameter offers the most simplistic Regex.\\nFor additional information, see Multi-Line Log Collection.\\nSelect a number to indicate the number of folder levels relative to the File Path entry.\\nExample: When the path = C:\\\\Logs\\nThe depth for files in C:\\\\Logs = 0\\nThe depth for files in C:\\\\Logs\\\\20100430 = 1\\nIf you do not want to collect logs from all files, add the inclusions required.\\nInclusion is extremely flexible and allows a complex use of wildcards. It is based on the model used in File Integrity Monitor. If you are not familiar with how Inclusion functions in FIM, read the FIM section Inclusion and Exclusion Filters for detailed information before you complete this field.\\nIf you do not want to collect logs from all files, add the exclusions required.\\nExclusion is extremely flexible and allows a complex use of wildcards. It is based on the model used in File Integrity Monitor. If you are not familiar with how Exclusion functions in FIM, read the FIM section Inclusion and Exclusion Filters for detailed information before you complete this field.\\nFile Path\\nFile Path\\nDate Parsing Format\\nOpen the Date Format Manager by clicking the ellipsis [...] button after the Date Parsing Format field.\\nTo select a system date format or create a new one, click the\\nFile\\nmenu, and then click\\nNew\\n.\\nDate Parsing Format\\nOpen the Date Format Manager by clicking the ellipsis [...] button after the Date Parsing Format field.\\nOpen the Date Format Manager by clicking the ellipsis [...] button after the Date Parsing Format field.\\nTo select a system date format or create a new one, click the\\nFile\\nmenu, and then click\\nNew\\n.\\nTo select a system date format or create a new one, click the\\nFile\\nmenu, and then click\\nNew\\n.\\nMultiline Log Message Settings\\nMultiline Log Message Settings\\nDirectory Collection\\nDirectory Collection\\nCompression Type\\nCompression Type\\nEnter the appropriate information in the UDLA Settings tab (Universal Database Log Adapter). For more information, see\\nConfigure UDLA Log Collection\\n.\\nProperty\\nDescription\\nUDLA Settings Tab\\nODBC / OLE DB\\nSelect the\\nODBC\\nor\\nOLE\\nDB connection type.\\nConnection String\\nThe connection\\xa0string for the UDLA\\xa0Log Message Source.\\nQuery Statement\\nThe SQL\\xa0select statement that returns the fields comprising the log entry. The select statement must contain a state field\\xa0and unique identifier fields.\\nOutput Format\\nDetermine how to format the returned rows as text.\\nUnique Identifier Field\\nDetermine how an absolute unique record identifier is defined. This value is used for state tracking. Can be a list of comma separated fields.\\nMessage Date Field\\nDetermine which field is used for determining log message date. The value parsed from this field is stored in Msg.MsgDate. This value is also normalized and stored in Msg.NormalMsgDate.\\nState Field Type\\nDetermine how state tracking is performed.\\nState Field\\nDetermine which table column to use for state tracking.\\nState\\xa0Field Conversion\\nThe SQL\\xa0statement required to convert the state column (if applicable).\\nGet\\xa0UTC\\xa0Date Statement\\nThe SQL\\xa0statement that returns the current system time in\\xa0UTC for use in date normalization.\\nEnter the appropriate information in the UDLA Settings tab (Universal Database Log Adapter). For more information, see\\nConfigure UDLA Log Collection\\n.\\nProperty, Description\\nUDLA Settings Tab\\nODBC / OLE DB, Select theODBCorOLEDB connection type.\\nConnection String, The connection\\xa0string for the UDLA\\xa0Log Message Source.\\nQuery Statement, The SQL\\xa0select statement that returns the fields comprising the log entry. The select statement must contain a state field\\xa0and unique identifier fields.\\nOutput Format, Determine how to format the returned rows as text.\\nUnique Identifier Field, Determine how an absolute unique record identifier is defined. This value is used for state tracking. Can be a list of comma separated fields.\\nMessage Date Field, Determine which field is used for determining log message date. The value parsed from this field is stored in Msg.MsgDate. This value is also normalized and stored in Msg.NormalMsgDate.\\nState Field Type, Determine how state tracking is performed.\\nState Field, Determine which table column to use for state tracking.\\nState\\xa0Field Conversion, The SQL\\xa0statement required to convert the state column (if applicable).\\nGet\\xa0UTC\\xa0Date Statement, The SQL\\xa0statement that returns the current system time in\\xa0UTC for use in date normalization.\\nIn the Additional Info tab, enter any additional notes or information.\\nProperty\\nDescription\\nAdditional Info Tab\\nAdditional Details\\nA text field to add descriptive information about the log source.\\nEvent Log Filter (XML query)\\nA text field to add an XML query.\\nFor information on creating and testing an XML query, see the Microsoft Tech Community post on\\nAdvanced XML filtering in the Windows Event Viewer\\n.\\nThe Event Log Filter text field is only enabled for the Vista Event Log type. All MS Windows Event Logging log sources are included in the Vista Event Log type.\\nIn the Additional Info tab, enter any additional notes or information.\\nProperty, Description\\nAdditional Info Tab\\nAdditional Details, A text field to add descriptive information about the log source.\\nEvent Log Filter (XML query), A text field to add an XML query.For information on creating and testing an XML query, see the Microsoft Tech Community post onAdvanced XML filtering in the Windows Event Viewer.The Event Log Filter text field is only enabled for the Vista Event Log type. All MS Windows Event Logging log sources are included in the Vista Event Log type.\\nA text field to add an XML query.\\nThe Event Log Filter text field is only enabled for the Vista Event Log type. All MS Windows Event Logging log sources are included in the Vista Event Log type.\\nClick\\nOK\\n.\\nClick\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n/\\nWork With Log Sources\\n', 'Configure Log Sources Automatically': '\\nAutomatic Log Source Configuration leverages the existing SNMP management infrastructure to specifically identify devices on the network. This functionality includes identification for the following virtual sources:\\nSyslog (TCP/UDP)\\nCisco NetFlow\\nIPFIX\\nJuniper J-Flow\\nsFlow\\nSNMP Traps\\nLogRhythm has many devices identified. However, if you have a device that was not automatically configured or you don’t see a device you would like configured in the Advanced Criteria Manager; you can send this information to\\nLogRhythm Support\\nto be added to LogRhythm’s list of devices.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nLog Sources\\n/\\nWork With Log Sources\\n', 'Modify a Single Log Source': 'Only Global Admins or Restricted Admins with elevated View and Manage privileges can take this action.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nLog Sources\\ntab.\\nIn the lower grid, double-click the Log Source you want to modify.\\nThe Log Message Source Properties dialog box appears.\\nIn the lower grid, double-click the Log Source you want to modify.\\nThe Log Message Source Properties dialog box appears.\\nModify the Log Source.\\nFor more information about the basic properties, see the tables in\\nAdd a Single Log Source\\n.\\nFor advanced properties, click the\\nAdvanced\\nbutton at the lower-left corner of the Message Source Properties window.\\nProperty\\nRange\\nDefault\\nDescription\\nCollectionThreadTimeout\\n0 - 600\\n120\\nThe maximum time to wait (in seconds) before timing out the collection thread. (0=no timeout).\\nMaxMessageCount\\n1-50000\\n100\\nThe maximum number of log messages to send at a time.\\nMonitorStart\\nThe time of the day to start collection from this source (HH:MM).\\nThis is the local time of the machine where the Agent is running. If you do not enter a MonitorStart value, a start time of 00:00 (midnight) is automatically inserted.\\nMonitorStop\\nThe time of the day to stop collection from this source (HH:MM).\\nThis is the local time of the machine where the Agent is running. If you do not enter a MonitorStop value, a stop time of 00:00 (midnight) is automatically inserted.\\nPersistentConnection\\nOn/Off\\nOff\\nSpecifies using a connection per session versus opening a new connection for each request.\\nThis option is intended for the ODBC and OLEDB connections, specifically Oracle. After it is set to true, only one connection to the DB exists, instead of creating a new connection for each call. This property limits the number of ODBC and OLEDB connections.\\nFor more information about the basic properties, see the tables in\\nAdd a Single Log Source\\n.\\nFor advanced properties, click the\\nAdvanced\\nbutton at the lower-left corner of the Message Source Properties window.\\nProperty\\nRange\\nDefault\\nDescription\\nCollectionThreadTimeout\\n0 - 600\\n120\\nThe maximum time to wait (in seconds) before timing out the collection thread. (0=no timeout).\\nMaxMessageCount\\n1-50000\\n100\\nThe maximum number of log messages to send at a time.\\nMonitorStart\\nThe time of the day to start collection from this source (HH:MM).\\nThis is the local time of the machine where the Agent is running. If you do not enter a MonitorStart value, a start time of 00:00 (midnight) is automatically inserted.\\nMonitorStop\\nThe time of the day to stop collection from this source (HH:MM).\\nThis is the local time of the machine where the Agent is running. If you do not enter a MonitorStop value, a stop time of 00:00 (midnight) is automatically inserted.\\nPersistentConnection\\nOn/Off\\nOff\\nSpecifies using a connection per session versus opening a new connection for each request.\\nThis option is intended for the ODBC and OLEDB connections, specifically Oracle. After it is set to true, only one connection to the DB exists, instead of creating a new connection for each call. This property limits the number of ODBC and OLEDB connections.\\nFor advanced properties, click the\\nAdvanced\\nbutton at the lower-left corner of the Message Source Properties window.\\nProperty, Range, Default, Description\\nCollectionThreadTimeout, 0 - 600, 120, The maximum time to wait (in seconds) before timing out the collection thread. (0=no timeout).\\nMaxMessageCount, 1-50000, 100, The maximum number of log messages to send at a time.\\nMonitorStart, , , The time of the day to start collection from this source (HH:MM).This is the local time of the machine where the Agent is running. If you do not enter a MonitorStart value, a start time of 00:00 (midnight) is automatically inserted.\\nMonitorStop, , , The time of the day to stop collection from this source (HH:MM).This is the local time of the machine where the Agent is running. If you do not enter a MonitorStop value, a stop time of 00:00 (midnight) is automatically inserted.\\nPersistentConnection, On/Off, Off, Specifies using a connection per session versus opening a new connection for each request.This option is intended for the ODBC and OLEDB connections, specifically Oracle. After it is set to true, only one connection to the DB exists, instead of creating a new connection for each call. This property limits the number of ODBC and OLEDB connections.\\nMaxMessageCount\\nThe maximum number of log messages to send at a time.\\nThe time of the day to start collection from this source (HH:MM).\\nThis is the local time of the machine where the Agent is running. If you do not enter a MonitorStart value, a start time of 00:00 (midnight) is automatically inserted.\\nSpecifies using a connection per session versus opening a new connection for each request.\\nThis option is intended for the ODBC and OLEDB connections, specifically Oracle. After it is set to true, only one connection to the DB exists, instead of creating a new connection for each call. This property limits the number of ODBC and OLEDB connections.\\nWhen you are finished, click\\nOK\\nto save your changes and close the dialog box.\\nWhen you are finished, click\\nOK\\nto save your changes and close the dialog box.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nPeople and Users\\n', 'User Profile Manager': 'User Profiles enable an administrator to group access permissions for hosts and Log Sources so they can be assigned to more than one user at a time.\\n', 'Default User Profiles': 'The LogRhythm Global Administrator and LogRhythm Global Analyst are default system user profiles. They are automatically created by and enabled. These user profiles have access to the following:\\nEntities\\nLog Sources\\nData Processors\\nGlobal AI Engine Events that Span Entities\\nSecondLook\\nSecurity Roles\\nNew profiles can be created for the Global Administrator, Global Analyst, Restricted Administrator, Restricted Analyst, and SOAP API Service Administrator security roles. The security roles enable the administrator to assign access to specific objects within the Entity to individual users. For example, a number of Restricted Analysts can be given access to Entity A, but not access to the same Log Sources within Entity A. Restricted Analyst 1 can have access to Log Sources 1, 2, and 3 on Entity A, while Restricted Analyst 2 has access to Log Sources 4, 5, and 6 on Entity A. Note:\\nWhile users are granted access to CloudAI through the User Profile Properties dialog box in the Client Console, CloudAI data is available only through the Web Console and the CloudAI Interface. To use the CloudAI, you must purchase a license. Granting permission to the CloudAI without a license has no effect on your deployment. Contact your Customer Relationship Manager to learn more and/or to sign up for these services.\\n', 'Global Administrator Security Role': 'The Global Administrator security role is granted access to all Entities, Data Processors, Log Sources, and SmartResponse Plugins. There can only be one Global Administrator security role.\\nThe Global Administrator security role can be granted permission to the following:\\nCase Management\\nCloudAI\\n', 'Global Analyst Security Role': 'The Global Analyst security role is granted access to all Entities, Data Processors, Log Sources, and SmartResponse Plugins.\\nThe Global Analyst security role can be granted permission to the following:\\nCase Management\\nCloudAI\\n', 'Restricted Administrator Security Role': 'The Restricted Administrator is granted access to specific Entities, Log Sources, and Data Processors. This security role can be configured with access to Global AI Engine Events or to a subset of AIE Events based on Entities and Child Entities. This enables large deployments to restrict access and provide filtering when Entity-based data segregation is enabled.\\nThe Restricted Administrator security role has Log Source access rights applied at the following levels:\\nCase Management\\nEntities\\nLog Sources\\nData Processors\\nThe Restricted Administrator security role can be customized and granted permission to anything the Global Administrator security role has access to. Multiple Restricted Administrator profiles can be created, each with access to different administrative functions.\\n', 'Restricted Analyst Security Role': 'The Restricted Analyst is granted access to specific Entities, Log Sources, and Data Processors. This security role can be configured with access to Global AI Engine Events or to a subset of AIE Events based on Entities and Child Entities. This enables large deployments to restrict access and provide filtering when Entity-based data segregation is enabled.\\nA Restricted Analyst can have Log Source access rights applied at the following levels:\\nEntities (and Child Entities)\\nLog Sources\\nData Processors\\nThe Restricted Analyst security role can be granted permission to the following:\\nGlobal AI Engine Events that Span Entities\\nSecondLook\\nLogRhythm API\\nCase Management\\nCloudAI\\nSmartResponse Plugins\\n', 'SOAP API Service Administrator': 'The SOAP API Service Administrator security role is granted access to all Entities, Data Processors, Log Sources, and SmartResponse Plugins.\\nThe SOAP API Service Administrator can be granted permission to the following:\\nCase Management\\nCloudAI\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nPeople and Users\\n/\\nUser Profile Manager\\n', 'Modify User Profile Management Permissions': 'Restricted Administrator security roles can be customized by granting access to many administrative functions this role does not normally have access to.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nUser Profile Manager\\n.\\nThe User Profile Manager window appears and lists the existing User Profiles.\\nClick an existing user profile to select it, and then click\\nProperties.\\nClick the\\nManagement Permissions\\ntab.\\nExpand the fields or use the search field to find the administrative function you want to grant access to.\\nSelect a level of access to grant.\\nView.\\nThe user profile can view the data and configurations but cannot make any changes.\\nManage.\\nThe user profile can view and make changes to the data and configurations.\\nSome permissions are dependent upon each other. For example, you need access to Manage AI Engines and Manage AI Engine Rules before you can access Manage AI Engine Rule Actions. If you grant access to AI Engine Rule Actions, in this example, the others are automatically checked, as shown below.\\nEntities\\nDisplay/Manage Entities\\nAdd, delete, and modify entities in the deployment\\nManage Re-Organization Wizard\\nUse the Entities Re-organization Wizard to migrate host and network records between entities\\nSystem Monitor\\nDisplay/Manage System Monitor Agents\\nManage System Monitor Lite and Pro Agents to collect and forward log data to Data Processors\\nManage Data Loss Defender Policies\\nConfigure a System Monitor agent to monitor and log the connection and disconnection of external data devices to the host computer where the Agent is running\\nManage File Integrity Monitor Policies\\nConfigure a System Monitor agent to monitor critical database and application files for unauthorized changes\\nManage Real Time Integrity Monitor Policies\\nConfigure FIM to use an event-driven model that provides real-time accuracy and enables precise user identification\\nDisplay/Manage System Monitor Configuration Policy Manager\\nUse policy-based management of System Monitor agents to configure how the Data Processor processes logs sent from the Agents\\nManage Agent Upgrade Packages\\nUse the System Monitor Package Manager to schedule automatic updates for multiple System Monitors at one time\\nNetwork Monitor\\nManage Network Monitors\\nAdd, delete, and modify Network Monitors in the deployment\\nLog Sources\\nDisplay/Manage Log Sources\\nCreate, modify, and manage log sources to collect data from hosts\\nWindows Host Wizard\\nManage the Windows Host Wizard to configure LogRhythm to collect Windows Event logs\\nManage Log Source Types\\nCreate, modify, and manage log source types to classify logs that come from common hardware or have the same data format and operate under the same processing rules\\nManage Automatic Log Source Configuration\\nManage the existing SNMP management infrastructure to specifically identify devices on the network\\nManage Log Virtualization Template Policies\\nCreate, modify, and manage templates to consume all the available intelligence within individual log source files that contain multiple records from different sources\\nManage Automatic Log Source Acceptance Rules\\nCreate, modify, and manage rules to automatically resolve log source hosts, identify log source types, and accept log sources through the IP address of a new Log Source or through regular expression pattern matching\\nData Processing\\nManage Data Processors\\nManage the Data Processor to control how logs are sent to the Indexer, the Indexer reads information from the EMDB, and the Client Console and Web Console issue queries about logs to the Indexer\\nManage Log Processing Policies\\nManage how your deployment parses, calculates, and derives information from raw log data and presents it in a way that makes it easier to analyze\\nManage MPE Rules\\nUse the MPE Rule Builder to create rules that identify the pattern of a log and isolate interesting pieces of metadata\\nManage Common Events\\nUse the Common Event Change Manager to make appropriate updates based on user input for common events that have been modified\\nManage Applications\\nUse the Application Manager to define an application and its ports and protocols so that MPE rules can identify a log origin\\nManage Common Event Change Manager\\nControl the migration of the Common Events in your affected objects (system objects with custom filters and custom objects)\\nManage Data Masking Rules\\nCreate, modify, and manage rules to control which log message have their data transformed into a more useable format or masked to hide sensitive or regulated data\\nManage Global Log Processing Policies\\nCreate, modify, and manage policies to apply Data Management settings across all Data Processors, Log Sources and Log Processing Policies to logs that meet your specific criteria\\nManage Data Processor Pool Manager\\nCreate, modify, and manage DP pools.\\nAI Engine\\nManage AI Engines\\nManage how the AI Engine receives logs, applies AI Engine rules, generates events, and provides diagnostic data\\nManage AI Engine Rules\\nCreate, modify, and manage AI Engine rules based off logs, thresholds, unique values, and behaviors\\nManage AI Engine Rule Actions\\nManage the actions that take place after an AI Engine rule fires\\nLists and Filters\\nDisplay/Manage Lists\\nCreate, modify, and view all lists in the deployment\\nManage Composite Filters\\nCreate, modify, and manage composite filters through the Filter Manager under the Administration menu\\nSearch and Report\\nDisplay and Run Investigations\\nAccess all Investigations in the deployment to view logs and events collected in near-real-time from both the Data Processor and Platform Manager Databases\\nDisplay and Run Tails\\nAccess all Tails in the deployment to query for new logs and update your log/event list in real-time\\nManage Report Templates, Reports, and Report Packages\\nModify and run all Report Templates, Reports and Report Packages in the deployment as needed\\nManage Scheduled Jobs for Reports\\nManage recipients, subject lines, report periods, and report schedules in the Scheduled Report Job Manager\\nManage SecondLook\\nCreate and run searches to restore archived logs for the purpose of further review in LogRhythm\\nMonitor and Alarm\\nManage Alarm Rules\\nCreate, modify, and manage alarm rules to control which events incur alarms\\nManage Alarm Rule Actions\\nManage the actions that take place after an Alarm rule fires\\nManage Notifications\\nSpecify the method of Alarm notification, recipients, and information that is included, as well as throttle the number of notifications in an allotted time\\nDisplay Personal Dashboard\\nConfigure Personal Dashboard filters and displays\\nDisplay Personal Alarms\\nAccess Alarms from the Alarm List on the Personal Dashboard\\nManage Global AI Engine Events\\nManage AI Engine events that span different Entities\\nDisplay Alarm Viewer\\nView alarms generated by LogRhythm, track alarm history, and update alarm statuses\\nAutomate and Orchestra\\nManage Smart Response Plug-Ins\\nUse the SmartResponse Plugin Manager to control the execution of preventative actions when threatening activity is observed\\nManage LogRhythm Case Management\\nManage Cases in the Web Console\\nUsers\\nManage People and Users\\nCreate, modify, and manage Person Records so users can log in with personal credentials\\nManage User Profiles\\nCreate, modify, and manage User Profiles to group access permissions for hosts and log sources so they can be assigned to more than one user at a time\\nManage User Preferences\\nManage User Preference settings\\nManage Active Directory\\nSync, manage, and search Active Directory users and groups\\nManage Object Permissions\\nSet new read and write access permissions for an object (investigation, tail, list, or alarm rule) and to assign it to a new owner and/or entity\\nManage Security Manager\\nView a list of logins for the deployment\\nGeneral Administration\\nDeployment Manager\\nAccess the Deployment Manager to configure and manage LogRhythm components and functionality such as alarming and reporting\\nManage Platform Managers\\nUse the Platform Manager to configure properties that affect the\\xa0SQL Server, the LogRhythm Alarming and Response Manager (ARM) service, the LogRhythm Job Manager service, events, configuration and licensing information, the LogRhythm Knowledge Base, and LogMart\\nManage CloudAI Access\\nAccess CloudAI in the Web Console\\nImport and Manage Knowledge Base\\nImport and update Knowledge Base modules, and manage the synchronization settings\\nManage TrueIdentity\\nManage collections of identifiers, such as logins and email addresses, that comprise a single identity\\nLogRhythm API Access\\nAccess the LogRhythm SOAP API, the Admin API, and the Case Management API\\nManage License File Import\\nImport a LogRhythm license file if your evaluation period has expired, you upgrade to a version not supported by your current license, or you purchase add-on components\\nDisplay License Report\\nView the LogRhythm License Report, which shows a list of licenses grouped by type, along with values for the total quantity purchased, the number assigned, and the remaining available. This also includes the License Metering Report, which displays MPS rates and overages for the period\\nDatabase Usage Widget (Web Console)\\nMonitor database levels by showing the percentage of each database that is currently being used\\nComponent Status Widget (Web Console)\\nSee whether all components of your deployment are running without having to load the Client Console\\nProcessing Widget (Web Console)\\nView charts representing the processing rates of any one of the following data sets: Log Rate, AI Engine Rate, Event Rate, Alarm Rate, and AI Engine Event Rate\\nThreat Activity Map Widget (Web Console)\\nView the geographical origin of log data in your deployment, as well as which locations are impacted by log data in your deployment.\\nManage Case Widgets (Web Console)\\nView the following Case Widgets in the Web Console: Case Metrics Trend, Case Trend by Status, and Case Trend by Priority.\\nManage All Cases (Web Console)\\nView all cases in the Web Console, even when you are not a case owner or case collaborator.\\nView.\\nThe user profile can view the data and configurations but cannot make any changes.\\nManage.\\nThe user profile can view and make changes to the data and configurations.\\nSome permissions are dependent upon each other. For example, you need access to Manage AI Engines and Manage AI Engine Rules before you can access Manage AI Engine Rule Actions. If you grant access to AI Engine Rule Actions, in this example, the others are automatically checked, as shown below.\\nManage.\\nThe user profile can view and make changes to the data and configurations.\\nSome permissions are dependent upon each other. For example, you need access to Manage AI Engines and Manage AI Engine Rules before you can access Manage AI Engine Rule Actions. If you grant access to AI Engine Rule Actions, in this example, the others are automatically checked, as shown below.\\nEntities\\nDisplay/Manage Entities, Add, delete, and modify entities in the deployment\\nManage Re-Organization Wizard, Use the Entities Re-organization Wizard to migrate host and network records between entities\\nSystem Monitor\\nDisplay/Manage System Monitor Agents, Manage System Monitor Lite and Pro Agents to collect and forward log data to Data Processors\\nManage Data Loss Defender Policies, Configure a System Monitor agent to monitor and log the connection and disconnection of external data devices to the host computer where the Agent is running\\nManage File Integrity Monitor Policies, Configure a System Monitor agent to monitor critical database and application files for unauthorized changes\\nManage Real Time Integrity Monitor Policies, Configure FIM to use an event-driven model that provides real-time accuracy and enables precise user identification\\nDisplay/Manage System Monitor Configuration Policy Manager, Use policy-based management of System Monitor agents to configure how the Data Processor processes logs sent from the Agents\\nManage Agent Upgrade Packages, Use the System Monitor Package Manager to schedule automatic updates for multiple System Monitors at one time\\nNetwork Monitor\\nManage Network Monitors, Add, delete, and modify Network Monitors in the deployment\\nLog Sources\\nDisplay/Manage Log Sources, Create, modify, and manage log sources to collect data from hosts\\nWindows Host Wizard, Manage the Windows Host Wizard to configure LogRhythm to collect Windows Event logs\\nManage Log Source Types, Create, modify, and manage log source types to classify logs that come from common hardware or have the same data format and operate under the same processing rules\\nManage Automatic Log Source Configuration, Manage the existing SNMP management infrastructure to specifically identify devices on the network\\nManage Log Virtualization Template Policies, Create, modify, and manage templates to consume all the available intelligence within individual log source files that contain multiple records from different sources\\nManage Automatic Log Source Acceptance Rules, Create, modify, and manage rules to automatically resolve log source hosts, identify log source types, and accept log sources through the IP address of a new Log Source or through regular expression pattern matching\\nData Processing\\nManage Data Processors, Manage the Data Processor to control how logs are sent to the Indexer, the Indexer reads information from the EMDB, and the Client Console and Web Console issue queries about logs to the Indexer\\nManage Log Processing Policies, Manage how your deployment parses, calculates, and derives information from raw log data and presents it in a way that makes it easier to analyze\\nManage MPE Rules, Use the MPE Rule Builder to create rules that identify the pattern of a log and isolate interesting pieces of metadata\\nManage Common Events, Use the Common Event Change Manager to make appropriate updates based on user input for common events that have been modified\\nManage Applications, Use the Application Manager to define an application and its ports and protocols so that MPE rules can identify a log origin\\nManage Common Event Change Manager, Control the migration of the Common Events in your affected objects (system objects with custom filters and custom objects)\\nManage Data Masking Rules, Create, modify, and manage rules to control which log message have their data transformed into a more useable format or masked to hide sensitive or regulated data\\nManage Global Log Processing Policies, Create, modify, and manage policies to apply Data Management settings across all Data Processors, Log Sources and Log Processing Policies to logs that meet your specific criteria\\nManage Data Processor Pool Manager, Create, modify, and manage DP pools.\\nAI Engine\\nManage AI Engines, Manage how the AI Engine receives logs, applies AI Engine rules, generates events, and provides diagnostic data\\nManage AI Engine Rules, Create, modify, and manage AI Engine rules based off logs, thresholds, unique values, and behaviors\\nManage AI Engine Rule Actions, Manage the actions that take place after an AI Engine rule fires\\nLists and Filters\\nDisplay/Manage Lists, Create, modify, and view all lists in the deployment\\nManage Composite Filters, Create, modify, and manage composite filters through the Filter Manager under the Administration menu\\nSearch and Report\\nDisplay and Run Investigations, Access all Investigations in the deployment to view logs and events collected in near-real-time from both the Data Processor and Platform Manager Databases\\nDisplay and Run Tails, Access all Tails in the deployment to query for new logs and update your log/event list in real-time\\nManage Report Templates, Reports, and Report Packages, Modify and run all Report Templates, Reports and Report Packages in the deployment as needed\\nManage Scheduled Jobs for Reports, Manage recipients, subject lines, report periods, and report schedules in the Scheduled Report Job Manager\\nManage SecondLook, Create and run searches to restore archived logs for the purpose of further review in LogRhythm\\nMonitor and Alarm\\nManage Alarm Rules, Create, modify, and manage alarm rules to control which events incur alarms\\nManage Alarm Rule Actions, Manage the actions that take place after an Alarm rule fires\\nManage Notifications, Specify the method of Alarm notification, recipients, and information that is included, as well as throttle the number of notifications in an allotted time\\nDisplay Personal Dashboard, Configure Personal Dashboard filters and displays\\nDisplay Personal Alarms, Access Alarms from the Alarm List on the Personal Dashboard\\nManage Global AI Engine Events, Manage AI Engine events that span different Entities\\nDisplay Alarm Viewer, View alarms generated by LogRhythm, track alarm history, and update alarm statuses\\nAutomate and Orchestra\\nManage Smart Response Plug-Ins, Use the SmartResponse Plugin Manager to control the execution of preventative actions when threatening activity is observed\\nManage LogRhythm Case Management, Manage Cases in the Web Console\\nUsers\\nManage People and Users, Create, modify, and manage Person Records so users can log in with personal credentials\\nManage User Profiles, Create, modify, and manage User Profiles to group access permissions for hosts and log sources so they can be assigned to more than one user at a time\\nManage User Preferences, Manage User Preference settings\\nManage Active Directory, Sync, manage, and search Active Directory users and groups\\nManage Object Permissions, Set new read and write access permissions for an object (investigation, tail, list, or alarm rule) and to assign it to a new owner and/or entity\\nManage Security Manager, View a list of logins for the deployment\\nGeneral Administration\\nDeployment Manager, Access the Deployment Manager to configure and manage LogRhythm components and functionality such as alarming and reporting\\nManage Platform Managers, Use the Platform Manager to configure properties that affect the\\xa0SQL Server, the LogRhythm Alarming and Response Manager (ARM) service, the LogRhythm Job Manager service, events, configuration and licensing information, the LogRhythm Knowledge Base, and LogMart\\nManage CloudAI Access, Access CloudAI in the Web Console\\nImport and Manage Knowledge Base, Import and update Knowledge Base modules, and manage the synchronization settings\\nManage TrueIdentity, Manage collections of identifiers, such as logins and email addresses, that comprise a single identity\\nLogRhythm API Access, Access the LogRhythm SOAP API, the Admin API, and the Case Management API\\nManage License File Import, Import a LogRhythm license file if your evaluation period has expired, you upgrade to a version not supported by your current license, or you purchase add-on components\\nDisplay License Report, View the LogRhythm License Report, which shows a list of licenses grouped by type, along with values for the total quantity purchased, the number assigned, and the remaining available. This also includes the License Metering Report, which displays MPS rates and overages for the period\\nDatabase Usage Widget (Web Console), Monitor database levels by showing the percentage of each database that is currently being used\\nComponent Status Widget (Web Console), See whether all components of your deployment are running without having to load the Client Console\\nProcessing Widget (Web Console), View charts representing the processing rates of any one of the following data sets: Log Rate, AI Engine Rate, Event Rate, Alarm Rate, and AI Engine Event Rate\\nThreat Activity Map Widget (Web Console), View the geographical origin of log data in your deployment, as well as which locations are impacted by log data in your deployment.\\nManage Case Widgets (Web Console), View the following Case Widgets in the Web Console: Case Metrics Trend, Case Trend by Status, and Case Trend by Priority.\\nManage All Cases (Web Console), View all cases in the Web Console, even when you are not a case owner or case collaborator.\\nManage Re-Organization Wizard\\nWindows Host Wizard\\nCreate, modify, and manage rules to automatically resolve log source hosts, identify log source types, and accept log sources through the IP address of a new Log Source or through regular expression pattern matching\\nManage the Data Processor to control how logs are sent to the Indexer, the Indexer reads information from the EMDB, and the Client Console and Web Console issue queries about logs to the Indexer\\nManage how your deployment parses, calculates, and derives information from raw log data and presents it in a way that makes it easier to analyze\\nTo return to any of the previous tabs click\\nBack\\n, or click\\nOK\\nto save the profile and close the User Profile Properties dialog box.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nPlatform Manager\\n', 'Alarming, Reporting, and Response Manager Services': 'The Alarming and Reporting Manager (ARM) service is a component of the Platform Manager and is responsible for the processing and delivery of all alerts and alarms. The ARM service runs as a Windows service named LogRhythm Alarming and Manager.\\n', 'SMTP Server Failover': 'The SMTP Server IP Addresses are located in the Platform Manager Properties. They are used to send email notifications. You can specify a primary, secondary, and tertiary server to allow for failover.\\nThree attempts are made to send each email notification to the IP Address(es) specified.\\nIf one SMTP server is specified, that same server is tried 3 times.\\nIf two SMTP servers are specified, the first is tried, then the second, then the first again.\\nIf three SMTP servers are specified, each is tried once.\\nIf an Email From address is not specified, the Alarming and Reporting Engine is disabled.\\nSuccessful or not, a record of all notifications are written to the nfns.log file in the ARM logs folder on the server.\\n', 'State': \"To ensure events aren't processed more than once, the ARM maintains the state in which events have been processed. This information is maintained in a state file located in the state directory where the ARM was installed (...LogRhythm\\\\LogRhythm Alarming and Response Manager\\\\state).\\nThe file is named ARMState.pos. If the state file is removed, the next time the ARM is started, all events are reprocessed.\\n\", 'Logging': 'The ARM logs data to C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Alarming and Response Manager\\\\logs\\\\scarm.log. When initially configuring and installing the ARM, a LogLevel of Info or Verbose provides detailed information on the ARM performance that is useful in ensuring the system is functioning properly. After the ARM is configured and operating properly, we recommend you set the LogLevel to Error or Warning.\\nThe LogLevel can be set from the\\nModify Platform Manager Basic Properties\\ndialog box.\\n', 'McAfee ePO': \"LogRhythm's Alarming and Response Manager (ARM) allows you to customize alarm rules that are triggered by identified events, and then send out alarm notifications via email and SNMP traps. LogRhythm also can forward alarm notifications to McAfee ePolicy Orchestrator (version 3.6, 4.0, 4.5, 5.0, 5.1, or 5.3) where they appear in the Console's Event Log interface. An ePO Administrator or Reviewer can view, filter, sort, and export these events and summarize them in custom charts, tables and ePO dashboards. LogRhythm's ePO notification events are securely transmitted from the LogRhythm Platform Manager server to the ePO server by the McAfee Agent.\\n\", 'LogRhythm Alarm Event Data in the ePolicy Orchestrator Event Log (May Vary by Version)': 'ePO Event Log Column, LogRhythm Alarm Event Data\\nDetecting Program, “LogRhythm”\\nDetected UTC, Alarm Date\\nEvent ID, “200000”\\nThreat Source Host Name, Source Host name\\nThreat Source IPv4 Address, Source IP Address\\nThreat Source Login Name, Login\\nTarget Host Name, Destination Host name\\nTarget IPv4, Destination IP Address\\nTarget Port, Destination Port\\nTarget User Name, Login\\nTarget Process Name, Process\\nTarget File Name, Object\\nNetwork Protocol, Protocol\\nSource URL, URL\\nThreat Category, “ops.detect”\\nThreat Type, “Audit”, “Operations”, “Security” or “Unknown”\\nThreat Name, Triggered Alarm Rule Name\\nThreat Severity, LogRhythm alarm priority, a range of 0 to 100, mapped to one of ePO’s eight Severity levels (Information, Debug, Warning, etc.).LogRhythm alarm priority is partially based on risk values assigned to the host referenced in the triggering events.\\nThreat Handled, LogRhythm always reports the alarm event, but never blocks the reported action\\nDetecting Program\\n“LogRhythm”\\nDetected UTC\\nAlarm Date\\nEvent ID\\n“200000”\\nThreat Source Host Name\\nSource Host name\\nThreat Source IPv4 Address\\nSource IP Address\\nThreat Source Login Name\\nLogin\\nTarget Host Name\\nDestination Host name\\nTarget IPv4\\nDestination IP Address\\nTarget Port\\nDestination Port\\nTarget User Name\\nLogin\\nTarget Process Name\\nProcess\\nTarget File Name\\nObject\\nNetwork Protocol\\nProtocol\\nSource URL\\nURL\\nThreat Category\\n“ops.detect”\\nThreat Type\\n“Audit”, “Operations”, “Security” or “Unknown”\\nThreat Name\\nTriggered Alarm Rule Name\\nThreat Severity\\nLogRhythm alarm priority, a range of 0 to 100, mapped to one of ePO’s eight Severity levels (Information, Debug, Warning, etc.).LogRhythm alarm priority is partially based on risk values assigned to the host referenced in the triggering events.\\nThreat Handled\\nLogRhythm always reports the alarm event, but never blocks the reported action\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nPlatform Manager\\n', 'Global Risk Based Priority': 'The Global Risk Based Priority (RBP) threshold represents the minimum RBP of events that you want to monitor. The 100-point RBP scale provides a relative measure of an event’s risk to help you prioritize analysis and response efforts. By default, all events are stored online and are searchable, even if they are not forwarded to the Platform Manager according to Global RBP.\\nThere are four fields that let you further customize RBP settings:\\nAIE RBP Settings\\n,\\nDefault Destination Risk Level (MPE/AIE)\\n,\\nDefault Source Threat Level (MPE/AIE)\\n, and\\nMPE RBP Settings\\n. These settings work with the Global RBP to customize the priority of logs coming through, and whether they are treated as Events.\\n', 'Risk-Based Priority Definitions': 'Abbreviation, Definition\\nBCR, Base-Class Risk Rating, (Audit: 1, Ops: 2, Security: 3)\\nCR, Classification Risk\\nCRR, Classification Risk Rating\\nCW, Classification Weight (Default is 5, set in Mediator Advanced Properties)\\nDRL, Destination Risk Level (set in Host, Basic Information tab)\\nDW, Destination Weight (Default is 5, Set in Mediator Advanced Properties)\\nER, Event Risk (Risk Rating value set in MPE Policy Rule Editor)\\nERR, Event Risk Rating\\nEW, Event Weight (Default is 5, Set in Mediator Advanced Properties)\\nFA, False Alarm Rating (set in MPE Properties)\\nFW, False Alarm Weight (Default is 5, set in Mediator Advanced Properties)\\nMAX, Max Classification Rating = 27 (9 is the highest SCR * 3 is the highest BCR)\\nRBP, Risk-Based Priority\\nRP, Risk Points\\nSCR, Sub-Class Risk Rating\\nSTL, Source Threat Level (set in Host, Threat Level tab)\\nSW, Source Weight (Default is 5, Set in Mediator Advanced Properties)\\nTAP, Total Available Points: 9 * (CW + EW + SW + DW) = 180 (by default)\\n', 'AIE RBP Calculation': 'To calculate an overall priority for AIE Events, LogRhythm gathers the following information:\\nOrigin Host (Source) Threat Level (STL): can be known, unknown, or default (internal or external)\\nImpacted Host (Destination) Risk Level (DRL): can be known, unknown, or default (internal or external)\\nOrigin Network\\nImpacted Network\\nAIE Rule\\nRisk Rating\\nFalse Positive Probability\\nRisk Rating\\nFalse Positive Probability\\nGlobal Weights for above values\\nInfluencer\\nBalanced\\nRule Risk Rating\\nImpacted Host\\nBalanced\\nRule Risk Rating\\nImpacted Host\\n', 'Destination Risk Level (DRL) Calculation (AIE or MPE)': 'If the log was resolved to a Known Impacted Host, the Host Risk Level assigned the Host record is used.\\nDRL = Host Risk Level for Known Impacted Host\\nDRL = Host Risk Level for Known Impacted Host\\nIf an IP was parsed, network resolution is performed. If a Network is found, the Network Risk Level is used.\\nDRL = Risk Level of Resolved Network based on Known Impacted Host IP Address\\nDRL = Risk Level of Resolved Network based on Known Impacted Host IP Address\\nIf a Risk Level cannot be determined via a Known Host or Network\\nDRL = Default Risk Level\\xa0as defined in the Platform Manager, in the Global Risk Based Priority section under Default Destination Risk Level (MPE/AIE)\\nDRL = Default Risk Level\\xa0as defined in the Platform Manager, in the Global Risk Based Priority section under Default Destination Risk Level (MPE/AIE)\\n', 'Source Threat Level (STL) Calculation (AIE or MPE)': 'If the log was resolved to a Known Origin Host, the value assigned the Host record for Threat Level is used.\\nSTL = Threat Level for Known Origin Host\\nSTL = Threat Level for Known Origin Host\\nIf an IP was parsed, network resolution is performed. If a Network is found, the Network Risk Level is used.\\nSTL = Risk Level of Resolved Network based on Known Origin Host IP Address\\nSTL = Risk Level of Resolved Network based on Known Origin Host IP Address\\nIf a Risk Rating cannot be determined via a Known Host or Network\\nSTL = Default Threat Level\\xa0as defined in the Platform Manager, in the Global Risk Based Priority section under Default Source Threat Level (MPE/AIE)\\nSTL = Default Threat Level\\xa0as defined in the Platform Manager, in the Global Risk Based Priority section under Default Source Threat Level (MPE/AIE)\\n', 'MPE RBP Calculation': 'To calculate an overall priority for MPE Events, LogRhythm gathers the following information:\\nOrigin Host (Source) Threat Level (STL): can be known, unknown, or default (internal or external)\\nImpacted Host (Destination) Risk Level (DRL): can be known, unknown, or default (internal or external)\\nOrigin Network\\nImpacted Network\\nMessage Classification\\nCommon Event\\nGlobal Weights for the above values\\n', 'Additional Factors': 'In addition to factors from the log message and MPE/AIE Rules, global RBP settings are also applied. Each factor in the list has a weight value, and there are three different settings for the AIE RBP calculation:\\nRule Risk Rating influence\\nImpacted Host influence\\nBalanced—a blend of the first two settings\\nFinally, there are global (internal and external) defaults for the Origin Host and Impacted Host threat and risk levels, as well as fallback methods for setting risk and threat levels. If there is no level set on the host, then risk falls back to the network level. If there is no network level, then risk falls back to the global defaults—internal or external, based on the host address.\\n', 'Risk-Based Priority Host Levels': 'DRL\\n. Host Risk Level represents the amount of risk developed if the system were to become compromised or the subject of some other issue. A value of 0 means no risk is involved in the loss of this system; a value of 9 means the most risk will be incurred if an issue arises. This is relevant when this host is the impacted system, target, or is acted upon by external forces.\\nSTL\\n. The Host Threat Level designates the amount of threat that is developed if the system were to be the origin of actions. A value of 0 means that actions originating from this host are of little cause for alarm or are possibly commonplace, and a value of 9 means that this system should not be the source of outgoing actions and that there is the greatest threat to security if such events are observed.\\n', 'Risk-Based Priority Network Levels': 'DRL\\n.\\nNetwork Risk Level represents the amount of risk developed if the network were to become compromised or the subject of some other issue. A value of 0 means no risk is involved in the loss of this network, a value of 9 means the most risk is incurred if an issue arises. This is relevant when this network is the impacted network, target, or is acted upon by external forces.\\nSTL\\n. The Network Threat Level designates the degree of threat when the network is the origin of actions. A value of 0 means that actions originating from this network are of little cause for alarm or are possibly commonplace. A value of 9 means that this network should not be the source of outgoing actions and that there is the greatest threat to security if such events are observed.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nPlatform Manager\\n', 'Job Manager Services': '\\nThe LogRhythm Job Manager is a Windows service that is a component of the Platform Manager. The following are the main responsibilities\\xa0of the Job Manager:\\n', 'Active Directory Synchronization': 'Administrators may opt to configure LogRhythm to synchronize user and group information from AD for the purposes of data contextualization and correlation tasks.\\nAD Synchronization\\ncan be performed through a regularly scheduled synchronization process via the Job Manager or as a manual process using the AD Synchronization Tool. The Job Manager service performs scheduled AD Synchronization with these conditions:\\nSynchronization starts five minutes after the Job Manager service starts.\\nSynchronization occurs every hour if the Job Manager service is running.\\nThe Job Manager attempts to synchronize three times after experiencing an error before waiting for the next scheduled synchronization.\\nThe service the Job Manager runs under must have the permissions required to query AD to avoid permission related errors.\\nOnly domains that have Include in Sync selected are synchronized.\\nAlong with Active Directory Synchronization, Job Manager also performs Active Directory group-based authorization synchronization.\\n', 'Knowledge Base Synchronization': 'The LogRhythm Knowledge Base is a package containing many of the system default settings for MPE\\xa0Rules, Message Source Types, Platforms, Log Processing Policies, System AIE Rules, System Alarm Rules, Report Templates, and Compliance Packages. Knowledge Base Synchronization is scheduled in the KB Manager in the Client Console. If the Job Manager is running, the service will try to update and\\nsynchronize the Knowledge Base\\nat scheduled time.\\n', 'Automatic Report Generation': 'Reports are created and managed from Client Console. Reports are scheduled in form of Report Packages, which are collections of reports. When\\nreports are scheduled from Client Console\\n, the Job Manager executes that scheduled job by creating, exporting, notifying parties, and delivering the reports.\\n', 'Automatic List Imports': 'The Job Manager List Import task runs continuously, polling at frequent intervals for list file changes. If a file with the correct name appears,\\nthe task imports the list\\n. After a file has been successfully imported, it is deleted. If an error occurs during import, it is renamed with a suffix of .bad. The status of each list import attempt is written to the log file and event log.\\nThe following default rules apply:\\nThe default import directory is config\\\\list_import (relative to the Job Manager install folder).\\nThe default processing interval is 60 seconds.\\nThe defaults cannot be changed.\\n', 'Automatic List Expiration': 'The Job Manager makes database calls for\\nlist items that are configured to expire\\nand marks them as expired at the appropriate time.\\n', 'Heartbeat Monitoring': \"The Job Manager\\nmonitors the heartbeat\\nof Mediators, System Monitor Agents, Log Sources, the AIE Communication Manager, the AIE Engine, and Network Montors. The Job Manager interacts with each component's state file and database information to get the component's heartbeat information.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nPlatform Manager\\n', 'System Management Settings': '', 'Global Data Management Settings': \"Administrators can enable global options that override settings at the Data Processor, Log Source, and MPE Policy levels. Global settings are applicable in both Classification Based and Standard Data Management configurations.\\nData Management profiles simplify configuration based on the deployment's data management model. Data Management settings have been pre-packaged into configurations which support various deployment models and uses of the product.\\nCollection Optimized\\nSearch Optimized\\nPerformance Optimized\\nCustom\\nYou have the option to manage these settings at a more granular level.\\nGlobal Data Management Settings are:\\na simpler way to configure and understand how LogRhythm manages log data.\\na global mechanism for configuring data management that does not require you to manage key settings in numerous places.\\na straightforward way to implement global data management overrides and event forwarding.\\npowerful enough to enable data management configuration at the Data Processor, Log Source, and MPE Policy levels for advanced users.\\n\", 'Intelligent Indexing': 'In many deployments, it is not feasible to keep all log data indexed or online. The system must be tuned so only a subset of data is indexed in your Data Processor(s) while ensuring the right data is indexed. Intelligent Indexing automates and simplifies tuning where LogRhythm automatically indexes the data known to be needed versus requiring manual and complex tuning.\\nThe following items have their log data indexed (i.e. brought online) into the applicable data source (Data Processor and/or LogMart):\\nReports\\nReport Packages\\nTails\\nInvestigations\\nThe Global Log Processing Rules supersede Intelligent Indexing settings and can be used to take specific data offline.\\nThe following performance counters monitor Intelligent Indexing:\\nIntelligent Indexing Data Processor % Indexed\\n. The percentage of logs processed against Data Processor Intelligent Indexing rules which matched a rule.\\nIntelligent Indexing LogMart % Indexed\\n. The percentage of logs processed against LogMart Intelligent Indexing rules which matched a rule.\\nIntelligent Indexing Processing Rate\\n. Intelligent Indexing Processing Rate\\n', 'Global System Settings': 'Data Management settings require site-specific modifications for global configuration. Global system settings include Identity Inference, which can help recognize the user responsible for an activity when identity information, such as account or login, is not available in the log message. Using an inference model, the identity associated with logs containing applicable host information, such as IP addresses, can be determined. This feature maintains a mapping of users to hosts based on log activity observed. When this feature is enabled, the Message Processing Engine performs the identify inference.\\n', 'Active Directory Domain Manager': 'The Active Directory Domain Manager window contains a grid to list the domains and subdomains that have been previously added for synchronization. The following table describes the columns in the grid.\\nColumn Name, Description\\nAction, The check box used in conjunction with the Actions context menu\\nDomain Name, The name of the domain.\\nInclude In Sync, The indicator to include in the synchronization\\nInclude in Group Based Authorization, Include the domain in the group-based authorization.\\nUser Name, The user name provided to scan the domain.\\nOrganizational Unit, The organizational unit for the domain. Used for Windows Host Wizard scanning.\\nDescription, The brief description given to the domain via the properties.\\nStatus, The status of the domain, either Active or Retired.\\nDomain ID, The unique identifier for the domain record.\\nThere are two menu items available: New and Properties. The OK, Cancel, and Apply buttons appear at the bottom of the window.\\nThe actions in the following table can be accessed by right-clicking the grid area.\\nContext Menu, Description\\nNew, Create a new domain and open the New Domain Properties Window.\\nAdd Subdomains, Query Active Directory for sub-domains of the active domain configuration and add rows to the grid for each. If the grid already contains active rows for the sub-domains, their details are updated. The Add Subdomains context menu is disabled if the active domain configuration is retired.\\nActions > Activate, Active domains.\\nActions > Retire, Retire domains.\\nView > Retired Domains, Display retired domains.\\nProperties, Open the domain properties window.\\n', 'Active Directory Synchronization': 'LogRhythm provides a regularly scheduled synchronization process to retrieve data from Active Directory and store it in the LogRhythm EMDB. After synchronization, you can access and filter the data using the following tools: Investigations, Tails, Reports, Personal Dashboard, Alarm Rule Criteria, SecondLook restore criteria, and Log Distribution Service (LDS) Policy criteria. You can also view the data from the Active Directory Browsers accessible via the Client Console.\\nLogRhythm administrators are able to manage LogRhythm users in the same manner as Active Directory users. This allows the administrators to put Active Directory users into the LogRhythm system based on their active directory.\\nSynchronization of Active Directory objects follows these rules:\\nAfter a Group or User has been created in the local database, it is never deleted.\\nAll Users must be synced or synchronization fails. Each user is synced independently. If failure occurs, all users synced prior to failure will have been updated in the database.\\nUser Login Values: three login values are stored for each user and represent possible AD login strings:\\n[Username] (i.e., pete). Saved in IDMUser.Login1.\\n[Username]@[FQDN] (i.e.,\\ntest@abcd.something.com\\n). Saved in IDMUser.Login2.\\n[NetBIOS Name]\\\\[Username] (i.e., something\\\\john). Saved in IDMUser.Login3.\\nThis format is only saved for root level domains. It is not saved for sub-domains because sub-domains may have the same NetBIOS name as the parent domain.\\nOnly login 1-3 fields are synchronized, login4 and login5 are not synced. Users can manually input values into these fields and they would be filtered on.\\n[Username] (i.e., pete). Saved in IDMUser.Login1.\\n[Username]@[FQDN] (i.e.,\\ntest@abcd.something.com\\n). Saved in IDMUser.Login2.\\n[NetBIOS Name]\\\\[Username] (i.e., something\\\\john). Saved in IDMUser.Login3.\\nThis format is only saved for root level domains. It is not saved for sub-domains because sub-domains may have the same NetBIOS name as the parent domain.\\nOnly login 1-3 fields are synchronized, login4 and login5 are not synced. Users can manually input values into these fields and they would be filtered on.\\nThis format is only saved for root level domains. It is not saved for sub-domains because sub-domains may have the same NetBIOS name as the parent domain.\\nOnly login 1-3 fields are synchronized, login4 and login5 are not synced. Users can manually input values into these fields and they would be filtered on.\\nAll Groups must be synced or sync fails. Each group is synced independently. If failure occurs, all groups synced prior to failure will have been updated in the database.\\nGroup membership is synced to reflect membership at time of sync. All group members must be successfully updated or no changes are made for that group. Group membership is updated within a transaction. If any failure occurs when updating a single group, no changes for that group are updated in the database. However, groups having membership synced prior to failure will have been updated in the database.\\n', 'Active Directory Permissions and Security': 'Active Directory Synchronization is required for the Windows Host Wizard to identify computers and for the Active Directory Group Authorization in the User Profile to identify users. The following permissions are required for Active Directory Synchronization.\\nPorts must be enabled for the LDAP environment. To determine the ports required for your specific LDAP environment, see\\nActive Directory and Active Directory Domain Services Port Requirements\\n. Most deployments will require TCP and UDP 389.\\nThe service account must have read permissions for the Job Manager.\\nThe service the Job Manager runs under must have the permissions required to query Active Directory to avoid permission-related errors.\\n', 'Synchronization of Domains': 'The domains are synchronized hourly. Domains must exist in the list and at least one must have Include in Sync or Include in Group Based Authorization checked in the appropriate column.\\nSynchronizing updates the LogRhythm deployment with the current users, groups, and group members in Active Directory. All domains where Include In Sync or Include in Group Based Authorization are checked will be synchronized.\\nThe synchronization process does not delete users or groups because they might be referred to by log, event, and alarm records.\\n', 'Scheduled Synchronization': 'The Job Manager service performs scheduled Active Directory Synchronization with these conditions:\\nSynchronization starts five minutes after the Job Manager service starts.\\nSynchronization occurs every hour as long as the Job Manager service is running.\\nThe Job Manager attempts to synchronize three times after experiencing an error before waiting for the next scheduled synchronization.\\nThe service the Job Manager runs under must have the permissions required to query AD to avoid permission related errors.\\nOnly domains that have Include In Sync selected are synchronized.\\n', 'Active Directory Browsers': 'There are two Active Directory browsers, both accessible under Knowledge on the Tools menu. The browsers provide a means to access the existing Active Directory information that has been synchronized and stored in the LogRhythm EMDB. However, users who are limited to Restricted Admin or Restricted Analyst roles do not have access to view Active Directory group or user membership information in these browsers.\\nThe Active Directory User Browser has two grids. The top grid contains all users who have been synchronized as part of the AD Synchronization process that stores the AD information in the LogRhythm EMDB. The lower grid lists the groups to which the user belongs.\\nThe Active Directory Group Browser has three grids. The top grid contains all groups that have been synchronized as part of the AD Synchronization process that stores the AD information in the LogRhythm EMDB. The lower-left grid lists the members of the group. The lower-right grid contains the user information for members of the group.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nPlatform Manager\\n/\\nAlarming, Reporting, and Response Manager Services\\n', 'Modify Platform Manager Advanced Properties': \"Only Global Admins or Restricted Admins with elevated View and Manage privileges can take this action.\\nThe Advanced Platform Manager properties consist of additional properties that are specific to the Alarming and Response Manager (ARM). To set or modify the advanced properties\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nPlatform Manager\\ntab, and then click\\nProperties\\nin the Alarming, Reporting, and Response Manager Services section.\\nThe Platform Manager Properties dialog box appears.\\nIn the lower left corner, click the\\nAdvanced\\nbutton.\\nThe Advanced Properties window appears.\\nIn the lower left corner, click the\\nAdvanced\\nbutton.\\nThe Advanced Properties window appears.\\nConfigure properties as described in the following table.\\nMake changes to the Advanced Properties with extreme care! LogRhythm recommends that the Data Processor Advanced Properties only be modified with the assistance of LogRhythm Support, or by advanced users who have attended LogRhythm training.\\nProperty\\nRange\\nDefault\\nDescription\\nCase API Group\\nCaseAPIPort\\n8501\\nThe port on which the Case API\\xa0service is running.\\nCaseAPIURL\\nhttps://127.0.0.1/\\nThe URL\\xa0to which Case API\\xa0requests should be directed.\\nEngine Group\\nAE_AlarmInsertTimeout\\n1-120\\n5\\nThe amount of time (in seconds) the process that inserts alarms has to complete before timing out.\\nAE_EventAgeLimit\\n1-2880\\n60\\nThe number of minutes old an event is allowed to be for alarming processing. The age is determined by subtracting the event's date minus the most recent event. When the alarming engine starts, the latest event date is set to the most recent event in the system.\\nAE_GetEventsMaxRecords\\n1-10000\\n1000\\nThe maximum number of events the engine should retrieve at a time.\\nAE_GetEventsTimeout\\n1-120\\n30\\nThe amount of time (in seconds) the get events process has to complete before timing out.\\nAE_MaxAlarmQueueSize\\n100-10000\\n1000\\nThe maximum size of the alarm queue. Additional events are not be processed after this size is reached.\\nAE_MaxAssociatedEventsPerAlarm\\n1-1000\\n100\\nThe maximum number of events that will be associated to a single alarm.\\nAlarmURL\\nhttp://localhost/\\n:\\n8443/alarms/\\nThe base web URL\\xa0to be used for the SMTP\\xa0alarm notification email.\\nAutoRmdnPluginDir\\nThe directory where the Engine deploys SmartResponse plugins for execution.\\nMain Group\\nMaxServiceMemory_ARM\\n512-64000\\n2048\\nMaximum memory allowed for the ARM process (in MB).\\nProcessPriority\\nLow-High\\nNormal\\nProcess priority for the ARM process.\\n1)\\xa0Low\\n2)\\xa0Below Normal\\n3)\\xa0Normal\\n4)\\xa0Above Normal\\n5)\\xa0High\\nSMTP\\xa0Group\\nSMTP_BatchEmailInterval\\n1-120\\n60\\nHow often (in seconds) the ARM should check to see if batch emails are ready to be sent.\\nSMTP_MaxAlarmsPerBatchEmail\\n1-1000\\n100\\nThe maximum number of Alarms to include in a single batch email notification.\\nThis system default is overridden by the Maximum Notifications Per Period value in individual Email Notification Policies. For more information, see\\nCreate New Email Alarm Notification Policies\\n.\\nSMTP_MaxLogLength\\n100-1000\\n200\\nThe maximum number of characters to print for log messages included in single or batch email notifications.\\nSMTP_MaxLogsPerBatchEmail\\n1-1000\\n3\\nThe maximum number of log messages to print in the content section of an Alarm within a batch email notification.\\nSMTP_MaxLogsPerEmail\\n1-1000\\n10\\nThe maximum number of log messages to print in the content section of a single email notification.\\nSMTP_MaxQueueSize\\n100-10000\\n1000\\nThe maximum number of email notifications that can be pending transmission before new email notifications are dropped.\\nSNMP\\xa0Group\\nSNMP_MaxQueueSize\\n100-10000\\n1000\\nSpecify the maximum number of SNMP traps that can be queued for sending. New SNMP traps are not processed after queue size is reached.\\nConfigure properties as described in the following table.\\nMake changes to the Advanced Properties with extreme care! LogRhythm recommends that the Data Processor Advanced Properties only be modified with the assistance of LogRhythm Support, or by advanced users who have attended LogRhythm training.\\nProperty, Range, Default, Description\\nCase API Group\\nCaseAPIPort, , 8501, The port on which the Case API\\xa0service is running.\\nCaseAPIURL, , https://127.0.0.1/, The URL\\xa0to which Case API\\xa0requests should be directed.\\nEngine Group\\nAE_AlarmInsertTimeout, 1-120, 5, The amount of time (in seconds) the process that inserts alarms has to complete before timing out.\\nAE_EventAgeLimit, 1-2880, 60, The number of minutes old an event is allowed to be for alarming processing. The age is determined by subtracting the event's date minus the most recent event. When the alarming engine starts, the latest event date is set to the most recent event in the system.\\nAE_GetEventsMaxRecords, 1-10000, 1000, The maximum number of events the engine should retrieve at a time.\\nAE_GetEventsTimeout, 1-120, 30, The amount of time (in seconds) the get events process has to complete before timing out.\\nAE_MaxAlarmQueueSize, 100-10000, 1000, The maximum size of the alarm queue. Additional events are not be processed after this size is reached.\\nAE_MaxAssociatedEventsPerAlarm, 1-1000, 100, The maximum number of events that will be associated to a single alarm.\\nAlarmURL, , http://localhost/:8443/alarms/, The base web URL\\xa0to be used for the SMTP\\xa0alarm notification email.\\nAutoRmdnPluginDir, , , The directory where the Engine deploys SmartResponse plugins for execution.\\nMain Group\\nMaxServiceMemory_ARM, 512-64000, 2048, Maximum memory allowed for the ARM process (in MB).\\nProcessPriority, Low-High, Normal, Process priority for the ARM process.1)\\xa0Low2)\\xa0Below Normal3)\\xa0Normal4)\\xa0Above Normal5)\\xa0High\\nSMTP\\xa0Group\\nSMTP_BatchEmailInterval, 1-120, 60, How often (in seconds) the ARM should check to see if batch emails are ready to be sent.\\nSMTP_MaxAlarmsPerBatchEmail, 1-1000, 100, The maximum number of Alarms to include in a single batch email notification.This system default is overridden by the Maximum Notifications Per Period value in individual Email Notification Policies. For more information, seeCreate New Email Alarm Notification Policies.\\nSMTP_MaxLogLength, 100-1000, 200, The maximum number of characters to print for log messages included in single or batch email notifications.\\nSMTP_MaxLogsPerBatchEmail, 1-1000, 3, The maximum number of log messages to print in the content section of an Alarm within a batch email notification.\\nSMTP_MaxLogsPerEmail, 1-1000, 10, The maximum number of log messages to print in the content section of a single email notification.\\nSMTP_MaxQueueSize, 100-10000, 1000, The maximum number of email notifications that can be pending transmission before new email notifications are dropped.\\nSNMP\\xa0Group\\nSNMP_MaxQueueSize, 100-10000, 1000, Specify the maximum number of SNMP traps that can be queued for sending. New SNMP traps are not processed after queue size is reached.\\n512-64000\\nProcess priority for the ARM process.\\n1)\\xa0Low\\n2)\\xa0Below Normal\\n3)\\xa0Normal\\n4)\\xa0Above Normal\\n5)\\xa0High\\nThe maximum number of Alarms to include in a single batch email notification.\\nThis system default is overridden by the Maximum Notifications Per Period value in individual Email Notification Policies. For more information, see\\nCreate New Email Alarm Notification Policies\\n.\\nTo save and return to the ARM Properties window, click\\nOK\\n, or to save your changes and continue working in the active window, click\\nApply\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nPlatform Manager\\n/\\nAlarming, Reporting, and Response Manager Services\\n', 'Modify Platform Manager Basic Properties': 'Only Global Admins or Restricted Admins with elevated View and Manage privileges can take this action.\\nTo modify the Alarming and Response Manager properties of the Platform Manager\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nPlatform Manager\\ntab, and then click\\nProperties\\nin the Alarming, Reporting, and Response Manager Services section.\\nThe Platform Manager Properties dialog box appears.\\nConfigure properties as described in the following table.\\nProperty\\nDescription\\nHost\\nThe host where the Platform Manager software physically resides.\\nTo select a different host, click the selector icon to the right of the Host box. Select the host, and then click\\nOK\\n.\\nPlatform\\nThe platform for the Platform Manager.\\nTo select a different platform, click the selector icon to the right of the Platform box. Select the platform, and then click\\nOK\\n.\\nGen6 hardware platforms are available in KB versions greater than 7.1.679.0.\\nEnable Alarming Engine\\nClick check box to enable alarm processing.\\nEnable Reporting Engine\\nClick check box to enable reporting.\\nLog Level\\nDetermines the amount of information logged to scarm.log.\\nOFF = No logging performed\\nERROR = Errors and above\\nWARNING = Warning messages and above\\nINFO = Informational messages and above\\nVERBOSE = Verbose messages and above\\nDEBUG = Extremely detailed logs showing all data\\nEmail From Address\\nThe sender address to use for messages coming from LogRhythm. It must be populated for alarming and reporting to remain enabled and function properly.\\nSMTP Servers\\nEnter the IP addresses of the SMTP servers LogRhythm can use for sending emails.\\nOnly enter a User and Password if you have an authentication mechanism configured on the server.\\nUse Windows authentication\\nClick check box to use Windows authentication.\\nUse SSL/TLS\\nClick check box to allow the use of SSL/TLS settings when sending notifications.\\nAdvanced\\nView or edit advanced properties for the Platform Manager. For more information, see\\nModify Platform Manager Advanced Properties\\n.\\nDefaults\\nSet any advanced properties that are updated from the Knowledge Base back to their default values.\\nConfigure properties as described in the following table.\\nProperty, Description\\nHost, The host where the Platform Manager software physically resides.To select a different host, click the selector icon to the right of the Host box. Select the host, and then clickOK.\\nPlatform, The platform for the Platform Manager.To select a different platform, click the selector icon to the right of the Platform box. Select the platform, and then clickOK.Gen6 hardware platforms are available in KB versions greater than 7.1.679.0.\\nEnable Alarming Engine, Click check box to enable alarm processing.\\nEnable Reporting Engine, Click check box to enable reporting.\\nLog Level, Determines the amount of information logged to scarm.log.OFF = No logging performedERROR = Errors and aboveWARNING = Warning messages and aboveINFO = Informational messages and aboveVERBOSE = Verbose messages and aboveDEBUG = Extremely detailed logs showing all data\\nEmail From Address, The sender address to use for messages coming from LogRhythm. It must be populated for alarming and reporting to remain enabled and function properly.\\nSMTP Servers, Enter the IP addresses of the SMTP servers LogRhythm can use for sending emails.Only enter a User and Password if you have an authentication mechanism configured on the server.\\nUse Windows authentication, Click check box to use Windows authentication.\\nUse SSL/TLS, Click check box to allow the use of SSL/TLS settings when sending notifications.\\nAdvanced, View or edit advanced properties for the Platform Manager. For more information, seeModify Platform Manager Advanced Properties.\\nDefaults, Set any advanced properties that are updated from the Knowledge Base back to their default values.\\nThe host where the Platform Manager software physically resides.\\nTo select a different host, click the selector icon to the right of the Host box. Select the host, and then click\\nOK\\n.\\nThe platform for the Platform Manager.\\nTo select a different platform, click the selector icon to the right of the Platform box. Select the platform, and then click\\nOK\\n.\\n\\nGen6 hardware platforms are available in KB versions greater than 7.1.679.0.\\nDetermines the amount of information logged to scarm.log.\\nOFF = No logging performed\\nERROR = Errors and above\\nWARNING = Warning messages and above\\nINFO = Informational messages and above\\nVERBOSE = Verbose messages and above\\nDEBUG = Extremely detailed logs showing all data\\nEnter the IP addresses of the SMTP servers LogRhythm can use for sending emails.\\nOnly enter a User and Password if you have an authentication mechanism configured on the server.\\nClick\\nOK\\nwhen you are finished.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nPlatform Manager\\n/\\nGlobal Risk Based Priority\\n', 'Modify AIE Risk Based Priority Settings': \"The AIE RBP Settings section of the Platform Manager tab allows you to set the AI Engine RBP value calculation's main influence and the False Alarm Probability. While editing the AIE RBP settings, ensure that you do not change the MPE RBP Settings box, as this unintentionally alters your MPE settings.\\nTo modify the AIE RBP settings:\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nPlatform Manager\\ntab.\\nModify the following settings\\nRBP settings\\n. Select one of the following:\\nRisk Rating Influence\\n. The calculation is primarily influenced by the AIE rule risk rating.\\nBalanced\\nThe calculation is influenced equally between the two.\\nImpacted Host Influenced\\n. The calculation is primarily influenced by the impacted host risk rating.\\nFalse Alarm Probability\\n. Specify the weight (importance) this factor has in computing the risk based priority (range 0-100):\\n0=Do not factor in calculation\\n1=minimum weight (importance)\\n100=maximum weight (importance)\\nRBP settings\\n. Select one of the following:\\nRisk Rating Influence\\n. The calculation is primarily influenced by the AIE rule risk rating.\\nBalanced\\nThe calculation is influenced equally between the two.\\nImpacted Host Influenced\\n. The calculation is primarily influenced by the impacted host risk rating.\\nRisk Rating Influence\\n. The calculation is primarily influenced by the AIE rule risk rating.\\nBalanced\\nThe calculation is influenced equally between the two.\\nImpacted Host Influenced\\n. The calculation is primarily influenced by the impacted host risk rating.\\nFalse Alarm Probability\\n. Specify the weight (importance) this factor has in computing the risk based priority (range 0-100):\\n0=Do not factor in calculation\\n1=minimum weight (importance)\\n100=maximum weight (importance)\\n0=Do not factor in calculation\\n1=minimum weight (importance)\\n100=maximum weight (importance)\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nPlatform Manager\\n/\\nGlobal Risk Based Priority\\n', 'Modify the Default Destination Risk Level': 'This Default Destination Risk section of the Platform Manager tab allows you to set the Default Destination Risk Level (DRL). You can set the Internal and External risk level, as well as the weight of the risk.\\nTo modify the Default Destination Risk Level settings:\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nPlatform Manager\\ntab.\\nModify the following settings\\nInternal and External Risk Level\\n.\\xa0These values are used for the internal host risk level when entity host lookup does not identify a known host (range 0-9):\\n0=Not set\\n1=minimum weight (importance)\\n9=maximum weight (importance)\\nIf the value in the Internal or External field is set to 0, then the default is used. The default value for the DRL internal field is 3, and the default for the External field is 1.\\nRisk Based Priority Weight\\n.\\xa0Specify the destination risk level used when it cannot be determined via network or host record (range 0-9):\\n0=No risk level (decreases RBP)\\n1=Lowest risk level (decreases RBP)\\n9=Highest risk level (increases RBP)\\nInternal and External Risk Level\\n.\\xa0These values are used for the internal host risk level when entity host lookup does not identify a known host (range 0-9):\\n0=Not set\\n1=minimum weight (importance)\\n9=maximum weight (importance)\\nIf the value in the Internal or External field is set to 0, then the default is used. The default value for the DRL internal field is 3, and the default for the External field is 1.\\n0=Not set\\n1=minimum weight (importance)\\n9=maximum weight (importance)\\nIf the value in the Internal or External field is set to 0, then the default is used. The default value for the DRL internal field is 3, and the default for the External field is 1.\\nRisk Based Priority Weight\\n.\\xa0Specify the destination risk level used when it cannot be determined via network or host record (range 0-9):\\n0=No risk level (decreases RBP)\\n1=Lowest risk level (decreases RBP)\\n9=Highest risk level (increases RBP)\\n0=No risk level (decreases RBP)\\n1=Lowest risk level (decreases RBP)\\n9=Highest risk level (increases RBP)\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nPlatform Manager\\n/\\nGlobal Risk Based Priority\\n', 'Modify the Default Source Threat Level': 'The Default Source Threat Level section of the Platform Manager tab allows you to set the Default Source Threat Level (STL). You can set the Internal and External Risk level, and the weight of the risk.\\nTo modify the Default Source Threat Level settings:\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nPlatform Manager\\ntab.\\nModify the following settings\\nInternal and External Risk Level\\n.\\xa0These values are used for the internal host risk level when entity host lookup does not identify a known host (range 0-9):\\n0=Not set\\n1=minimum weight (importance)\\n9=maximum weight (importance)\\nIf the value in the Internal or External field is set to 0, then the default is used. The default value for the STL internal field is 1, and the default for the External field is 3.\\nRisk Based Priority Weight\\n. This section allows you to set the Default Source Risk Level. Specify the source threat level used when it cannot be determined via network or host record (range 0-9):\\n0=No risk level (decreases RBP)\\n1=Lowest risk level (decreases RBP)\\n9=Highest risk level (increases RBP)\\nInternal and External Risk Level\\n.\\xa0These values are used for the internal host risk level when entity host lookup does not identify a known host (range 0-9):\\n0=Not set\\n1=minimum weight (importance)\\n9=maximum weight (importance)\\nIf the value in the Internal or External field is set to 0, then the default is used. The default value for the STL internal field is 1, and the default for the External field is 3.\\n0=Not set\\n1=minimum weight (importance)\\n9=maximum weight (importance)\\nIf the value in the Internal or External field is set to 0, then the default is used. The default value for the STL internal field is 1, and the default for the External field is 3.\\nRisk Based Priority Weight\\n. This section allows you to set the Default Source Risk Level. Specify the source threat level used when it cannot be determined via network or host record (range 0-9):\\n0=No risk level (decreases RBP)\\n1=Lowest risk level (decreases RBP)\\n9=Highest risk level (increases RBP)\\n0=No risk level (decreases RBP)\\n1=Lowest risk level (decreases RBP)\\n9=Highest risk level (increases RBP)\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nPlatform Manager\\n/\\nGlobal Risk Based Priority\\n', 'Modify the MPE Risk Based Priority Settings': 'The MPE RBP Settings section of the Platform Manager tab allows you to set the Event Risk Rating, and Classification Risk Rating.\\nWhile editing the MPE RBP settings, ensure that you do not change the AIE RBP Settings box, as this unintentionally alters your AIE settings.\\nTo modify the MPE RBP settings:\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nPlatform Manager\\ntab.\\nModify the following settings\\nEvent Risk Rating Weight\\n.\\xa0Specify the weight (importance) this factor has in computing the risk based priority (range 0-100):\\n0=Do not factor in calculation\\n1=minimum weight (importance)\\n100=maximum weight (importance)\\nClassification Risk Rating Weight\\n. Specify the weight (importance) this factor has in computing the risk based priority (range 0-100):\\n0=Do not factor in calculation\\n1=minimum weight (importance)\\n100=maximum weight (importance)\\nEvent Risk Rating Weight\\n.\\xa0Specify the weight (importance) this factor has in computing the risk based priority (range 0-100):\\n0=Do not factor in calculation\\n1=minimum weight (importance)\\n100=maximum weight (importance)\\n0=Do not factor in calculation\\n1=minimum weight (importance)\\n100=maximum weight (importance)\\nClassification Risk Rating Weight\\n. Specify the weight (importance) this factor has in computing the risk based priority (range 0-100):\\n0=Do not factor in calculation\\n1=minimum weight (importance)\\n100=maximum weight (importance)\\n0=Do not factor in calculation\\n1=minimum weight (importance)\\n100=maximum weight (importance)\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nPlatform Manager\\n/\\nSystem Management Settings\\n', 'Active Directory Domain Manager': 'The Active Directory Domain Manager window contains a grid to list the domains and subdomains that have been previously added for synchronization. The following table describes the columns in the grid.\\nColumn Name, Description\\nAction, The check box used in conjunction with the Actions context menu\\nDomain Name, The name of the domain.\\nInclude In Sync, The indicator to include in the synchronization\\nInclude in Group Based Authorization, Include the domain in the group-based authorization.\\nUser Name, The user name provided to scan the domain.\\nOrganizational Unit, The organizational unit for the domain. Used for Windows Host Wizard scanning.The Organizational Unit should be entered in the following format:ABCCompany/computers/servers/OUName\\nDescription, The brief description given to the domain via the properties.\\nStatus, The status of the domain, either Active or Retired.\\nDomain ID, The unique identifier for the domain record.\\nThe organizational unit for the domain. Used for Windows Host Wizard scanning.\\nThe Organizational Unit should be entered in the following format:\\nABCCompany/computers/servers/OUName\\nThere are two menu items available: New and Properties. The OK, Cancel, and Apply buttons appear at the bottom of the window.\\nThe actions in the following table can be accessed by right-clicking the grid area.\\nContext Menu, Description\\nNew, Create a new domain and open the New Domain Properties Window.\\nAdd Subdomains, Query Active Directory for sub-domains of the active domain configuration and add rows to the grid for each. If the grid already contains active rows for the sub-domains, their details are updated. The Add Subdomains context menu is disabled if the active domain configuration is retired.\\nActions > Activate, Active domains.\\nActions > Retire, Retire domains.\\nView > Retired Domains, Display retired domains.\\nProperties, Open the domain properties window.\\n', 'Active Directory Synchronization': 'LogRhythm provides a regularly scheduled synchronization process to retrieve data from Active Directory and store it in the LogRhythm EMDB. After synchronization, you can access and filter the data using the following tools: Investigations, Tails, Reports, Personal Dashboard, Alarm Rule Criteria, SecondLook restore criteria, and Log Distribution Service (LDS) Policy criteria. You can also view the data from the Active Directory Browsers accessible via the Client Console.\\nLogRhythm administrators are able to manage LogRhythm users in the same manner as Active Directory users. This allows the administrators to put Active Directory users into the LogRhythm system based on their active directory.\\nActive Directory Group Based Authorization requires the Platform Manager to be a Domain member to function correctly.\\nSynchronization of Active Directory objects follows these rules:\\nAfter a Group or User has been created in the local database, it is never deleted.\\nAll Users must be synced or synchronization fails. Each user is synced independently. If failure occurs, all users synced prior to failure will have been updated in the database.\\nUser Login Values: three login values are stored for each user and represent possible AD login strings:\\n[Username] (i.e., pete). Saved in IDMUser.Login1.\\n[Username]@[FQDN] (i.e.,\\ntest@abcd.something.com\\n). Saved in IDMUser.Login2.\\n[NetBIOS Name]\\\\[Username] (i.e., something\\\\john). Saved in IDMUser.Login3.\\nThis format is only saved for root level domains. It is not saved for sub-domains because sub-domains may have the same NetBIOS name as the parent domain.\\nOnly login 1-3 fields are synchronized, login4 and login5 are not synced. Users can manually input values into these fields and they would be filtered on.\\n[Username] (i.e., pete). Saved in IDMUser.Login1.\\n[Username]@[FQDN] (i.e.,\\ntest@abcd.something.com\\n). Saved in IDMUser.Login2.\\n[NetBIOS Name]\\\\[Username] (i.e., something\\\\john). Saved in IDMUser.Login3.\\nThis format is only saved for root level domains. It is not saved for sub-domains because sub-domains may have the same NetBIOS name as the parent domain.\\nOnly login 1-3 fields are synchronized, login4 and login5 are not synced. Users can manually input values into these fields and they would be filtered on.\\nThis format is only saved for root level domains. It is not saved for sub-domains because sub-domains may have the same NetBIOS name as the parent domain.\\nOnly login 1-3 fields are synchronized, login4 and login5 are not synced. Users can manually input values into these fields and they would be filtered on.\\nAll Groups must be synced or sync fails. Each group is synced independently. If failure occurs, all groups synced prior to failure will have been updated in the database.\\nGroup membership is synced to reflect membership at time of sync. All group members must be successfully updated or no changes are made for that group. Group membership is updated within a transaction. If any failure occurs when updating a single group, no changes for that group are updated in the database. However, groups having membership synced prior to failure will have been updated in the database.\\n', 'Active Directory Permissions and Security': 'Active Directory Synchronization is required for the Windows Host Wizard to identify computers and for the Active Directory Group Authorization in the User Profile to identify users. The following permissions are required for Active Directory Synchronization.\\nPorts must be enabled for the LDAP environment. To determine the ports required for your specific LDAP environment, see\\nActive Directory and Active Directory Domain Services Port Requirements\\n. Most deployments will require TCP and UDP 389.\\nLDAP and Secure LDAP requires\\xa0a trust relationship with remote domains to validate and synchronize. While\\nTrust over LDAPS (LDAP with SSL) can be established with certs without having to set up an actual trust relationship, this configuration is currently not supported.\\nThe service account must have read permissions for the Job Manager.\\nThe service the Job Manager runs under must have the permissions required to query Active Directory to avoid permission-related errors.\\n', 'Synchronization of Domains': 'The domains are synchronized hourly. Domains must exist in the list and at least one must have Include in Sync or Include in Group Based Authorization checked in the appropriate column.\\nSynchronizing updates the LogRhythm deployment with the current users, groups, and group members in Active Directory. All domains where Include In Sync or Include in Group Based Authorization are checked will be synchronized.\\nThe synchronization process does not delete users or groups because they might be referred to by log, event, and alarm records.\\n', 'Scheduled Synchronization': 'The Job Manager service performs scheduled Active Directory Synchronization with these conditions:\\nSynchronization starts five minutes after the Job Manager service starts.\\nSynchronization occurs every hour as long as the Job Manager service is running.\\nThe Job Manager attempts to synchronize three times after experiencing an error before waiting for the next scheduled synchronization.\\nThe service the Job Manager runs under must have the permissions required to query AD to avoid permission related errors.\\nOnly domains that have Include In Sync selected are synchronized.\\n', 'Active Directory Browsers': 'There are two Active Directory browsers, both accessible under Knowledge on the Tools menu. The browsers provide a means to access the existing Active Directory information that has been synchronized and stored in the LogRhythm EMDB. However, users who are limited to Restricted Admin or Restricted Analyst roles do not have access to view Active Directory group or user membership information in these browsers.\\n', 'Active Directory User Browser': 'The Active Directory User Browser has two grids. The top grid contains all users who have been synchronized as part of the AD Synchronization process that stores the AD information in the LogRhythm EMDB. The lower grid lists the groups to which the user belongs.\\n', 'Active Directory Group Browser': 'The Active Directory Group Browser has three grids. The top grid contains all groups that have been synchronized as part of the AD Synchronization process that stores the AD information in the LogRhythm EMDB. The lower-left grid lists the members of the group. The lower-right grid contains the user information for members of the group.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nPlatform Manager\\n/\\nSystem Management Settings\\n/\\nActive Directory Domain Manager\\n', 'Run Active Directory Browser Investigations': 'If an Active Directory Browser grid has an Action column, you can run an investigation against the login or account.\\nTo run an investigation\\nOn the Tools menu, click\\nKnowledge\\n.\\nClick the\\nActive Directory User Browser\\nor\\nActive Directory Group Browser\\n.\\nConfigure the following values in the Quick Search Toolbar at the bottom of the window.\\nIn the past\\n. Enter the number of minutes, hours, or days to use in pulling the log data\\nInclude\\n. Select the classifications to use as filters for the investigation\\nOptions\\n. Set specific options for:\\nUse Investigator\\n. Defaults to Platform Manager Search, but can change to Data Processor Search if Configure New Investigation is selected.\\nUse Log Miner\\n. Uses LogMart\\nQuery Platform Manager\\nQuery Default Data Processors\\n. Default Data Processor uses the defaults accessible by going to My LogRhythm, and then clicking My Preferences.\\nInvestigation Wizard\\n. Indicate if you want the Investigation Wizard to open prior to running so that you can set additional criteria.\\nIn the past\\n. Enter the number of minutes, hours, or days to use in pulling the log data\\nIn the past\\n. Enter the number of minutes, hours, or days to use in pulling the log data\\nInclude\\n. Select the classifications to use as filters for the investigation\\nInclude\\n. Select the classifications to use as filters for the investigation\\nOptions\\n. Set specific options for:\\nUse Investigator\\n. Defaults to Platform Manager Search, but can change to Data Processor Search if Configure New Investigation is selected.\\nUse Log Miner\\n. Uses LogMart\\nQuery Platform Manager\\nQuery Default Data Processors\\n. Default Data Processor uses the defaults accessible by going to My LogRhythm, and then clicking My Preferences.\\nInvestigation Wizard\\n. Indicate if you want the Investigation Wizard to open prior to running so that you can set additional criteria.\\nOptions\\n. Set specific options for:\\nUse Investigator\\n. Defaults to Platform Manager Search, but can change to Data Processor Search if Configure New Investigation is selected.\\nUse Investigator\\n. Defaults to Platform Manager Search, but can change to Data Processor Search if Configure New Investigation is selected.\\nUse Log Miner\\n. Uses LogMart\\nUse Log Miner\\n. Uses LogMart\\nQuery Platform Manager\\nQuery Platform Manager\\nQuery Default Data Processors\\n. Default Data Processor uses the defaults accessible by going to My LogRhythm, and then clicking My Preferences.\\nInvestigation Wizard\\n. Indicate if you want the Investigation Wizard to open prior to running so that you can set additional criteria.\\nSelect the\\nAction\\ncheck box for the records you want.\\nRight-click the grid.\\nClick\\nAction\\n, and then click the Investigation you want.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nSmartResponse\\n', 'Develop SmartResponse Plugins': \"\\nCreating a SmartResponse plugin is an advanced procedure. You must be familiar with XML and with writing executable scripts. For help creating a SmartResponse plugin, please contact your Customer Relationship Manager (CRM) or Professional Services Engineer.\\nLogRhythm’s SmartResponse® Plugin (SRP) framework delivers an extensible mechanism for responding to security and operational incidents. An analyst can execute SmartResponse Plugins manually, or the SIEM can execute them automatically based on a particular alarm. Depending on configuration, the action can be executed under the context of the Platform Manager (via the Alarm and Response Manager (ARM) service), or remotely under the context of a specific System Monitor.\\nSmartResponse plugins are used in Security Orchestration Automation and Response (SOAR) in the following distinct ways:\\nContext enrichment\\n. SRPs can be launched directly from the web console in the Analyzer grid. Generally, SRPs used in this fashion are designed to provide additional context on an alarm or log message. The SRP's primary function is to gather some external data that adds additional context to the source object. Typical examples include running an IP address through a reputation service like VirusTotal.\\nRemediation\\n. SRPs were originally designed for remediation of threats. Therefore, there are references to remediation actions throughout the configuration. A SRP focused on remediation has a primary function of completing an action to change the environment. For example, an SRP that integrates with a Firewall vendor might change the Firewall settings as a result of an alarm from a threat feed, or in response to a ransomware attack.\\nBoth types of SmartResponse Plugins follow the same development and packaging process. The only difference is that a context SRP will typically write out information to standard out, whereas a remediation plugin may not write out any messages at all.\\nThis guide is divided into the following sections to help you learn how to develop and deploy custom SmartResponse Plugins:\\nCreate\\nthe Payload\\nCreate the Configuration File\\nPackage and Test the SmartResponse\\nDeploy Custom SmartResponse Plugins\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nSmartResponse\\n', 'Import SmartResponse Plugins': '\\nOnly Global Admins or Restricted Admins with elevated View and Manage privileges can take this action.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nSmartResponse Plugin Manager\\n.\\nOn the Actions menu, click\\nImport\\n.\\nBrowse to the location where the plugin is stored and select the appropriate .lpi file.\\nFor some plugins, the End User License Agreement appears prior to importing the plugin. You must accept the license terms and click\\nOK\\nto continue.\\nThe plugin is listed in the grid, and the plugin actions are available in AI Engine Rules and Alarm Rules.\\nYou can download SmartResponse plugins by going to the\\nLogRhythm Community\\nand clicking on the\\nShareables\\nlink on menu at the top of the page. The filters allow you to choose from supported and unsupported plugins, as well as ones created by LogRhythm or by other users.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nSmartResponse\\n/\\nDevelop SmartResponse Plugins\\n', 'Create the Configuration File': '\\n\\nContent Formatting Macros for Confluence\\ncannot be exported to this format.\\nContent Formatting Macros for Confluence\\ncannot be exported to this format.\\n\\nBased on the payload, you next create a SmartResponse configuration file called actions.xml.\\xa0This file defines actions taken by the plugin and provides a mechanism for passing arguments to the plugin.\\n', 'The Basic Configuration File': 'The XML wrapper consists of a mandatory header and one or more action blocks. The header names the SmartResponse and assigns it a unique identifier (GUID). Each action section has two basic tasks. First, to define the functions performed by the SmartResponse. Second, to map input fields from the SIEM into command line arguments for the action. A simple version of this file completes the following:\\nDefines a single action.\\nRequires \"-file AddItemToList.ps1\" as the first command line argument.\\nProvides the filename as the second command line argument.\\nProvides the item to add as the third command line argument.\\nThe last two are string values that need to be dynamically set at runtime. Each time you run the SmartResponse, there is a chance you add a different item to a different list.\\nThis full configuration file would appear follows:\\nThe configuration file must be named actions.xml.\\nNote the following items in bold in the sample configuration file above:\\nThe plugin is named Add Item To List.\\nThe plugin contains one action, also called Add Item To List, that calls powershell.exe.\\nThe first command line parameter is always -file AddItemToList.ps1.\\nThe second command line parameter is a filename with no command line switch.\\nThe third command line parameter is the item to add, with no command line switch.\\nThe configuration file must model the expected parameters of the command line prompt execution of the payload. When you start writing the configuration file, refer to how you would expect to execute the response in the command line prompt.\\n', 'A Complex Configuration File': 'In the previous section, we used a simple configuration wrapper with one action and simple parameters. In this section, we cover all of the optional elements in the wrapper and more complex configurations.\\n', 'The XML Header': 'The configuration file is provided as an XML document which starts with an XML header (see the following example) and a schema reference defining the file as a plugin.\\nThe initial tag consists of the following key attributes:\\nThe XML namespace\\n. All of the SmartResponse wrapper syntax is defined in RemediationVersion1.xsd and all tags in the namespace start with \"remv1:.\"\\nName\\n. Every plugin must have a unique Name, as the name field is used to identify the script to the Plugin Manager.\\nGUID\\n. The Guid is an optional tag to uniquely identify the plugin in your SIEM environment. In the XML, you must use the exact capitalization of Guid, not GUID.\\nVersion\\n. The optional Version tag manages multiple versions of the same plugin.\\nIsLogRhythmPlugin\\n. This optional tag is reserved for LogRhythm internal use. You must omit it or set it to false. If you set this attribute to true, you must also supply LogRyhthm’s license and sign the plugin (which cannot be done outside of LogRhythm).\\nHistorically, few plugins have included the Guid, Version and IsLogRhythmPlugin attributes, and the XML can be created without these elements. The console generates a GUID for you if it is not included in the plugin.\\nThe following shows the simplest possible XML header and closing tag. This wrapper has no actions and would be ineffective deployed in this way.\\nIn version 7.2.2 and higher, the SmartResponse Plugin Manager requires the Guid, Version and IsLoGrhythmPlugin attributes in the XML. The minimal XML header is therefore:\\nIf you upload a plugin with a duplicated GUID, you are prompted to replace the existing or create a new one for that plugin. The collision detection makes uploading a standard \"000\" GUID acceptable.\\nIf present in the configuration file, the GUID and version display in the Console and are used as identifiers. If not, the plugin manager automatically generates both fields when the plugin is created.\\n', 'The Action Section': 'A SmartResponse exists to perform actions. The Action section gives us a way to define what action to take, and what parameters to pass into the action from the Alarm.\\nThe Action tag defines a name for the action and a command to execute. The tag may also contain additional xml parameter elements. For example, the following action tag defines an action to open PowerShell:\\nA plugin may define a single action, or it may define multiple actions. Therefore, there may be several Action elements within the configuration file, each representing an individual action related to the overall plugin purpose. For example, an NG Firewall may expose an API that offers multiple actions that may be initiated, and these actions may be delivered in a single SmartResponse Plugin. Placing multiple actions in a single plugin is simply an administrative convenience. Doing so has no effect on the eventual action of the plugin. Each action can exist in a standalone SmartResponse Plugin.\\nThe name field provides a textual description of what the action does, and must be unique within the plugin. There is no requirement for it to be unique within the LogRhythm deployment. The action name may be the same as the plugin name. This is typically the case when a plugin only delivers one action. You can also have several named Actions contained within the plugin.\\nIn the LogRhythm Console, the action displays as <plugin name>:<action name>. Long names may wrap or not display fully. The best practice is to keep the names as short as possible while maintaining descriptive clarity.\\nThe Command attribute provides the fully qualified path and name of the application which executes to complete the action. This Command field can be any executable program that is installed on the Platform Manager or System Monitor. The best practice is to include the fully qualified path of the binary to be executed to avoid deliberate or inadvertent launching of a different binary.\\nIn the case of PowerShell scripts, the command is the script engine \"powershell.exe\" with a fully qualified Windows path.\\nIf the path to the binary cannot be resolved, the plugin fails at run time. The resulting error message in this case is a generic failure message and not indicative that the command or command path is missing or incorrect.\\n', 'Parameters': 'Very few SmartResponse Plugins are stand-alone actions that can be run without any input parameters. In fact, the main purpose of a SmartResponse is to take action based on information present in an alarm. The Action XML tag can contain Parameter tags to pass additional data into the executable defined in the Command attribute.\\nParameters may be defined as one of the following:\\nConstant\\n. Constant parameters are fixed and never change. The most common use case is to pass a script name into PowerShell.\\nString\\n. String parameters can be changed when the system is deployed. Use Input subtags to map string parameters to values in the SIEM alarm. For more information on Input tags, see\\n52795118\\n.\\nEncrypted Parameter.\\nA third type of parameter tag, called EncryptedParameter, is a wrapper tag around a StringParameter. For more information, see\\n52795118\\n.\\nAll parameters share a common set of attributes within the tag:\\nName\\n. The name defines the parameter and is useful for understanding the intended purpose of the parameter.\\nSwitch\\n. If present, the switch is the integral part of a command line parameter when named parameters are used.\\nOrder\\n. The order field is used to indicate the order of the parameters. Order can contain a number indicating the parameter position, or a text value of unsorted parameters.\\nSwitch and Order are used to indicate named or positional parameters. As a best practice, use either named or positional parameters in an action, but not both. Incorrect or blank ordering for the parameters may result in an error when creating a new SRP xml.\\nIf you are using a mix of named parameters and ordered parameters that do not have switches, make sure that the switch field contains a single space.\\nConstant parameters are command-line arguments fixed for the action regardless of how the SmartResponse is initiated.\\nA ConstantParameter always remains the same, and cannot be configured by the user or alarm that triggers the SmartResponse Plugin. These parameters are useful for fixing a command line parameter within the context of a particular action.\\nA good use case for a ConstantParameter occurs when an Action tries to execute a PowerShell script called \"Sample.ps1.\" The full command line for this would be \"powershell.exe –File Sample.ps1.\" As discussed previously, the Action would have Command set to \"C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe.\" A ConstantParameter would be set to the complete value \"-File Sample.ps1\" which indicates the script to run. In this case, we always run this script regardless of any other parameters or configuration to the SmartResponse.\\nIn LogRhythm 7.0 or higher, the SmartResponse Switch attribute for PowerShell scripts must be in the following format: \"-File Sample.ps1\". This is because the PowerShell binary has the ability to directly ingest PowerShell cmdlets as arguments from the command line. This could lead to the SmartResponse being used for remote code execution in limited circumstances. Using the \"-File\" method of specifying the script prevents abuse of PowerShell.\\nString parameters are command-line arguments that may be different each time an Action is executed depending on how the LogRhythm Administrator configures the plugin for a particular alarm. A string parameter’s value can be set at either configuration time (in which case it never changes for that particular configuration) or at run time (in which case it changes every time the response executes).\\nString parameters allow the definition of command line switches or parameters by name using user defined strings instead of a constant that is fixed for the plugin action.\\nThe following example would add a parameter called DisplayName. This value is passed on the command as an argument called \"address:\" as defined in the Switch attribute.\\nThe actual value passed is extracted at runtime as either a static value set by the administrator when configuring the SmartResponse, or as a dynamic value injected from the alarm or event.\\nIt is critical that the Switch attribute contains the complete command line switch including the prefix (most commonly ‘\\\\’ or ‘-‘) and the delimiter (most commonly ‘:’ ‘=’ or a space). Command-line programs vary widely on how well they support variation in the switch prefix and delimiter. The only way to ensure the value provided matches expectations is to require the information in the parameter definition.\\nIn order to execute a remediation action, all string parameters must completely resolve their arguments prior to executing the SmartResponse action. The values are determined at runtime based on how the LogRhythm administrator configures the SmartResponse for the alarm. The value might be a metadata field passed through from the alarm, or a fixed value manually set when the alarm is configured.\\nYou can pre-define default values using Input Value tags. Input tags are optional and only used to simplify the deployment process. For more information, see\\n52795118\\n.\\nEncrypted Parameters modify the behavior of a String Parameter so that the value is stored with additional encryption.\\nAn Encrypted Parameter has no options and simply wraps an existing String Parameter. Encrypted parameters identify another parameter as one whose value contains sensitive information (e.g., a password or community string). When a parameter is identified as encrypted, any input value assigned to that parameter when the SmartResponse is configured for an alarm is encrypted when it is stored in the EMDB.\\nUsing the EncryptedParameter tag forces the executor of the plugin (the Platform Manager or System Monitor) to leverage the LRcrypt tool to encrypt the values passed in the string parameter. LRcrypt leverages Windows libraries for encryption. The default behavior is to use an AES algorithm. The actual algorithm choice depends on how the Windows environment is configured.\\nUse encrypted parameters sparingly since not everything is sensitive. Parameters that use information from an alarm or event do not require encryption because the information is already provided in plain text. Typically items such as passwords and API keys should be encrypted. Additionally, it is recommended that Encrypted Parameters are not provided with a Default Input Value, because that value is stored in the configuration file in plaintext and is contained within the plugin.\\n', 'Input Values': 'A String Parameter can optionally contain sub-tags that define a default value or pre-configure the value to be filled from specific metadata. Input parameters are optional in the configuration file, but reduce the time it takes to deploy and configure a SmartResponse.\\nInput Values can be one of the following types:\\nStatic\\n. Configured by the LogRhythm administrator and does not change on a per-alarm basis.\\nMetadata\\n. Deteremined by the data contained in the alarm or event triggering the SmartResponse. These values change on every execution of the SmartResponse.\\nInput values are optional. Using them in the configuration file reduces the time it takes to deploy and configure a SmartResponse, but makes the configuration file more complicated.\\nBoth Static and Metadata input values must be contained inside a DefaultInput tag:\\nIn this example, a default static value of 127.0.0.1 is passed to the string parameter. A LogRhythm administrator can override this value when configuring the SmartResponse. The value is an initial default setting.\\nStatic Input values are entered by the LogRhythm administrator when the SmartResponse Plugin is configured against a particular alarm rule. Once configured, these values remain the same every time the plugin is called by the specific alarm.\\nUsing a String Parameter with a Static Default Input value is similar to using a Constant Parameter, with one exception. This pattern provides an override mechanism where the administrator can either accept the default or replace it with a new value when registering the response. Default Input values act as built in context-sensitive help or suggestions. An example of this is a SmartResponse that calls a firewall API—the administrator enters the IP address of the firewall as a Static Input value since it would always remain the same within this deployment.\\nMetadata Input values are dynamic values included when the SmartResponse executes. The LogRhythm administrator maps the Metadata Input to a particular alarm field when the SmartResponse Plugin is configured.\\nEach field of the alarm or event has its own tag that can be used to specify the intended metadata field. In the example below, the default value for the StringParameter is populated with the destination IP address of the first action associated with the alarm. For more information and a list of supported Metadata Input values, see Appendix A: Metadata Inputs on page 26.\\nAn example of this would be a SmartResponse that is going to call a Firewall API to block a destination IP address. The administrator might select the destination IP address metadata field from the alarm as the Metadata Input value since the IP address to be blocked varies depending on the event that triggered the alarm.\\nMetadata field names are case sensitive. If you do not use the correct capitalization, you will get errors when you import the SmartResponse.\\nThe following reference table provides information about the fields that are consumable by a SmartResponse plugin and additional guidance on working with date formats in the data fields. Each SmartResponse is triggered by an alarm. Depending on the alarm configuration, different fields are available for use in the SmartResponse.\\n<remv1:BytesIn />\\nField, Alarm or First Event, Example Tag (tags are case sensitive), Format Support\\nAlarmID, Alarm, <remv1:AlarmId />, \\nAlarmDate, Alarm, <remv1:AlarmDate><remv1:TimeFormat TimeZone=\"Eastern Standard Time\" FormattingString=\"MMMM dd, yyyy\" /></remv1:AlarmDate>, Date and Time\\nAlarmRuleName, Alarm, <remv1:AlarmRuleName />, \\nMARCMsgID, First Event, <remv1:MARCMsgId />, \\nDirection, First Event, <remv1:Direction />, \\nNormalMessageDate, First Event, <remv1:NormalMessageDate><remv1:TimeFormat TimeZone=\"Eastern Standard Time\" FormattingString=\"MMMM dd, yyyy\" /></remv1:NormalMessageDate>, Date and Time\\nMsgClass, First Event, <remv1:MessageClass />, \\nCommonEvent, First Event, <remv1:CommonEvent />, \\nMPERule, First Event, <remv1:MPERule />, \\nKnownSHost, First Event, <remv1:KnownSHost />, \\nKnownDHost, First Event, <remv1:KnownDHost />, \\nKnownService, First Event, <remv1:KnownService />, \\nSIP, First Event, <remv1:SIP />, \\nDIP, First Event, <remv1:DIP />, \\nSHostName, First Event, <remv1:SHostName />, \\nDHostName, First Event, <remv1:DHostName />, \\nSPort, First Event, <remv1:SPort />, \\nDPort, First Event, <remv1:DPort />, \\nProtocol, First Event, <remv1:Protocol />, \\nLogin, First Event, <remv1:Login />, \\nAccount, First Event, <remv1:Account />, \\nSender, First Event, <remv1:Sender />, \\nRecipient, First Event, <remv1:Recipient />, \\nSubject, First Event, <remv1:Subject />, \\nObject, First Event, <remv1:Object />, \\nVendorMessageID, First Event, <remv1:VenderMessageId />, \\nBytesIn, First Event, <remv1:BytesIn />\\nBytesOut, First Event, <remv1:BytesOut />, \\nItemsIn, First Event, <remv1:ItemsIn />, \\nItemsOut, First Event, <remv1:ItemsOut />, \\nDuration, First Event, <remv1:Duration />, \\nProcess, First Event, <remv1:Process />, \\nAmount, First Event, <remv1:Amount />, \\nQuantity, First Event, <remv1:Quantity />, \\nRate, First Event, <remv1:Rate />, \\nSize, First Event, <remv1:Size />, \\nDomain, First Event, <remv1:Domain />, \\nGroup, First Event, <remv1:Group />, \\nURL, First Event, <remv1:URL />, \\nSession, First Event, <remv1:Session />, \\nSNetwork, First Event, <remv1:SNetwork />, \\nDNetwork, First Event, <remv1:DNetwork />, \\nSLocationCountry, First Event, <remv1:SLocationCountry />, \\nSLocationRegion, First Event, <remv1:SLocationRegion />, \\nSLocationCity, First Event, <remv1:SLocationCity />, \\nDLocationCountry, First Event, <remv1:DLocationCountry />, \\nDLocationRegion, First Event, <remv1:DLocationRegion />, \\nDLocationCity, First Event, <remv1:DLocationCity />, \\nSEntity, First Event, <remv1:SEntity />, \\nDEntity, First Event, <remv1:DEntity />, \\nSZone, First Event, <remv1:SZone />, \\nDZone, First Event, <remv1:DZone />, \\nProtocol Number, First Event, <remv1:ProtocolNumber />, \\nAlarmID\\nAlarmDate\\n<remv1:AlarmDate>\\n<remv1:TimeFormat TimeZone=\"Eastern Standard Time\" FormattingString=\"MMMM dd, yyyy\" />\\n</remv1:AlarmDate>\\nAlarmRuleName\\nMARCMsgID\\nDirection\\nNormalMessageDate\\n<remv1:NormalMessageDate>\\n<remv1:TimeFormat TimeZone=\"Eastern Standard Time\" FormattingString=\"MMMM dd, yyyy\" />\\n</remv1:NormalMessageDate>\\nMsgClass\\nCommonEvent\\nMPERule\\nKnownSHost\\nKnownDHost\\nKnownService\\nSIP\\nDIP\\nSHostName\\nDHostName\\nSPort\\nDPort\\nProtocol\\nLogin\\nAccount\\nSender\\nRecipient\\nSubject\\nObject\\nVendorMessageID\\nBytesIn\\nBytesOut\\nItemsIn\\nItemsOut\\nDuration\\nProcess\\nAmount\\nQuantity\\nRate\\nSize\\nDomain\\nGroup\\nURL\\nSession\\nSNetwork\\nDNetwork\\nSLocationCountry\\nSLocationRegion\\nSLocationCity\\nDLocationCountry\\nDLocationRegion\\nDLocationCity\\nSEntity\\nDEntity\\nSZone\\nDZone\\nProtocol Number\\n\\nSeveral metadata fields contain date and time stamp values. Use a TimeFormat tag to force these metadata fields to conform to the desired format.\\nThe structure of the TimeFormat tag contains the following attributes:\\nTimeZone.\\nAllows you to configure a specific time zone to convert the date and time output. Inside the configuration the time zone is specified by the Windows ID used for the time zone (this value can be looked up within the Windows Registry under HKEY_LOCAL_MACHINE\\\\Software\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\Time Zone). If no value is provided, the time zone of the machine creating Remediation Actions is used (either the Platform Manager or the System Monitor depending on configuration).\\nFormattingString\\n. Defines the format of the date and time information. This allows you to customize which parts of the date and time are available to the executing program and what structure this information has. Omitting this option causes the date and time to be formatted by the default .NET date/time format. See the following for more information about the default .NET date/time formats:\\nMSDN: Standard DateTime Format Strings\\nMSDN: Custom DateTime Format Strings\\nSince both of these values are optional, there are four permutations TimeFormat can take. However, any field accepting a TimeFormat must have exactly one TimeFormat specified.\\nDefault Values for the output format and time zone:\\n<remv1:TimeFormat />\\nSpecify only the Time Zone, Use the .NET Date Time Format:\\n<remv1:TimeFormat TimeZone=\"Eastern Standard Time\" />\\nSpecify only the Format, Use the Event Manager’s Time Zone:\\n<remv1:TimeFormat FormattingString=\"MMMM dd, yyyy\" />\\nSpecify both the Format and the Time Zone:\\n<remv1:TimeFormat TimeZone=\"Eastern Standard Time\" FormattingString=\"MMMM dd, yyyy\" />\\n<remv1:BytesIn />\\n\\nContent Formatting Macros for Confluence\\ncannot be exported to this format.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nSmartResponse\\n/\\nDevelop SmartResponse Plugins\\n', 'Create the Payload': 'Although a SmartResponse can call any executable program, Windows PowerShell is the most common type of payload. PowerShell offers an incredible range of scriptable capabilities and is installed by default on most systems that have either a LogRhythm Platform Manager or a LogRhythm Windows System Monitor. If your targeted action is not installed by default on the execution system, you will have to install it so that the SmartResponse Plugin can execute.\\nThe PowerShell payload must be designed in a way that it:\\nAccepts command line arguments.\\nPerforms proper error handling.\\nExecutes an action.\\n(Optional)\\nWrites any output to standard out.\\nTo use the SmartResponse as part of a context operation, write any messages to standard out (typically using Write-Host in PowerShell). When the SmartResponse Plugin is executed from the Web Console, the output from standard out maps to a display window so that an analyst can review and act on the information.\\n', 'PowerShell Scripts as a SmartResponse Plugin Payload': 'SmartResponse Plugins can run on the LogRhythm Platform Manager (W2K8R2 or W2K12) or on a v7.0 or higher LogRhythm System Monitor running on Windows XP.\\nWhile administrators can use any executable file for a SmartResponse action, PowerShell is the most commonly used scripting language for SmartResponse. Since Microsoft has included it with all versions of Windows since Windows 2008, and it can be installed on all versions since and including Windows XP, it is one of the most widely available scripting platforms within the Microsoft Windows ecosystem. The minimum supported version of PowerShell is v2. If the plugin requires a newer version then this is included in the documentation accompanying the plugin, or as a validation step in the PowerShell Script itself.\\nPowerShell best practices specific to SmartResponse Plugin scripts are listed below. General guidelines and best practices for PowerShell are beyond the scope of this document.\\n', 'Comments in PowerShell': 'As a best practice, provide useful comments in the PowerShell script. The comments should give a description of what the script is intended to accomplish, note any limitations, and provide explanations of specific logic. LogRhythm recommends specific comments for SmartResponse Plugins that describe which LogRhythm data should be supplied and whether the script runs on the Platform Manager or a System Monitor.\\nThe following is an example of the header comments listing what LogRhythm components can execute the script:\\n', 'Command-Line Parameters': 'PowerShell offers a number of ways for scripts to consume command-line parameters. The most important thing is that the script consumes them in a robust manner, since the plugin containing the PowerShell is run silently by the ARM or System Monitor process. Note that the PowerShell execution policy should be set to All-Signed before executing any SRP.\\nThe following example shows the preferred method for consuming command-line parameters. This provides clear feedback to the LogRhythm or Web Console if an invalid parameter is passed, supports both positional and named parameters, and allows parameters to be mandatory or optional.\\nUsing CmdletBinding() provides Verbose and Debug options. The binding command and parameter definitions must be the first executable lines in the script (including before the exception handling), otherwise the script will not work.\\nIn this example, two parameters are passed to the script. The first is mandatory, and is defined as being in position 1. This parameter may be passed without specifying its name by placing it in position 1 at the command prompt, since the position is defined. Alternatively, the parameter name may be specified. The second parameter is also mandatory, but no positional value is given, so this parameter must be passed as a named parameter at the command prompt.\\nThe SmartResponse Plugin configuration file supports using positional or named parameters. Positional parameters are defined by the Order field, whereas named parameters are defined by the Switch field. A trailing space must be included within the quotations marks:\\nFor clarity, each SmartResponse should use either all positional or all named parameters, and not a combination of the two to avoid confusion.\\n', 'Debugging Scripts': 'Using the CmdLetBinding() approach to parameters provides Verbose and Debug logging methods. Any PowerShell script using CmdLetBinding() may be called using a -verbose or -debug switch. There is no need to provide any parameters or code handling for this switch.\\nIf -verbose is used as a command-line parameter, it activates any Write-Verbose commands in the script. Output is written to the command prompt in yellow text with the prefix of \"VERBOSE:\".\\nIf -debug is used as a command-line parameter, it activates any Write-Debug commands in the script. Output is written to the command prompt in red text with the prefix of \"DEBUG:\".\\nThis has the effect of allowing Write-Debug and Write-Verbose statements to be placed inline in the code for the purposes of debugging or troubleshooting, but those statements will automatically be ignored if the appropriate switch is not specified on the command line.\\nIt is sufficient for most SmartResponse plugins using PowerShell script to implement either Verbose or Debug. It is unnecessary to implement both.\\n', 'Errors and Exceptions': 'PowerShell offers a variety of ways to handle errors and exceptions in scripts. Errors and exceptions may be included at a variety of levels, and the mechanisms provided can be nested so that different exceptions and errors are handled in different ways.\\nWrite-Error and Write-Host are typically used to report errors in the PowerShell script. The SmartResponse framework captures standard and error output and writes it to the agent log. Additionally, the output is sent back to the SmartResponse interface to be displayed in the output field.\\nIt is recommended to include a high-level exception handling routine for the whole script. The following example provides some guidance:\\nThis locates any terminating exceptions and exits the script with an error code.\\nImplement more focused error handling for specific scenarios using the try/catch/finally construct. For example:\\n', 'PowerShell Execution': 'Permission to execute PowerShell scripts is governed by an Execution Policy. The PowerShell ExecutionPolicy setting allows restricting from where and what types of scripts can be executed. By default, Windows only allows interactive shell use.\\nThe following are the possible states of an ExecutionPolicy:\\nRestricted\\nUnrestricted\\nAllSigned\\nRemoteSigned\\nBypass\\nIn addition to the ExecutionPolicy, there are a number of different scopes for the ExecutionPolicy:CurrentUser, Machine or Process. For more information, see\\nAbout Execution Policies\\non Microsoft’s Website.\\nLogRhythm recommends the following for all customers:\\nSet the ExecutionPolicy on hosts that run SmartResponse to AllSigned for the scope of the service account running the SmartResponse.\\nDigitally sign PowerShell Scripts developed for use in SmartResponse with a trusted code signing certificate before the plugin is created for final release.\\nThe ExecutionPolicy may already be defined via GPO or otherwise.\\n', 'Sample PowerShell Script \"AddItemToList.ps1\"': 'The following sample PowerShell script follows the pattern of most SmartResponse payloads. The error handling and argument parsing are standard. Variability between different SmartResponse Plugins comes from what functions are executed after parsing the arguments.\\nThis script has been reduced to the most simplified format for readability, and does not conform to all best practices.\\n\\n\\n\\n\\n\\nTo simplify testing and evaluation of your code, LogRhythm recommends writing one script per action and keeping the function logic as simple as possible. Avoid using switch logic to make a single script perform multiple actions based on an input argument. It is often better to make multiple actions to keep the logic cleaner, and make the code more testable and re-usable.\\nThe sample payload consists of a single action. Execute the payload by typing the following in a command line prompt:\\n\\nContent Formatting Macros for Confluence\\ncannot be exported to this format.\\n\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nSmartResponse\\n/\\nDevelop SmartResponse Plugins\\n', 'Deploy Custom SmartResponse Plugins': '\\n\\nContent Formatting Macros for Confluence\\ncannot be exported to this format.\\nContent Formatting Macros for Confluence\\ncannot be exported to this format.\\n\\n', 'Configure SmartResponse as Part of an Alarm': 'There are many ways to configure a SmartResponse Plugin to act on an alarm. You have the following options:\\nDetermine what events trigger the SmartResponse.\\nDetermine if there is an approval workflow.\\nDetermine which alarm values are passed into the SmartResponse Plugin.\\nConfigure any parameters that are environment specific.\\nBecause of the number of options and variety of use cases, see the\\nSmartResponse Plugin installer guides\\nfor more details on configuring the SmartResponse Plugin.\\nAdditionally, many of the Threat Detection module user guides contain recommended actions sections for linking LogRhythm published SmartResponse Plugins to specific Advanced Intelligence Engine (AIE) rules. Review these guides for ideas about possible use cases for SmartResponse Plugins.\\n', 'Executing a SmartResponse Plugin for Context Enrichment': 'As of LogRhythm 7.2.3, you can execute an SRP from the context of the Analyzer grid in the Web Console. Any output from the SRP displays in a window inside the Web Console. This allows a new opportunity to use SRPs for context enrichment when hunting or analyzing a log, event, or alarm.\\nTo run SmartResponse in the Web Console, you much first enable SmartResponse in LogRhythm by importing SmartResponse plugins in the Client Console. For more information, see\\nImport SmartResponse Plugins\\n.\\n', 'Security Considerations for Running SmartResponse Plugins': '', 'Service Accounts': 'SmartResponse Plugins use the credentials of the System Monitor Agent Service Account on hosts, or with the credentials of the ARM Service Account if launched from the Platform Manager.\\nOften these services use the LocalSystem Service Account.\\n', 'Best Practices for Service Accounts': 'The System Monitor Agent Service and ARM Service should be configured to run under a specific service account, rather than LocalSystem.\\nUse the Least Privilege User Guide to limit the privileges of the account running the System Monitor Agent or ARM Service.\\n', 'Monitoring SmartResponse': 'SmartResponse actions may be highly privileged, or subject to attack, and should therefore be monitored. Signed PowerShell scripts can be logged by the CAPI2 Event Logging in Windows, and thus it may be validated that a LogRhythm signed script was in fact executed.\\nSmartResponse Plugins are delivered to System Monitor Agents and saved to the C:\\\\Program Files\\\\LogRhythm folder structure, in LogRhythm System Monitor\\\\State\\\\SmartResponse. This folder should be monitored by File Integrity Monitoring (FIM) and an AIE alarm should be created to monitor for any activity in that folder not originating with the scsm.exe process.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nSmartResponse\\n/\\nDevelop SmartResponse Plugins\\n', 'Package and Test the SmartResponse': '\\n\\nContent Formatting Macros for Confluence\\ncannot be exported to this format.\\nContent Formatting Macros for Confluence\\ncannot be exported to this format.\\n\\nA LogRhythm Global Administrator or Restricted Administrator with elevated privileges can validate the configuration file, package the plugin contents, and create a single plugin file (.lpi) for distribution. After the plugin file is made,\\nimport the plugin\\ninto any LogRhythm deployment via the LogRhythm Console.\\nTo test, package, and import the plugin\\nMove the actions.xml and any supporting files to a single folder. In PowerShell-based plugins, the supporting files include the PowerShell script.\\nOn the main toolbar of the Client Console, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nSmartResponse Plugin Manager\\n.\\nTo open the Create SmartResponse Plugin dialog box, click\\nCreate Plugin\\nin the top ribbon.\\nClick\\nBrowse\\nand select the folder containing the configuration file and other supporting files.\\nClick\\nValidate\\nand ensure that the configuration file is correct.\\nClick\\nCreate\\n, and select a folder location where the resulting plugin should be created.\\nAfter the plugin is created, go back to the SmartResponse Plugin Manager.\\nIn the upper left, Click\\nActions\\n, and then click\\nImport\\nto open the SmartResponse Plugin Import screen.\\xa0 After it is imported, the plugin appears in the list of SmartResponse Plugins. Sort by Last Updated On to find the most recent addition.\\nBrowse to the plugin you just created and click\\nOpen\\n. Plugins are created with a default extension of \".lpi,\" and the filename is the GUID of the plugin.\\nAll SmartResponse Plugins that are registered in the SmartResponse Plugin manager are automatically available from the Analyzer grid inside the Web Console. No additional configuration is necessary to leverage the plugin.\\nBrowse to the plugin you just created and click\\nOpen\\n. Plugins are created with a default extension of \".lpi,\" and the filename is the GUID of the plugin.\\nAll SmartResponse Plugins that are registered in the SmartResponse Plugin manager are automatically available from the Analyzer grid inside the Web Console. No additional configuration is necessary to leverage the plugin.\\n\\nContent Formatting Macros for Confluence\\ncannot be exported to this format.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nSystem Monitor\\n', 'Agent Identification and Acceptance': 'Unidentified Agents are saved in a separate “acceptance” table pending a direct action on the part of the user. This can be seen on the System Monitors tab in the New System Monitor Agents grid. Accepted System Monitor Agents appear in the grid below the New System Monitor Agents grid.\\nColumn, Description\\nAction, Batch actions operate on all checked rows.\\nStatus, Pending: The System Monitor Agent is waiting to be accepted before it will start delivering logs.Rejected: The System Monitor Agent is not allowed to connect to the system.Typically, new entries have a status of pending. If the administrator rejects them, the status is rejected. Because System Monitor Agents repeatedly try to connect, the entry should remain in Rejected state until the agent is uninstalled. Then, the entry can be deleted.\\nHost Name, Displays the computer name of the host the agent is running on.\\nHost OS, Displays the operating system for the computer the agent is running on.\\nHost OS\\xa0Version, Displays the version of the OS the agent is running on.\\nHost IP\\xa0Address, Displays the IP address of the computer the agent is running on.\\nResolved Known Host, If the mediator can find a matching host in the database, the host appears here. Otherwise this field displays “Entity name:Host name:New”. The user can also resolve the host manually on the properties form.\\nAgent Name, Displays the system generated name of the Agent. By default, this is the same as the computer name. The user can change this in the properties form. The batch accept process prepends the host entity name if necessary to make the agent name unique.\\nAgent Type, Identifies the type of agent installed on the computer. This field has the same values as Agent Type on the System Monitors tab.\\nAgent Version, The LogRhythm assigned version of the System Monitor Agent.\\nAgent GUID, The globally unique identifier generated by the agent.\\nPending: The System Monitor Agent is waiting to be accepted before it will start delivering logs.\\nRejected: The System Monitor Agent is not allowed to connect to the system.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nSystem Monitor\\n', 'System Monitor Configuration Policy Manager': \"The System Monitor Configuration Policy Manager provides LogRhythm administrators policy-based management of Agents. A LogRhythm Administrator creates a System Monitor Configuration Policy and then applies the policy to multiple Agents. The policy determines how the Data Processor processes logs sent from the Agents.\\nWhen an Agent has a System Monitor Configuration Policy applied to it, the Agent's configuration is locked. The policy applied to the Agent must be updated to change the Agent’s configuration. By locking down the Agent’s configuration, the LogRhythm Administrator can easily control the configuration of many Agents over large geographic locations.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nSystem Monitor\\n', 'Work With System Monitor Agents': 'System Monitor Lite, Pro, and Collector Agents collect and forward log data to Data Processors. Additionally, System Monitor Pro or Collector Agents can also perform File Integrity Monitor (FIM) operations. When FIM detects changes in files and directories, the Agent generates a log and sends it to the Data Processor. For more information, see\\nNetworking and Communication\\n.\\nThe Windows version of the Agent can also collect Event Logs remotely from other Windows hosts. It has an RFC 3164 compliant syslog server built in that can be used to collect syslog data transmitted over a network.\\n', 'License System Monitors': 'One System Monitor Pro or Collector license is provided and assigned to the System Monitor that runs on each LogRhythm appliance. When you add a new System Monitor, it will be assigned a System Monitor Pro license if available. If a System Monitor Pro license is not available, a System Monitor Lite license is assigned.\\nTo view the agent functionality matrix, see\\nLogRhythm Compatibility and System Monitor Functionality Guide\\n.\\nTo view System Monitor Lite and System Monitor Pro or Collector features, see\\nSystem Monitor Functionality by License: Lite vs. Pro/Collector\\n.\\n', 'Least Privileged Users': 'In some cases, a System Monitor will need to be created with least privilege user rights. This enables the System Monitor to exist in an environment outside the DMZ. In this case, the System Monitor needs limited access to other components such as the Performance Monitor. To configure the System Monitor with least privilege user rights, see\\nLeast Privileged User\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nSystem Monitor\\n/\\nWork With System Monitor Agents\\n', 'Configure a Secure Syslog Agent': 'Complete the following to configure a secure syslog agent.\\n', 'Enable Secure Syslog': 'When using secure syslog, log messages are encrypted and sent over the network using SSL/TLS. When syslog is enabled, the default setting is for the sending syslog clients to connect to the Agent (syslog server) without using an SSL client certificate.\\xa0 The default setting for the Agent is to use a self-signed and self-generated SSL server certificate. For more information, see\\nPublic Key Infrastructure (PKI) Support\\n.\\nTo enable the LogRhythm Agent to listen for incoming syslog messages for both standard syslog and secure syslog:\\nIn the Client Console, on the main toolbar, click the\\nDeployment Manager\\n.\\nRight-click the System Monitor you want to configure, and then click\\nProperties\\nClick the\\nSyslog and Flow Settings\\ntab, then select\\nEnable Syslog Server.\\nWhen the Enable Syslog Server box is checked, the Agent listens for incoming syslog messages using the ports configured in the Agent’s Advanced settings.\\xa0 The default settings use the standard IANA port numbers:\\nStandard syslog\\n. UDP/TCP port 514\\nSecure syslog\\n. TCP port 6514\\nStandard syslog\\n. UDP/TCP port 514\\nSecure syslog\\n. TCP port 6514\\nThe minimum configuration is to enable the syslog server in the Agent’s configuration and syslog clients should immediately be able to establish secure connections to the Agent.\\n', 'Use a Self-Generated Certificate': \"If the Agent uses a self-generated server certificate (default), the syslog clients do not need to import the server certificate's signing certificates into their certificate store.\\xa0 In this case, the Agent generates a new server certificate every time it is restarted, so any saved certificates in the syslog client system become irrelevant. Using a self-generated certificate encrypts data while it is traveling through the network, but does not ensure sender/receiver authentication.\\nTo ensure both encryption and authentication, users can specify their own Agent (server) certificate as well as check the integrity of the syslog client by requiring it to present a client certificate.\\n\", 'Create a Custom Server Certificate': \"The instructions below describe how to configure the Agent to use a custom SSL server certificate and how to generate the server certificate using OpenSSL (downloadable from\\nwww.openssl.org\\n).\\nTo create a custom server certificate and private and public keys using OpenSSL:\\nInstall the OpenSSL package, or extract the OpenSSL files to the directory C:\\\\Program Files (x86)\\\\Common Files\\\\SSL if using Windows operating system.\\nThe OpenSSL executable expects the “openssl.cnf” file to be located in the C:\\\\Program Files (x86)\\\\Common Files\\\\SSL directory. Ensure that you copy it there from the C:\\\\OpenSSL\\\\bin folder.\\nThe openssl.cnf file is the main configuration file for the certificate. This certificate allows the syslog clients to establish a secure connection to the LR Agent using either the Agent's host name, fully qualified host name, or IP address. See the following example:\\n[ req ]\\ndefault_bits = 2048\\ndistinguished_name = req_distinguished_name\\nreq_extensions = req_ext\\n[ req_distinguished_name ]\\ncountryName = US # 2 letter code for country name\\nstateOrProvinceName = Califoria # State or Province Name (full name)\\nlocalityName = Los Angeles # city or locality name\\norganizationName = Acme Mfg # company name\\ncommonName = LRAgent12 # e.g. server name or IP address\\n[ req_ext ]\\nsubjectAltName = @alt_names\\n[alt_names]\\nDNS.1 = LRAgent12.AcmeMfg.com\\nIP.1 = 10.2.0.5\\nInstall the OpenSSL package, or extract the OpenSSL files to the directory C:\\\\Program Files (x86)\\\\Common Files\\\\SSL if using Windows operating system.\\nThe OpenSSL executable expects the “openssl.cnf” file to be located in the C:\\\\Program Files (x86)\\\\Common Files\\\\SSL directory. Ensure that you copy it there from the C:\\\\OpenSSL\\\\bin folder.\\nThe openssl.cnf file is the main configuration file for the certificate. This certificate allows the syslog clients to establish a secure connection to the LR Agent using either the Agent's host name, fully qualified host name, or IP address. See the following example:\\n[ req ]\\ndefault_bits = 2048\\ndistinguished_name = req_distinguished_name\\nreq_extensions = req_ext\\n[ req_distinguished_name ]\\ncountryName = US # 2 letter code for country name\\nstateOrProvinceName = Califoria # State or Province Name (full name)\\nlocalityName = Los Angeles # city or locality name\\norganizationName = Acme Mfg # company name\\ncommonName = LRAgent12 # e.g. server name or IP address\\n[ req_ext ]\\nsubjectAltName = @alt_names\\n[alt_names]\\nDNS.1 = LRAgent12.AcmeMfg.com\\nIP.1 = 10.2.0.5\\nGenerate the Agent SSL Key using the following command:\\nopenssl.exe req -x509 -days 1825 -newkey rsa:2048 -keyout C:\\\\LogRhythm\\\\agent_key.pem -out C:\\\\LogRhythm\\\\agent_cert_private.pem\\nThe Common Name must be the IP address of the Agent server.\\nGenerate the Agent SSL Key using the following command:\\nopenssl.exe req -x509 -days 1825 -newkey rsa:2048 -keyout C:\\\\LogRhythm\\\\agent_key.pem -out C:\\\\LogRhythm\\\\agent_cert_private.pem\\nThe Common Name must be the IP address of the Agent server.\\nGenerate the Agent Private Key using the following command:\\nopenssl.exe pkcs12 -export -in C:\\\\LogRhythm\\\\agent_cert_private.pem -inkey C:\\\\LogRhythm\\\\agent_key.pem -out C:\\\\LogRhythm\\\\agent_cert.pfx\\nExport the Public Key from the certificate using the following command:\\nopenssl.exe pkcs12 -in C:\\\\LogRhythm\\\\agent_cert.pfx -clcerts -nokeys -out C:\\\\LogRhythm\\\\agent_cert_public.pem\\nThe following files should now have been created.\\nagent_cert.pfx\\nagent_cert_private.pem\\nagent_cert_public.pem\\nagent_key.pem\\nagent_cert.pfx\\nagent_cert_private.pem\\nagent_cert_public.pem\\nagent_key.pem\\n\", 'Install the Agent Server Certificate in the Windows Certificate Store': 'Import the signing certificate:\\nOpen the Microsoft Management Console on the\\xa0server where the agent is running.\\nOn the\\nFile\\nmenu, click\\nAdd/Remove Snap-in\\n.\\nUnder Available snap-ins, select\\nCertificates\\n, and then click\\nAdd\\n.\\nWhen prompted about which certificates this snap-in will manage, select\\nComputer Account\\n, and then click\\nNext\\n.\\nIn the Select Computer dialog box, select\\nLocal computer: (the computer this console is running on)\\n, and then click\\nFinish\\n.\\nExpand\\nTrusted Root Certificate Authorities\\n, right-click on\\nCertificates\\n, click\\nAll Tasks\\n, and then click\\nImport\\n.\\nOn the Welcome screen, click\\nNext\\n.\\nBrowse to the .pfx file created above, and then click\\nNext\\n.\\nType the password specified when you created the certificate, select the\\nMark this key as exportable\\nand\\nInclude all extended properties\\ncheck boxes, and then click\\nNext\\n.\\nEnsure that the certificate will be placed in the Trusted Root Certificate Authorities store, and then click\\nNext\\n.\\nClick\\nFinish\\nto import the certificate.\\nThe new certificate should now be listed in the Microsoft Management Console.\\nImport the server certificate:\\nOpen the Microsoft Management Console on the\\xa0server where the agent is running.\\nOn the\\nFile\\nmenu, click\\nAdd/Remove Snap-in\\n.\\nUnder Available snap-ins, select\\nCertificates\\n, and then click\\nAdd\\n.\\nWhen prompted about which certificates this snap-in will manage, select\\nComputer Account\\n, and then click\\nNext\\n.\\nIn the Select Computer dialog box, select\\nLocal computer: (the computer this console is running on)\\n, and then click\\nFinish\\n.\\nExpand\\nPersonal\\n, right-click on\\nCertificates\\n, click\\nAll Tasks\\n, and then click\\nImport\\n.\\nOn the Welcome screen, click\\nNext\\n.\\nBrowse to the .pfx file created above, and then click\\nNext\\n.\\nType the password specified when you created the certificate, select the\\nMark this key as exportable\\nand\\nInclude all extended properties\\ncheck boxes, and then click\\nNext\\n.\\nEnsure that the certificate will be placed in the Personal store, and then click\\nNext\\n.\\nClick\\nFinish\\nto import the certificate.\\nThe new certificate should now be listed in the Microsoft Management Console.\\n', 'Install the Agent Signing Certificate on the Syslog Client': \"In the Microsoft Management Console, right-click on the new certificate in\\nTrusted Root Certificate Authorities\\n, click\\nAll Tasks\\n, and then click\\nExport\\n.\\nClick\\nNext\\nin the opening page of the Certificate Export Wizard.\\nWhen prompted to export the private key, select\\nNo, do not export the private key\\n, and then click\\nNext\\n.\\nFor the export file format, select\\nBase-64 encoded X.509 (.CER)\\n, and then click\\nNext\\n.\\nType a name for the public key, and then click\\nNext\\n.\\nIn the last page of the Certificate Export Wizard, click\\nFinish\\nto export the public key.\\nThe .cer file will be saved to the specified folder.\\nCopy the exported .cer file to all syslog client\\xa0systems.\\nCopy the .cer file from the Agent server to the syslog client system.\\nUse the syslog client's configuration interface to import the Agent's signing certificate.\\n\", 'Update the System Monitor Agent Configuration': 'To configure the Secure Syslog Group fields:\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nSystem Monitors\\ntab.\\nRight-click the System Monitor you want to configure, and then click\\nProperties\\n.\\nIn the lower-left corner of the\\nSystem Monitor Agent Properties\\nwindow, click\\nAdvanced\\n.\\nScroll to the Secure Syslog Server Group.\\nSetting, Accepted Values, Default Value, Description\\nEnforceSecureSyslogClientCertRevocation, Enabled/Disabled, Disabled, Enforce Agent Certificate Revocation Check. If this fails, the Agent disconnects from the syslog client.\\nEnforceSecureSyslogClientCertTrust, Enabled/Disabled, Disabled, Enforce secure syslog certificate Trusted Authority Check. If this fails, the Agent disconnects from the syslog client.\\nRequireSecureSylogClientCert, Enabled/Disabled, Disabled, Require secure syslog clients to present a client certificate when connecting.\\nSecureSyslogClientCertOCSPURL, , , The OCSP URL for Agent certificate revocation checking.\\nSecureSyslogPort, 1-65535, 6514, Secure syslog TCP port to listen on. Default is 6514.\\nSecureSyslogServerCertLocation, LocalMachine, , The Windows certificate location where the Agent secure syslog server certificate is installed. Can be LocalMachine or CurrentUser.\\nSecureSyslogServerCertStore, MY, , The Windows certificate store where the Agent secure syslog server certificate is installed--can be MY or ROOT.\\nSecureSyslogServerCertSubject, CN=<FQDN>, , The Subject of the server certificate that the Agent should use for secure syslog (e.g., CN=190.1.2.123 or CN=lr-0870eds-msa or CN=lr-0870eds-msa.secious.com). This must be the IP address specified in step 2 under the Create Certificates section above and must match what the syslog client uses in the configuration.\\nUseSecureSyslogServerCert, Enabled/Disabled, Disabled, If checked, the Agent uses the specified server certificate for server-side authentication during the establishment of secure syslog connections; otherwise, the Agent will use a self-generated/signed certificate (default).\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nSystem Monitor\\n/\\nWork With System Monitor Agents\\n', 'Data Processor Pooling': 'Data Processor pooling makes it easy for administrators to distribute log volume across a pool of Data Processors and create well-balanced Data Indexer clusters.\\nAdministrators can quickly define Data Processor pools, assign Data Processors to those pools, and then configure agents to send logs to all Data Processors in the pool. Agents assigned to a DP pool use a round robin based log flushing mechanism to evenly distribute their logs across the Data Processors in the pool. One\\nData Processor in the pool is designated to receive heartbeats and\\nmessage source states. If the control DP is unreachable or offline, the Agent will designate another Data Processor in the pool as the control DP.\\nData Processor Pooling applies to all log sources and log types collected by an Agent.\\n\\nStarting with version 7.13, Data Processor pooling is available to customers with multiple Data Processors in their deployment.\\nData Processor Pooling mode is not enabled for deployments or agents on versions prior to 7.13. In such cases, Administrators can configure the Agent to pinned mode, which sends logs to a single Data Processor.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nSystem Monitor\\n/\\nWork With System Monitor Agents\\n', 'Load Balanced Agent Groups': 'Administrators can group load-balanced System Monitors together when multiple System Monitors are connected to a commercial or open source round-robin load balancer.\\nWhen System Monitor Agents are configured into a Load Balanced Agent Group, all parent and child syslog virtual log sources assigned to one collection Agent in the group appear in all scsm.ini files for Agents in that group. This feature allows all System Monitor Agents within the group to immediately recognize identifiers for all log sources within the group. This prevents log loss that can happen during virtual identifier search scope lookups.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nSystem Monitor\\n/\\nWork With System Monitor Agents\\n', 'Modify System Monitor Advanced Properties': \"To configure Advanced System Monitor properties\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nSystem Monitors\\ntab.\\nRight-click the System Monitor you want to configure, and then click\\nProperties\\n.\\nIn the lower-left corner of the\\nSystem Monitor Agent Properties\\nwindow, click\\nAdvanced\\n.\\nThe Agent Advanced Properties window appears.\\nDo one of the following:\\nConfigure the values according to the information in the following table.\\nIn the lower-left corner, click\\nApply Recommended Values\\n, and then click\\nYes\\nto confirm your selection.\\nConfigure the values according to the information in the following table.\\nIn the lower-left corner, click\\nApply Recommended Values\\n, and then click\\nYes\\nto confirm your selection.\\nClick\\nOK.\\nIf you have the correct permissions but are unable to modify an Agent's settings, it likely has a configuration policy applied. Look at the Agent Settings tab of the properties dialogue box to see if there is a policy listed under Configuration Policy. For more information, see\\nSystem Monitor Configuration Policy Manager\\n.\\n\\nAgent Advanced Properties, Range, Default, Description\\nFile Integrity Monitor Group\\nRealtimeRecordBufferLimit, 0-2147483647, 10485760, Maximum number of bytes the RealtimeFileMonitor can use. Set to zero to buffer until exhaustion.\\nRTFIMExcludeNestedDirectoryEvents, Enabled/Disabled, Disabled, Enable this option to filter out directory events within a monitored directory (for example, creating or deleting a directory). If this option is not enabled, RT\\xa0FIM\\xa0creates an event for such actions.\\nGeneral Group\\nCompress, 0-9, 0, Compression level, range 0-9:0=no compression or batching,1=fast compression,9=highest compression.\\nConnectionTimeout, 3-7200, 120, Connection timeout for Agent socket connections (in seconds).\\nCycleTime, 1-86400, 10, Time for a single processing cycle (in seconds). If a cycle time is completed faster than CycleTime, the Agent sleeps for the remainder of CycleTime.\\nEventLogBuffer, 4-256, 8, Size of the Event Log read buffer (in KB).\\nEventLogCacheLifetime, 5-1440, 30, Lifetime of the event log cache (in minutes).\\nEventLogTimeout, 1-120, 10, Time allowed for remote systems to respond to event log read requests (in seconds).\\nFailbackDelay, 0-3600, 60, The number of minutes to wait before failing back to a higher priority Data Processor, range 0-3600; 0=no failback; 1-3600=number of minutes to wait before failing back to a higher priority Data Processor.\\nFlushBatch, 1-50000, 100, Set the number of logs to flush in each batch between DP Ack. Recommended to set no higher than 10,000 when using DP Pooling\\nHeartbeatInterval, 1-60, 6, Number of processing cycles between heartbeats.\\nLoadBalanceDelay, 0-10080, 4320, The number of minutes to wait before failing back to a higher priority Data Processor when in a load balancing deployment. Range 0-10080. 0=No failback; 1-10080=number of minutes to wait before failing back to a higher priority Data Processor.\\nLocalLogLifetime, 1-30, 7, Time to keep Agent logs (in days).\\nLogLevel, Off, Error, Warning, Info, Verbose, Debug, Verbose, Sets the Agent logging level (log written to scsm.log).\\nLogSourceSearchScope, System Monitor Search, Parent Entity Search, Global Search, Parent Entity Search, Defines the scope in which Auto-Discovered Log Sources are located.\\nLogSourceVirtualizationThreadCount, 1-50, 10, Number of threads to process Log Source Virtualization rules.\\nLogSourceVirtualizationTimeoutMillSec, 1-1000, 100, Time (in milliseconds) after which a Log Source Virtualization regular expression stops processing and creates a diagnostic error.\\nMaxLogQueueMemory, 10-8192, 25, Maximum amount of memory the Agent uses for its in memory data queue before spooling incoming syslog data to a temporary file (in MB).\\nMaxServiceMemory, 100-16384, 512, Maximum memory allowed for the Agent process (in MB).\\nMaxSuspenseFileSize, 1-5, 5, Maximum Syslog, NetFlow, and SNMP trap suspense file size (in MB).\\nProcessPriority, Low,Below NormalNormal,Above Normal, High, Normal, Process priority for the Agent process.\\nSocketReceiveTimeout, 1000-7200000, 60000, Socket receive timeout (in ms).\\nSocketSendTimeout, 1000-7200000, 60000, Socket send timeout (in ms).\\nTCPNodeDelay, Enabled/Disabled, Enabled, Enables or disables TCP\\xa0delay to reduce protocol overhead.\\nTCPRecvBufferSize, 1-67108864, 524288, The size, in bytes, of the TCP\\xa0receive buffer.\\nTCPReuse, Enabled/Disabled, Enabled, Enables or disables the reuse of local addresses with the SO_REUSEADDR protocol.\\nTCPSendBufferSize, 1-67108864, 524288, The size, in bytes, of the TCP\\xa0send buffer.\\nVirtualSourceDNSResolution, Enabled/Disabled, Enabled, When enabled, the Agent attempts to resolve host names for syslog devices that send IP addresses as the identifier and attempt to resolve IP addresses for syslog sending devices that send host names as their identifier.\\nJSON Parser Group\\nFilterBatchSize, 1-10000, 1000, The size of a single batch used to filter data to find the source to assign a parsing policy.\\nListeningPort, Any port value., 5044, The port to which the agent listens for JSON data sent by Beats.\\nOriginalMessage, Enabled/Disabled, Disabled, A flag to append the output received from beat at the end of raw log. By default, this is disabled, meaning that the beat output will not be appended to a raw log.\\nOutBatchSize, 1-10000, 1000, The size of a single batch of parsed values used to create raw logs concurrently.\\nParsingBatchSize, 1-10000, 1000, The size of a single batch of JSON to parse them concurrently as per the assigned policy.\\nNetFlow Server Group\\nNetFlowServerNIC, , 0, Specify the interface to receive IPFIX/NetFlow/J-Flow data. Valid values are eth0-99 (Linux), 0-99 (Windows), or an IP address. Numeric values determine which network interface card to use - a value of eth0 (Linux) or 0 (Windows) is the first available network interface card. An IP address value is the static IP address of the NIC to receive NetFlow data on.\\nNetFlowServerPort, 1-65535, 5500, Port on which the IPFIX/NetFlow/J-Flow server receives NetFlow packets.\\nNetFlowVerbose, Enabled/Disabled, Disabled, Create IPFIX/NetFlow/J-Flow v9 verbose log messages. NetFlow v9 data records may include many data fields that were not available in earlier NetFlow versions. Enabling NetFlowVerbose captures all these fields in the raw log, but may also significantly increase storage and network requirements.\\nNetworkConnectionMonitor Group\\nNetworkConnectionMonitorInterval, 1-86400, 5, The polling interval in seconds for the Network Connection Monitor. The polling interval uses a snapshot approach and compares the differences between the previous and current snapshot. A process that startsandstops between polling times will not be detected, so a small interval is recommended.\\nProcess Monitor Group\\nProcessMonitorInterval, 1-86400, 5, The polling interval in seconds for the Process Monitor. The polling interval uses a snapshot approach and compares the differences between the previous and current snapshot. A process that startsandstops between polling times will not be detected, so a small interval is recommended.\\nSecure Syslog Server Group\\nEnforceSecureSyslogClientCertRevocation, Enabled/Disabled, Disabled, Enforce Agent Certificate Revocation Check. If this fails, the Agent disconnects from the syslog client.\\nEnforceSecureSyslogClientCertTrust, Enabled/Disabled, Disabled, Enforce secure syslog certificate Trusted Authority Check. If this fails, the Agent disconnects from the syslog client.\\nRequireSecureSylogClientCert, Enabled/Disabled, Disabled, Require secure syslog clients to present a client certificate when connecting.\\nSecureSyslogClientCertOCSPURL, , , The OCSP URL for Agent certificate revocation checking.\\nSecureSyslogPort, 1-65535, 6514, Secure syslog TCP port to listen on. Default is 6514.\\nSecureSyslogServerCertLocation, , , The Windows certificate location where the Agent secure syslog server certificate is installed. Can be LocalMachine or CurrentUser.\\nSecureSyslogServerCertStore, , , The Windows certificate store where the Agent secure syslog server certificate is installed--can be MY or ROOT.\\nSecureSyslogServerCertSubject, , , The Subject of the server certificate that the Agent should use for secure syslog (e.g., CN=190.1.2.123 or CN=lr-0870eds-msa or CN=lr-0870eds-msa.secious.com). This must be the\\xa0IP address specified in step 2 under the Create Certificates section above and\\xa0must match what the syslog client uses in the configuration.\\nUseSecureSyslogServerCert, Enabled/Disabled, Disabled, If checked, the Agent uses the specified server certificate for server-side authentication during the establishment of secure syslog connections; otherwise, the Agent will use a self-generated/signed certificate (default).\\nFor more information on configuring a secure syslog server, seeConfigure a Secure Syslog Agent.\\nsFlow Server Group\\nsFlowExtraLogging, Enabled/Disabled, Disabled, Check to enable logging of unknown sFlow records to a local file. If disabled, the records are discarded.\\nsFlowLogDetails, Enabled/Disabled, Disabled, Check to enable logging of uninteresting sFlow counter data in a details section of the scsm.log.\\nsFlowServerNIC, , 0, Specify the interface to receive sFlow data.\\nsFlowServerUDPPort, 1-65535, 6343, Port on which the sFlow server receives packets.\\nSyslog Server Group (Windows Agents Only)\\nSyslogFile, Enabled/Disabled, Disabled, Check to enable writing syslog data to the text file specified in the SyslogFilePath property.\\nSyslogFileHistory, 1-30, 7, Maximum number of days to keep rotated syslog files.\\nSyslogFilePath, , See descrip-tion, All syslog messages received are written to this file if the SyslogFile property is enabled. Default path is: C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm System Monitor\\\\logs\\\\syslogfile.log\\nSyslogFileRotationSize, 5-100, 5, Syslog file rotation size (in MB). The size at which the syslog file is rotated.\\nSyslogServerNIC, Character length max = 15, 0, Specify the interface to receive syslog data. This is either an IP address (recommended) or a numeric value of an interface card.An IP address value is the static IP address of the NIC where syslog is receiving data. A numeric value (0 – 99) should be the number of the first available network interface card.\\nSyslogTCPPort, 1-65535, 514, Syslog TCP port on which to listen. For exceptions to the default, seeNetworking and Communication.\\nSyslogUDPPort, 1-65535, 514, Syslog UDP port on which to listen. For exceptions to the default, seeNetworking and Communication.\\nSyslogUseEnhancedTCPDelimiters, Enabled/Disabled, Disabled, Check to enable parsing TCP syslog messages using additional delimiters: '\\\\r' and '\\\\0'. If unchecked, only '\\\\r\\\\n' and the standard newline character '\\\\n' is used.TCP syslog delimiter descriptions:'\\\\n' - LF, Newline/Linefeed, 10 in decimal, usage = standard, syslogng, PIX Firewall'\\\\r'- CR, Carriage return, 13 in decimal‘\\\\r\\\\n’- CRLF, CR+LF, 13 10 in decimal'\\\\0'- NULL, 00 in decimal, usage = Juniper Netscreen Firewall\\nTLS Certificates GroupFor an example of how to use these values to utilize custom certificates for Agent to Mediator communications, seeCertificate Configuration for LogRhythm Component Connections.\\nAgentTLSCertLocation, , , The location of the Windows certificate where the Agent client certificate is installed: LocalMachine or Current User.\\nAgentTLSCertStore, , , The Windows certificate store where the Agent client certificate is installed: MY or ROOT.\\nAgentTLSCertSubject, , , The Subject of the client certificate that the Agent should use.\\nEnforceMediatorTLSCertRevocation, Enabled/Disabled, Disabled, Enforce Mediator Certificate Revocation Check. If this fails, the Agent will disconnect from the Mediator and logs will be written to the scsm.log.\\nEnforceMediatorTLSCertTrust, Enabled/Disabled, Disabled, Enforce Mediator Certificate Trusted Authority Check. If this fails, the Agent disconnects the Mediator and logs are written to the scsm.log.\\nMediatorTLSCertOCSPURL, , , The OCSP URL for Mediator certificate revocation checking.\\nUseAgentTLSCert, Enabled/Disabled, Disabled, If checked, the Agent will use the specified client when connecting to the Mediator; otherwise, no Agent certificate will be used (default).\\nUAM\\xa0Group\\nUserActivityMonitorHistory, 1-24, 24, The maximum number of hours to keep User Activity Monitor history.\\nUserActivityMonitorInterval, 3-86400, 30, The polling interval in seconds for the User Activity Monitor\\nUnidirectional Agent Group\\nEnabled, True/False, False, Check to enable unidirectional Agent communications with the Data Processor\\nHashMode, No Hash, SHA256, SHA512, No Hash, The hash to use when sending messages from the unidirectional Agent to the Data Processor.\\nMediatorPort, 1-65535, 40000, Specifies the Data Processor port to use when running in unidirectional Agent mode.\\nCompression level, range 0-9:\\n0=no compression or batching,\\n1=fast compression,\\n9=highest compression.\\nSet the number of logs to flush in each batch between DP Ack. Recommended to set no higher than 10,000 when using DP Pooling\\nDisabled\\nSpecify the interface to receive syslog data. This is either an IP address (recommended) or a numeric value of an interface card.\\nAn IP address value is the static IP address of the NIC where syslog is receiving data. A numeric value (0 – 99) should be the number of the first available network interface card.\\nCheck to enable parsing TCP syslog messages using additional delimiters: '\\\\r' and '\\\\0'. If unchecked, only '\\\\r\\\\n' and the standard newline character '\\\\n' is used.\\nTCP syslog delimiter descriptions:\\n'\\\\n\\n' - LF, Newline/Linefeed, 10 in decimal, usage = standard, syslogng, PIX Firewall\\n'\\\\r'\\n- CR, Carriage return, 13 in decimal\\n‘\\\\r\\\\n’\\n- CRLF, CR+LF, 13 10 in decimal\\n'\\\\0'\\n- NULL, 00 in decimal, usage = Juniper Netscreen Firewall\\nFor an example of how to use these values to utilize custom certificates for Agent to Mediator communications, see\\nCertificate Configuration for LogRhythm Component Connections\\n.\\nNo Hash, SHA256, SHA512\\nSpecifies the Data Processor port to use when running in unidirectional Agent mode.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nSystem Monitor\\n/\\nWork With System Monitor Agents\\n', 'Modify System Monitor Basic Properties': \"You can modify basic System Monitor properties using the tabs in the System Monitor Agent Properties window.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nSystem Monitors\\ntab.\\nRight-click the System Monitor you want to configure, and then click\\nProperties\\n.\\nConfigure the values according to the information in the following table, and then click\\nOK.\\nIf you have the correct permissions but are unable to modify an Agent's settings, it likely has a configuration policy applied. Look at the Agent Settings tab of the properties dialogue box to see if there is a policy listed under Configuration Policy. For more information, see\\nSystem Monitor Configuration Policy Manager\\n.\\n\", 'Agent Settings Tab': 'Property, Agent Settings Tab Description\\nHost Agent is Installed on, The default Host record log messages collected by the System Monitor should be assigned to. This value can be overridden at the Message Source level.\\nSystem Monitor Agent Name, Enter a unique name for the System Monitor. The name cannot be same as an existing or previously deleted System Monitor.\\nConfiguration Policy, Select a configuration policy to apply to the agent.\\nHost OS Type, Specify whether the agent is installed on a Windows, Linux, Solaris, AIX, or HP-UX host.Linux Debian/Ubuntu is supported.\\nHeartbeatWarning Interval, Specify a value between 1 minute and 30 days. This is the amount of time that a heartbeat signal from this Agent can be late by, before a Missing Heartbeat Warning event is generated. Warnings continue to be generated at this interval until a heartbeat is successfully received. The default value is one minute, or 60 seconds.To avoid generating unnecessary events, it is recommended that the minimum Heartbeat Warning Interval be set to CycleTime * HeartbeatInterval. You may want to add some extra time to account for network or environmental latency. For more information about these advanced Agent properties, seeModify System Monitor Advanced Properties.\\nHost Agent is Installed on\\nThe default Host record log messages collected by the System Monitor should be assigned to. This value can be overridden at the Message Source level.\\nSystem Monitor Agent Name\\nEnter a unique name for the System Monitor. The name cannot be same as an existing or previously deleted System Monitor.\\nHost OS Type\\nSpecify whether the agent is installed on a Windows, Linux, Solaris, AIX, or HP-UX host.\\nSpecify a value between 1 minute and 30 days. This is the amount of time that a heartbeat signal from this Agent can be late by, before a Missing Heartbeat Warning event is generated. Warnings continue to be generated at this interval until a heartbeat is successfully received. The default value is one minute, or 60 seconds.\\n', 'Data Processor Settings Tab': 'Property, Data Processor Settings Tab Description\\nData Processors to Use, Select and configure Data Processors the agent should forward logs to. Determine order in which Data Processors are used by increasing or decreasing the priority. The first checked Data Processor in the list has the highest priority. An Agent can only connect to one Data Processor at a time, but tries other Data Processors if the primary is unavailable. Reorder the entries to set the priority.For Agents that collect load balanced log sources, select all available Data Processors that are used for load balancing for that set of Agents. For example, Agents 1, 2, and 3 are load balanced and sending logs to Data Processors A, B and C. Agents 4, 5, and 6 are load balanced and sending logs to Data Processors X, Y, and Z. When configuring the System Monitor Agent Properties for Agent 2, you will see all available Data Processors in the Data Processors to Use section. You would select Data Processors A, B, and C to prevent errors in data processing. For more information, seeLoad Balancing.You can set them to any priority order, but if all load balanced Agents don’t include the same Data Processors in their configuration, the Data Processors receiving load balanced log sources data from load balanced Agents will fail to process the data.The following warning in\\xa0scmedsvr.log indicates your load balanced log source agents might be configured incorrectly. **WARNING** Invalid message source ID received from Agent<agent name>(LogSourceId=<ID number>) - no such ID exists in the LogRhythm deployment.\\nUse all Available NICs, Select this to allow the agent to use all available NICs until it is able to connect to the Data Processor. The Agent IP address input option is unavailable if this option is selected.\\nAgent IP/Address Index, Specify the interface that the System Monitor uses for communications to this Data Processor. Valid values for the Agent IP/Address Index are0-99, or an IP address. Numeric values determine which network interface card to use. A value of0is the first available network interface card. An Agent IP address value is the static IP address of the NIC to listen on. Only use an IP address when the IP never changes (no DHCP).For backward compatibility, Linux and versions of UNIX-based Agents continue to accepteth0-eth99as a valid interface name.\\nAgent Port, The local agent port the System Monitor uses to communicate with this Data Processor. The valid range is 0 to to 65535.A value of 0 is used to allow the agent to auto-negotiate a random high port with the mediator for communication between the two.\\nSelect and configure Data Processors the agent should forward logs to. Determine order in which Data Processors are used by increasing or decreasing the priority. The first checked Data Processor in the list has the highest priority. An Agent can only connect to one Data Processor at a time, but tries other Data Processors if the primary is unavailable. Reorder the entries to set the priority.\\nFor Agents that collect load balanced log sources, select all available Data Processors that are used for load balancing for that set of Agents. For example, Agents 1, 2, and 3 are load balanced and sending logs to Data Processors A, B and C. Agents 4, 5, and 6 are load balanced and sending logs to Data Processors X, Y, and Z. When configuring the System Monitor Agent Properties for Agent 2, you will see all available Data Processors in the Data Processors to Use section. You would select Data Processors A, B, and C to prevent errors in data processing. For more information, see\\nLoad Balancing\\n.\\nYou can set them to any priority order, but if all load balanced Agents don’t include the same Data Processors in their configuration, the Data Processors receiving load balanced log sources data from load balanced Agents will fail to process the data.\\nThe following warning in\\xa0scmedsvr.log indicates your load balanced log source agents might be configured incorrectly. **WARNING** Invalid message source ID received from Agent\\n<agent name>\\n(LogSourceId=\\n<ID number>\\n) - no such ID exists in the LogRhythm deployment.\\nSpecify the interface that the System Monitor uses for communications to this Data Processor. Valid values for the Agent IP/Address Index are\\n0\\n-\\n99\\n, or an IP address. Numeric values determine which network interface card to use. A value of\\n0\\nis the first available network interface card. An Agent IP address value is the static IP address of the NIC to listen on. Only use an IP address when the IP never changes (no DHCP).\\nThe local agent port the System Monitor uses to communicate with this Data Processor. The valid range is 0 to to 65535.\\n', 'Syslog and Flow Settings Tab': \"When processing a syslog, the Agent attempts to parse out the time stamp embedded in the syslog message and uses that value as the collection time (normal message date) for the log rather than the time the Agent received the syslog. If no timestamp can be parsed from the syslog message, the collection time (the time the log was received on the Agent’s syslog interface) is used as the normal message date.\\nProperty, Syslog and Flow Settings Tab Description\\nEnable Syslog Server, Enables the Windows, Linux, or UNIX Agent component that receives and collects Syslog data. For more information on configuring a secure syslog server, seeConfigure a Secure Syslog Agent.\\nSyslog Relay Hosts, Entries indicate that the IP address the Agent is receiving the log from, specified in the list. This is not the real source of the message. It is a relaying device. When the Agent sees an IP listed here, it uses special parsing, specified in the Syslog Relay Regular Expressions field, to determine the true source of the traffic. The list should contain a single IP address per line.\\nSyslog Relay RegularExpressions, Contains Regex strings that serve to identify and parse information from syslog data. Note the following:If a syslog sending device's IP address is contained in the Syslog Relay Hosts field, then these Regex strings are used to find and parse out the host identifier information. The host identifier information can be either an IP address or a host name. If none of the Regex strings in this field successfully parse out ahostidentifierthen the IP address of the sending device is used as the host identifier.This field should contain a single Regex string per line.The regex is case sensitive.The regex match is done against the pre-processed log with the syslog header, not against the raw log after it reaches the Data Processor.The following Regex tags are valid within the syslog Regex strings:prioritymessageyearmonthdayhourminutesecondshostidentifier\\nEnable Load Balancing, Designates the Agent as one that collects logs from a load balancer. When Agents and Log Sources are marked as load balanced, all such Agents receive the configuration information for load balanced log sources.\\nLoad Balanced Group, Open the drop-list and select the load balanced group with which to associate the Agent.For more information on creating load balanced groups, seeLoad Balanced Agent Groups.\\nEnable JSON Parsing, Enables the Agent component that allows for JSON parsing.\\nEnable IPFIX/NetFlow/J-Flow Server, Enables the Agent component that will receive and collect IPFIX/NetFlow/J-Flow data.\\nEnable sFlow Server, Enables the Agent component that receives and collects sFlow data. If it is disabled, a sFlow listener is not created.\\nLog sFlow Counters, Enables or disables the logging of sFlow counter structures.\\nEntries indicate that the IP address the Agent is receiving the log from, specified in the list. This is not the real source of the message. It is a relaying device. When the Agent sees an IP listed here, it uses special parsing, specified in the Syslog Relay Regular Expressions field, to determine the true source of the traffic. The list should contain a single IP address per line.\\nSyslog Relay Regular\\nExpressions\\nContains Regex strings that serve to identify and parse information from syslog data. Note the following:\\nIf a syslog sending device's IP address is contained in the Syslog Relay Hosts field, then these Regex strings are used to find and parse out the host identifier information. The host identifier information can be either an IP address or a host name. If none of the Regex strings in this field successfully parse out a\\nhostidentifier\\nthen the IP address of the sending device is used as the host identifier.\\nThis field should contain a single Regex string per line.\\nThe regex is case sensitive.\\nThe regex match is done against the pre-processed log with the syslog header, not against the raw log after it reaches the Data Processor.\\nThe following Regex tags are valid within the syslog Regex strings:\\npriority\\nmessage\\nyear\\nmonth\\nday\\nhour\\nminute\\nseconds\\nhostidentifier\\npriority\\nmessage\\nyear\\nmonth\\nday\\nhour\\nminute\\nseconds\\nhostidentifier\\nOpen the drop-list and select the load balanced group with which to associate the Agent.\\nFor more information on creating load balanced groups, see\\nLoad Balanced Agent Groups\\n.\\n\", 'SNMP Trap Receiver\\xa0Tab': 'Property, SNMP Trap Receiver Tab Description\\nEnable SNMPTrap Receiver, Check the box to receive v1, v2c, and v3 SNMP Traps collected from third-party network devices and systems. Default is unchecked.\\nListener Settings, Enter the IP Address and Port.\\nSNMP v1/v2c, Enter the Community\\nSNMP v3Authentication, Enter the User, Password, and Confirm Password. Only one user and password is supported.\\nSNMP v3 Encryption, Enter the Password, Confirm Password, and select an Algorithm (3DES, AES, DES) from the list.\\n', 'Endpoint Monitoring Tab': '', 'File Integrity Monitor': 'Property, File Integrity Monitor Tab Description\\nEnable File Integrity Monitor, Check the box to enable File Integrity Monitor (FIM).\\xa0Default is unchecked.\\nMode, Enable Standard or Realtime FIM.Standard and Realtime FIM are included with the System Monitor Lite license for desktop operating systems only. Server operating systems require System Monitor Pro or Collector. For specific operating system support, see Realtime File Integrity Monitor (FIM) Support by Operating System\\nEnable Realtime Mode Anomaly Detection, If an active FIM\\xa0Policy is monitoring for Modify events, the Realtime FIM engine recomputes the hash for monitored items after every Modify.If Realtime Mode Anomaly Detection is enabled, the Realtime FIM engine recomputes the hash for each file once every 24 hours. If the hash value has changed since it was last computed, FIM\\xa0generates a \"missed\"\\xa0modify event (MissedModifyAnomalyEvent).\\nInclude User Activity Monitor Data (Requires UAM), If enabled and User Activity Monitor (UAM) is enabled, user logon information is included in the FIM logs. This setting is disabled by default.\\nPolicy Name, When File Integrity Monitor is enabled, you must select at least one policy from the list. The field is only enabled when Enable File Integrity Monitor is selected.The policies are applied consecutively. Each policy selected is applied to the agent.\\nPreview, Click to open the Directories Monitored With Selected Policies window, which displays directories or files being monitored by the selected policies.\\nEnable Standard or Realtime FIM.\\nIf Realtime Mode Anomaly Detection is enabled, the Realtime FIM engine recomputes the hash for each file once every 24 hours. If the hash value has changed since it was last computed, FIM\\xa0generates a \"missed\"\\xa0modify event (MissedModifyAnomalyEvent).\\nWhen File Integrity Monitor is enabled, you must select at least one policy from the list. The field is only enabled when Enable File Integrity Monitor is selected.\\n', 'Registry Integrity Monitor': 'Property, Data Loss Defender Tab Description\\nEnable Registry Integrity Monitor, Check the box to enable Registry Integrity Monitor. Default is unchecked.\\nPolicy, The field is enabled when the Enable Registry Integrity Monitor box is selected. Select a policy from the list.\\n', 'Data Loss Defender': 'Property, Data Loss Defender Tab Description\\nEnable Data Loss Defender, Check the box to enable Data Loss Defender (DLD). Default is unchecked.\\nPolicy Name, The field is enabled when the Enable Data Loss Defender box is checked. Select a policy from the list.\\n', 'Process Monitor': 'Property, Process Monitor Tab Description\\nEnable Process Monitor, Check the box to enable Process Monitor. Default is unchecked.\\nInclude User Activity Monitor Data (Requires UAM), If checked and User Activity Monitor (UAM) is enabled, user logon information is included in the FIM logs. Default is unchecked.\\n', 'Network Connection Monitor': 'Property, Network Connection Monitor Tab Description\\nEnable Network Connection Monitor, Check the box to enable Network Connection Monitor. Default is unchecked.\\nMonitor Inbound TCP Connections, Check the box to monitor Inbound TCP Connections. Default is unchecked.\\nMonitor Outbound TCP Connections, Check the box to monitor Outbound TCP Connections. Default is unchecked.\\nMonitor Listening TCP/UDP Sockets, Check to box to monitor listening on TCP/UDP sockets.\\nInclude User Activity Monitor Data (Requires UAM), If checked and User Activity Monitor (UAM) is enabled, user logon information is included in the FIM logs. Default is unchecked.\\n', 'User Activity Monitor': 'Property, User Activity Monitor Tab Description\\nMonitor Logon Activity, Check the box to Monitor Logon Activity. Default is unchecked.\\nMonitor Network Session Activity, Check the box to Monitor Network Session Activity. Default is unchecked.\\nMonitor Process Activity, Check the box to Monitor Process Activity. Default is unchecked.\\nMonitor Process Activity\\n', 'Additional Information Tab': 'Property, Additional Information Tab Description\\nBrief Description, A short description of the information.\\nDetails, The details of the information.\\n', 'Axon Settings Tab': 'Property, Axon Settings Tab Description\\nEnable log forwarding to Axon, Check the box to allow a second copy of the logs collected by the System Monitor to be sent to Axon. Default is unchecked.\\nBase URL of Axon APIs, Enter the Axon base API URL.\\nAPI Key, Enter the Axon API key.\\nTenant ID, Enter the tenant (directory) ID.\\nBatch Size, Enter a value between 1000 and 10000 to specify the size of each batch sent to Axon. Default value is 1000.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Administrator Guide\\n/\\nSystem Monitor\\n/\\nWork With System Monitor Agents\\n/\\nData Processor Pooling\\n', 'Data Processor Pool Manager': \"You must be logged in as an Administrator to take this action.\\nThe Data Processor Pool Manager allows administrators to add, modify, or delete DP pools. To access the Data Processor Pool Manager:\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nData Processor Pool Manager\\n.\\nThe Data Processor Pool Manager window appears showing the following columns:\\nName\\nThe name of the DP\\xa0pool.\\nDescription\\nA brief description of the DP pool.\\nData Processor's Associated\\nThe number of Data Processors in the pool.\\nOn the Tools menu, click\\nAdministration\\n, and then click\\nData Processor Pool Manager\\n.\\nThe Data Processor Pool Manager window appears showing the following columns:\\nName, The name of the DP\\xa0pool.\\nDescription, A brief description of the DP pool.\\nData Processor's Associated, The number of Data Processors in the pool.\\nTo close the Data Processor Pool Manager window, click the red\\nX\\nin the upper-right corner.\\n\", 'Data Processor Pool Manager Actions': 'Right-clicking on a DP pool in the Data Processor Pool Manager window displays the following actions:\\nAction, Description\\nNew, ClickNewtoopen a dialog box where you can create a\\xa0DP pool. Enter a unique name and description, and then clickOk.\\nDelete, Right-click on an existing\\xa0DP pool and then clickDeletetoremove the\\xa0Data Processor pool from the list.Attempting to delete a\\xa0DP pool with associated Data Processors displays an error message.Associated Data Processors must first be removed before the\\xa0DP pool can be deleted.\\nUpdate, Right-click on an existing\\xa0DP pool and then clickUpdatetomake changes.\\nAction\\nDescription\\nRight-click on an existing\\xa0DP pool and then click\\nDelete\\nto\\nremove the\\xa0Data Processor pool from the list.\\nAttempting to delete a\\xa0DP pool with associated Data Processors displays an error message.\\nAssociated Data Processors must first be removed before the\\xa0DP pool can be deleted.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n', 'Filters and Wizards': 'Filtering is used in searches and configuration in many parts of the LogRhythm Client Console, including:\\nPersonal Dashboard Filters\\nInvestigator Wizard\\nTail Wizard\\nReport Wizard\\nAlarm Rule Wizard\\nLog Distribution Services Policy Wizard\\nSecondLook Wizard\\nThe Filter Editor and associated Wizard tabs are used with slight variations in many places in the LogRhythm Client Console.\\xa0This means that not every tab in this topic appears in every situation.\\n', 'Filter Processing Order': 'The order in which you work through the filter editor is not the same as the order in which filters are applied. During processing, the order is:\\nLog Source\\nDay and Time\\nPrimary Criteria\\nInclude Filters\\nExclude Filters\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n', 'General Console Features': '', 'Grid Exports': 'The Export Grid to File feature allows you to export information that appears in various grids throughout the Client Console to a comma separated value (.csv) file. The following areas allow Export to Grid:\\nDeployment Manager Tabs\\nHosts & Host Roles\\nNetworks\\nData Processors\\nSystem Monitors\\nLog Sources\\nLog Processing Policies\\nAlarm Rules\\nPeople\\nHosts & Host Roles\\nNetworks\\nData Processors\\nSystem Monitors\\nLog Sources\\nLog Processing Policies\\nAlarm Rules\\nPeople\\nAnalysis Tools\\nSaved Investigations\\nSaved Tails\\nReport Center\\nReport Templates\\nSaved Investigations\\nSaved Tails\\nReport Center\\nReport Templates\\nReports\\nReport Packages\\nReport Packages\\nOther\\nSaved Lists\\nSaved Applications\\nSaved GLPRs\\nAI Engine Rules\\nKnowledge Base Module Objects\\nAlarm List and Alarm Properties (Alarm Viewer)\\nSaved Lists\\nSaved Applications\\nSaved GLPRs\\nAI Engine Rules\\nKnowledge Base Module Objects\\nKnowledge Base Module Objects\\nAlarm List and Alarm Properties (Alarm Viewer)\\nAlarm List and Alarm Properties (Alarm Viewer)\\nLog Source Acceptance\\nLog Source Acceptance\\nSystem Monitor Acceptance\\nSystem Monitor Acceptance\\nPermissions are based on user visibility to the area. Only users that have access to the Deployment Manager can export the grid to a file for the areas that exist within this location. For items outside Deployment Manager, such as Saved Investigations, users are only able to export public items and items which they own.\\n', 'Crash Reports': 'If the Client Console generates an error, you can generate a Crash Report that captures information regarding the process and events leading to the crash to better enable LogRhythm Support to understand what triggered the crash. This report can provide LogRhythm engineers key details that may lead to the development of a more resilient Client Console.\\nTo generate the Crash Report\\nOn your machine, open\\nWindows Task Manager\\n.\\nClick the\\nProcesses\\ntab.\\nRight-click LogRhythm Console and then select\\nCreate dump file\\n. This process may take some time.\\nWhen the dump file is created, a message appears showing where the file was stored.\\nThe dump file is stored at: C:\\\\Users|Administrator\\\\AppData\\\\Local\\\\Temp\\\\lrconsole.DMP.\\nTo clear the message, click\\nOK\\n.\\nFor further assistance in the investigation into the crash, send the file to\\nLogRhythm Support\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n', 'Layouts': 'Layouts consist of the look and feel for how widgets appear within the Personal Dashboard and Investigate. With LogRhythm Layouts you can create and save multiple layouts within Personal Dashboard and Investigate to best model the needs of the audience, apply layouts at will to show the data in a format suitable to the immediate audience, and define a default that is used when a new view is opened. In addition, for saved investigations, you can specify the layout to use every time that investigation is run.\\n', 'Layouts Menu': '\\nWhen you run Personal Dashboard or Investigator, the Layouts button and menu are available on the main toolbar.\\nThe Layouts menu includes the following information:\\nSave Layout\\nSave Layout As\\nMake/Clear Default\\nReset Layout\\nManage Layouts\\nLayouts.\\nActive Layout\\n. A check mark appears before the name of the active layout.\\nPublic Layouts\\n. Are denoted with the word (public) in parenthesis after the name.\\nDefault Layout\\n. Is denoted by the word (default) in parenthesis after the name.\\nPrivate Layout\\n. Has no label.\\nActive Layout\\n. A check mark appears before the name of the active layout.\\nPublic Layouts\\n. Are denoted with the word (public) in parenthesis after the name.\\nDefault Layout\\n. Is denoted by the word (default) in parenthesis after the name.\\nPrivate Layout\\n. Has no label.\\n', 'Layout Manager Grid': '\\nThe Layout Manager grid contains the following fields:\\nField, Description\\nAction, The check box that indicates which layouts are selected.\\nIs Default, Indicates the default layout. Can be modified directly in the grid or from the Layouts menu in the main toolbar.\\nName, The name given to the layout by the owner.\\nDescription, The description given to the layout by the owner.\\nPermissions, The level of permissions for the layout (Public All or Private).\\nOwner, The person who created the layout.\\nLast Updated On, The date the layout was last updated.\\nLayout ID, Unique identifier for the Layout record.\\nThe level of permissions for the layout (Public All or Private).\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n', 'Lists in the Client Console': 'Lists provide a mechanism for organizing and saving common search criteria used within filters throughout the Application, such as within Investigations, Reports, Alarm Rules, and AI Engine Rules. While many lists are provided by LogRhythm Labs, you can create custom lists for public or private use, and you can publish lists without displaying their contents.\\n', 'Use Cases for Lists': 'You can create a list of SuperUsers and publish it without displaying the contents of the list. An analyst can use the list in an investigation to see if any SuperUser accounts were utilized within a specified time period on specified hosts.\\nYou can create a list of unauthorized software processes. This list can be applied to servers and workstations where LogRhythm Process Monitoring is enabled to detect unauthorized software use.\\nYou can create a list of countries to which inbound network communications should never be allowed. This list can be used in an AI Engine rule to detect inbound connections through the firewall from suspicious locations.\\n', 'List Types': 'List Types are associated with field filters in alarms, searches, and reports. To add a list to a filter, the list type must match the field filter. The following table includes a summary of:\\nList Types\\n. The metadata field for the list.\\nItem Types\\n. The field values that can be used for that type of list.\\nFilter Types Supported\\n. The fields within the filter selection that are supported for the list type. This means that if you select a field within the filter drop down, any lists with the associated list type appear.\\nImport Supported\\n. Whether the list type can have values imported.\\nList Type, Item Types, Filter Types Supported, Import Supported?\\nApplication, Known ServicePortPort RangeProtocolApplication List, Application, N\\nClassification, ClassificationClassification List, Classification, N\\nCommon Event, Common EventCommon Event List, Common Event, N\\nEntity, EntityRoot Entity, Entity, N\\nGeneral Value, String PatternString GeneralValue list, AccountAddress (Sender or Recipient)DomainGroupHostname (I, O/I, O)Message TextObjectOrigin LoginProcessSender, RecipientSessionSubjectURLUser (Login or Account)Vender Msg ID, Y\\nHost, Known HostIPIP RangeHost NameHost List, , Y (with some restrictions)\\nIdentity, Identities, , N\\nIP Address, IP address, Host (I, O/I, O)IP (I, O/I, O), Y\\nIP Range, IP address range, Host (I, O/I, O)IP\\xa0Range (I, O/I, O), Y\\nLocation, LocationLocation List, Location (I, O/I, O), N\\nLog Source, Log SourceLog Source List, N/A, N\\nLog Source Type, Log Source TypeLog Source Type List, Log Source Type, N\\nMPE Rule, MPE RuleMPE Rule List, MPE Rule, N\\nNetwork, NetworkNetwork List, Network (I, O/I, O), N\\nRoot Entity, EntityRoot Entity, Entity, N\\nUser, StringPattern StringAD GroupUser List, AccountUser (Login or Account)Origin Login, Y (users only, no AD groups)\\nKnown Service\\nPort\\nPort Range\\nProtocol\\nApplication List\\nClassification\\nClassification List\\nCommon Event\\nCommon Event List\\nEntity\\nRoot Entity\\nString Pattern\\nString General\\nValue list\\nAccount\\nAddress (Sender or Recipient)\\nDomain\\nGroup\\nHostname (I, O/I, O)\\nMessage Text\\nObject\\nOrigin Login\\nProcess\\nSender, Recipient\\nSession\\nSubject\\nURL\\nUser (Login or Account)\\nVender Msg ID\\nKnown Host\\nIP\\nIP Range\\nHost Name\\nHost List\\nHost (I, O/I, O)\\nIP (I, O/I, O)\\nHost (I, O/I, O)\\nIP\\xa0Range (I, O/I, O)\\nLocation\\nLocation List\\nLog Source\\nLog Source List\\nLog Source Type\\nLog Source Type List\\nMPE Rule\\nMPE Rule List\\nNetwork\\nNetwork List\\nEntity\\nRoot Entity\\nString\\nPattern String\\nAD Group\\nUser List\\nAccount\\nUser (Login or Account)\\nOrigin Login\\n', 'Use Contexts': 'Use contexts are used specifically with the General Value list type. They provide the system with the filter types supported for the General Value list created. This allows the filtering within the Analysis Tools to know what lists should appear for the selected field.\\nThis table shows the Use Context types and associated Filter Types that are supported.\\nUse Context Types, Filter Types Supported\\nAction, Action\\nAddress, Address, Sender or Recipient\\nCommand, Command\\nCVE, CVE\\nDomain Impacted, Domain Impacted\\nDomain Origin, Domain Origin\\nGroup, Group\\nHash, Hash\\nHost Name, Hostname, SHostName, DHostName\\nMAC Address, mac, smac, dmac\\nMessage, Message\\nObject, Object\\nObject Name, Object Name\\nProcess, Process\\nParent Process Id, Parent Process Id\\nParent Process Name, Parent Process Name\\nParent Process Path, Parent Process Path\\nPolicy, Policy\\nProcess, Process\\nReason, Reason\\nResponse Code, Response Code\\nResult, Result\\nSerial Number, Serial Number\\nSession, Session\\nSession Type, Session Type\\nStatus, Status\\nSubject, Subject\\nThreat Id, Threat Id\\nThreat Name, Threat Name\\nURL, URL\\nUser, Account, Login, or User\\nUser Agent, User Agent\\nVendor Info, Vendor Info\\nVendor Message ID, Vendor Message ID\\nFor example, if you select the Process Use Context type for a General Value list, when you perform a filter using the Process field, the General Value list created appears in the list selector.\\n', 'Multi-Type Lists': 'Some list types allow for multi-type lists including Application, Hosts, and Users. These list types allow the user to add values for multiple fields related to its type. When these fields are selected for filtering from within an Analysis Tool, any lists associated with their type can be selected.\\nApplication\\n. The following fields can be used to add values to an Application list:\\nImpacted Known Application\\nTCP/UDP Port (Impacted)\\nTCP/UDP Port Range (Impacted)\\nProtocol\\nHost\\n. The following fields can be used to add values to a Host list:\\nKnown Host\\nIP Address\\nIP Address Range\\nHostname\\nUser\\n. The following fields can be used to add values to a User list. This includes values that are associated with the Account and Origin Login fields.\\nUsername\\nActive Directory Group\\nYou can add a list of specific users by typing in values or you can add a list of users associated with an active directory group.\\n', 'Lists Within Lists': 'Lists are flexible enough to allow you to add a list to another list of a compatible type. The added list is called a sub list. This enables you to create sub lists with elements that are to be shared by other lists,\\xa0rather than having to manage the duplicated items across several lists.\\nLists that can contain other lists raise the possibility of loops, where a nested sub list could ultimately reference an outer containing list. The system makes certain that when lists are processed (such as in creating filters) that each list is only processed once.\\nThe following are not checked:\\nFor nested lists, permission and visibility compatibility is not checked. So, for example, it is possible to add a Private list to a Public list.\\nFor nested General Value lists, compatibility of the Use Contexts is not checked.\\n', 'Permissions': 'All users have access to lists. The permissions can be set to limit access to specific lists.\\nThere are two types of Security Permissions: Custom and System. Custom Security Permissions are created by users. System Permissions are created by LogRhythm and come in two flavors, Private and Public. System Lists are imported with the Knowledge Base. The Knowledge Base Module must be enabled and the module synchronized to see the system list in the list manager. For details on modules, see\\nKnowledge Base Manager\\n.\\nThe Security Permissions are described in the following table.\\nSecurity Permission, Description\\nCustom, Created by users.\\nSystem: Private, This is provided by LogRhythm. The list items and properties are controlled by LogRhythm and synced during a Knowledge Base import. Except for controlling Read Access (visibility), these lists are locked for users.\\nSystem: Public, This is provided by LogRhythm. The list items and some properties can be edited by users. The initial Knowledge Base import initializes the properties. Legacy Log Source Lists are of this type. Some properties, particularly the Items, can be re-synchronized on a Knowledge Base Import.\\nList Security is controlled by Read, Write, and Restricted Read attributes, which are described in the following table.\\nPermission, Description\\nRead Permissions, This controls who can see and use a List, and indirectly controls other permissions. Everyone can create Private lists (the default.)A Global Administrator can assign any permission.A Restricted Administrator can assign Public Analyst permissionsA Global Analyst can assign Public or Global Analyst.Restricted Analysts can only assign Public.System Lists cannot be Private.\\nWrite Permissions, This controls who can edit a List. This is always at least as permissive as the visibility, but never more (example: A List cannot be set to \"read\" for Admins and \"write\" for Public.)Only the list owner or an Admin can change this value.This can be set to any value consistent with the Read Permissions.For System: Private Lists this value is Private and cannot be changed.For System: Public Lists this value is Admins and cannot be changed.\\nRestricted Read, Restricted Read is used to prevent users who do not have Write Permissions to the list from viewing the items on the list; such users can only use the List (such as using it in a Filter).\\nThis controls who can see and use a List, and indirectly controls other permissions. Everyone can create Private lists (the default.)\\nA Global Administrator can assign any permission.\\nA Restricted Administrator can assign Public Analyst permissions\\nA Global Analyst can assign Public or Global Analyst.\\nRestricted Analysts can only assign Public.\\nSystem Lists cannot be Private.\\nOnly the list owner or an Admin can change this value.\\nThis can be set to any value consistent with the Read Permissions.\\nFor System: Private Lists this value is Private and cannot be changed.\\nFor System: Public Lists this value is Admins and cannot be changed.\\n', 'List Manager': 'The List Manager lets you view and manage lists in LogRhythm, including the ability to add and retire lists. Lists are available (with appropriate security permissions) to all users. The menu buttons on the List Manager, from left to right, include Properties, Refresh, and New. The file menu options related to lists include Properties, New, and Clone. The following table describes the columns in the grid of the List Manager.\\nField, Description\\nAction, The check box used in conjunction with the Actions context menu to indicate which lists to include in the action.\\nList Type, The type of list, such as Log Source, General Value, and Host.\\nName, The name of the list.\\nEntry Count, The total number of items and lists that the list contains. If a list contains 10 items and two lists and the Entry Count for the list is 12. The Entry Count value appears for all lists, even if a list is used as a sub list elsewhere in the system.The List Manager highlights system lists that do not contain any items, indicating that the system list has not been populated. Empty custom lists are not highlighted.\\nUse Context, The associated use contexts for the list, such as log source, process, host, and user. It is the same as the type for all but General Values, in which case one or more values appear based on what is selected in the properties.\\nAuto Import, An indicator of whether the import occurs automatically.\\nImport Options, The options selected for importing the list.\\nImport Filename, The name of the file to be imported when the list is used.\\nRestricted Read, The indicator for Restricted Read permissions.\\nDescription, The description of the list.\\nStatus, The status of the list: Active or Retired.\\nLast Updated, The date the list was last updated.\\nRead Access, The Read permissions for the list.\\nWrite Access, The Write permissions for the list.\\nEntity, The Entity with which the list is associated.\\nOwner, The user who created the list. For System lists, the owner appears as N/A.\\nList ID, The unique ID for the list.\\nThe total number of items and lists that the list contains. If a list contains 10 items and two lists and the Entry Count for the list is 12. The Entry Count value appears for all lists, even if a list is used as a sub list elsewhere in the system.\\nThe List Manager highlights system lists that do not contain any items, indicating that the system list has not been populated. Empty custom lists are not highlighted.\\n', 'Automated File Import': 'Lists can be imported by the Job Manager using an automated protocol. The lists follow the same rules as the List Properties Editor and File/Clipboard Import (for details on the rules, see\\nCreate Lists in the Client Console\\n). The Job Manager List Import task runs continuously, polling at frequent intervals for List file changes. If a file with the correct name appears, the task imports the list. The task waits on a writer to the file. It requires exclusive access to the file. After a file has been successfully imported, it is deleted. If an error occurs during import, it is renamed with a suffix of .bad. The status of each list import attempt is written to the log file and event log. The following default rules apply:\\nThe default import directory is config\\\\list_import, relative to the path specified in the Configuration File Parent Directory field in the Job Manager Configuration Manager.\\nThe default processing interval is 60 seconds.\\nThe defaults cannot be changed.\\n', 'Expiration of List Items': \"Under certain circumstances, list items are only needed on a temporary basis. For example, when an employee leaves the company, the IT department might want to monitor the employee's account for 90 days for any activity. Instead of having to manually remove the list item, it can be configured to be automatically removed in 90 days. The time span configured for expiring list items is counted from the time of the list's creation into the future. For example, if a Terminated User Account list was created on March 2nd at 12:00 PM with an expiration time of 10 days, all of the list items entered in the list expire at the same time. The last configured time span is saved when the list is saved. If new items are added to the list 5 days after it was saved, the new list items expire in 10 days from the current day. If the intention was to add more items to the list that needed to expire on the same day as the original items, the day field and the hours and minutes field have to be adjusted before the new items are added to the list.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n', 'Message Processing Engine Rule Builder': 'You use the Message Processing Engine (MPE) Rule Builder to view, create, and edit new MPE base rules and sub-rules. New rules are needed to collect and process logs from any new Log Source Type.\\n', 'Training for Rule Building': 'You can submit a Device Support Request to LogRhythm to have new rules developed by LogRhythm Engineers. Alternatively, you can build MPE Rules yourself; however, it is highly recommended that you attend the rule building training offered by LogRhythm before you attempt to build custom rules. Customers who attend LogRhythm Custom Rules Training have the option of taking the additional two-day Advanced Rule Development class. The class includes hands-on, instructor-led training and class materials that instruct you on how to create rules for your organization. This topic presents a brief overview of the MPE Rule Builder, but is not intended to be a substitute for the Advanced Rule Development training.\\nTo find out more about available training schedules, contact your LogRhythm sales representative.\\n', 'MPE Policies': 'An MPE Policy is a collection of MPE Rules designed for a specific Log Source Type such as Cisco PIX or Windows 2003/2005 Security Event Log. Only Logs that are generated from Log Sources that have an assigned MPE Policy are processed by the MPE.\\nLog Sources can only be:\\nAssigned an MPE Policy associated with the same Log Source Type.\\nAssigned an individual MPE Policy.\\nThe LogRhythm Knowledge Base comes with pre-packaged default MPE Policies for all supported devices. It is the MPE Policy, not the MPE Rule, that determines the data management and event management settings. The MPE Rule sets the default settings for the policy when the Rule is first added.\\nCustom Policies can be tailored to the type of system to which they are assigned. For example, event forwarding settings for security event logs on a file server could be different from those on a domain controller.\\nYou can download MPE rules by going to the\\nLogRhythm Community\\n, clicking on the\\nShareables\\nlink on menu at the top of the page, and then click on the\\nLog Sources\\noption. The filters allow you to choose from supported and unsupported plugins, as well as ones created by LogRhythm or by other users.\\n', 'Base Rules and Sub-Rules': 'The rules used for identifying and processing log messages include:\\nBase Rule\\n. Contains a tagged regular expression (the regex) used to identify the pattern of a log and isolate interesting pieces of metadata. Using a tagging system, these metadata strings can be directed to special fields used by LogRhythm to better interpret a log or specifically identify it. In general, base rules identify log messages by matching the fields to a specific log format or pattern.\\nSub-rule\\n. Differentiates log messages that match the same base rule using values in the log. Sub-rule tags can include a regex that only applies to the string in a specific field to identify information such as a log / event identification number, a message string, or even a user or group name.\\nLogRhythm MPE rules use .NET/C# syntax for writing regular expressions.\\n', 'Examples': \"Here is an example of a log message that might be received via syslog depicting a Microsoft SQL Server authentication.\\n6/18/2007 2:36 PM TYPE=Information USER=NT AUTHORITY\\\\SYSTEM COMP=DBSERVER SORC=MSSQLSERVER CATG=Logon EVID=17055 MESG=18453 : Login succeeded for\\nuser ''NT AUTHORITY\\\\SYSTEM''. Connection: Trusted.\\nThe base rule matching this log is named SQL Server Authentication, and has the following regex:\\nCOMP=(?<dname>[^\\\\s]+)?\\\\s+SORC=mssqlserver\\\\sCATG=.+?EVID=17055\\\\s+MESG=(?<tag1>\\n18453|18454|18455|18456).+?user\\\\s\\\\'([^\\\\\\\\]+?\\\\\\\\)?(?<tag2.login>[^\\\\']+)\\\\'.*+?\\\\\\\\)\\n?(?<tag2.login>[^\\\\']+)\\\\'.*\\nThis base rule matches the pattern of the log and pull the metadata textDBSERVER into the <dname> tag, 18453 into <tag1>, and NT AUTHORITY\\\\SYSTEM into <tag2.login> (which puts the metadata into both the <tag2> and <login> fields).\\nThe sub-rule matching the metadata in those tags is then MS-AppLog Msg 18453: Successful Authentication, which matches when 18453 is in <tag1>, and anything (*) is in the <tag2> field. This sub-rule specifically identifies the occurrence as a successful authentication to a SQL server.\\n\", 'Rule Processing Logic': 'Rules are evaluated in the following order:\\nCustom base rules are always run before system base rules\\nCustom sub-rules are always run before system sub-rules\\nSub-rules where VMID should equal a specific value are always processed before sub-rules where VMID can be any value including system sub-rules\\nProcessing logic for a log:\\nEvaluate log against base rule, if matched.\\nEvaluate log against all sub-rules:\\nIf sub-rule is matched, associate log with sub-rule.\\nIf no sub-rules or no sub-rule match, associate log with base rule unless base rule is a pattern.\\nPattern rules:\\nUse in instances where a log should only match a sub-rule.\\nTo specify a base rule as a pattern, prefix the rule name with “Pattern”.\\nPattern rules are processed differently in the Test Center. To test such rules, rename them without using the prefix \"Pattern.\" Add the \"Pattern\" prefix back when you have finished testing.\\nTo specify a base rule as a pattern, prefix the rule name with “Pattern”.\\nPattern rules are processed differently in the Test Center. To test such rules, rename them without using the prefix \"Pattern.\" Add the \"Pattern\" prefix back when you have finished testing.\\n', 'Base Rule Sorting': 'MPE Base rules are auto-sorted and have the following options\\nCustomers can specify static or auto-sorting for each custom base rule.\\nCustomers can enforce relative ordering for each auto-sorted custom base rule.\\nCustomers can override the relative ordering for each auto-sorted system base rule.\\nCustomers can specify that an auto-sorted custom rule should sort above all system rules.\\nSystem sub-rules and custom sub-rules are statically sorted.\\nThe rule processing order for Base Rules is:\\nCustom Base rules by Sort Order\\nCustom Sub-rules where the value parsed for VMID should be a specific value (i.e., VMID=1001, VMID=1002…) by sort order.\\nAll other Custom Sub-rules by sort order.\\nSystem Base rules by Sort Order:\\nCustom Sub-rules where the value parsed for VMID should be a specific value (i.e., VMID=1001, VMID=1002…) by sort order.\\nSystem Sub-rules where the value parsed for VMID should be a specific value (i.e., VMID=1001, VMID=1002…) by sort order.\\nAll other Custom Sub-rules by sort order.\\nAll other System Sub-rules by sort order\\n', 'Sub-Rule Sorting': 'When using wildcards and Regexes, it is important to understand how their sorting is treated by the MPE. The sort order determines the priority in which a sub-rule is matched. For instance, if you have a sub-rule where all the mapping tags are wildcards, you want to make sure this sub-rule is the last sorted item, because sorting it higher would cause it to always match, and rules below would never be tested for matching. Sorting only affects sub-rules with wildcards and Regexes. Sorting is irrelevant for sub-rules where each mapping tag value is specified since the sub-rule only matches the exact values specified.\\nThe MPE processes rules in the following order:\\nCustom sub-rules where VMID is equal to a specific value.\\nSystem sub-rules where VMID is equal to a specific value.\\nCustom sub-rules where VMID is NOT equal to a specific value.\\nSystem sub-rules where VMID is NOT equal to a specific value.\\n', 'MPE Rule Statuses': 'There are three statuses used in the MPE Rule Builder, which can determine how created MPE rules are applied to log messages.\\nStatus, Description\\nDevelopment, While creating new rules, use the Development status to ensure they are not used to identify log messages while being built.\\nTest/Production, This allows the rule to be applied to log messages by the MPE in the LogRhythm SIEM.Previously, the Test status would not trigger alarms and would automatically disable rules after 1000 log messages were processed. However, the Test status is currently functionally identical to the Production status. MPE rules that are new and undergoing testing can be given the Test status, and once the rules have passed testing and are ready for everyday use, they can be given the Production status.The logs that match the MPE Rule can be displayed on the Dashboard.Custom MPE rules can be edited, even in Production mode; however, System MPE Rules (created by LogRhythm) cannot be edited.Review the scmedsvr.log file for messages about performance issues.\\nThis allows the rule to be applied to log messages by the MPE in the LogRhythm SIEM.\\nPreviously, the Test status would not trigger alarms and would automatically disable rules after 1000 log messages were processed. However, the Test status is currently functionally identical to the Production status. MPE rules that are new and undergoing testing can be given the Test status, and once the rules have passed testing and are ready for everyday use, they can be given the Production status.\\nThe logs that match the MPE Rule can be displayed on the Dashboard.\\nCustom MPE rules can be edited, even in Production mode; however, System MPE Rules (created by LogRhythm) cannot be edited.\\nReview the scmedsvr.log file for messages about performance issues.\\n', 'Parse Fields and Tags': 'The following tables provide lists of all the metadata fields LogRhythm can parse, as well as their associated parsing tags, and default regex. The fields are grouped by how they appear in the Web Console. If you do not see a field in the Web Console in the same tab as this document, you may have tagged the field as a favorite, in which case the field will appear in the Favorites tab instead of the main group tab as shown in this document. If necessary, the default regex can be overridden, as described in Override the Default Regex.\\nAll Mapping and Parsing tags are lower case.\\nField, Description, Tags, Default Regex\\nApplication Tab\\nApplication, Application derived by IANA protocol and port number or directly assigned in MPE processing settings., N/A, N/A\\nObject, The resource (i.e., file) referenced or impacted by activity reported in the log., <object>, \\\\w+\\nObject Name, The descriptive name of the object. Do not use unless Object is also used., <objectname>, \\\\w+\\nObject Type, A category type for the object (e.g., file, image, pdf, etc.)., <objecttype>, \\\\w+\\nHash, The hash value reported in the log. Choose MD5 > Sha1 > Sha256., <hash>, \\\\w+\\nPolicy, The specific policy referenced (i.e., Firewall, Proxy) in a log message., <policy>, \\\\w+\\nResult, The outcome of a command operation or action. For example, the result ofquarantinemight besuccess., <result>, \\\\w+\\nURL, The URL referenced or impacted by activity reported in the log. You may need to override the default regex for URLs that are not HTTP/HTTPS., <url>, https?://.+\\nUser Agent, The User Agent string from web server logs., <useragent>, \\\\w+\\nResponse Code, The explicit and well-defined response code for an action or command captured in a log.Response Code differs from Result in that response code should be well- structured and easily identifiable as a code., <responsecode>, \\\\w+\\nSubject, The subject of an email or the general category of the log., <subject>, \\\\w+\\nVersion, The software or hardware device version described in either the process or object., <version>, \\\\w+\\nCommand, The specific command executed that has been recorded in the log message., <command>, \\\\w+\\nReason, The justification for an action or result when not an explicit policy., <reason>, \\\\w+\\nAction, Field for \"what was done\" as described in the log. Action is usually a secondary function of a command or process., <action>, \\\\w+\\nStatus, The vendor\\'s perspective on the state of a system, process, or entity. Status should NOT be used as the result of an action., <status>, \\\\w+\\nSession Type, The type of session described in the log (e.g., console, CLI, web). Unique from IANA Protocol., <sessiontype>, \\\\w+\\nProcess Name, System or application process described by the log message., <process>, \\\\w+\\nProcess ID, Numeric ID value for a process., <processid>, \\\\d+\\nParent Process ID, The parent process ID of a system or application process that is of interest., <parentprocessid>, \\\\w+\\nParent Process Name, The parent process name of a system or application process., <parentprocessname>, \\\\w+\\nParent Process Path, The full path of a parent process of a system or application process., <parentprocesspath>, \\\\w+\\nQuantity, A numeric count of something. For example, there are 4 lights (quantity is 4)., <quantity>, [0123456789\\\\.]+\\nAmount, The qualitative description of quantity (percentage or relative numbers) For example, half the lights are on (amount is .5 or 50). Amount is also used for currency., <amount>, [0123456789\\\\.]+\\nSize, Numeric description of capacity (e.g., disk size) without a specific unit of measurement. Size is generally used as a limit rather than a current measurement. Use Amount for non- specific measurements., <size>, [0123456789\\\\.]+\\nRate, Defines a number of something per unit of time without a specific unit of measurement. Always expressed as a fraction., <rate>, [0123456789\\\\.]+\\nDuration, The elapsed time reported in a log message, derived from multiple fields. Timestart and Timeend need custom parsing patterns., If log has start/end use: (?<timestart>pattern)(?<timeend>pattern)If log has elapsed time use:<days><hours><minutes><seconds><milliseconds><microseconds><nanoseconds>, [0123456789\\\\.]+Note: Time Start and Time End tags must be overloaded to function properly.\\nSession, Unique user or system session identifier., <session>, \\\\w+\\nKnown Application, Application derived from IANA protocol and port number. If a known application cannot be derived, it is displayed as unknown., N/A, N/A\\nKbytes/Packets Tab\\nHost (Impacted) KBytes RcvdHost (Impacted) KBytes SentHost (Impacted) Kbytes Total, The number of bytes sent or received in the context of the Impacted Host.Rcvd – Bytes received by impacted hostSent – Bytes sent by impacted hostTotal – Total bytes in session as seen by impacted host, Use the appropriate tags based upon the units and direction represented by the log data:<bitsin>, <bitsout><bytesin>, <bytesout><kilobitsin>, <kilobitsout><kilobytesin>, <kilobytesout><megabitsin>, <megabitsout><megabytein>, <megabyteout><gigabitsin>, <gigabitsout><gigabytein>, <gigabyteout><terabitsin>, <terabitsout><terabytesin>, <terabytesout><petabitsin>, <petabitsout><petabytesin>, <petabytesout>,<bits>, <bytes>, <kilobits>,<kilobytes>, <megabits>,<megabytes>, <gigabits>,<gigabytes>, <terabits>,<terabytes>, <petabits>,<petabytes>, [0123456789\\\\.]+\\nHost (Impacted) Packets RcvdHost (Impacted) Packets SentHost (Impacted) Packets Total, The number of packets sent or received in the context of the Impacted Host.Rcvd – Packets received by impacted hostSent – Packets sent by impacted hostTotal – Total packets in session as seen by impacted host, <packetsin>, <packetsout>,<packets>, [0123456789\\\\.]+\\nClassification Tab\\nClassification, Value is determined based on the MPE Rule\\'s assigned Common Event., N/A, N/A\\nCommon Event, Value is determined based on the MPE Rule\\'s Assigned Common Event., N/A, N/A\\nPriority, Value is determined based on the Risk-Based-Priority (RBP) calculation., N/A, N/A\\nDirection, Indicates the directional flow of data between the Origin Host and the Impacted Host — Inbound, Outbound, Internal, External, or Unknown., N/A, N/A\\nSeverity, The vendor\\'s view of the severity of the log., <severity>, \\\\w+\\nVendor Message ID, Specific vendor for the log used to describe a type of event., <vmid>, \\\\w+\\nVendor Info, Description of a specific vendor log or event identifier for the log. Human readable elaboration that directly correlates to the VMID., <vendorinfo>, \\\\w+\\nMPE Rule Name, Name of rule that matched, assigned on rule creation., N/A, N/A\\nThreat Name, The name of a threat described in the log message (e.g., malware, exploit name, signature name). Do not overload with Policy., <threatname>, \\\\w+\\nThreat ID, ID number or unique identifier of a threat. Note that CVE is stored separately., <threatid>, \\\\w+\\nCVE, CVE ID (i.e., CVE-1999-0003) from vulnerability scan data., <cve>, \\\\w+\\nHost Tab\\nHost (Origin), Origin host derived from Origin IP Address and/or Origin Hostname., N/A, N/A\\nHost (Impacted), Impacted host derived from Impacted IP Address and/or Impacted Hostname., N/A, N/A\\nMAC Address (Origin), The MAC address from which activity originated (i.e., attacker, client)., <smac>, (\\\\w{2}(:|-)?){6}\\nMAC Address (Impacted), The MAC address that was affected by the activity (i.e., target, server)., <dmac>, (\\\\w{2}(:|-)?){6}\\nInterface (Origin), The network port/interface from which the activity originated (i.e., attacker, client)., <sinterface>, \\\\w+\\nInterface (Impacted), The network port/interface that was affected by the activity (i.e., target, server)., <dinterface>, \\\\w+\\nIP Address (Origin), The IP address from which activity originated (i.e., attacker, client)., <sip> (parses IPv4 and IPv6), ((?<sipv4>(?<sipv4>1??(1??\\\\d{1,2}|2[0-4]\\\\d|25[0-5])\\\\.(1??\\\\d{1,2}|2[0-4]\\\\d|25[0-5])\\\\.(1??\\\\d{1,2}|2[0-4]\\\\d|25[0-5])\\\\.(1??\\\\d{1,2}|2[0-4]\\\\d|25[0-5])))|(?<sipv6>(?<sipv6>1??((?:(?:[0-9A-Fa-f]{1,4}:){7}[0-9A-Fa-f]{1,4}|(?=(?:[0-9A-Fa-f]{1,4}:){0,7}[0-9A-Fa-f]{1,4}\\\\z)|(([0-9A-Fa-f]{1,4}:){1,7}|:)((:[0-9A-Fa-f]{1,4}){1,7}|:))))))\\nIP Address (Impacted), The IP address that was affected by the activity (i.e., target, server)., <dip> (parses IPv4 and IPv6), ((?<dipv4>(?<dipv4>1??(1??\\\\d{1,2}|2[0-4]\\\\d|25[0-5])\\\\.(1??\\\\d{1,2}|2[0-4]\\\\d|25[0-5])\\\\.(1??\\\\d{1,2}|2[0-4]\\\\d|25[0-5])\\\\.(1??\\\\d{1,2}|2[0-4]\\\\d|25[0- 5])))|(?<dipv6>(?<dipv6>1??((?:(?:[0-9A-Fa-f]{1,4}:){7}[0-9A-Fa-f]{1,4}|(?=(?:[0-9A-Fa-f]{1,4}:){0,7}[0-9A-Fa-f]{1,4}\\\\z)|(([0-9A-Fa- f]{1,4}:){1,7}|:)((:[0-9A-Fa-f]{1,4}){1,7}|:))))))\\nNAT IP Address (Origin), The Network Address Translated (NAT) IP address from which activity originated (i.e., attacker, client)., <snatip>, Same as IP Origin (<sip>)\\nNAT IP Address (Impacted), The Network Address Translated (NAT) IP address that was affected by the activity (i.e., target, server)., <dnatip>, Same as IP Impacted (<dip>)\\nHostname (Origin), The hostname from which activity originated (i.e., attacker, client)., <sname> (or DNS resolved from IP), ([^\\\\s\\\\.]+\\\\.?)+\\nHostname (Impacted), The hostname that was affected by the activity (i.e., target, server)., <dname> (or DNS resolved from IP), ([^\\\\s\\\\.]+\\\\.?)+\\nKnown Host (Origin), A value determined by mapping parsed origin host identifiers, such as IP address or hostname, to a LogRhythm host record., N/A, N/A\\nKnown Host (Impacted), A value determined by mapping parsed impacted host identifiers, such as IP address or hostname, to a LogRhythm host record., N/A, N/A\\nSerial Number, The hardware or software serial number in a log message. This value should be a permanent unique identifier., <serialnumber>, \\\\w+\\nIdentity Tab\\nUser (Origin), The originating user or system account of the activity reported in the log., <login>, \\\\w+\\nUser (Impacted), The user or system account impacted by activity reported in the log., <account>, \\\\w+\\nSender, The sender of an email or the \"caller number\" for a VOIP log. This value must relate to a specific user or unique address in the case of a phone call or email., <sender>, [^\\\\s]+@[^\\\\s]+\\nRecipient, The recipient of an email or the dialed number for a VOIP log., <recipient>, [^\\\\s]+@[^\\\\s]+\\nGroup, The user group or role impacted by activity reported in the log. Do not use for entity group (zone or domain)., <group>, \\\\w+\\nLocation Tab\\nEntity (Origin), A value determined based on the origin host’s assigned entity., N/A, N/A\\nEntity (Impacted), A value determined based on the impacted host’s assigned entity., N/A, N/A\\nZone (Origin), A value determined based on the zone of the origin host — Internal, External, DMZ, or Unknown., N/A, N/A\\nZone (Impacted), A value determined based on the zone of the impacted host — Internal, External, DMZ, or Unknown., N/A, N/A\\nLocation (Origin), A value determined by resolving the parsed origin IP address against a Geo-IP database., N/A, N/A\\nLocation (Impacted), A value determined by resolving the parsed impacted IP address against a Geo-IP database., N/A, N/A\\nCountry (Origin), The country in which the determined origin location exists., N/A, N/A\\nCountry (Impacted), The country in which the determined impacted location exists., N/A, N/A\\nLog Tab\\nLog Date, Timestamp when the log was generated or received, corrected to UTC., N/A, N/A\\nLog Count, The number of identical log messages received., N/A, N/A\\nLog Source Entity, The entity to which the log source belongs., N/A, N/A\\nLog Source Type, The device or application type from which a log was received., N/A, N/A\\nLog Source Host, The origin host from which the log was received., N/A, N/A\\nLog Source, The assigned name of a log source., N/A, N/A\\nLog Sequence Number, The sequence in which a log was collected, generated by the Agent., N/A, N/A\\nLog Message, The raw log message., N/A, N/A\\nFirst Log Date, Timestamp when the first identical log message was received., N/A, N/A\\nLast Log Date, Timestamp when the last identical log message was received., N/A, N/A\\nNetwork Tab\\nNetwork (Origin), A value determined by mapping the origin IP address to a LogRhythm network record., N/A, N/A\\nNetwork (Impacted), A value determined by mapping the impacted IP address to a LogRhythm network record., N/A, N/A\\nDomain (Impacted), The Windows or DNS domain name referenced or impacted by activity reported in the log., <domain> or <domainimpacted>, \\\\w+\\nDomain (Origin), The Windows or DNS domain where the logged activity originated., <domainorigin>, \\\\w+\\nProtocol, The IANA protocol name or number., <protnum>,<protname>, 1??\\\\d{1,2}|2[0-4]\\\\d|25[0-5]\\\\w+\\nTCP/UDP Port (Origin), The port from which activity originated (i.e., client, attacker port)., <sport>, \\\\d+\\nTCP/UDP Port (Impacted), The port to which activity was targeted (i.e., server, target port)., <dport>, \\\\d+\\nNAT TCP/UDP Port(Origin), The Network Address Translated (NAT) port from which activity originated (i.e., client, attacker port)., <snatport>, \\\\d+\\nNAT TCP/UDP Port(Impacted), The Network Address Translated (NAT) port to which activity was targeted (i.e., server, target port)., <dnatport>, \\\\d+\\nApplication\\nApplication derived by IANA protocol and port number or directly assigned in MPE processing settings.\\nN/A\\nN/A\\nObject\\nThe resource (i.e., file) referenced or impacted by activity reported in the log.\\n<object>\\n\\\\w+\\nObject Name\\nThe descriptive name of the object. Do not use unless Object is also used.\\n<objectname>\\n\\\\w+\\nObject Type\\nA category type for the object (e.g., file, image, pdf, etc.).\\n<objecttype>\\n\\\\w+\\nHash\\nThe hash value reported in the log. Choose MD5 > Sha1 > Sha256.\\n<hash>\\n\\\\w+\\nPolicy\\nThe specific policy referenced (i.e., Firewall, Proxy) in a log message.\\n<policy>\\n\\\\w+\\nResult\\nThe outcome of a command operation or action. For example, the result of\\nquarantine\\nmight be\\nsuccess\\n.\\n<result>\\n\\\\w+\\nURL\\nThe URL referenced or impacted by activity reported in the log. You may need to override the default regex for URLs that are not HTTP/HTTPS.\\n<url>\\nhttps?://.+\\nUser Agent\\nThe User Agent string from web server logs.\\n<useragent>\\n\\\\w+\\nResponse Code\\nThe explicit and well-defined response code for an action or command captured in a log.\\nResponse Code differs from Result in that response code should be well- structured and easily identifiable as a code.\\n<responsecode>\\n\\\\w+\\nSubject\\nThe subject of an email or the general category of the log.\\n<subject>\\n\\\\w+\\nVersion\\nThe software or hardware device version described in either the process or object.\\n<version>\\n\\\\w+\\nCommand\\nThe specific command executed that has been recorded in the log message.\\n<command>\\n\\\\w+\\nReason\\nThe justification for an action or result when not an explicit policy.\\n<reason>\\n\\\\w+\\nAction\\nField for \"what was done\" as described in the log. Action is usually a secondary function of a command or process.\\n<action>\\n\\\\w+\\nStatus\\nThe vendor\\'s perspective on the state of a system, process, or entity. Status should NOT be used as the result of an action.\\n<status>\\n\\\\w+\\nSession Type\\nThe type of session described in the log (e.g., console, CLI, web). Unique from IANA Protocol.\\n<sessiontype>\\n\\\\w+\\nProcess Name\\nSystem or application process described by the log message.\\n<process>\\n\\\\w+\\nProcess ID\\nNumeric ID value for a process.\\n<processid>\\n\\\\d+\\nParent Process ID\\nThe parent process ID of a system or application process that is of interest.\\n<parentprocessid>\\n\\\\w+\\nParent Process Name\\nThe parent process name of a system or application process.\\n<parentprocessname>\\n\\\\w+\\nParent Process Path\\nThe full path of a parent process of a system or application process.\\n<parentprocesspath>\\n\\\\w+\\nQuantity\\nA numeric count of something. For example, there are 4 lights (quantity is 4).\\n<quantity>\\n[0123456789\\\\.]+\\nAmount\\nThe qualitative description of quantity (percentage or relative numbers) For example, half the lights are on (amount is .5 or 50). Amount is also used for currency.\\n<amount>\\n[0123456789\\\\.]+\\nSize\\nNumeric description of capacity (e.g., disk size) without a specific unit of measurement. Size is generally used as a limit rather than a current measurement. Use Amount for non- specific measurements.\\n<size>\\n[0123456789\\\\.]+\\nRate\\nDefines a number of something per unit of time without a specific unit of measurement. Always expressed as a fraction.\\n<rate>\\n[0123456789\\\\.]+\\nDuration\\nThe elapsed time reported in a log message, derived from multiple fields. Timestart and Timeend need custom parsing patterns.\\nIf log has start/end use: (?<timestart>\\npattern)\\n(?<timeend>\\npattern)\\nIf log has elapsed time use:\\n<days>\\n<hours>\\n<minutes>\\n<seconds>\\n<milliseconds>\\n<microseconds>\\n<nanoseconds>\\n[0123456789\\\\.]+\\nNote: Time Start and Time End tags must be overloaded to function properly.\\nSession\\nUnique user or system session identifier.\\n<session>\\n\\\\w+\\nKnown Application\\nApplication derived from IANA protocol and port number. If a known application cannot be derived, it is displayed as unknown.\\nN/A\\nN/A\\nHost (Impacted) KBytes Rcvd\\nHost (Impacted) KBytes Sent\\nHost (Impacted) Kbytes Total\\nThe number of bytes sent or received in the context of the Impacted Host.\\nRcvd – Bytes received by impacted host\\nSent – Bytes sent by impacted host\\nTotal – Total bytes in session as seen by impacted host\\nUse the appropriate tags based upon the units and direction represented by the log data:\\n<bitsin>, <bitsout>\\n<bytesin>, <bytesout>\\n<kilobitsin>, <kilobitsout><kilobytesin>, <kilobytesout><megabitsin>, <megabitsout>\\n<megabytein>, <megabyteout><gigabitsin>, <gigabitsout><gigabytein>, <gigabyteout>\\n<terabitsin>, <terabitsout><terabytesin>, <terabytesout><petabitsin>, <petabitsout>\\n<petabytesin>, <petabytesout>,<bits>, <bytes>, <kilobits>,<kilobytes>, <megabits>,\\n<megabytes>, <gigabits>,<gigabytes>, <terabits>,<terabytes>, <petabits>,<petabytes>\\nHost (Impacted) Packets Rcvd\\nHost (Impacted) Packets Sent\\nHost (Impacted) Packets Total\\nThe number of packets sent or received in the context of the Impacted Host.\\nRcvd – Packets received by impacted host\\nSent – Packets sent by impacted host\\nTotal – Total packets in session as seen by impacted host\\n<packetsin>, <packetsout>,\\nVendor Message ID\\nHost (Origin)\\nIP Address (Origin)\\nThe IP address from which activity originated (i.e., attacker, client).\\n((?<sipv4>(?<sipv4>1??(1\\n??\\\\d{1,2}|2[0-4]\\\\d|25[0-\\n5])\\\\.(1??\\\\d{1,2}|2[0-\\n4]\\\\d|25[0-\\n5])\\\\.(1??\\\\d{1,2}|2[0-\\n4]\\\\d|25[0-\\n5])\\\\.(1??\\\\d{1,2}|2[0-\\n4]\\\\d|25[0-\\n5])))|(?<sipv6>(?<sipv6>1\\n??((?:(?:[0-9A-Fa-\\nf]{1,4}:){7}[0-9A-Fa-\\nf]{1,4}|(?=(?:[0-9A-Fa-\\nf]{1,4}:){0,7}[0-9A-Fa-\\nf]{1,4}\\\\z)|(([0-9A-Fa-\\nf]{1,4}:){1,7}|:)((:[0-9A-Fa-\\nf]{1,4}){1,7}|:))))))\\n((?<dipv4>(?<dipv4>1??(\\n1??\\\\d{1,2}|2[0-4]\\\\d|25[0-\\n5])\\\\.(1??\\\\d{1,2}|2[0-\\n4]\\\\d|25[0-\\n5])\\\\.(1??\\\\d{1,2}|2[0-\\n4]\\\\d|25[0-\\n5])\\\\.(1??\\\\d{1,2}|2[0-\\n4]\\\\d|25[0- 5])))|(?<dipv6>(?<dipv6>1\\n??((?:(?:[0-9A-Fa-\\nf]{1,4}:){7}[0-9A-Fa-\\nf]{1,4}|(?=(?:[0-9A-Fa-\\nf]{1,4}:){0,7}[0-9A-Fa-\\nf]{1,4}\\\\z)|(([0-9A-Fa- f]{1,4}:){1,7}|:)((:[0-9A-Fa-\\nf]{1,4}){1,7}|:))))))\\nNAT IP Address (Origin)\\nUser (Origin)\\nEntity (Origin)\\nA value determined based on the zone of the origin host — Internal, External, DMZ, or Unknown.\\nLog Date\\nNetwork (Origin)\\n<domain> or <domainimpacted>\\n<protnum>,<protname>\\n1??\\\\d{1,2}|2[0-4]\\\\d|25[0-5]\\n\\\\w+\\nNAT TCP/UDP Port\\n(Origin)\\nNAT TCP/UDP Port\\n(Impacted)\\n', 'Map Tags': 'Five additional tags are available for identifying data in the log specifically for sub-rules. These tags do not parse text into metadata fields, so they do not appear in Investigations, Reports, and so on. These tags are intended only to identify portions of the log message that should be used in the development of sub-rules.\\nTag, Field Type, Default Regex\\n<tag1>, Text, .*\\n<tag2>, Text, .*\\n<tag3>, Text, .*\\n<tag4>, Text, .*\\n<tag5>, Text, .*\\n', 'Override the Default Regex': 'The default regex is applied by using only the named group tag. For example, <account> will apply the regex pattern \\\\w+ in the rule, as shown in the table above.\\nIf the default regex for a parsing tag will not properly parse the correct data out of the log message or is not the optimal regex from a performance perspective, the default should be overridden. To override the default regex, the following syntax should be used:\\nFor example, suppose your regex needs to match file names with a specific extension such as the sample log message below:\\nIf the base rule was written as:\\nThe value parsed for login would be john and the value for object would be AnnualReport. This is due to the fact that a period is not a word character and the default regex of “\\\\w+” would only match up to the period. Instead, the default regular expressions should be overridden, and the base rule should be:\\nNow, the base rule will parse anything for login starting with a word character that optionally contains a period followed by additional word characters.\\nDo not override the default regex for fields which parse an IP address, such as <sip>, <dip>, <sipv6>, and so on.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n', 'Monitor, Search, and Analysis': 'Monitoring, searching, and analyzing are done through a number of features in the Client Console. These include:\\nAlarm Viewer\\nInvestigator\\nPersonal Dashboard\\nQuick Search Toolbar\\nTail\\nTopX Analysis\\nIn addition, the following tools assist with further using these monitoring, searching, and analyzing features.\\n', 'Tool Selector': 'Monitoring and searching the system for logs is done with the Tool Selector. It provides a user-friendly method to manage the many views of Personal Dashboard and Investigator. In the system layout, it is docked at the left of the window. The Tool Selector is specific to the Tool in which it resides.\\nTo unpin the Tool Selector, click the pin icon in the upper-right corner of the Tool Selector so that the point faces left. This collapses the Tool Selector so that it is a tab along the left that you can then open to see the groups and views.\\nTo pin the Tool Selector, click the pin icon in the upper-right corner of the Tool Selector so that it appears to be pointing down into the screen. This keeps the Tool Selector visible while working within the tool.\\nThe Tool Selector has four groups of views. Each group is encapsulated in a box that can be collapsed or expanded by clicking the arrow at the right of the header. Views that are open and displayed within the window are listed in bold within the group. Views that are not open and displayed within the window will be listed in regular text (not bold).\\nTo bring a view into the window, select it within the group box. It changes to bold and is brought forth as the active displayed view within the window.\\nTo remove a view from the window, select it within the group box. It changes from bold to regular text and is removed from the tabs of available views within the window.\\n', 'Context Menus': 'LogRhythm provides several tools to search and retrieve log data. After your search results appear, right-click to access additional options in the following locations:\\nInvestigate\\n. Log / Event Analyzer and Log Viewer tabs\\nLog Miner\\n. Aggregate Log Messages section\\nTail\\n. Aggregate Log/Event List section, Log/Event List section\\nPersonal Dashboard\\n. Aggregate Event List section\\nThese are the options in the context menus of LogRhythm search tools. Not all options are found in every menu.\\nContext Menu Option, Description\\nSelect All, Select all search results.\\nCheck All, Select the Action check box for all search results.\\nCheck All Displayed, Select the Action check box for all displayed search results.\\nUncheck All -> Check All Displayed, Clear the Action check box for all rows, then select the Action check box for just the rows that are displayed.\\nUncheck All, Clear the Action check box for all search results.\\nUncheck All Displayed, Clear the Action check box for all displayed results.\\nAction, Remove Selected LogsRemove All But Selected LogsFilter In Selected LogsFilter Out Selected LogsInvestigate Sample of Selected LogsInvestigate Selected Logs\\nReport, Open the Report Wizard where you can run reports with the selected search results as input.\\nExport the Grid to a File, Export grid to a csv file.\\nChart Events, Toggle the graph between Logs and Events.\\nCopy Selected Logs to Rule Builder, Access the MPE Rule Builder with populate the Test Center tab.\\nCopy Selected Logs to Rule Builder and Load Rule, Access the MPE Rule Builder and load with data in the Test Center tab\\nExport All Logs, Export all logs via the LogRhythm Log Exporter.\\nExport Selected Logs, Export all logs via the LogRhythm Log Exporter.\\nSend All Logs, Display the Log Submission Tool that will guide you through sending all logs in the search results to LogRhythm support.\\nSend Selected Logs, Display the Log Submission Tool that will guide you through sending the selected logs in the search results to LogRhythm support.\\nEdit Event Settings, Display the Edit Policy Event Settings window.\\nCreate an Alarm Rule, Create an alarm rule using information in the log message.\\nCreate a GLPR, Create Global Log Processing Rule (GLPR) rule using information in the log message.\\nContextualize, Access information about hosts, ports, or users associated with a log or event.\\nCorrelate, Narrow the displayed search results even further based on the selected log or event.\\nAI\\xa0Engine Search and Drill Down, Drill down on selected logs with the AI Engine Event Drill Down Manager.\\nAdd Values to a List, Add selected values to a list.\\nCopy Values to Clipboard, Add selected values to the clipboard.\\nAdd Origin Host as Known Host, Add the origin host of the selected log to an entity.\\nAdd Impacted Host as Known Host, Add the impacted host of the selected log to an entity.\\nGrid Properties, Select which aggregate log fields to include in the grid.\\nRemove Selected Logs\\nRemove All But Selected Logs\\nFilter In Selected Logs\\nFilter Out Selected Logs\\nInvestigate Sample of Selected Logs\\nInvestigate Selected Logs\\nSelect which aggregate log fields to include in the grid.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n', 'My LogRhythm': 'The My LogRhythm menu provides access to several tools that allow you to modify preferences, settings, and records in LogRhythm that are unique to you.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n', 'Report Center': 'The LogRhythm installation includes predefined templates, reports, and Report Packages which are sets of reports that pertain to a single topic such as security compliance standards, usage auditing, or LogRhythm diagnostics. The following tasks can be performed from the Report Center:\\nGenerate a report from a predefined report format included in the LogRhythm installation.\\nGenerate a group of reports (a report package) from a predefined Report Package format included in the LogRhythm installation.\\nGenerate a report from a custom format.\\nCopy, import, and export reports.\\nCreate a custom template.\\nImport a custom report logo.\\nNew and updated reports are loaded with the updated Knowledge Base. You must have administrative privileges to import a Knowledge Base.\\n', 'Report Templates': 'A report template defines the report format including the columns, group order, and sort order. The report configuration defines the data that is included in the report. All available report templates are listed on the Report Templates tab of the Report Center page. The table below describes the columns that appear in the Report Template grid.\\nColumn, Description\\nTemplate Type, Category of Report TypeAlarm and Response Report. Alarms and related events.Audit Log Report. Auditing activity events by user and date.Executive Report. Trending information for executive/management analysis.Log Detail Report. Raw logs and/or parsed metadata.Log Management Statistics Report.Log Summary Report. Summarized data.\\nName, The Name of the template.\\nPM, When selected, the Platform Manager is available for selection as an input source at in the Report Wizard.\\nDP, When selected, the Data Processor is available for selection as an input source at in the Report Wizard.\\nLogMart, When selected, the LogMart is available for selection as an input source at in the Report Wizard.\\nFields Included, A list of the data fields that define the columns in the Report.\\nField Grouping and Operations, Governs how the report data is grouped and sorted in the report.\\nDescription, A report definition.\\nPermissions, Determines who can view and generate reports: Private, Public All Users, Public Global Analysts, and Public Global Administrators.\\nOwner, Displays who owns the reports.\\nDate Updated, Displays the date and time the report was last updated.\\nVersion, Displays the Version in which the report was updated.\\nID, A system-generated identification number.\\nCategory of Report Type\\nAlarm and Response Report\\n. Alarms and related events.\\nAudit Log Report\\n. Auditing activity events by user and date.\\nExecutive Report\\n. Trending information for executive/management analysis.\\nLog Detail Report\\n. Raw logs and/or parsed metadata.\\nLog Management Statistics Report\\n.\\nLog Summary Report\\n. Summarized data.\\n', 'Report Permissions': 'There are four categories of permissions for reports:\\nPrivate\\n. Only the owner can run or edit the report.\\nPublic All Users\\n. Only Global Administrators or the owner can edit the report, but everyone can run it.\\nPublic Global Analysts\\n. Only Global Administrators or the owner can edit the report, but everyone except standard Restricted Analysts can run it.\\nPublic Global Administrator.\\nOnly Global Administrators or the owner can edit the report, but everyone except standard Restricted Analysts and Global Analysts can run it.\\nRestricted Analysts with elevated permissions have access to more functions than do standard Restricted Analysts. For more information, see\\nModify User Profile Management Permissions\\n.\\nPublic Global Administrator.\\nOnly Global Administrators or the owner can edit the report, but everyone except standard Restricted Analysts and Global Analysts can run it.\\nRestricted Analysts with elevated permissions have access to more functions than do standard Restricted Analysts. For more information, see\\nModify User Profile Management Permissions\\n.\\n', 'Permissions Table for Custom Reports: Report Permission Level vs. User Role': 'User Role, Private, Public All Users, Public Global Analysts, Public Global Administrators\\nOwner, Full, Full, Full, Full\\nRestricted Analyst, None, Run/View, None, None\\nGlobal Analyst, None, Run/View, Run/View, None\\nGlobal Administrator, None, Full, Full, Full\\n', 'Permissions Table for System Reports: Report Permission Level vs. User Role': 'User Role, Public All Users, Public Global Analysts, Public Global Administrators\\nRestricted Analyst, Run/View, None, None\\nGlobal Analyst, Run/View, Run/View, None\\nGlobal Administrator, Run/View, Run/View, Run/View\\nIf you change the Authorized User Profiles after a report has been run, users with newly granted access cannot see the report in the Web Console. You must run the report again for it to be visible to the new user profiles.\\n', 'Report Data Sources': 'Understanding how data is retrieved, from where, and what state it is in helps determine which template to use.\\nIn LogRhythm, all dates are stored in Greenwich Mean Time (GMT). LogMart dates use whole hour resolution. Activity occurring between the start and the end of the hour is recorded as occurring on the hour. For example, a log entry dated 1/1/10 3:34:33 PM would be associated with the aggregated occurrence record dated 1/1/10 3:00:00 PM.\\nBecause LogMart occurrences are aggregated by the hour, reports contain results within whole hours. For example, a report run 1/1/10 5:30 AM GMT thru 1/1/10 5:30 PM GMT will actually contain results on or after 1/1/10 6:00 AM GMT and prior to 1/1/10 6:00 PM GMT.\\n', 'Manage Reporting Memory': 'If a report query causes Client Console memory usage to exceed the threshold, then the report is rendered with partial data and the label (Sample Dataset) is added to the title page footer:\\nReport prepared for LogRhythm Inc. on 1/28/11 2:00 PM MST (GMT-07:00) (Sample Dataset)\\nThe reporting memory can be set from 0-100%. When set to 100%, the behavior is identical to LogRhythm 6.0 memory management.\\nThe amount of application memory available to the Client Console is different for 32-bit versus 64-bit systems because 32-bit systems can only access the first 1 GB of memory.\\nMaximum application memory:\\nLogRhythm Client Console (32-bit) = 1 GB\\nLogRhythm Client Console (64-bit) = installed physical memory\\nFor example, if 8 GB RAM is installed and the reporting memory threshold is set to 50%, the following amount of memory is available:\\nLogRhythm Client Console (32-bit) = 0.5 GB report memory threshold\\nLogRhythm Client Console (64-bit) = 4.0 GB report memory threshold\\nTo adjust these values, use the Report Center tab in\\nMy Preferences\\n.\\n', 'ARM and Job Manager Memory Allocation': 'The memory allocation can be distributed between the ARM and the Job Manager. In the ARM Advanced Properties settings, MaxServiceMemory has been replaced with two properties:\\nMaxServiceMemory_ARM. Range 512-64000 MB; Default 2048 MB\\nMaxServiceMemory_JobManager. Range 512-64000 MB; Default 2048 MB\\n', 'Maximum Errors per Job Package': 'Reports can be run individually or in packages. If one of more individual reports are selected, Report Center bundles the reports into an ad hoc package. Errors can occur due to factors such as connections, permissions, and timeouts.\\nIn the ARM Advanced Properties settings, the maximum number of errors per job package can be adjusted:\\nSRE_MaxErrorsPerJobPackage. Range 1-100; Default 5\\nAfter the limit has been reached, the package is stopped.\\n', 'Large Deployments': 'In some large deployments, where scheduled reports are not finishing or timing out, the following settings may be effective at preventing timeouts. First, stagger multiple schedule report jobs so one does not cancel out the other when it executes, and ensure run time does not conflict with the LogRhythm nightly maintenance. By default, each report can take as much as 600 seconds to complete, and nightly maintenance begins at 1 AM every day.\\nNightly database maintenance jobs may take hours to run.\\nFor example, schedule your first report package to start execution at 3 AM, and allow more than 600 seconds (for each report within the package) before scheduling your second package. If your first package has six reports in it, your second report package should be scheduled to start 3600 seconds, or one hour, later.\\nIf the above does not solve your problem, consider changing the following\\nadvanced properties on the Platform Manager\\n, and recalculate the time needed between report package scheduled execution time:\\nSRE_QueryCommandTimeout. Change to 1800 seconds.\\nSRE_MaxErrorsPerJobPackage. Change from 3 to 1.\\nThe SQL Server remote query timeout, which is 600 seconds or 10 minutes by default, is also taken into account. To view this setting, start SQL Server Management Studio, right-click the EMDB host in Object Explorer, and then click Properties. Click the Connections page, and the timeout value can be found under Remote server connections on the right.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nFilters and Wizards\\n', 'Use Filter Modes': 'Items and Item Types in filters can be included (Filter In) or excluded (Filter Out).\\nFrom the feature you want to add a filter to, select an option in the Add New Field Filter.\\nClick\\nEdit Values\\n.\\nSelect one of the following:\\nTo include all matching values, select\\nFilter In (Is)\\n.\\nWhen Filter In (Is) is selected, the option to Filter in Null Values appears. If you want to include events when the field option is blank, select the\\nFilter in Null Values?\\ncheck box.\\nTo exclude all matching values, select\\nFilter Out (Is Not)\\n.\\nWhen Filter Out is selected, the option to Filter out Null Values appears. If you want to exclude events when the field option is blank, select the\\nFilter out Null values?\\ncheck box.\\nTo include all matching values, select\\nFilter In (Is)\\n.\\nWhen Filter In (Is) is selected, the option to Filter in Null Values appears. If you want to include events when the field option is blank, select the\\nFilter in Null Values?\\ncheck box.\\nTo exclude all matching values, select\\nFilter Out (Is Not)\\n.\\nWhen Filter Out is selected, the option to Filter out Null Values appears. If you want to exclude events when the field option is blank, select the\\nFilter out Null values?\\ncheck box.\\nAdd an Item or List, and then click\\nOK\\n.\\nYou can also edit the Filter Mode from the Add New Field Filter dialog box by selecting a different option in the Filter Mode column in the grid.\\nYou can also add a filter on the selected fields by clicking the Add List button in the common Field Filter Values popup window. This popup window is displayed wherever you can apply filters like Investigation, Tail, Alarm Rules, AI Engine, etc.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nFilters and Wizards\\n', 'Use Multi-Type Filters': 'Multi-type filter fields allow you to add values for multiple item types that are related. When these field filters are selected, an Item type list is available that allows you to specify values to add to the filter.\\nFrom the feature you want to add a filter to, select a multi-type option in the Add New Field Filter.\\nApplication\\nHost\\nUser\\nApplication\\nHost\\nUser\\nSelect one Item type, and then configure any required fields. The item types are:\\nApplication\\nKnown Application\\nTCP/UDP Port (Impacted)\\nTCP/UDP Port Range (Impacted)\\nProtocol\\nHosts\\nKnown Host\\nIP Address\\nIP Address Range\\nHostname\\nMAC Address\\nNAT IP Address\\nNAT IP Address Range\\nUsers\\nUsername\\nActive Directory Group\\nApplication\\nKnown Application\\nTCP/UDP Port (Impacted)\\nTCP/UDP Port Range (Impacted)\\nProtocol\\nKnown Application\\nTCP/UDP Port (Impacted)\\nTCP/UDP Port Range (Impacted)\\nProtocol\\nHosts\\nKnown Host\\nIP Address\\nIP Address Range\\nHostname\\nMAC Address\\nNAT IP Address\\nNAT IP Address Range\\nKnown Host\\nIP Address\\nIP Address Range\\nHostname\\nMAC Address\\nNAT IP Address\\nNAT IP Address Range\\nUsers\\nUsername\\nActive Directory Group\\nUsername\\nActive Directory Group\\nClick\\nAdd Item\\n.\\nRepeat the process as many times as necessary to add other Item Types.\\nClick\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nFilters and Wizards\\n', 'Use Multiple Filters': 'When adding multiple filters, you can select operators to set relationships among them.\\nFrom the feature you want to add a filter to, select an option in the Add New Field Filter.\\nClick\\nEdit Values\\n.\\nAdd Items or Lists, and then click\\nOK\\n.\\nAdd a second Field Filter.\\nBoth filters now appear in the grid in the Add New Field Filter dialog box.\\nIn the Operator column, select the operator you need.\\nOperator\\nBehavior\\nAND\\nAll criteria before and after the AND operator must be met.\\nOR\\nEither the criteria before or after the OR must be met.\\nAND PREVIOUS\\nAll criteria after the AND PREVIOUS operator must be met. In addition, all criteria before the AND PREVIOUS but after an AND/OR operator must be met.\\nOR PREVIOUS\\nOne or more criteria after the OR PREVIOUS operator must be met. Alternatively, any criteria before the OR PREVIOUS but after an AND/OR operator can be met.\\nIn the Operator column, select the operator you need.\\nOperator, Behavior\\nAND, All criteria before and after the AND operator must be met.\\nOR, Either the criteria before or after the OR must be met.\\nAND PREVIOUS, All criteria after the AND PREVIOUS operator must be met. In addition, all criteria before the AND PREVIOUS but after an AND/OR operator must be met.\\nOR PREVIOUS, One or more criteria after the OR PREVIOUS operator must be met. Alternatively, any criteria before the OR PREVIOUS but after an AND/OR operator can be met.\\n(Optional)\\nAdd more field filters as necessary and configure the operators. Operators included in searches and filters are validated and must meet the following rules to be run.\\nAn expression can contain unlimited AND or OR operators, but all operators must be one or the other:\\nVALID: a AND b AND c AND d\\nVALID: a OR b OR c OR d\\nINVALID a AND b OR c\\nAND PREVIOUS cannot immediately follow OR PREVIOUS:\\nVALID: a AND PREVIOUS b AND PREVIOUS c\\nINVALID: a OR PREVIOUS b AND PREVIOUS c\\nOR PREVIOUS cannot immediately follow AND PREVIOUS:\\nVALID: a OR PREVIOUS b OR PREVIOUS c\\nINVALID: a AND PREVIOUS b OR PREVIOUS c\\nValid expressions are show in the following table.\\nLogRhythm Expression\\nExpression As Compiled\\na AND b AND c\\na AND b AND c\\na OR b OR c\\na OR b OR c\\na AND b OR PREVIOUS c OR PREVIOUS d\\na AND (b OR c OR d)\\na OR b AND PREVIOUS c AND PREVIOUS d\\na OR (b AND c AND d)\\nAn expression can contain unlimited AND or OR operators, but all operators must be one or the other:\\nVALID: a AND b AND c AND d\\nVALID: a OR b OR c OR d\\nINVALID a AND b OR c\\nVALID: a AND b AND c AND d\\nVALID: a OR b OR c OR d\\nINVALID a AND b OR c\\nAND PREVIOUS cannot immediately follow OR PREVIOUS:\\nVALID: a AND PREVIOUS b AND PREVIOUS c\\nINVALID: a OR PREVIOUS b AND PREVIOUS c\\nVALID: a AND PREVIOUS b AND PREVIOUS c\\nINVALID: a OR PREVIOUS b AND PREVIOUS c\\nOR PREVIOUS cannot immediately follow AND PREVIOUS:\\nVALID: a OR PREVIOUS b OR PREVIOUS c\\nINVALID: a AND PREVIOUS b OR PREVIOUS c\\nVALID: a OR PREVIOUS b OR PREVIOUS c\\nINVALID: a AND PREVIOUS b OR PREVIOUS c\\nValid expressions are show in the following table.\\nLogRhythm Expression, Expression As Compiled\\na AND b AND c, a AND b AND c\\na OR b OR c, a OR b OR c\\na AND b OR PREVIOUS c OR PREVIOUS d, a AND (b OR c OR d)\\na OR b AND PREVIOUS c AND PREVIOUS d, a OR (b AND c AND d)\\nWhen you are finished adding all field filters you need, click\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nFilters and Wizards\\n', 'Use Search Strings with Filters': 'Some filter selections require that you enter a search string. For example, you can filter for a specific email recipient, email sender, or host name.\\nFrom the feature you want to add a filter to, select an option in the Add New Field Filter.\\nClick\\nEdit Values\\n.\\nIn the Add Item field, type the string you want to find. LogRhythm filters support the wildcard characters shown in the following table.\\nWildcard\\nUsage\\n%\\nMatch zero characters, single characters, or any string.\\nFind all records that contain\\nyou\\n= %you% - Default, you do not have to type in the wildcards\\nFind all records that start with\\nyou\\n= you%\\nFind all records that end with\\nyou\\n= %you\\n*\\nMatch zero characters, single characters, or any string.\\xa0 Same as %.\\nFind all records that start with\\nyou\\n= you*\\nFind all records that end with\\n‘me\\n’ = *me\\n_\\nUnderscore\\nMatch any single character.\\nFind all five-letter records that start with\\na\\nand end with\\nz\\n= a_____z\\n[ ]\\nMatch any character within the brackets or in the range defined within the brackets.\\nFind all records that end with\\na\\n,\\nm\\n, or\\nz\\n= *[amz]\\nFind all records that start with\\na\\n,\\nb\\n,\\nc\\n, or\\nd\\n= [a-d]*\\nFind all records that contain\\na\\n,\\nm\\n, or\\nz\\n= *[amz]*\\n[^]\\nMatch any character that is NOT in the brackets or NOT in the range defined within the brackets.\\nFind all records that do NOT contain\\na\\n= [^a]\\nFind all records that are NOT between\\na\\nand\\nx\\n= [^a-x]\\nIn the Add Item field, type the string you want to find. LogRhythm filters support the wildcard characters shown in the following table.\\nWildcard, Usage\\n%, Match zero characters, single characters, or any string.Find all records that containyou= %you% - Default, you do not have to type in the wildcardsFind all records that start withyou= you%Find all records that end withyou= %you\\n*, Match zero characters, single characters, or any string.\\xa0 Same as %.Find all records that start withyou= you*Find all records that end with‘me’ = *me\\n_, UnderscoreMatch any single character.Find all five-letter records that start withaand end withz= a_____z\\n[ ], Match any character within the brackets or in the range defined within the brackets.Find all records that end witha,m, orz= *[amz]Find all records that start witha,b,c, ord= [a-d]*Find all records that containa,m, orz= *[amz]*\\n[^], Match any character that is NOT in the brackets or NOT in the range defined within the brackets.Find all records that do NOT containa= [^a]Find all records that are NOT betweenaandx= [^a-x]\\n%\\nMatch zero characters, single characters, or any string.\\nFind all records that contain\\nyou\\n= %you% - Default, you do not have to type in the wildcards\\nFind all records that start with\\nyou\\n= you%\\nFind all records that end with\\nyou\\n= %you\\n*\\nMatch zero characters, single characters, or any string.\\xa0 Same as %.\\nFind all records that start with\\nyou\\n= you*\\nFind all records that end with\\n‘me\\n’ = *me\\n_\\nUnderscore\\nMatch any single character.\\nFind all five-letter records that start with\\na\\nand end with\\nz\\n= a_____z\\n[ ]\\nMatch any character within the brackets or in the range defined within the brackets.\\nFind all records that end with\\na\\n,\\nm\\n, or\\nz\\n= *[amz]\\nFind all records that start with\\na\\n,\\nb\\n,\\nc\\n, or\\nd\\n= [a-d]*\\nFind all records that contain\\na\\n,\\nm\\n, or\\nz\\n= *[amz]*\\n[^]\\nMatch any character that is NOT in the brackets or NOT in the range defined within the brackets.\\nFind all records that do NOT contain\\na\\n= [^a]\\nFind all records that are NOT between\\na\\nand\\nx\\n= [^a-x]\\n(Optional)\\nUse the escape character (backslash (\\\\)) on any of the following characters to search for the string literals.\\n\\\\\\xa0\\xa0\\xa0\\xa0 *\\xa0\\xa0\\xa0\\xa0 %\\xa0\\xa0\\xa0\\xa0 _\\xa0\\xa0\\xa0\\xa0 [\\xa0\\xa0\\xa0\\xa0\\xa0 ]\\xa0\\xa0\\xa0\\xa0 -\\xa0\\xa0\\xa0\\xa0 ^\\nFor example, to filter on John_Smith, where the _ character is part of the value, you must enter John\\\\_Smith.\\n(Optional)\\nUse the escape character (backslash (\\\\)) on any of the following characters to search for the string literals.\\n\\\\\\xa0\\xa0\\xa0\\xa0 *\\xa0\\xa0\\xa0\\xa0 %\\xa0\\xa0\\xa0\\xa0 _\\xa0\\xa0\\xa0\\xa0 [\\xa0\\xa0\\xa0\\xa0\\xa0 ]\\xa0\\xa0\\xa0\\xa0 -\\xa0\\xa0\\xa0\\xa0 ^\\nSelect the\\nSQL Pattern Match\\ncheck box.\\nClick\\nAdd Item\\n.\\n(Optional)\\nAdd more items, clearing the\\nSQL Pattern Match\\ncheck box if not using strings.\\nClick\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nFilters and Wizards\\n', 'Use the Filter Editor': '', 'Filter Modes': 'Items and item\\ntypes in filters can be set to include or exclude. The following examples explain those settings.\\nFilter In (Is)\\nUser (Origin or Impacted) IS ‘pete’\\nResult: Either Origin nor Impacted has the value ‘pete’. At least one of the fields has a value of ‘pete’.\\nFilter In (Is) Blank with Filter in Null Values?\\nUser (Origin or Impacted) IS NULL\\nResult: Either Origin or Impacted is NULL. At least one of the fields must be null.\\nFilter In (Is) Blank with Filter in Null Values?\\nUser (Origin or Impacted) IS NULL\\nResult: Either Origin or Impacted is NULL. At least one of the fields must be null.\\nFilter Out (Is Not)\\nUser (Origin or Impacted) IS NOT ‘pete’\\nResult: Neither Origin nor Impacted has the value ‘pete’. Both fields have a value other than ‘pete’\\nFilter Out (Is Not)\\nUser (Origin or Impacted) IS NOT ‘pete’\\nResult: Neither Origin nor Impacted has the value ‘pete’. Both fields have a value other than ‘pete’\\nFilter Out (Is Not) Blank with Filter out Null Values?\\nUser (Origin or Impacted) IS NOT NULL\\nResult: Neither Origin nor Impacted is NULL. Both fields must have a value.\\n', 'Quantitative Filters': 'Quantitative filters are available from these LogRhythm tools and utilities:\\nAlarm Rules\\nGLPR wizard\\nInvestigator\\nLog Distribution Services (LDS )\\nPersonal Dashboard filters\\nReports\\nSecondLook\\nTail\\nQuantitative fields include:\\nAmount\\nBytes Sent and Bytes Rcvd\\nDuration\\nPackets Sent and Packets Rcvd\\nQuantity\\nRate\\nSize\\nThe operators for quantitative filters are described in the following table.\\nOperator, Description\\n=, Equal to\\n!=, Not equal to\\n>, Greater than\\n>=, Greater than or equal to\\n<, Less than\\n<=, Less than or equal to\\n<>, Less than or greater than - (outside range)\\n<=>=, Less or equal to OR greater or equal to - (outside range)\\n><, Greater than AND less than - (between range)\\n>=<=, Greater or equal to AND less than or equal to - (between range)\\n', 'Wildcards in Search Strings': 'LogRhythm can use wildcards and pattern matching in search string filters to increase flexibility and efficiency. For example:\\nUse wildcards to search for a particular sender or recipient email address in the Platform Manager, Data Processor, or LogMart by specifying only some of the characters in the address.\\nFilter to find any matches for senders at a given domain name.\\nFilter to find a specific host name.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nFilters and Wizards\\n/\\nUse the Filter Editor\\n', 'Filters—Action': '\\nOn the Actions tab of the Filter Editor, you assign Actions (SmartResponses) to Alarms. More than one Action can be assigned to a single Alarm. The Actions can be configured to run in a specified order or all at the same time. Actions can also be required to have approval before being executed.\\nThe Actions tab consists of the following sections:\\nAction\\n. Manage the actions to be executed and how they are executed.\\nRun Actions\\n. Set the order in which actions are executed.\\nSet Action\\n. Select one of the available actions from all active SmartResponse plugins.\\nParameters\\n. Define the command line parameters that pass constant values or data fields to the executable.\\nApprovals\\n. Manage approvals required before the action is executed.\\nExecute SmartResponse Action from\\n. Specify the component from which the SmartResponse action should be executed.\\nSave Action\\n. Save the action to add it to the Action list.\\n', 'Actions': 'The sections below explain all the actions associated with a rule or alarm. You can add more than one action to the list, delete actions, reorder actions, and specify whether actions should run at the same time or in the order listed.\\nFor AI Engine rules, SmartResponse actions do not work if the Alarm on event occurrence check box is not selected on the\\nSettings tab\\n.\\n', 'Add an Action': 'Click\\nNew\\nAction.\\nIf no\\nSmartResponse actions are configured yet\\n, New Action is unavailable. For more information, see\\nSmartResponse\\n.\\nOn the Set Action menu, select an action.\\nIn the\\nParameters\\nsection, configure all the required parameters for the action.\\n(Optional)\\nIn the\\nApprovals\\nsection, add approvals for the action.\\nIn the\\nExecute SmartResponse From\\nsection, select the component from where the action should run.\\nClick\\nSave Action\\n.\\n', 'Delete an Action': 'In the Action grid, select one or more actions.\\nClick\\nDelete\\n, and then click\\nYes\\nwhen prompted to confirm the deletion.\\nThe selected actions are removed from the list.\\n', 'Reorder Actions': 'In the Action grid, select an action.\\nClick the up or down arrow to move the action.\\n', 'Specify How Actions Run': 'When at least two actions are configured in the Action list, you can specify how the actions should run using the Run Actions option.\\nIn the Run Actions section, do one of the following:\\nSelect\\nAt the Same Time\\nif you want all actions to run at the same time.\\nIf any action requires approval, an approval notification will be sent, and the action remains in a state of pending execution until all of its approval requirements have been met.\\nSelect\\nIn the order listed\\nif you want the actions to run one after the other, in the order listed from top to bottom.\\nEach action waits for its predecessor action to complete before it is initiated. If an action requires approval, an approval notification is sent, and the Action remains in a state of pending execution until all of its approval requirements have been met. Subsequent actions will not run until the action needing approval has completed.\\nAn action in a sequenced response executes regardless of whether the action before it fails or succeeds.\\nSelect\\nAt the Same Time\\nif you want all actions to run at the same time.\\nIf any action requires approval, an approval notification will be sent, and the action remains in a state of pending execution until all of its approval requirements have been met.\\nSelect\\nIn the order listed\\nif you want the actions to run one after the other, in the order listed from top to bottom.\\nEach action waits for its predecessor action to complete before it is initiated. If an action requires approval, an approval notification is sent, and the Action remains in a state of pending execution until all of its approval requirements have been met. Subsequent actions will not run until the action needing approval has completed.\\nAn action in a sequenced response executes regardless of whether the action before it fails or succeeds.\\nSelect\\nIn the order listed\\nif you want the actions to run one after the other, in the order listed from top to bottom.\\nEach action waits for its predecessor action to complete before it is initiated. If an action requires approval, an approval notification is sent, and the Action remains in a state of pending execution until all of its approval requirements have been met. Subsequent actions will not run until the action needing approval has completed.\\nAn action in a sequenced response executes regardless of whether the action before it fails or succeeds.\\n', 'Set Action': 'To configure any of the available SmartResponse actions, select an action from the Set Action menu. The Set Action menu only displays actions available in SmartResponse Plugins that have been loaded in the SmartResponse Plugin Manager.\\n', 'Define Parameters': \"The Parameters grid displays the selected action's script and all the command line parameters that can be passed to the action. The Script row is fixed and cannot be modified. All other rows can be modified.\\nFor each configurable parameter, do the following:\\nChose one of the following for the Type column. Your choice determines the options available for the Value column:\\nConstant Value\\n. Requires a manual entry in the Value column, to be used when running the script. Requires user input.\\nAlarm Field\\n. Requires a specific metadata field be selected in the Value column. Does not require user input but you can change which field is selected.\\nConstant Value\\n. Requires a manual entry in the Value column, to be used when running the script. Requires user input.\\nAlarm Field\\n. Requires a specific metadata field be selected in the Value column. Does not require user input but you can change which field is selected.\\nFor fields whose type is Encrypted Value, you need to enter a value in the Value column. The value is masked as it is typed.\\nConfigure the Values fields as needed.\\n(Optional)\\nFor time-based metadata fields, specify a time zone and format to use in the Time Zone and Time Format columns.\\n\", 'Set Approvals': 'The Approvals section allows you to select individuals or groups who must approve the selected action before it is executed. This is optional and if no approvals are specified, the action executes immediately when the alarm is raised. Approvers with valid email addresses specified in their contact method are notified of any pending approvals.\\nIn the Approvals section, click\\nAdd\\n.\\nThe Person Selector window displays.\\n(Optional)\\nTo show retired Individuals or roles, click the\\nShow Retired\\ncheck box.\\nClick\\nIndividual\\nor\\nRole\\n.\\n(Optional)\\nTo narrow the list in the Person Section, enter text in the Text Filter field.\\nSelect the search type, Keyword or Regex, and then click\\nApply\\n.\\nSelect the individuals or roles who will approve or deny the selected action.\\nTo save approvers, click\\nOK\\n.\\n(Optional)\\nEdit the type of Approver in the Type field. The default value is Person.\\nIn the Approvals section, click\\nAdd Group\\nto add distribution groups.\\nSelect the groups responsible for approving the Action.\\nTo add the Groups to the Approvals list, click\\nOK\\n.\\n(Optional)\\nEdit the type of Approver in the Type field. The default entry is Person.\\n', 'Delete Approvers': 'In the Approvals grid, select the individuals or groups to be deleted.\\nTo remove the individual or group approvers, click\\nDelete\\n.\\nTo confirm the deletion, click\\nYes\\n.\\n', 'Set the Levels for Approvers': 'You can specify up to three levels of approval for a SmartResponse action. You can have more than one person in each level, and at least one person in each level must approve the action before it moves to the next level or is finally executed.\\n', 'Set the Origin for a SmartResponse Action': 'For each configured action, you must decide where the SmartResponse is going to be deployed.\\nIn the Execute SmartResponse Action From section, do one of the following:\\nFrom Platform Manager, select\\nFrom Platform Manager\\n.\\nFrom System Monitor Hosts, select\\nFrom System Monitor\\n.\\nClick\\nBrowse\\n.\\nSelect the Entity to which the host belongs.\\n(Optional)\\nFilter the list of hosts by entering search criteria in the Text Filter box, and then click\\nApply\\n.\\nSelect the System Monitor host on which to run the SmartResponse, and then click\\nOK\\n.\\nFrom System Monitor Host in Alarm, select\\nSystem Monitor Host in Alarm\\nand do one of the following:\\nTo run the SmartResponse on the host impacted by the event, select\\nImpacted Host\\n.\\nTo run the SmartResponse on the host from which the event was initiated, select\\nOrigin Host\\n.\\nFrom Platform Manager, select\\nFrom Platform Manager\\n.\\nFrom System Monitor Hosts, select\\nFrom System Monitor\\n.\\nClick\\nBrowse\\n.\\nSelect the Entity to which the host belongs.\\n(Optional)\\nFilter the list of hosts by entering search criteria in the Text Filter box, and then click\\nApply\\n.\\nSelect the System Monitor host on which to run the SmartResponse, and then click\\nOK\\n.\\nClick\\nBrowse\\n.\\nSelect the Entity to which the host belongs.\\n(Optional)\\nFilter the list of hosts by entering search criteria in the Text Filter box, and then click\\nApply\\n.\\nSelect the System Monitor host on which to run the SmartResponse, and then click\\nOK\\n.\\nFrom System Monitor Host in Alarm, select\\nSystem Monitor Host in Alarm\\nand do one of the following:\\nTo run the SmartResponse on the host impacted by the event, select\\nImpacted Host\\n.\\nTo run the SmartResponse on the host from which the event was initiated, select\\nOrigin Host\\n.\\nTo run the SmartResponse on the host impacted by the event, select\\nImpacted Host\\n.\\nTo run the SmartResponse on the host from which the event was initiated, select\\nOrigin Host\\n.\\n', 'Save and Add an Associated Action': 'After you have configured all options for the selected SmartResponse action, click\\nSave Action\\nto add it to the Action list.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nFilters and Wizards\\n/\\nUse the Filter Editor\\n', 'Filters—Aggregation': '\\nThe Aggregation tab of the Filter Editor allows you to restrict similar events from incurring alarms unless a specified number of them occur within a specified time span. You define what makes them similar by indicating which fields must have matching values.\\nTo configure event threshold and group settings\\nIn the Alarm after X Event Occurrences field, enter the number of times similar events must occur before an alarm is incurred.\\nIn the Within X Hrs. X Mins. X Secs. fields, enter the time span during which the specified number of similar events must occur before an alarm is incurred.\\nIn the Group Events Having Identical Values in the Following Fields list, select the fields that must have matching values to be included in the aggregation.\\nWhen you complete the Aggregation tab, click\\nNext\\nto move to the next tab.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nFilters and Wizards\\n/\\nUse the Filter Editor\\n', 'Filters—Day and Time Criteria': '\\nThe Day and Time Criteria tab of the Filter Editor allows you to define the time span within which an event must occur to trigger an alarm. For example, when both these things are true:\\nThe day and time search criteria is 3/4/10 1:00 PM to 2:00 PM.\\nAn aggregate log message exists with three logs that occur between 12:30 PM and 3:00 PM of 3/4/10.\\nThe log message will be included in the search results because an occurrence may fall within the 1:00-2:00 time span.\\nTo configure day and time criteria\\nConfirm that the correct time zone is selected on the Day and Time Criteria tab.\\nClick\\nAdd\\n.\\nA row is added to the list with a start and end for the day and time.\\nTo modify the Start Day and End Day fields, click the down-arrow at the right and select an option from the list.\\nTo modify the Start Time and End Time fields, click the down-arrow at the right and select AM or PM from the list, and then enter the hour.\\nRepeat steps 2 through 4 until you have entered all the time constraints required for this rule.\\nWhen you complete the Day and Time Criteria tab, click\\nNext\\nto move to the next the tab.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nFilters and Wizards\\n/\\nUse the Filter Editor\\n', 'Filters—Exclude Filter': '\\nThe Exclude Filters tab of the Filter Editor allows you to prevent all events with matching values from being processed by this alarm rule. Exclude filters are applied only against events returned from the primary criteria search, providing a very efficient way to refine the search.\\nTo configure exclude filters\\nIn the upper-left corner of the window, click\\nNew\\n.\\nThe Log Message Filter window appears.\\nFrom the Add New Field Filter list, select a field to use as a primary filter.\\nThe User (Impacted/Origin) by Active Directory Group filter is only available to Global Administrators and Global Analysts. Restricted Analysts and Restricted Administrators may not create or edit an User (Impacted/Origin) by Active Directory Group filter in Personal Dashboard, Investigator Wizard, Tail Wizard, or Report Wizard. Restricted Analysts may run objects that reference an Active Directory Group filter in saved Investigations, Reports, and Report Packages.\\nFrom the Add New Field Filter list, select a field to use as a primary filter.\\nThe User (Impacted/Origin) by Active Directory Group filter is only available to Global Administrators and Global Analysts. Restricted Analysts and Restricted Administrators may not create or edit an User (Impacted/Origin) by Active Directory Group filter in Personal Dashboard, Investigator Wizard, Tail Wizard, or Report Wizard. Restricted Analysts may run objects that reference an Active Directory Group filter in saved Investigations, Reports, and Report Packages.\\nClick\\nEdit Values\\n.\\nThe Field Filter Values window appears with options based on your Field Filter selection.\\nSelect a\\nFilter Mode\\n.\\nDo one of the following:\\nIf you selected a\\nQuantitative Field Filter\\n, such as Host (Impacted) Bytes Rcvd, enter the operator and values.\\nIf you selected a Field Filter that requires a user-defined value such as IP Address, enter the value you want in the Add Item field. Select any additional options that are required.\\nIf you selected a\\nmulti-type field\\nsuch as Application, select an option from the Item Type list.\\nIf you selected a Field Filter such as Log Source Type, the Field Filter Selector window appears. It is populated based on your Field Filter selection. Follow the prompts to further refine your filter, and then click\\nOK\\n.\\nIf you selected a\\nQuantitative Field Filter\\n, such as Host (Impacted) Bytes Rcvd, enter the operator and values.\\nIf you selected a Field Filter that requires a user-defined value such as IP Address, enter the value you want in the Add Item field. Select any additional options that are required.\\nIf you selected a\\nmulti-type field\\nsuch as Application, select an option from the Item Type list.\\nIf you selected a Field Filter such as Log Source Type, the Field Filter Selector window appears. It is populated based on your Field Filter selection. Follow the prompts to further refine your filter, and then click\\nOK\\n.\\n(Optional)\\nUse the filter options to shorten the list. Enter characters you want to match, select\\nKeyword or Regex\\n, and then click\\nApply\\n. Only items that contain the characters you entered appear.\\nClick\\nAdd Item\\n.\\n(Optional)\\nContinue adding items.\\n(Optional)\\nTo delete a filter from the list, select it and click\\nRemove Filter\\n.\\n(Optional)\\nTo delete a filter from the list, select it and click\\nRemove Filter\\n.\\nClick\\nOK\\n.\\nThe Add New Field Filters window appears with the newly added filter in the list.\\nContinue adding filters until you are finished with this field.\\n(Optional)\\nContinue adding filters.\\n(Optional)\\nTo modify a filter in the list, select it and click Edit Values.\\n(Optional)\\nTo delete a filter from the list, select it and click\\nDelete\\n.\\nClick\\nOK\\n.\\nWhen you complete the Exclude Filters tab, click\\nNext\\nto move to the next tab.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nFilters and Wizards\\n/\\nUse the Filter Editor\\n', 'Filters—Include Filter': '\\nThe Include Filters tab of the Filter Editor allows you to specify that only events with matching values will be processed by this alarm rule. Include filters are applied only against the events returned from the primary criteria search, providing a very efficient way to refine the search.\\nTo configure include filters\\nIn the upper-left corner of the window, click\\nNew\\n.\\nThe Log Message Filter window appears.\\nFrom the Add New Field Filter list, select a field to use as a primary filter.\\nThe User (Impacted/Origin) by Active Directory Group filter is only available to Global Administrators and Global Analysts. Restricted Analysts and Restricted Administrators may not create or edit an User (Impacted/Origin) by Active Directory Group filter in Personal Dashboard, Investigator Wizard, Tail Wizard, or Report Wizard. Restricted Analysts may run objects that reference an Active Directory Group filter in saved Investigations, Reports, and Report Packages.\\nFrom the Add New Field Filter list, select a field to use as a primary filter.\\nThe User (Impacted/Origin) by Active Directory Group filter is only available to Global Administrators and Global Analysts. Restricted Analysts and Restricted Administrators may not create or edit an User (Impacted/Origin) by Active Directory Group filter in Personal Dashboard, Investigator Wizard, Tail Wizard, or Report Wizard. Restricted Analysts may run objects that reference an Active Directory Group filter in saved Investigations, Reports, and Report Packages.\\nClick\\nEdit Values\\n.\\nThe Field Filter Values window appears with options based on your Field Filter selection.\\nSelect a\\nFilter Mode\\n.\\nDo one of the following:\\nIf you selected a\\nQuantitative Field Filter\\n, such as Host (Impacted) Bytes Rcvd, enter the operator and values.\\nIf you selected a Field Filter that requires a user-defined value such as IP Address, enter the value you want in the Add Item field. Select any additional options that are required.\\nIf you selected a\\nmulti-type field\\nsuch as Application, select an option from the Item Type list.\\nIf you selected a Field Filter such as Log Source Type, the Field Filter Selector window appears. It is populated based on your Field Filter selection. Follow the prompts to further refine your filter, and then click\\nOK\\n.\\nIf you selected a\\nQuantitative Field Filter\\n, such as Host (Impacted) Bytes Rcvd, enter the operator and values.\\nIf you selected a Field Filter that requires a user-defined value such as IP Address, enter the value you want in the Add Item field. Select any additional options that are required.\\nIf you selected a\\nmulti-type field\\nsuch as Application, select an option from the Item Type list.\\nIf you selected a Field Filter such as Log Source Type, the Field Filter Selector window appears. It is populated based on your Field Filter selection. Follow the prompts to further refine your filter, and then click\\nOK\\n.\\n(Optional)\\nUse the filter options to shorten the list. Enter characters you want to match, select\\nKeyword or Regex\\n, and then click\\nApply\\n. Only items that contain the characters you entered appear.\\nClick\\nAdd Item\\n.\\n(Optional)\\nContinue adding items.\\n(Optional)\\nTo delete a filter from the list, select it and click\\nRemove Filter\\n.\\n(Optional)\\nTo delete a filter from the list, select it and click\\nRemove Filter\\n.\\nClick\\nOK\\n.\\nThe Add New Field Filters window appears with the newly added filter in the list.\\nContinue adding filters until you are finished with this field.\\n(Optional)\\nContinue adding filters.\\n(Optional)\\nTo modify a filter in the list, select it and click Edit Values.\\n(Optional)\\nTo delete a filter from the list, select it and click\\nDelete\\n.\\nClick\\nOK\\n.\\nWhen you complete the Exclude Filters tab, click\\nNext\\nto move to the next tab.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nFilters and Wizards\\n/\\nUse the Filter Editor\\n', 'Filters—Information': '\\nOn the Information tab of the Filter Editor you are required to enter a name for the alarm rule, and you have the option of entering additional information.\\nTo configure name and description information\\nType a name in the Alarm Rule Name field.\\nClick the ellipsis [...] button at the end of the Alarm Rule Group field.\\nThe Alarm Rule Group Assignment window appears.\\nType a name in the Assign New Alarm Rule Group or select an existing Alarm Rule Group.\\nClick\\nOK\\n.\\n(Optional)\\nType a brief description.\\nThe Description column appears in the Alarm Rules tab.\\n(Optional)\\nType any other relevant information in Additional Details.\\nClick\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nFilters and Wizards\\n/\\nUse the Filter Editor\\n', 'Filters—Log Source Criteria': '\\nThe Log Source Criteria tab of the Filter Editor allows you to specify which log sources are included in this alarm rule definition.\\nTo configure log source criteria:\\nSelect the log sources option you want:\\nInclude All Log Sources\\n. This is the default.\\nInclude Log Sources from the Selected Lists\\n. Select this to populate the grid with log source lists, and then check the ones you want to include.\\nInclude the Selected Log Sources\\n. Select this to populate the grid with log sources by doing the following:\\nInclude All Log Sources\\n. This is the default.\\nInclude Log Sources from the Selected Lists\\n. Select this to populate the grid with log source lists, and then check the ones you want to include.\\nInclude the Selected Log Sources\\n. Select this to populate the grid with log sources by doing the following:\\nClick\\nAdd\\n.\\nThe Log Source Criteria Add window appears.\\nFilter by one or more of the following options:\\nEntities\\nLog Source Types\\nLog Source Name\\nDescription\\nHost Name\\nHost IP Address\\nInclude Retired Log Sources\\nEntities\\nLog Source Types\\nLog Source Name\\nDescription\\nHost Name\\nHost IP Address\\nInclude Retired Log Sources\\nAfter entering your options, click\\nSearch\\n.\\nTo view additional pages of data, click\\nNext Batch\\n.\\nSelect the\\nAction\\nbox for the Log Sources you wish to add.\\nClick\\nOK\\n.\\n(Optional)\\nPerform additional searches and add more Log Sources.\\nWhen you complete the Day and Time Criteria tab, click\\nNext\\nto move to the next tab.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nFilters and Wizards\\n/\\nUse the Filter Editor\\n', 'Filters—Notify': '\\nOn the Notify tab of the Filter Editor you can set notifications for roles on the affected host, people, and groups.\\nFor AI Engine rules, notifications do not work if the Alarm on event occurrence check box is not selected on the\\nSettings tab\\n.\\nYou can also set any notification to\\nIs Silent\\n. A notification is created and saved for audit and report purposes, but is not sent.\\nCan Batch\\n. Notifications are sent in timed batches rather than as they occur.\\nTo set notifications\\nSelect the boxes in the Selected column to include roles you want to notify.\\nTo notify people, click the\\nAdd Person\\nbutton.\\nThe Person Selector window appears.\\nSelect an item in the Person Record Type Filter to populate the Person list.\\nSelect the people you want to notify for this alarm. Press Ctrl to select more than one person.\\nIf you are using data segregation to limit alarm notifications to only people who have access to a certain entity, each recipient on this tab must have an associated user profile that grants them access to that entity. For more information, see\\nUser Profile Manager\\n.\\nUse the filter options to shorten the list. Enter characters you want to match, select\\nKeyword\\nor\\nRegex\\n, and then click\\nApply\\n. Only items that contain the characters you entered appear.\\nSelect the people you want to notify for this alarm. Press Ctrl to select more than one person.\\nIf you are using data segregation to limit alarm notifications to only people who have access to a certain entity, each recipient on this tab must have an associated user profile that grants them access to that entity. For more information, see\\nUser Profile Manager\\n.\\nUse the filter options to shorten the list. Enter characters you want to match, select\\nKeyword\\nor\\nRegex\\n, and then click\\nApply\\n. Only items that contain the characters you entered appear.\\nTo return to the Alarm Rule window, click\\nOK\\n.\\nTo include groups you want to notify, select the boxes in the Selected column.\\nWhen you complete the Notify tab, click\\nNext\\nto move to the next tab.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nFilters and Wizards\\n/\\nUse the Filter Editor\\n', 'Filters—Primary Criteria': '\\nThe Primary Criteria tab of the Filter Editor is where you specify the filter that will be applied to all qualified events.\\nTo configure primary criteria\\n(For AI Engine Rules)\\nSelect one of the following Data Sources for the Rule Block:\\nData Processor Logs\\nAdvanced Intelligence Engine Events\\nIf Advanced Intelligence Engine Events is selected, it is highly recommended that you add an AIE Common Event filter to the Primary Criteria to specify which AIE Rules to include. Then follow the steps described in Create an Alarm Rule to create the filter. You can also add a saved filter, instead of creating a new one, by following the steps in the next two sections.\\nData Processor Logs\\nAdvanced Intelligence Engine Events\\nAdvanced Intelligence Engine Events\\nIf Advanced Intelligence Engine Events is selected, it is highly recommended that you add an AIE Common Event filter to the Primary Criteria to specify which AIE Rules to include. Then follow the steps described in Create an Alarm Rule to create the filter. You can also add a saved filter, instead of creating a new one, by following the steps in the next two sections.\\nIn the upper-left corner of the window, click\\nNew\\n.\\nThe Log Message Filter window appears.\\nFrom the Add New Field Filter list, select a field to use as a primary filter.\\nThe User (Impacted/Origin) by Active Directory Group filter is only available to Global Administrators and Global Analysts. Restricted Analysts and Restricted Administrators may not create or edit an User (Impacted/Origin) by Active Directory Group filter in Personal Dashboard, Investigator Wizard, Tail Wizard, or Report Wizard. Restricted Analysts may run objects that reference an Active Directory Group filter in saved Investigations, Reports, and Report Packages.\\nFrom the Add New Field Filter list, select a field to use as a primary filter.\\nThe User (Impacted/Origin) by Active Directory Group filter is only available to Global Administrators and Global Analysts. Restricted Analysts and Restricted Administrators may not create or edit an User (Impacted/Origin) by Active Directory Group filter in Personal Dashboard, Investigator Wizard, Tail Wizard, or Report Wizard. Restricted Analysts may run objects that reference an Active Directory Group filter in saved Investigations, Reports, and Report Packages.\\nClick\\nEdit Values\\n.\\nThe Field Filter Values window appears with options based on your Field Filter selection.\\nSelect a\\nFilter Mode\\n.\\nDo one of the following:\\nIf you selected a\\nQuantitative Field Filter\\n, such as Host (Impacted) Bytes Rcvd, enter the operator and values.\\nIf you selected a Field Filter that requires a user-defined value such as IP Address, enter the value you want in the Add Item field. Select any additional options that are required.\\nIf you selected a\\nmulti-type field\\nsuch as Application, select an option from the Item Type list.\\nIf you selected a Field Filter such as Log Source Type, the Field Filter Selector window appears. It is populated based on your Field Filter selection. Follow the prompts to further refine your filter, and then click\\nOK\\n.\\nIf you selected a\\nQuantitative Field Filter\\n, such as Host (Impacted) Bytes Rcvd, enter the operator and values.\\nIf you selected a Field Filter that requires a user-defined value such as IP Address, enter the value you want in the Add Item field. Select any additional options that are required.\\nIf you selected a\\nmulti-type field\\nsuch as Application, select an option from the Item Type list.\\nIf you selected a Field Filter such as Log Source Type, the Field Filter Selector window appears. It is populated based on your Field Filter selection. Follow the prompts to further refine your filter, and then click\\nOK\\n.\\n(Optional)\\nUse the filter options to shorten the list. Enter characters you want to match, select\\nKeyword or Regex\\n, and then click\\nApply\\n. Only items that contain the characters you entered appear.\\nClick\\nAdd Item\\n.\\n(Optional)\\nContinue adding items.\\n(Optional).\\nTo delete a filter from the list, select it and click\\nRemove Filter\\n.\\n(Optional).\\nTo delete a filter from the list, select it and click\\nRemove Filter\\n.\\nClick\\nOK\\n.\\nThe Add New Field Filters window appears with the newly added filter in the list.\\nContinue adding filters until you are finished with this field.\\n(Optional)\\nContinue adding filters.\\n(Optional)\\nTo modify a filter in the list, select it and click Edit Values.\\n(Optional)\\nTo delete a filter from the list, select it and click\\nDelete\\n.\\n(For Alarms)\\nIn the Minimum Event Priority section, specify the minimum priority an event must have to be considered for alarming.\\nClick\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nFilters and Wizards\\n/\\nUse the Filter Editor\\n', 'Filters—Settings': '\\nThe Settings tab allows you to configure common event properties, alarm properties, and general properties for the AI Engine Rule or Alarm Rule. It also enables you to set a suppression period for alarms. During the suppression period, additional logs or events that match the exact criteria of the suppressed alarm do create new events or alarms. Suppression looks at all the Group By fields in an AI Engine rule. All fields must match for the suppression to work. For example, if you have a rule configured to detect three failed logins from a single source to a single destination, after the first alarm, any matching logs with that source and destination combo are ignored. However, if that source fails three logins to a different destination, the alarm fires again and the suppression period for that combination begins.\\nThe following table describes the settings you can configure on the Settings tab of the AI Engine Wizard.\\nSettings Tab Field, Description\\nNew Event Settings\\nCommon Event Name, AI Engine Common Events always start with \"AIE.\" Maximum additional characters = 45.\\nSync with rule name, Select to synchronize the Common Event name with the rule name, up to 45 characters.\\nClassification, Common Event classification. Click the selector for an option list.\\nRisk Rating, Select from 0 to 9 on the list. For more information, seeGlobal Risk Based Priority.\\nEvent Suppression, Select theEnable Suppressioncheck box to limit the number of events created by a rule so only the first occurrence of a qualifying event is created during the Suppression Period.If you select the Enable Suppression check box, the Suppression Multiple field is enabled. The value you enter here is used in the formula:Suppression Multiple * Suppression Interval = Suppression PeriodThe Suppression Interval value reflects the rule definition and the time limits set on the Thresholds and Unique Values tabs and in the AI Engine Rule Block Relationship.When you tab off the Suppression Multiple field, the Suppression Period is recalculated.\\nAIE Event Forwarding, Select to forward the AI Engine Event to the Platform Manager\\nNew Alarm Settings\\nAlarm on event occurrence, Select to create an alarm when this event occurs and to enable the alarm status.This box must be selected for notifications and SmartResponse actions to work.\\nAutomatically drill down and cache results, If Alarm on event occurrence is selected, you can automatically drill down and cache results for this rule.If the AIE Drill Down Cache is disabled in the LogRhythm Configuration Manager, automatic drilldown does not work, even if this check box is selected. For more information, see theLogRhythm Software Installation Guide.\\nNotification Settings, Select the number of decimal places from 0 to 10 to print for quantitative values.\\nRule Settings\\nFalse Positive Probability (FPP), The False Positive Probability is used in Risk-Based Priority (RBP) calculation for AI Engine Rules. It estimates how likely the rule is to generate a false positive response. A value of low indicates the pattern the rule matches is almost always a true positive. However, a value of high indicates the pattern the rule matches is very likely to be a false positive.Options range from 0 to 9 with:0 indicating the pattern the rule matched is almost always a true positive to9 indicating the pattern the rule matched is very likely to be a false positiveThe default = 5 - Medium-Medium.\\nEnvironmental Dependence Factor (EDF), The Environmental Dependence Factor is used in Risk-Based Priority (RBP) Calculation for AI Engine Rules. It determines how much additional configuration is required for the rule to function as expected within different network environments.The options are:None. Default, no additional configuration required.Low. Minimum additional configuration required.Medium. Additional configuration required.High. Significant additional configuration required\\nExpiration Date, SelectNo expirationorExpires onwith the appropriate date. After the expiration date passes, the rule is not processed but does appear in the grid with Rule Status = Expired.\\nRule Set, Rule sets are used to divide rules among multiple AI Engine Servers. Minimum = 0, maximum = 100. 0 Appears asNonein the Rule Manager grid.\\nRuntime Priority, Under heavy load, the AI Engine Server may need to suspend the lowest priority rules first.Values = Low, Normal, or High.If the AI Engine begins to run out of memory or fall behind, it automatically suspends rules starting with the lowest runtime priority.\\nData Segregation, Segregate the rule processing and Event at runtime by the specified entity grouping.None.Log Source Entity. Segregates within the specific Entity of every log.Log Source Root EntitySegregates within the Root Entity of every log.Data Segregation enables a single logical rule definition to be automatically applied at the Entity or Root Entity level to distinct groups of Log Sources within a deployment. Each Event is then guaranteed to only have considered Logs within the scope of the chosen Entity grouping.Data segregation by entity also ensures that alarm notification emails sent by the Notification Service are only sent to recipients who have access to that entity. For the Notification Service to work, the AIE Drill Down Cache must be enabled in the LogRhythm Configuration Manager. Both the AIE Drill Down Cache API and the Notification Service settings can be modified in the Configuration Manager. For more information, see the information on the LogRhythm Configuration Manager in theLogRhythm Software Installation Guide.\\nSelect the\\nEnable Suppression\\ncheck box to limit the number of events created by a rule so only the first occurrence of a qualifying event is created during the Suppression Period.\\nIf you select the Enable Suppression check box, the Suppression Multiple field is enabled. The value you enter here is used in the formula:\\nSuppression Multiple * Suppression Interval = Suppression Period\\nThe Suppression Interval value reflects the rule definition and the time limits set on the Thresholds and Unique Values tabs and in the AI Engine Rule Block Relationship.\\nWhen you tab off the Suppression Multiple field, the Suppression Period is recalculated.\\nSelect to create an alarm when this event occurs and to enable the alarm status.\\nThis box must be selected for notifications and SmartResponse actions to work.\\nIf Alarm on event occurrence is selected, you can automatically drill down and cache results for this rule.\\nIf the AIE Drill Down Cache is disabled in the LogRhythm Configuration Manager, automatic drilldown does not work, even if this check box is selected. For more information, see the\\nLogRhythm Software Installation Guide\\n.\\nThe False Positive Probability is used in Risk-Based Priority (RBP) calculation for AI Engine Rules. It estimates how likely the rule is to generate a false positive response. A value of low indicates the pattern the rule matches is almost always a true positive. However, a value of high indicates the pattern the rule matches is very likely to be a false positive.\\nOptions range from 0 to 9 with:\\n0 indicating the pattern the rule matched is almost always a true positive to\\n9 indicating the pattern the rule matched is very likely to be a false positive\\nThe default = 5 - Medium-Medium.\\nThe Environmental Dependence Factor is used in Risk-Based Priority (RBP) Calculation for AI Engine Rules. It determines how much additional configuration is required for the rule to function as expected within different network environments.\\nThe options are:\\nNone\\n. Default, no additional configuration required.\\nLow\\n. Minimum additional configuration required.\\nMedium\\n. Additional configuration required.\\nHigh\\n. Significant additional configuration required\\nRule sets are used to divide rules among multiple AI Engine Servers. Minimum = 0, maximum = 100. 0 Appears as\\nNone\\nin the Rule Manager grid.\\nUnder heavy load, the AI Engine Server may need to suspend the lowest priority rules first.\\nValues = Low, Normal, or High.\\nIf the AI Engine begins to run out of memory or fall behind, it automatically suspends rules starting with the lowest runtime priority.\\nSegregate the rule processing and Event at runtime by the specified entity grouping.\\nNone\\n.\\nLog Source Entity\\n. Segregates within the specific Entity of every log.\\nLog Source Root Entity\\nSegregates within the Root Entity of every log.\\nData Segregation enables a single logical rule definition to be automatically applied at the Entity or Root Entity level to distinct groups of Log Sources within a deployment. Each Event is then guaranteed to only have considered Logs within the scope of the chosen Entity grouping.\\nData segregation by entity also ensures that alarm notification emails sent by the Notification Service are only sent to recipients who have access to that entity. For the Notification Service to work, the AIE Drill Down Cache must be enabled in the LogRhythm Configuration Manager. Both the AIE Drill Down Cache API and the Notification Service settings can be modified in the Configuration Manager. For more information, see the information on the LogRhythm Configuration Manager in the\\nLogRhythm Software Installation Guide\\n.\\nThe following table describes the settings you can configure on the Settings tab of the Alarm Wizard.\\nSettings Tab Field, Description\\nAlarm Suppression\\nSuppress Identical Alarms for, Enter the time span you want.\\nNotification Settings\\nUse custom alarm rule name in email notification, Select to enter a custom subject name. The custom subject line can be up to 100 characters long.If you want to change the prefix of the subject of the email, you need to update the Email Notification Policy. For more details, seeCreate New Email Alarm Notification Policies.\\nAppend the grouped event field values to the title of the alarm notification, Select to append the selected Group By values to the end of the Notification Subject Line. For example: LogRhythm Alarm - Brute Force Password Attack - oHost=10.1.1.18 oLogin=fred.smith.\\nSpecific the number of decimal places to print for quantitative values, Select a value from 0 to 10\\nData Segregation\\nSegregate event data by Entity when processed by the rule and output as an Alarm, Select one of the following:None.Log Source Entity. Segregates within the specific Entity of every log.Log Source Root EntitySegregates within the Root Entity of every log.Data Segregation enables a single logical rule definition to be automatically applied at the Entity or Root Entity level to distinct groups of Log Sources within a deployment. Each Event is then guaranteed to only have considered Logs within the scope of the chosen Entity grouping.Data segregation by entity also ensures that alarm notification emails sent by the Notification Service are only sent to recipients who have access to that entity. For the Notification Service to work, the AIE Drill Down Cache must be enabled in the LogRhythm Configuration Manager and TLS 1.2 must be enabled. For more information, seetheLogRhythm Software Installation Guide.\\nSelect to enter a custom subject name. The custom subject line can be up to 100 characters long.\\nIf you want to change the prefix of the subject of the email, you need to update the Email Notification Policy. For more details, see\\nCreate New Email Alarm Notification Policies\\n.\\nSelect one of the following:\\nNone\\n.\\nLog Source Entity\\n. Segregates within the specific Entity of every log.\\nLog Source Root Entity\\nSegregates within the Root Entity of every log.\\nData Segregation enables a single logical rule definition to be automatically applied at the Entity or Root Entity level to distinct groups of Log Sources within a deployment. Each Event is then guaranteed to only have considered Logs within the scope of the chosen Entity grouping.\\nData segregation by entity also ensures that alarm notification emails sent by the Notification Service are only sent to recipients who have access to that entity. For the Notification Service to work, the AIE Drill Down Cache must be enabled in the LogRhythm Configuration Manager and TLS 1.2 must be enabled. For more information, see\\nthe\\nLogRhythm Software Installation Guide\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nGeneral Console Features\\n', 'Export Grid to File': '\\nRight-click the grid you want to export.\\nSelect\\nGrid Properties\\n.\\nSelect the check box of the fields you want to include in the export and clear the check box of the fields you want to exclude. Click a field to display its description in the bottom of the window.\\nClick\\nOK.\\nRight-click the grid you want to export.\\nClick\\nExport Grid to File\\nor\\nExport to file\\n.\\nEntity Networks, Entity Hosts, and Entity Host Roles grids provide the option to either Export Networks for Selected Entity or Export Networks for All Entities.\\nKnowledge Base Modules grids provide options to export for primary, dependent, or all objects in the module.\\nIn general, the columns in the grid are exported to the file in the order shown. The following exceptions apply:\\nThe Alarm Viewer export condenses both the Alarm List and the Alarm Properties grids into a single row (one row for each alarm record). The properties are included in the row and are in the same order they appear in alarm properties panel.\\nHosts include the entity to which they belong as the first column.\\nNetworks include the entity to which they belong as the first column.\\nThe files are named in the following format: LogRhythm_<ExportTypeName>.<Date&Time(YYYYMMDD)>\\nEntity Networks, Entity Hosts, and Entity Host Roles grids provide the option to either Export Networks for Selected Entity or Export Networks for All Entities.\\nKnowledge Base Modules grids provide options to export for primary, dependent, or all objects in the module.\\nIn general, the columns in the grid are exported to the file in the order shown. The following exceptions apply:\\nThe Alarm Viewer export condenses both the Alarm List and the Alarm Properties grids into a single row (one row for each alarm record). The properties are included in the row and are in the same order they appear in alarm properties panel.\\nHosts include the entity to which they belong as the first column.\\nNetworks include the entity to which they belong as the first column.\\nIn general, the columns in the grid are exported to the file in the order shown. The following exceptions apply:\\nThe Alarm Viewer export condenses both the Alarm List and the Alarm Properties grids into a single row (one row for each alarm record). The properties are included in the row and are in the same order they appear in alarm properties panel.\\nHosts include the entity to which they belong as the first column.\\nNetworks include the entity to which they belong as the first column.\\nThe files are named in the following format: LogRhythm_<ExportTypeName>.<Date&Time(YYYYMMDD)>\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nLists in the Client Console\\n', 'Add Expiring Items to a List': '\\nYou must be logged in as an administrator to take this action.\\nTo add expiring list items to a list:\\nOn the main toolbar, click\\nList Manager\\n.\\nDouble-click an existing list.\\nThe List Properties window appears.\\nIn the TTL section on the Basic Configuration tab, select the\\nExpiring Items\\ncheck box, and then complete the following fields:\\nDays\\n. Enter the number days that must pass before these list items expire.\\nHours and minutes\\n. Enter the number of hours and minutes that must pass before these list items expire.\\nLog on Expiration\\n. Select this check box to have log entries created when the list items expire. Job Manager logs are stored in the jobmgr.log file and events are logged in the Windows Application Event log.\\nExpired list items are logged only when the Platform Manager logging level is set to INFO or higher. The default logging level is WARNING. For more information, see\\nModify Platform Manager Basic Properties\\n.\\nDays\\n. Enter the number days that must pass before these list items expire.\\nHours and minutes\\n. Enter the number of hours and minutes that must pass before these list items expire.\\nLog on Expiration\\n. Select this check box to have log entries created when the list items expire. Job Manager logs are stored in the jobmgr.log file and events are logged in the Windows Application Event log.\\nExpired list items are logged only when the Platform Manager logging level is set to INFO or higher. The default logging level is WARNING. For more information, see\\nModify Platform Manager Basic Properties\\n.\\nLog on Expiration\\n. Select this check box to have log entries created when the list items expire. Job Manager logs are stored in the jobmgr.log file and events are logged in the Windows Application Event log.\\nExpired list items are logged only when the Platform Manager logging level is set to INFO or higher. The default logging level is WARNING. For more information, see\\nModify Platform Manager Basic Properties\\n.\\nClick the\\nList Items\\ntab.\\nAdd list items.\\nIf Expiring List Items are added to an existing list, the previous list items are marked with N/A.\\nAdd list items.\\nIf Expiring List Items are added to an existing list, the previous list items are marked with N/A.\\nTo save the list, click\\nApply\\n.\\nTo close the List Properties window, click\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nLists in the Client Console\\n', 'Add Values to a List': 'You can add values to a list directly or copy values to the clipboard for import from any of the following places:\\nPersonal Dashboard\\nAggregate Event List Context Menu\\nAll TopX Tools\\nAggregate Event List Context Menu\\nAll TopX Tools\\nInvestigator\\nAggregate Log/Event List Context Menu\\nLog/Event List Context Menu\\nAll TopX Tools\\nAggregate Log/Event List Context Menu\\nLog/Event List Context Menu\\nAll TopX Tools\\nTail\\nAggregate Log/Event List Context Menu\\nLog/Event List Context Menu\\nAll TopX Tools\\nAggregate Log/Event List Context Menu\\nLog/Event List Context Menu\\nAll TopX Tools\\nTo add values to a list:\\nGo to the location that contains the values you want to add.\\nSelect the rows that contain the values you want to add.\\nRight-click anywhere on the selected rows, and then do one of the following:\\nClick\\nAdd Values to List\\n, and then select the appropriate field.\\nThe Add Values to List window appears and displays all lists you can write to. Only lists applicable to the specified field appear.\\nSelect the list you want to add the values to and click\\nAdd\\n.\\nThe List Properties window appears. The List Items tab contains both existing and newly added items.\\nTo add the new values, click\\nOK\\nor\\nApply\\n.\\nClick\\nCopy Values to Clipboard\\n, and then select the appropriate field.\\nClick\\nAdd Values to List\\n, and then select the appropriate field.\\nThe Add Values to List window appears and displays all lists you can write to. Only lists applicable to the specified field appear.\\nSelect the list you want to add the values to and click\\nAdd\\n.\\nThe List Properties window appears. The List Items tab contains both existing and newly added items.\\nTo add the new values, click\\nOK\\nor\\nApply\\n.\\nSelect the list you want to add the values to and click\\nAdd\\n.\\nSelect the list you want to add the values to and click\\nAdd\\n.\\nThe List Properties window appears. The List Items tab contains both existing and newly added items.\\nThe List Properties window appears. The List Items tab contains both existing and newly added items.\\nTo add the new values, click\\nOK\\nor\\nApply\\n.\\nTo add the new values, click\\nOK\\nor\\nApply\\n.\\nClick\\nCopy Values to Clipboard\\n, and then select the appropriate field.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nLists in the Client Console\\n', 'Create Lists in the Client Console': 'Lists are comprised of items or other lists.\\nOn the main toolbar, click\\nList Manager\\n.\\nOn the File menu, click\\nNew\\n.\\nThe New List dialog box appears.\\nSelect a list type, and then click\\nOK\\n.\\nThe New (List Type) List Properties window appears.\\nOn the Basic Configuration tab, complete the following fields to identify the list:\\nName\\n. Enter a name for the list.\\nBrief Description\\n.\\n(Optional)\\nEnter a description for the list.\\nName\\n. Enter a name for the list.\\nBrief Description\\n.\\n(Optional)\\nEnter a description for the list.\\nSet the permissions for the list by selecting the appropriate options from the lists in the Permissions section.\\nRead Access\\n. Read Access permissions override Write Access permissions. For example, if Read Access permissions are set to Private, Write Access permissions cannot be set to anything other than Private. In addition, Read permissions have to be less restrictive than Write Permissions. Read permissions cannot be set to Private if Write permissions are set to Public All. Grant read access to the list by selecting one of the following options.\\nRead Access\\nDescription\\nPublic Global Administrator\\nGrants read access to Global Administrators.\\nPublic Global Analyst\\nGrants read access to Global Analysts.\\nPublic Restricted Admin\\nGrants read access to Restricted Administrators\\nPublic Restricted Analyst\\nGrants read access to Restricted Analysts.\\nPublic All Users\\nGrants read access to all users.\\nPrivate\\nGrants read access only to the owner of the list.\\nWrite Access\\n. Write Access options vary with the level of Read Access you selected. Grant write access by selecting one of the following options.\\nWrite Access\\nDescription\\nPublic Global Administrator\\nGrants write access to Global Administrators.\\nPublic Global Analyst\\nGrants write access to Global Analysts.\\nPublic Restricted Admin\\nGrants write access to Restricted Administrators\\nPublic Restricted Analyst\\nGrants write access to Restricted Analysts.\\nPublic All Users\\nGrants write access to all users.\\nPrivate\\nGrants write access only to the owner of the list.\\nOwner\\n. This field is disabled. It shows the owner of the list.\\nDefault Entity\\n. This field displays the entity with which the list is associated. To change the Default Entity, click the search icon at the end of the field and select an entity from the Entity Selector window.\\nRestricted Read\\n. Restricted Read is used to prevent users who do not have Write Permissions to the list from viewing the items on the list. Selecting a Read Access value other than Private enables the Restricted Read check box.\\nRead Access\\n. Read Access permissions override Write Access permissions. For example, if Read Access permissions are set to Private, Write Access permissions cannot be set to anything other than Private. In addition, Read permissions have to be less restrictive than Write Permissions. Read permissions cannot be set to Private if Write permissions are set to Public All. Grant read access to the list by selecting one of the following options.\\nRead Access\\nDescription\\nPublic Global Administrator\\nGrants read access to Global Administrators.\\nPublic Global Analyst\\nGrants read access to Global Analysts.\\nPublic Restricted Admin\\nGrants read access to Restricted Administrators\\nPublic Restricted Analyst\\nGrants read access to Restricted Analysts.\\nPublic All Users\\nGrants read access to all users.\\nPrivate\\nGrants read access only to the owner of the list.\\nRead Access\\n. Read Access permissions override Write Access permissions. For example, if Read Access permissions are set to Private, Write Access permissions cannot be set to anything other than Private. In addition, Read permissions have to be less restrictive than Write Permissions. Read permissions cannot be set to Private if Write permissions are set to Public All. Grant read access to the list by selecting one of the following options.\\nRead Access, Description\\nPublic Global Administrator, Grants read access to Global Administrators.\\nPublic Global Analyst, Grants read access to Global Analysts.\\nPublic Restricted Admin, Grants read access to Restricted Administrators\\nPublic Restricted Analyst, Grants read access to Restricted Analysts.\\nPublic All Users, Grants read access to all users.\\nPrivate, Grants read access only to the owner of the list.\\nWrite Access\\n. Write Access options vary with the level of Read Access you selected. Grant write access by selecting one of the following options.\\nWrite Access\\nDescription\\nPublic Global Administrator\\nGrants write access to Global Administrators.\\nPublic Global Analyst\\nGrants write access to Global Analysts.\\nPublic Restricted Admin\\nGrants write access to Restricted Administrators\\nPublic Restricted Analyst\\nGrants write access to Restricted Analysts.\\nPublic All Users\\nGrants write access to all users.\\nPrivate\\nGrants write access only to the owner of the list.\\nWrite Access\\n. Write Access options vary with the level of Read Access you selected. Grant write access by selecting one of the following options.\\nWrite Access, Description\\nPublic Global Administrator, Grants write access to Global Administrators.\\nPublic Global Analyst, Grants write access to Global Analysts.\\nPublic Restricted Admin, Grants write access to Restricted Administrators\\nPublic Restricted Analyst, Grants write access to Restricted Analysts.\\nPublic All Users, Grants write access to all users.\\nPrivate, Grants write access only to the owner of the list.\\nOwner\\n. This field is disabled. It shows the owner of the list.\\nDefault Entity\\n. This field displays the entity with which the list is associated. To change the Default Entity, click the search icon at the end of the field and select an entity from the Entity Selector window.\\nRestricted Read\\n. Restricted Read is used to prevent users who do not have Write Permissions to the list from viewing the items on the list. Selecting a Read Access value other than Private enables the Restricted Read check box.\\nConfigure the Auto Import settings. Auto Import is only available for the following types of lists: Domain Impacted, General Value, Host, IP Address, IP Range, and User.\\nEnable\\n. Select to enable Auto Import.\\nReplace existing items\\n. Select to replace the existing list values. This does not remove any existing lists, only the values.\\nImport items as patterns\\n. Select if your imported list contains values with wildcard patterns. Otherwise, wildcard characters will be treated literally.\\nFile name\\n. The default import directory is config\\\\list_import.\\nThis section is disabled if the function is not available for the list type you created.\\nEnable\\n. Select to enable Auto Import.\\nReplace existing items\\n. Select to replace the existing list values. This does not remove any existing lists, only the values.\\nImport items as patterns\\n. Select if your imported list contains values with wildcard patterns. Otherwise, wildcard characters will be treated literally.\\nFile name\\n. The default import directory is config\\\\list_import.\\n(Optional)\\nTo give the items in the list an expiration date, select the\\nExpiring Items\\ncheck box. Configure the expiration settings.\\nIf you select the Expiring Items check box, all List items you add will have an expiration date. To add some list items without an expiration date, clear the Expiring Items check box, add list items, save the list, and close the window. Then modify the list following the steps in\\nAdd Expiring Items to a List\\n.\\n(Optional)\\nTo give the items in the list an expiration date, select the\\nExpiring Items\\ncheck box. Configure the expiration settings.\\nIf you select the Expiring Items check box, all List items you add will have an expiration date. To add some list items without an expiration date, clear the Expiring Items check box, add list items, save the list, and close the window. Then modify the list following the steps in\\nAdd Expiring Items to a List\\n.\\nClick the\\nList Items\\ntab.\\nDo one of the following:\\nAdd an Item.\\nClick\\nAdd Item\\n.\\nThe appropriate selector box appears, based on the selected list type.\\nSelect the items or lists to include in the list being created.\\nAdd a List.\\nClick\\nAdd List\\n.\\nThe appropriate list selector box appears, based on the selected list type.\\nSelect the items or lists to include in the list being created.\\nWhen adding a related list, only lists that are compatible with the current list are shown. Each list type allows lists of the same type to be added as a related list.\\nHost lists allow you to add General Value, IP Address, and IP Range lists in the Related Lists section.\\nUser lists allow you to add General Value lists in the Related Lists section.\\nItems and lists that are added appear in the text box. The Lists appear with an icon as shown.\\nImport a list.\\nClick\\nImport items\\non the bottom of the window.\\xa0Not all List Types can import values. The following can import values:\\nGeneral Value\\nHost\\nUsers\\nIt is not possible to specify a sub list via Import, but Imported lists may contain sub lists (only items are affected by the import process).\\nSelect the Import behavior from the following:\\nReplace existing items (lists are not removed)\\n. Select this option to replace existing list values. This does not remove any existing lists, only values.\\nImport items as patterns\\n. Select this option to have the list items treated as wildcards instead of literal values. When this option is selected, each list item is wrapped in percent (%) signs. The default (off) is to treat all input as literal values, with no patterns or escaping. Turning the option on enables Pattern characters, in which case all pattern-literals need to be escaped. The following table indicates how values are interpreted. Where multiple types are supported, the type is determined in the indicated priority order.\\nList/Entry Type\\nExamples\\nComments\\nHost/IPv6 Range\\nfe80::1~fe80::\\nffff ::~::1\\nContains tilde and both parts meet valid IPv6 format, including dotted decimal-suffix.\\nHost/IPv4 Range\\n192.168.1.1~192.168.1.255\\nContains tilde and both parts meet valid IPv4 format. Otherwise, an error is raised.\\nHost/IPv6\\nfe80::1\\n::1\\nContains two colons. Any valid IPv6 format, including dotted decimal-suffix. Otherwise, an error is raised.\\nHost/IPv4\\n192.168.1.1\\nMeets valid IPv4 format.\\nHost/Hostname\\ngandalf\\ngandalf.com\\n*.\\ngandalf.com\\nserver___.com\\nShould use valid hostname characters plus wildcards (if enabled), but these are not verified.\\nHostnames may start with a leading digit per RFC 1123.\\nHostnames with a space are not supported.\\nHost/Known Host\\nn/a\\nNot supported.\\nGeneral Value (all contexts)\\nconfidential\\nhttp://www.facebook.com\\ndearest%\\nValid text plus wildcards (if enabled).\\nUser\\njoe\\njoe.user\\njoe.user@someorg.com\\njohn%\\njohn\\\\%\\nValid text plus wildcards (if enabled).\\nActive Directory Groups are not supported.\\nDo not put AD Groups in import lists, because they will be deleted. Use a sub list to hold AD Groups.\\nClick an Import format from the following:\\nImport Text File\\n. To import a text file, click\\nImport Text File\\n, go to the file, and then click\\nOpen\\n.\\nImport Clipboard Text\\n. To import a list from the clipboard, ensure you have already copied the values you want to import, and then click\\nImport Clipboard Text\\n. This pastes the values into the List Items tab.\\nUp to 2 million items can be imported. However, only 30,000 items can be edited in the interface.\\nItems in a list that are going to be imported must be separated with a comma (,) or line breaks. Leading/trailing spaces are removed.\\nNo validation is done on the contents of a file or the clipboard. They are both treated as if they were text. The items are imported as if the user had added them manually using repeated Add Item operations. The Items list is left in an uncommitted state, so you can preview the result and choose either\\nApply\\nor\\nCancel\\n.\\nCan be ANSI or UTF. If the file has a UTF byte mark header, it is interpreted as UTF. Otherwise, it is interpreted as Extended ASCII.\\nOnly extended ASCII (not Unicode) characters are officially supported in LogRhythm.\\nSimple textual file of line-break-separated list items. All three line-break formats are supported (CR, LF, CRLF).\\nFinal item does not need to be terminated.\\nEmpty items are ignored (that is, two or more successive line breaks.)\\nEmpty files are legal (removes all items.)\\nDo one of the following:\\nAdd an Item.\\nClick\\nAdd Item\\n.\\nThe appropriate selector box appears, based on the selected list type.\\nSelect the items or lists to include in the list being created.\\nAdd an Item.\\nClick\\nAdd Item\\n.\\nThe appropriate selector box appears, based on the selected list type.\\nClick\\nAdd Item\\n.\\nThe appropriate selector box appears, based on the selected list type.\\nSelect the items or lists to include in the list being created.\\nSelect the items or lists to include in the list being created.\\nAdd a List.\\nClick\\nAdd List\\n.\\nThe appropriate list selector box appears, based on the selected list type.\\nSelect the items or lists to include in the list being created.\\nWhen adding a related list, only lists that are compatible with the current list are shown. Each list type allows lists of the same type to be added as a related list.\\nHost lists allow you to add General Value, IP Address, and IP Range lists in the Related Lists section.\\nUser lists allow you to add General Value lists in the Related Lists section.\\nItems and lists that are added appear in the text box. The Lists appear with an icon as shown.\\nAdd a List.\\nClick\\nAdd List\\n.\\nThe appropriate list selector box appears, based on the selected list type.\\nClick\\nAdd List\\n.\\nThe appropriate list selector box appears, based on the selected list type.\\nSelect the items or lists to include in the list being created.\\nWhen adding a related list, only lists that are compatible with the current list are shown. Each list type allows lists of the same type to be added as a related list.\\nHost lists allow you to add General Value, IP Address, and IP Range lists in the Related Lists section.\\nUser lists allow you to add General Value lists in the Related Lists section.\\nItems and lists that are added appear in the text box. The Lists appear with an icon as shown.\\nSelect the items or lists to include in the list being created.\\nWhen adding a related list, only lists that are compatible with the current list are shown. Each list type allows lists of the same type to be added as a related list.\\nHost lists allow you to add General Value, IP Address, and IP Range lists in the Related Lists section.\\nHost lists allow you to add General Value, IP Address, and IP Range lists in the Related Lists section.\\nUser lists allow you to add General Value lists in the Related Lists section.\\nUser lists allow you to add General Value lists in the Related Lists section.\\nItems and lists that are added appear in the text box. The Lists appear with an icon as shown.\\nImport a list.\\nClick\\nImport items\\non the bottom of the window.\\xa0Not all List Types can import values. The following can import values:\\nGeneral Value\\nHost\\nUsers\\nIt is not possible to specify a sub list via Import, but Imported lists may contain sub lists (only items are affected by the import process).\\nSelect the Import behavior from the following:\\nReplace existing items (lists are not removed)\\n. Select this option to replace existing list values. This does not remove any existing lists, only values.\\nImport items as patterns\\n. Select this option to have the list items treated as wildcards instead of literal values. When this option is selected, each list item is wrapped in percent (%) signs. The default (off) is to treat all input as literal values, with no patterns or escaping. Turning the option on enables Pattern characters, in which case all pattern-literals need to be escaped. The following table indicates how values are interpreted. Where multiple types are supported, the type is determined in the indicated priority order.\\nList/Entry Type\\nExamples\\nComments\\nHost/IPv6 Range\\nfe80::1~fe80::\\nffff ::~::1\\nContains tilde and both parts meet valid IPv6 format, including dotted decimal-suffix.\\nHost/IPv4 Range\\n192.168.1.1~192.168.1.255\\nContains tilde and both parts meet valid IPv4 format. Otherwise, an error is raised.\\nHost/IPv6\\nfe80::1\\n::1\\nContains two colons. Any valid IPv6 format, including dotted decimal-suffix. Otherwise, an error is raised.\\nHost/IPv4\\n192.168.1.1\\nMeets valid IPv4 format.\\nHost/Hostname\\ngandalf\\ngandalf.com\\n*.\\ngandalf.com\\nserver___.com\\nShould use valid hostname characters plus wildcards (if enabled), but these are not verified.\\nHostnames may start with a leading digit per RFC 1123.\\nHostnames with a space are not supported.\\nHost/Known Host\\nn/a\\nNot supported.\\nGeneral Value (all contexts)\\nconfidential\\nhttp://www.facebook.com\\ndearest%\\nValid text plus wildcards (if enabled).\\nUser\\njoe\\njoe.user\\njoe.user@someorg.com\\njohn%\\njohn\\\\%\\nValid text plus wildcards (if enabled).\\nActive Directory Groups are not supported.\\nDo not put AD Groups in import lists, because they will be deleted. Use a sub list to hold AD Groups.\\nClick an Import format from the following:\\nImport Text File\\n. To import a text file, click\\nImport Text File\\n, go to the file, and then click\\nOpen\\n.\\nImport Clipboard Text\\n. To import a list from the clipboard, ensure you have already copied the values you want to import, and then click\\nImport Clipboard Text\\n. This pastes the values into the List Items tab.\\nUp to 2 million items can be imported. However, only 30,000 items can be edited in the interface.\\nItems in a list that are going to be imported must be separated with a comma (,) or line breaks. Leading/trailing spaces are removed.\\nNo validation is done on the contents of a file or the clipboard. They are both treated as if they were text. The items are imported as if the user had added them manually using repeated Add Item operations. The Items list is left in an uncommitted state, so you can preview the result and choose either\\nApply\\nor\\nCancel\\n.\\nCan be ANSI or UTF. If the file has a UTF byte mark header, it is interpreted as UTF. Otherwise, it is interpreted as Extended ASCII.\\nOnly extended ASCII (not Unicode) characters are officially supported in LogRhythm.\\nSimple textual file of line-break-separated list items. All three line-break formats are supported (CR, LF, CRLF).\\nFinal item does not need to be terminated.\\nEmpty items are ignored (that is, two or more successive line breaks.)\\nEmpty files are legal (removes all items.)\\nImport a list.\\nClick\\nImport items\\non the bottom of the window.\\xa0Not all List Types can import values. The following can import values:\\nGeneral Value\\nHost\\nUsers\\nIt is not possible to specify a sub list via Import, but Imported lists may contain sub lists (only items are affected by the import process).\\nClick\\nImport items\\non the bottom of the window.\\xa0Not all List Types can import values. The following can import values:\\nGeneral Value\\nGeneral Value\\nHost\\nHost\\nUsers\\nIt is not possible to specify a sub list via Import, but Imported lists may contain sub lists (only items are affected by the import process).\\nUsers\\nIt is not possible to specify a sub list via Import, but Imported lists may contain sub lists (only items are affected by the import process).\\nSelect the Import behavior from the following:\\nReplace existing items (lists are not removed)\\n. Select this option to replace existing list values. This does not remove any existing lists, only values.\\nImport items as patterns\\n. Select this option to have the list items treated as wildcards instead of literal values. When this option is selected, each list item is wrapped in percent (%) signs. The default (off) is to treat all input as literal values, with no patterns or escaping. Turning the option on enables Pattern characters, in which case all pattern-literals need to be escaped. The following table indicates how values are interpreted. Where multiple types are supported, the type is determined in the indicated priority order.\\nList/Entry Type\\nExamples\\nComments\\nHost/IPv6 Range\\nfe80::1~fe80::\\nffff ::~::1\\nContains tilde and both parts meet valid IPv6 format, including dotted decimal-suffix.\\nHost/IPv4 Range\\n192.168.1.1~192.168.1.255\\nContains tilde and both parts meet valid IPv4 format. Otherwise, an error is raised.\\nHost/IPv6\\nfe80::1\\n::1\\nContains two colons. Any valid IPv6 format, including dotted decimal-suffix. Otherwise, an error is raised.\\nHost/IPv4\\n192.168.1.1\\nMeets valid IPv4 format.\\nHost/Hostname\\ngandalf\\ngandalf.com\\n*.\\ngandalf.com\\nserver___.com\\nShould use valid hostname characters plus wildcards (if enabled), but these are not verified.\\nHostnames may start with a leading digit per RFC 1123.\\nHostnames with a space are not supported.\\nHost/Known Host\\nn/a\\nNot supported.\\nGeneral Value (all contexts)\\nconfidential\\nhttp://www.facebook.com\\ndearest%\\nValid text plus wildcards (if enabled).\\nUser\\njoe\\njoe.user\\njoe.user@someorg.com\\njohn%\\njohn\\\\%\\nValid text plus wildcards (if enabled).\\nActive Directory Groups are not supported.\\nDo not put AD Groups in import lists, because they will be deleted. Use a sub list to hold AD Groups.\\nReplace existing items (lists are not removed)\\n. Select this option to replace existing list values. This does not remove any existing lists, only values.\\nImport items as patterns\\n. Select this option to have the list items treated as wildcards instead of literal values. When this option is selected, each list item is wrapped in percent (%) signs. The default (off) is to treat all input as literal values, with no patterns or escaping. Turning the option on enables Pattern characters, in which case all pattern-literals need to be escaped. The following table indicates how values are interpreted. Where multiple types are supported, the type is determined in the indicated priority order.\\nList/Entry Type\\nExamples\\nComments\\nHost/IPv6 Range\\nfe80::1~fe80::\\nffff ::~::1\\nContains tilde and both parts meet valid IPv6 format, including dotted decimal-suffix.\\nHost/IPv4 Range\\n192.168.1.1~192.168.1.255\\nContains tilde and both parts meet valid IPv4 format. Otherwise, an error is raised.\\nHost/IPv6\\nfe80::1\\n::1\\nContains two colons. Any valid IPv6 format, including dotted decimal-suffix. Otherwise, an error is raised.\\nHost/IPv4\\n192.168.1.1\\nMeets valid IPv4 format.\\nHost/Hostname\\ngandalf\\ngandalf.com\\n*.\\ngandalf.com\\nserver___.com\\nShould use valid hostname characters plus wildcards (if enabled), but these are not verified.\\nHostnames may start with a leading digit per RFC 1123.\\nHostnames with a space are not supported.\\nHost/Known Host\\nn/a\\nNot supported.\\nGeneral Value (all contexts)\\nconfidential\\nhttp://www.facebook.com\\ndearest%\\nValid text plus wildcards (if enabled).\\nUser\\njoe\\njoe.user\\njoe.user@someorg.com\\njohn%\\njohn\\\\%\\nValid text plus wildcards (if enabled).\\nActive Directory Groups are not supported.\\nDo not put AD Groups in import lists, because they will be deleted. Use a sub list to hold AD Groups.\\nImport items as patterns\\n. Select this option to have the list items treated as wildcards instead of literal values. When this option is selected, each list item is wrapped in percent (%) signs. The default (off) is to treat all input as literal values, with no patterns or escaping. Turning the option on enables Pattern characters, in which case all pattern-literals need to be escaped. The following table indicates how values are interpreted. Where multiple types are supported, the type is determined in the indicated priority order.\\nList/Entry Type, Examples, Comments\\nHost/IPv6 Range, fe80::1~fe80::ffff ::~::1, Contains tilde and both parts meet valid IPv6 format, including dotted decimal-suffix.\\nHost/IPv4 Range, 192.168.1.1~192.168.1.255, Contains tilde and both parts meet valid IPv4 format. Otherwise, an error is raised.\\nHost/IPv6, fe80::1::1, Contains two colons. Any valid IPv6 format, including dotted decimal-suffix. Otherwise, an error is raised.\\nHost/IPv4, 192.168.1.1, Meets valid IPv4 format.\\nHost/Hostname, gandalfgandalf.com*.gandalf.comserver___.com, Should use valid hostname characters plus wildcards (if enabled), but these are not verified.Hostnames may start with a leading digit per RFC 1123.Hostnames with a space are not supported.\\nHost/Known Host, n/a, Not supported.\\nGeneral Value (all contexts), confidentialhttp://www.facebook.comdearest%, Valid text plus wildcards (if enabled).\\nUser, joejoe.userjoe.user@someorg.comjohn%john\\\\%, Valid text plus wildcards (if enabled).Active Directory Groups are not supported.Do not put AD Groups in import lists, because they will be deleted. Use a sub list to hold AD Groups.\\nfe80::1~fe80::\\nffff ::~::1\\nfe80::1\\n::1\\ngandalf\\ngandalf.com\\n*.\\ngandalf.com\\nserver___.com\\nShould use valid hostname characters plus wildcards (if enabled), but these are not verified.\\nHostnames may start with a leading digit per RFC 1123.\\nHostnames with a space are not supported.\\njoe\\njoe.user\\njoe.user@someorg.com\\njohn%\\njohn\\\\%\\nValid text plus wildcards (if enabled).\\nActive Directory Groups are not supported.\\nDo not put AD Groups in import lists, because they will be deleted. Use a sub list to hold AD Groups.\\nClick an Import format from the following:\\nImport Text File\\n. To import a text file, click\\nImport Text File\\n, go to the file, and then click\\nOpen\\n.\\nImport Clipboard Text\\n. To import a list from the clipboard, ensure you have already copied the values you want to import, and then click\\nImport Clipboard Text\\n. This pastes the values into the List Items tab.\\nUp to 2 million items can be imported. However, only 30,000 items can be edited in the interface.\\nItems in a list that are going to be imported must be separated with a comma (,) or line breaks. Leading/trailing spaces are removed.\\nNo validation is done on the contents of a file or the clipboard. They are both treated as if they were text. The items are imported as if the user had added them manually using repeated Add Item operations. The Items list is left in an uncommitted state, so you can preview the result and choose either\\nApply\\nor\\nCancel\\n.\\nCan be ANSI or UTF. If the file has a UTF byte mark header, it is interpreted as UTF. Otherwise, it is interpreted as Extended ASCII.\\nOnly extended ASCII (not Unicode) characters are officially supported in LogRhythm.\\nSimple textual file of line-break-separated list items. All three line-break formats are supported (CR, LF, CRLF).\\nFinal item does not need to be terminated.\\nEmpty items are ignored (that is, two or more successive line breaks.)\\nEmpty files are legal (removes all items.)\\nClick an Import format from the following:\\nImport Text File\\n. To import a text file, click\\nImport Text File\\n, go to the file, and then click\\nOpen\\n.\\nImport Text File\\n. To import a text file, click\\nImport Text File\\n, go to the file, and then click\\nOpen\\n.\\nImport Clipboard Text\\n. To import a list from the clipboard, ensure you have already copied the values you want to import, and then click\\nImport Clipboard Text\\n. This pastes the values into the List Items tab.\\nImport Clipboard Text\\n. To import a list from the clipboard, ensure you have already copied the values you want to import, and then click\\nImport Clipboard Text\\n. This pastes the values into the List Items tab.\\nUp to 2 million items can be imported. However, only 30,000 items can be edited in the interface.\\nItems in a list that are going to be imported must be separated with a comma (,) or line breaks. Leading/trailing spaces are removed.\\nNo validation is done on the contents of a file or the clipboard. They are both treated as if they were text. The items are imported as if the user had added them manually using repeated Add Item operations. The Items list is left in an uncommitted state, so you can preview the result and choose either\\nApply\\nor\\nCancel\\n.\\nCan be ANSI or UTF. If the file has a UTF byte mark header, it is interpreted as UTF. Otherwise, it is interpreted as Extended ASCII.\\nOnly extended ASCII (not Unicode) characters are officially supported in LogRhythm.\\nSimple textual file of line-break-separated list items. All three line-break formats are supported (CR, LF, CRLF).\\nFinal item does not need to be terminated.\\nEmpty items are ignored (that is, two or more successive line breaks.)\\nEmpty files are legal (removes all items.)\\nTo bind the selected items or lists to the new list, click\\nApply\\n.\\nTo bind the selected items or lists to the new list, click\\nApply\\n.\\nClick the\\nAdditional Settings\\ntab.\\nThe Additional Settings tab of the List Properties dialog box is optional for all but General Value lists. It includes fields for Use Contexts and Additional Details. The Use Contexts box displays items for General Values Lists. For all other list types, the Use Contexts box is empty and disabled.\\nClick the\\nAdditional Settings\\ntab.\\nThe Additional Settings tab of the List Properties dialog box is optional for all but General Value lists. It includes fields for Use Contexts and Additional Details. The Use Contexts box displays items for General Values Lists. For all other list types, the Use Contexts box is empty and disabled.\\nSelect at least one Use Context option.\\n(Optional)\\nIn the Additional Details box, enter a long description for the list.\\nTo save the new list, click\\nOK\\n.\\nTo save the new list, click\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nMessage Processing Engine Rule Builder\\n', 'Application Manager': 'Application records define an application and its ports and protocols so that MPE rules can identify a log origin. For example, if TCP port 53 is mapped to the DNS application, then rules that identify traffic on TCP port 53 can associate it correctly with DNS. Rules can also be set to associate all logs that match a particular application record automatically, regardless of port and protocol.\\nAn association between an application and a port or protocol is global. There can only be one unique pairing for a single LogRhythm deployment.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nMessage Processing Engine Rule Builder\\n', 'Common Event Manager': 'Using the Rule Builder Common Event Browser, you can view the complete list of more than 40,000 common events. Use the predefined common events wherever possible. You can use the Common Event Manager to add, delete, and maintain the many different types of common events, and the classifications in which they reside. Common Events have a Risk Rating attribute that helps the Platform Manager determine how to handle an event properly. Common Events are specific to Rule Building, which uses rules developed to identify and extract, or parse specific, useful information from log messages. If you need to create a new common event, use the following guidelines:\\nCommon events should be generically named so that they can be re-used for a wide variety of devices. For example, if a common event is being created for a log message that describes a successful connection to an FTP server, the common event should be named so that the FTP server type is irrelevant.\\nGood Name: FTP Connection Succeeded\\nBad Name: Gene6 FTP Connection Succeeded\\nGood Name: FTP Connection Succeeded\\nBad Name: Gene6 FTP Connection Succeeded\\nCommon event names should always have the first letter of each word capitalized to make viewing common events in analysis tools more consistent.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nMonitor, Search, and Analysis\\n', 'Alarm Viewer': 'The Alarm Viewer lists alarms generated by LogRhythm, tracks alarm history, and updates alarm statuses.\\n', 'Alarm Viewer Access Control': 'Access, Global Admin, Global Analyst, Restricted Analyst\\nRead, All alarms, all associated events, All alarms, all associated events, Alarms associated with AnalystEvents within Analyst access rightsIt is possible for an Alarm to be associated with a Restricted Analyst (RA) and yet not allow the RA to see all associated events. This occurs when a Restricted Analyst has access to a Log Source for configuration purposes, but does not have access to the logs generated by the log source.\\nUpdate Status, All, All, For associated Alarms\\nFilter by Status, Yes, Yes, Yes\\nFilter by Alarm Rule, Yes - all, Yes - all, Yes - all\\nFilter by who was Notified, Yes - all, Yes - all, No - The Restricted Analyst can only view alarms of which they were notified.\\nAll alarms, all associated events\\nAll alarms, all associated events\\nAlarms associated with Analyst\\nEvents within Analyst access rights\\nIt is possible for an Alarm to be associated with a Restricted Analyst (RA) and yet not allow the RA to see all associated events. This occurs when a Restricted Analyst has access to a Log Source for configuration purposes, but does not have access to the logs generated by the log source.\\nFor associated Alarms\\nFilter by Status\\nYes - all\\nYes - all\\nYes - all\\nYes - all\\nYes - all\\nNo - The Restricted Analyst can only view alarms of which they were notified.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nMonitor, Search, and Analysis\\n', 'Investigator': 'The powerful LogRhythm Investigator search tool allows you to view logs and events collected in near-real-time from both the Data Processor and Platform Manager Databases. Investigator default settings are configured in\\nMy Preferences\\n.\\n', 'Investigation Views': 'After you run an investigation, LogRhythm offers a rich set of grids, graphs, and charts to view the collected data. The initial search results window that appears depends on the type of search that was run. Results from Platform Manager and Data Processor searches appear in a window with two primary tabs, Log/Event Analyzer and Log Viewer, with additional views available from the Properties window under the File menu on the toolbar. Results from a Log Miner search appear in several different panes. A screen tip displays a definition of any column heading when you point to it.\\n', 'Log/Event Analyzer Tab': 'The Log/Event Analyzer tab allows you to view aggregate statistics from the following tabs and sub-tabs, which are located at the bottom of the window.\\xa0On the Tool Selector, the active view(s) are in boldface type.\\xa0In Platform Manager and Data Processor searches, the Tool Selector appears on the left side of the screen.\\nTab, Purpose\\nAggregate Log/Event List, Logs with the same value for each of the primary metadata fields.\\nLogs/Events by Time by Type, Logs/events for each type over the specified time frame.\\nLogs/Events by Time by Direction, Logs/events for each Direction over the specified time frame.\\nLogs by Day and Hour, Graphic display of logs by hour within day.\\nLogs by Day of Week and Hour, Graphic display of logs by hour and day within week.\\nLogs/Events by Type, A pie chart that displays the number of logs/events for each Type of Audit, Operations, Security, and Unknown.\\nLogs/Events by Direction, A pie chart that displays the number of logs/events for each direction.\\nAudit Logs/Events by Classification, A bar chart that displays the number of logs/events for each Audit classification.\\nOperations Logs/Events by Classification, A bar chart that displays the number of logs/events for each Operations classification.\\nSecurity Logs/Events by Classification, A bar chart that displays the number of logs/events for each Security classification.\\nLog Source Statistics, A grid of Log Source statistics with a graph of the selected row.\\nCommon Event Statistics, A grid of statistics for log/event Common Event and a graph of the selected row.\\nUser (Origin) Statistics, Provides log statistics for each recorded User Origin.All statistics tabs include the following subtabs: Logs by Time, KBytes by Time, Packets by Time, User (Origin) by Logs, Host (Impacted) by KBytes (iHost Total), Host (Impacted) by Packets (iHost Total).\\nHost (Origin) Statistics, Provides log statistics for each recorded Origin Host.\\nHost (Impacted) Statistics, Provides log statistics for each recorded Impacted Host.\\nApplication Statistics, Provides log statistics for each recorded Impacted Application.\\nVendor Message ID Statistics, Provides log statistics for each recorded Vendor Message ID.\\nNetwork Visualization, This diagram shows the relationship between Hosts in the current set of aggregated logs/events.The right side of the window displays a diagram based on the Investigation results. Only logs that have a source or destination host appear. The left side of the window lists statistics for items selected in the diagram and provides options and controls to modify the view. The diagram features include the following:A high-level aggregate view that you can expand by clicking the + signsA hierarchical display that includes the following:Root. The diagram hub. Its statistics show the logs processed and logs skipped.Entity. Global, Primary, and custom Entities including child Entities.Zone. Internal; DMZ; External; UnknownLocation. Country, Region, City.Location is only available when GeoIPLevel is enabled in theData Processor Advanced Properties.Network. The order is:Known Network. Logs where Host.NetworkID is in the Network.IP Range Network. Logs where Host.IP has a value.Named Host. All other Hosts.Host Group. If any Hosts remain in a higher-level group after all other grouping, they are placed in a generic Host Group sorted by IP and then Name.A red outline around nodes that contain logs with a log failure count> 0.A width of the links between parent and child nodes that is proportional to the Link Display Mode value of the parent. The larger the number, the wider the line. This allows you to locate the greatest areas of activity at a glance.For example, in the following diagram where Link Display Mode is set to Logs:Primary Site, Total Log Count = 48,000 logs:Internal node, widest line, Total Log Count = 42,000 logs.Named Hosts, widest line, Total Log Count = 35,0000.0.0.0:255.255.255.255, medium line, Total Log Count = 6,000Wallis and Futuna (green field hidden at the bottom), narrowest line, Total Log Count = 1,000\\nAggregate Log/Event List\\nLogs/Events by Time by Type\\nLogs/Events by Time by Direction\\nLogs by Day and Hour\\nLogs by Day of Week and Hour\\nUser (Origin) Statistics\\nProvides log statistics for each recorded User Origin.\\nAll statistics tabs include the following subtabs: Logs by Time, KBytes by Time, Packets by Time, User (Origin) by Logs, Host (Impacted) by KBytes (iHost Total), Host (Impacted) by Packets (iHost Total).\\nHost (Origin) Statistics\\nHost (Impacted) Statistics\\nApplication Statistics\\nVendor Message ID Statistics\\nThis diagram shows the relationship between Hosts in the current set of aggregated logs/events.\\nThe right side of the window displays a diagram based on the Investigation results. Only logs that have a source or destination host appear. The left side of the window lists statistics for items selected in the diagram and provides options and controls to modify the view. The diagram features include the following:\\nA high-level aggregate view that you can expand by clicking the + signs\\nA hierarchical display that includes the following:\\nRoot\\n. The diagram hub. Its statistics show the logs processed and logs skipped.\\nEntity\\n. Global, Primary, and custom Entities including child Entities.\\nZone\\n. Internal; DMZ; External; Unknown\\nLocation\\n. Country, Region, City.\\nLocation is only available when GeoIPLevel is enabled in the\\nData Processor Advanced Properties\\n.\\nNetwork\\n. The order is:\\nKnown Network\\n. Logs where Host.NetworkID is in the Network.\\nIP Range Network\\n. Logs where Host.IP has a value.\\nNamed Host\\n. All other Hosts.\\nHost Group\\n. If any Hosts remain in a higher-level group after all other grouping, they are placed in a generic Host Group sorted by IP and then Name.\\nRoot\\n. The diagram hub. Its statistics show the logs processed and logs skipped.\\nEntity\\n. Global, Primary, and custom Entities including child Entities.\\nZone\\n. Internal; DMZ; External; Unknown\\nLocation\\n. Country, Region, City.\\nLocation is only available when GeoIPLevel is enabled in the\\nData Processor Advanced Properties\\n.\\nLocation\\n. Country, Region, City.\\nLocation is only available when GeoIPLevel is enabled in the\\nData Processor Advanced Properties\\n.\\nNetwork\\n. The order is:\\nKnown Network\\n. Logs where Host.NetworkID is in the Network.\\nIP Range Network\\n. Logs where Host.IP has a value.\\nNamed Host\\n. All other Hosts.\\nKnown Network\\n. Logs where Host.NetworkID is in the Network.\\nIP Range Network\\n. Logs where Host.IP has a value.\\nNamed Host\\n. All other Hosts.\\nHost Group\\n. If any Hosts remain in a higher-level group after all other grouping, they are placed in a generic Host Group sorted by IP and then Name.\\nA red outline around nodes that contain logs with a log failure count> 0.\\nA width of the links between parent and child nodes that is proportional to the Link Display Mode value of the parent. The larger the number, the wider the line. This allows you to locate the greatest areas of activity at a glance.\\nFor example, in the following diagram where Link Display Mode is set to Logs:\\nPrimary Site, Total Log Count = 48,000 logs:\\nInternal node, widest line, Total Log Count = 42,000 logs.\\nNamed Hosts, widest line, Total Log Count = 35,000\\n0.0.0.0:255.255.255.255, medium line, Total Log Count = 6,000\\nWallis and Futuna (green field hidden at the bottom), narrowest line, Total Log Count = 1,000\\n\\n', 'Log Viewer Tab': 'The Log Viewer tab allows you to view individual logs and events and perform other operations on selected logs.\\n', 'Log Miner': \"Log Miner is a summary overview and trending tool that is opened after you perform a LogMart Search with Investigator. Log Miner's flexible graphing capabilities make it extremely helpful in understanding your environment's activity for time periods far longer than the time to live (TTL) setting.\\nLog Miner has five view panes that display data in different ways.\\nLog Message Occurrences by Day and Hour of Day\\n. This graph displays each day's logs as a solid shape of a unique color. By viewing the log data by day, in a stack, it is easy to see peak times for log data by looking for the tallest peak stacks in the graph. This pane has the following functionality:\\nHovering over a day selects that shape.\\nHovering over different areas of one day's colored shape displays log counts by hour in the screen tip.\\nDouble-clicking one day's colored shape causes Log Miner to drill down to that day.\\nHovering over a day selects that shape.\\nHovering over different areas of one day's colored shape displays log counts by hour in the screen tip.\\nDouble-clicking one day's colored shape causes Log Miner to drill down to that day.\\nLog Message Occurrences by Day of Week and Hour of Day\\n. This graph displays each day's logs in a unique color and row, and each hour's logs as a distinct data pillar. By viewing log data by days broken into hours, it is easy to recognize peak days of activity by the row with the highest values, or a peak hour of activity by the tallest pillar. This pane has the following functionality:\\nHovering over a day's colored row highlights that day's row and fade out other days for easier viewing.\\nHovering over different hours of one day's colored row displays log counts by hour in the screen tip.\\nDouble-clicking one hour's pillar causes Log Miner to drill down to that hour.\\nHovering over a day's colored row highlights that day's row and fade out other days for easier viewing.\\nHovering over different hours of one day's colored row displays log counts by hour in the screen tip.\\nDouble-clicking one hour's pillar causes Log Miner to drill down to that hour.\\nAggregate Log Messages\\n. This pane gives a detailed view of the aggregate log data being used to generate the graphs. Information on date / time, counts, Common Event, direction, and more are all included.\\nLog Message Occurrences by Hour\\n. This graph provides a linear timeline view of the log activity, with each bar representing a particular hour.\\nDay of Week and Hour of Day Filter\\n. This pane allows filtering, by days or hours, to be completed very quickly. Select or clear the check boxes in this pane to change filtering.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nMonitor, Search, and Analysis\\n', 'Personal Dashboard': 'The LogRhythm Personal Dashboard is a high-level analytical tool that you configure to meet your specific needs. It appears with the Tool Selector on the left and the graphs and tables on the right. Loading the data may take a few moments depending on the query settings in My Preferences.\\n', 'Available Tabs and Views': 'Many of these views display columns of data. You can point to any column heading to display a definition.\\n', 'General Analysis': 'Alarm List\\n. A grid listing alarms. Select an alarm and select Alarm Properties from the context menu to display additional information about the alarm.\\nAggregate Log/Event List\\n. A grid listing aggregated logs/events that have the same value in the primary metadata fields. Options you can access in the grid context-menu are described in Search Context Menus.\\nLogs/Events by Direction\\n. A pie chart displays the number of logs/events for each Direction; for example, External or Internal. Does not appear by default.\\nLogs/Events by Type\\n. A pie chart displays the number of logs/events for each Type; for example, Audit, Operations, or Security. Does not appear by default.\\n', 'Time Analysis': 'Events by Time by Type\\n. A bar chart displays the number of logs/events for each Type over a specified time frame.\\nEvents by Time by Direction\\n. A bar chart displays the number of logs/events for each Direction over a specified time frame.\\nLogs by Day and Hour\\n. Log message occurrences by day and hour of day.\\nLogs by Day of Week and Hour\\n. Log message occurrences by day of week and hour.\\n', 'Statistical Analysis': 'Log Source Statistics\\n. A grid that provides statistics for log/event Log Source.\\nCommon Event Statistics\\n. A grid that provides statistics for log/event Common Event.\\nUser (Origin) Statistics\\n. A grid listing statistics for log/event Origin User.\\nLogs By Time\\nKBytes by Time\\nItems by Time\\nLogs By Time\\nKBytes by Time\\nItems by Time\\nHost (Origin) Statistics\\n. A grid listing statistics for log/event Origin Host. Options accessed in the grid context menu are described in Search Context Menus.\\nLogs By Time\\nKBytes by Time\\nItems by Time\\nLogs By Time\\nKBytes by Time\\nItems by Time\\nHost (Impacted) Statistics\\n. A grid listing statistics for log/event Impacted Host. Options accessed in the grid context menu are described in Search Context Menus.\\nLogs By Time\\nKBytes by Time\\nItems by Time\\nLogs By Time\\nKBytes by Time\\nItems by Time\\nApplication Statistics\\n. A grid tool that provides statistics for log/event Impacted Application.\\nLogs By Time\\nKBytes by Time\\nItems by Time\\nLogs By Time\\nKBytes by Time\\nItems by Time\\nVendor Message ID Statistics\\n. A grid listing statistics for log/event Vendor Message IDs.\\nLogs By Time\\nKBytes by Time\\nItems by Time\\nLogs By Time\\nKBytes by Time\\nItems by Time\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nMonitor, Search, and Analysis\\n', 'Quick Search Toolbar': 'The Quick Search toolbar provides an easy way to perform common analysis tasks. By default, the toolbar is located at the bottom of the Client Console window. It includes the following capabilities:\\nQuick lookup of the events comprising an individual alarm based on ID.\\nQuick lookup of an event based on ID.\\nQuick search based on user activity.\\nQuick search of host activity.\\nQuick search of email address activity.\\nYou can\\nRun Correlate\\nwith the Quick Search toolbar to narrow the results from Tail, Investigation, or Personal Dashboard searches.\\n', 'Search Details': 'The Quick Search toolbar performs a search based on the Search For options you select. The following is a list of those options with additional information where appropriate.\\nAlarm\\n. A record indicating that an alarm rule has been triggered by an event. Enter the id of the Alarm for which you are searching.\\nClassification\\n. LogRhythm uses classifications to group similar log messages into logical containers. These classifications provide organizations vast amounts of log data, making it easier to sort through and understand. Classifications fall under three main categories: Audit, Security, and Operations.\\nCommon Event\\n. Specify the name of the event. Logs identified by Common Events matching the specified value will be searched. Wildcards are (*) allowed.\\nEmail Address\\n. The value specified can exist in either the sender or recipient field.\\nEvent\\n. A log having more immediate operational, security, or compliance relevance. Typically logs classified as errors, failures, or attacks are considered events.\\nHost\\n. The value specified can exist in either Origin or Impacted host fields. If the value entered is an IP address, Origin and Impacted IP is searched. If the value entered is a host name, Known Host records are searched for first. If one or more Known Hosts are found, Origin and Impacted Known Host is searched. If no Known Host is found, Origin and Impacted DNS host name is searched. Wildcards (*) allowed\\nLog Host\\n. Standard hostname given to the address of the loopback network interface. Localhost is specified where one would otherwise use the hostname of a computer.\\nMPE Rule.\\nSpecify the name of the rule you are searching for. Logs matched by Message Processing Engine (MPE) Rules matching the specified value will be searched for. Wildcards (*) are allowed.\\nPort\\n. When searching for a TCP/UDP port, the value specified can exist in either the origin or impacted port field.\\nUser\\n. When searching for a login, the value specified can exist in either the Login or the Account field.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nMonitor, Search, and Analysis\\n', 'Run Correlate': 'After you perform an Investigation, Log Miner, Tail, or Personal Dashboard search, you can use correlate to search those results. Correlate can narrow the original search results to display just the logs that match either a log from the original search or the values you set in the Quick Search toolbar. Because correlate only searches the logs returned in the original search, it is very efficient.\\nOn the My LogRhythm menu, click\\nMy Preferences\\n.\\nOn the My LogRhythm menu, click\\nMy Preferences\\n.\\nSet your Data Processor defaults.\\nIf correlate returns the error message No log or event repositories were configured for the search, it means no Data Processor defaults are set in My Preferences.\\nSet your Data Processor defaults.\\nIf correlate returns the error message No log or event repositories were configured for the search, it means no Data Processor defaults are set in My Preferences.\\nGenerate initial search results from Investigator, Tail, Log Miner, or Personal Dashboard.\\n(Optional)\\nSet up criteria in the Quick Search toolbar. You can include the following Quick Search toolbar options in a correlation:\\nIn the past\\n. Enter the number of minutes, hours, or days to use in the log data search.\\nInclude\\n. Select the classifications to use as filters for the investigation.\\nOptions\\n. Set values for:\\nType of investigation\\nUse Investigation\\n. Defaults to Data Processor. It can change to Platform Manager if you select Investigation Wizard.\\nUse Log Miner\\n. Uses LogMart.\\nQuery Platform Manager?\\nQueries the Platform Manager in addition to the selection above.\\nQuery Default Data Processors?\\nQueries the Data Processors set as defaults.\\nInvestigation Wizard\\n. Opens before correlation starts so you can set additional criteria.\\nThe correlated search runs using the date range of the aggregate event or log padded on either end by the settings in the Quick Search toolbar. Example:\\nAggregate log settings. First Normal Date = 8:00 AM, Last Normal Date = 12:00 PM\\nQuick Search Toolbar setting. In the past 1 hour\\nResult. The Correlated search date range = 7:00 AM to 1:00 PM.\\nIn the past\\n. Enter the number of minutes, hours, or days to use in the log data search.\\nInclude\\n. Select the classifications to use as filters for the investigation.\\nOptions\\n. Set values for:\\nType of investigation\\nUse Investigation\\n. Defaults to Data Processor. It can change to Platform Manager if you select Investigation Wizard.\\nUse Log Miner\\n. Uses LogMart.\\nQuery Platform Manager?\\nQueries the Platform Manager in addition to the selection above.\\nQuery Default Data Processors?\\nQueries the Data Processors set as defaults.\\nInvestigation Wizard\\n. Opens before correlation starts so you can set additional criteria.\\nType of investigation\\nUse Investigation\\n. Defaults to Data Processor. It can change to Platform Manager if you select Investigation Wizard.\\nUse Log Miner\\n. Uses LogMart.\\nUse Investigation\\n. Defaults to Data Processor. It can change to Platform Manager if you select Investigation Wizard.\\nUse Log Miner\\n. Uses LogMart.\\nQuery Platform Manager?\\nQueries the Platform Manager in addition to the selection above.\\nQuery Default Data Processors?\\nQueries the Data Processors set as defaults.\\nInvestigation Wizard\\n. Opens before correlation starts so you can set additional criteria.\\nAggregate log settings. First Normal Date = 8:00 AM, Last Normal Date = 12:00 PM\\nQuick Search Toolbar setting. In the past 1 hour\\nResult. The Correlated search date range = 7:00 AM to 1:00 PM.\\nSelect a log from the initial search.\\nRight-click the selected log, and then click\\nCorrelate\\n.\\nFrom the Correlate options, select the field that you want to match. The options include the following:\\nAll Fields\\n. All fields with data will be used within the investigations filter.\\nSelect Field\\n. Click the down-arrow and select from the drop-down list. Available options depend on the selected log.\\nField Combinations\\n. The combination selected will be used within the investigations filter. For example, if User (Impacted) in User (Origin) is selected, the filter within the investigation will take the value that is in User (Impacted) within the record selected and use that value to filter the User (Origin) field regardless what is in the User (Origin) field for the record selected.\\nFIM/DLD\\n. Only available from non-aggregate/event lists within Investigator or DLD for Data Loss Defender and Tail. Only available for FIM/DLD logs – the log source is type FileMon for File Integrity Mon.\\nAs soon as you make your selection, correlate runs and returns all matching logs.\\nAll Fields\\n. All fields with data will be used within the investigations filter.\\nSelect Field\\n. Click the down-arrow and select from the drop-down list. Available options depend on the selected log.\\nField Combinations\\n. The combination selected will be used within the investigations filter. For example, if User (Impacted) in User (Origin) is selected, the filter within the investigation will take the value that is in User (Impacted) within the record selected and use that value to filter the User (Origin) field regardless what is in the User (Origin) field for the record selected.\\nFIM/DLD\\n. Only available from non-aggregate/event lists within Investigator or DLD for Data Loss Defender and Tail. Only available for FIM/DLD logs – the log source is type FileMon for File Integrity Mon.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nMonitor, Search, and Analysis\\n', 'Tail': \"Using LogRhythm's Tail tool is similar to using the Investigator. However, a Tail queries for new logs and updates your log/event list in real-time. Tail is primarily used to track real-time and near-time logs and events. The concept of the Tail command should be familiar to users of UNIX/Linux based operating systems. Tails that you save are only available to your user login.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nMonitor, Search, and Analysis\\n', 'TopX Analysis': 'The TopX Analysis feature provides a powerful, quickly configurable tool that offers custom views into logs and events based on metadata generated by LogRhythm. TopX allows you to select a standard metadata field (e.g., Common Event, Impacted Host, Origin Country), available metric (by count, by KBytes, by Packets), and available item (3, 5, 7, 10, 12, 15, or 20) to then view the top or bottom items within the result set.\\nOther available functionality includes:\\nViewing the data in chart and/or list format\\nViewing the chart in 3D\\nApplying custom properties such as additional filters and a custom label\\nShowing the total for the Other values outside the TopX items shown\\nFull drill-down and one-click correlation support. For instance, double-clicking on a value in a TopX pie chart or list immediately drills down into the logs detail for that item\\nContextualizing on Host, Port, or User Information\\nAdding Host as a Known Host\\n', 'TopX Charts': 'You can access TopX Analysis from within Personal Dashboard or Investigator. They are identical between the two analysis tools. The TopX Analysis widgets, along with all others, are accessible from the Tools Selector which resides as a left pane within Personal Dashboard or Investigator.\\nWhen you open Personal Dashboard or Investigator and no TopX widgets are configured, they are listed as Unconfigured TopX in the list. Twelve TopX widgets can be configured per layout. Each layout has its own set of TopX widgets. Because the Top X widgets are part of a Layout, they can also be shared as part of that layout. For details on how to manage and use them, see\\nLayouts\\n.\\nYou can also\\nadd values from a TopX chart to a list\\nand\\nexport a whole grid from a TopX widget to a file\\n.\\n', 'TopX Use Cases': 'There are many use cases for TopX, but to give you an example, there are a few listed below:\\nConfigure TopX tools to show the top 10 attackers, target hosts, target applications, and countries or origin to obtain high-level visibility into threats.\\nConfigure TopX tools to show the top 5 hosts, applications, ports, and protocols generating network traffic.\\nConfigure TopX tools to show the top 10 events impacting production servers as well as the top 10 least observed events. Often events seen less often are the ones to be concerned about.\\n', 'Examples': 'Analyst Model Example\\n. This shows many TopX lists for an Analyst who wants to see the details.\\n\\nExecutive Model Example\\n. This shows many TopX pie charts for an Executive who just wants the big picture.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nMonitor, Search, and Analysis\\n/\\nPersonal Dashboard\\n', 'Configure the Personal Dashboard Display': 'When you open the Personal Dashboard the first time, a set of default charts and graphs appears. You can move, resize, close, pin, and unpin all of them. There are also additional charts and graphs available that you can display. When you close the dashboard, any modifications you made to the view are saved and appear the next time you open the dashboard.\\nOn the main toolbar, click\\nPersonal Dashboard\\n.\\nDo any of the following:\\nTo move an analysis tool, click in the tool title bar and drag it to the new location. Before you release the mouse button, a faint gray outline will show the new location.\\nTo resize an analysis tool, click the border of the tool and drag it to the new size.\\nTo close an analysis tool, click the X in the upper right corner.\\nTo pin an analysis tool, click the pin icon so that it appears to be pointing down into the screen.\\nTo unpin a chart or graph so that it hides when the mouse is not hovering over it, click the pin icon so that it is pointing toward the left.\\nTo move an analysis tool, click in the tool title bar and drag it to the new location. Before you release the mouse button, a faint gray outline will show the new location.\\nTo resize an analysis tool, click the border of the tool and drag it to the new size.\\nTo close an analysis tool, click the X in the upper right corner.\\nTo pin an analysis tool, click the pin icon so that it appears to be pointing down into the screen.\\nTo unpin a chart or graph so that it hides when the mouse is not hovering over it, click the pin icon so that it is pointing toward the left.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nMy LogRhythm\\n', 'Create Email Notification Policies': 'The Alarm Notification Policy is used to specify the information that is included in a notification, as well as throttle the number of notifications sent in an allotted time. The Notification Policy Manager is used to view and work with alarm notification policies. You can access the Notification Policy Manager through the My LogRhythm menu. The Notification Policy Manager limits the visible notification policies to those privately belonging to the currently logged in user. For more information, see\\nAlarm Notification Policies\\n.\\nYou must have TLS 1.2 enabled on the SMTP server to receive email alarm notifications for AI Engine rules.\\nTo create a new, private email notification policy\\nOn the My LogRhythm menu, click\\nMy Notification Policies\\n.\\nClick\\nFile\\n, and then click either\\nNew SMTP Policy\\nor\\nNew SNMP Policy\\n. SMTP is used for most email notifications.\\nFor information specific to SNMP Policy settings, see Create a New SNMP Alarm Notification Policy.\\nThe Email Notification Policy window appears.\\nIn the Policy Name field, type a name for your policy.\\nEnter Notification Period in Minutes and Maximum Notifications Per Period settings to establish how many notifications will be sent in a specified time period.\\nFor example, if the Notification Period in Minutes is set to 60 minutes and the Maximum Notifications Per Period is set to 10 and you receive 15 alarms in 60 minutes, the first 10 alarms will notify individually, the last 5 will be sent in a batch notification at the end of the Notification Period in Minutes.\\nSetting the Notification Period in Minutes to 0 disables batch notifications, which results in all alarms being sent in individual notifications.\\nEnter Notification Period in Minutes and Maximum Notifications Per Period settings to establish how many notifications will be sent in a specified time period.\\nFor example, if the Notification Period in Minutes is set to 60 minutes and the Maximum Notifications Per Period is set to 10 and you receive 15 alarms in 60 minutes, the first 10 alarms will notify individually, the last 5 will be sent in a batch notification at the end of the Notification Period in Minutes.\\nSetting the Notification Period in Minutes to 0 disables batch notifications, which results in all alarms being sent in individual notifications.\\nDecide whether to include N/A fields. If Include N/A Fields is selected, the email includes headers for all selected items, even if they are blank. If Include N/A Fields is cleared, selected items that are blank are omitted completely.\\nIn the Include Alarms Fields section, select the information to be included in the Email Notification.\\nOrigin/Impacted section is a summary of all Origin/Impacted fields (Entity, Host, User, etc.)\\nIn the Include Alarms Fields section, select the information to be included in the Email Notification.\\nOrigin/Impacted section is a summary of all Origin/Impacted fields (Entity, Host, User, etc.)\\n(Optional)\\nClick the\\nAdditional Info\\ntab and type additional information in the Details box.\\nClick\\nOK\\n.\\nClick\\nOK\\n.\\nA new private policy is created. To create a group policy that can be used by others, see\\nCreate Group Notifications for Alarms\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nMy LogRhythm\\n', 'Manage Your Preferences': 'To manage your Client Console preferences\\nOn the My LogRhythm menu, click\\nMy Preferences\\n.\\nConfigure the properties by accessing the tabs, described in the following tables, and modifying the information you want.\\nPersonal Dashboard tab\\n. The Personal Dashboard tab contains settings related to Personal Dashboard, which can be set to start at startup or accessed by clicking Personal Dashboard on the main toolbar.\\nProperty\\nDescription\\nRefresh Rate\\nThe interval between updates to Personal Dashboard or how long the Client Console waits between refresh cycles before it checks for new events.\\nThe Query Timeout setting defines how long the query waits before timing out.\\nAlarm Settings\\nThe time period of Alarms to display, and whether to load all or just your alarms.\\nThe History setting specifies how much alarm history to load in hours and minutes.\\nThe Alarm Cache setting specifies the maximum number of alarms to load and cache in memory.\\nThe Only Load Assigned Alarms setting should be selected if you only want to load alarms assigned to your user account.\\nEvent Settings\\nThe History setting specifies how much event history to load in hours and minutes.\\nThe Event Cache setting specifies the maximum number of individual events to cache in memory for immediate analysis via drill-down capabilities.\\nThe Aggregate Event Cache setting specifies the maximum number of aggregate events to cache in memory.\\nThe Include Diagnostic Events setting should be selected to enable the display of diagnostic events in the Personal Dashboard.\\nInvestigator and Tail tab\\n. The Investigator and Tail tab is where properties specific to Investigations and Tails are selected.\\nProperty\\nDescription\\nQuery Settings\\nSettings pertaining to the querying of logs, such as maximum logs to fetch.\\nThe Maximum logs/events to query setting specifies the maximum number of logs/events to query.\\nThe Query Timeout setting specifies the amount of time before the query terminates due to a timeout.\\nLog/Event Cache\\nThe maximum number of logs that are retained in memory. Logs/events cached in memory are available for immediate analysis via drill-down capabilities.\\nThis is very important because the cached logs and events are the only ones available when performing a drill-down Investigation from the Dashboard.\\nAggregate Log/Event Cache\\nThe maximum number of aggregate logs and events to cache in memory.\\nThis is very important as the cached aggregate logs and events are the only ones available when performing a drill-down Investigation from the Dashboard.\\nDefault Log Repositories to Query\\nThe Log Repositories you would like to query by default when you run an Investigation or Tail. Other Data Processors will still be available to be optionally selected, unless they are specifically not allowed to be accessed due to account restrictions.\\nRegional Settings tab\\n. The Regional Settings tab supports regionalization of date and number formats. These formats are controlled from the Regional Settings tab.\\nProperty\\nDescription\\nCultures\\nThere are many standard cultures available for selection from the Cultures drop-down box. Selecting a culture changes the date and\\xa0time and number formats below.\\nIf you select a language that is not installed on the Client Console host machine, you may see unexpected results in alpha characters that are part of the date and time formats.\\nDate &\\xa0Time Formats\\nThe Date and Time format is set automatically according to the Culture selected. However, these formats can be modified manually after selecting the Culture.\\nIf the date and time show unexpected characters, ensure that the language you selected in the Culture setting is installed on the Client Console host machine.\\nNumber Formats\\nThe Number format is set automatically according to the Culture selected. However, this format can be modified manually after selecting the Culture.\\nTime Zone Settings\\nThe time zones to use as the defaults for Notifications and Reports.\\nReport Center tab\\n. The Report Center tab allows the user to specify a reporting memory threshold. These adjustments are controlled from the Report Center tab.\\nProperty\\nDescription\\nReporting Memory\\nSpecify the memory limit to enforce during report preparation. If a report query causes Client Console memory usage to exceed the threshold, then the report is rendered with partial data and the label (Sample Dataset) is added to the title page footer.\\nThe reporting memory can be set from 0-100%\\nMaximum application memory:\\nLogRhythm Client Console (32-bit) = 1 GB\\nLogRhythm Client Console (64-bit) = installed physical memory\\nExample scenario: 8 GB RAM\\xa0installed, 50% Reporting Memory\\nLogRhythm Client Console (32-bit) = 0.5 GB report memory threshold\\nLogRhythm Client Console (64-bit) = 4.0 GB report memory threshold\\nGeneral tab\\n. The General tab contains additional information.\\nProperty\\nDescription\\nAuto Login\\nIf the Automatically login next time check box was selected on the login screen, this button disables it, forcing the login dialog box to appear the next time the Client Console is opened.\\nRestore Defaults\\nUse the buttons to restore settings to their default values for various components.\\nReset Deployment Monitor Layout\\nReset Alarm Viewer Layout\\nReset Log Miner Layout\\nDelete All Saved Investigations\\nDelete All Saved Tails\\nColor Themes\\nUse the default color themes or choose your own.\\nRecord Count\\nChose the number of records to be displayed in the System Monitor and Log Sources grids.\\nFilter System Log Sources from Grid Views\\nEnabling this option will prevent the display of the following log source types in Log Sources grids within the Client Console:\\nLogRhythm Data Loss Defender\\nLogRhythm File Monitor\\nLogRhythm Network Connection Monitor\\nLogRhythm Process Monitor\\nLogRhythm Registry Integrity Monitor\\nLogRhythm User Activity Monitor\\nPersonal Dashboard tab\\n. The Personal Dashboard tab contains settings related to Personal Dashboard, which can be set to start at startup or accessed by clicking Personal Dashboard on the main toolbar.\\nProperty\\nDescription\\nRefresh Rate\\nThe interval between updates to Personal Dashboard or how long the Client Console waits between refresh cycles before it checks for new events.\\nThe Query Timeout setting defines how long the query waits before timing out.\\nAlarm Settings\\nThe time period of Alarms to display, and whether to load all or just your alarms.\\nThe History setting specifies how much alarm history to load in hours and minutes.\\nThe Alarm Cache setting specifies the maximum number of alarms to load and cache in memory.\\nThe Only Load Assigned Alarms setting should be selected if you only want to load alarms assigned to your user account.\\nEvent Settings\\nThe History setting specifies how much event history to load in hours and minutes.\\nThe Event Cache setting specifies the maximum number of individual events to cache in memory for immediate analysis via drill-down capabilities.\\nThe Aggregate Event Cache setting specifies the maximum number of aggregate events to cache in memory.\\nThe Include Diagnostic Events setting should be selected to enable the display of diagnostic events in the Personal Dashboard.\\nPersonal Dashboard tab\\n. The Personal Dashboard tab contains settings related to Personal Dashboard, which can be set to start at startup or accessed by clicking Personal Dashboard on the main toolbar.\\nProperty, Description\\nRefresh Rate, The interval between updates to Personal Dashboard or how long the Client Console waits between refresh cycles before it checks for new events.The Query Timeout setting defines how long the query waits before timing out.\\nAlarm Settings, The time period of Alarms to display, and whether to load all or just your alarms.The History setting specifies how much alarm history to load in hours and minutes.The Alarm Cache setting specifies the maximum number of alarms to load and cache in memory.The Only Load Assigned Alarms setting should be selected if you only want to load alarms assigned to your user account.\\nEvent Settings, The History setting specifies how much event history to load in hours and minutes.The Event Cache setting specifies the maximum number of individual events to cache in memory for immediate analysis via drill-down capabilities.The Aggregate Event Cache setting specifies the maximum number of aggregate events to cache in memory.The Include Diagnostic Events setting should be selected to enable the display of diagnostic events in the Personal Dashboard.\\nThe interval between updates to Personal Dashboard or how long the Client Console waits between refresh cycles before it checks for new events.\\nThe Query Timeout setting defines how long the query waits before timing out.\\nThe time period of Alarms to display, and whether to load all or just your alarms.\\nThe History setting specifies how much alarm history to load in hours and minutes.\\nThe Alarm Cache setting specifies the maximum number of alarms to load and cache in memory.\\nThe Only Load Assigned Alarms setting should be selected if you only want to load alarms assigned to your user account.\\nThe History setting specifies how much event history to load in hours and minutes.\\nThe Event Cache setting specifies the maximum number of individual events to cache in memory for immediate analysis via drill-down capabilities.\\nThe Aggregate Event Cache setting specifies the maximum number of aggregate events to cache in memory.\\nThe Include Diagnostic Events setting should be selected to enable the display of diagnostic events in the Personal Dashboard.\\nInvestigator and Tail tab\\n. The Investigator and Tail tab is where properties specific to Investigations and Tails are selected.\\nProperty\\nDescription\\nQuery Settings\\nSettings pertaining to the querying of logs, such as maximum logs to fetch.\\nThe Maximum logs/events to query setting specifies the maximum number of logs/events to query.\\nThe Query Timeout setting specifies the amount of time before the query terminates due to a timeout.\\nLog/Event Cache\\nThe maximum number of logs that are retained in memory. Logs/events cached in memory are available for immediate analysis via drill-down capabilities.\\nThis is very important because the cached logs and events are the only ones available when performing a drill-down Investigation from the Dashboard.\\nAggregate Log/Event Cache\\nThe maximum number of aggregate logs and events to cache in memory.\\nThis is very important as the cached aggregate logs and events are the only ones available when performing a drill-down Investigation from the Dashboard.\\nDefault Log Repositories to Query\\nThe Log Repositories you would like to query by default when you run an Investigation or Tail. Other Data Processors will still be available to be optionally selected, unless they are specifically not allowed to be accessed due to account restrictions.\\nInvestigator and Tail tab\\n. The Investigator and Tail tab is where properties specific to Investigations and Tails are selected.\\nProperty, Description\\nQuery Settings, Settings pertaining to the querying of logs, such as maximum logs to fetch.The Maximum logs/events to query setting specifies the maximum number of logs/events to query.The Query Timeout setting specifies the amount of time before the query terminates due to a timeout.\\nLog/Event Cache, The maximum number of logs that are retained in memory. Logs/events cached in memory are available for immediate analysis via drill-down capabilities.This is very important because the cached logs and events are the only ones available when performing a drill-down Investigation from the Dashboard.\\nAggregate Log/Event Cache, The maximum number of aggregate logs and events to cache in memory.This is very important as the cached aggregate logs and events are the only ones available when performing a drill-down Investigation from the Dashboard.\\nDefault Log Repositories to Query, The Log Repositories you would like to query by default when you run an Investigation or Tail. Other Data Processors will still be available to be optionally selected, unless they are specifically not allowed to be accessed due to account restrictions.\\nSettings pertaining to the querying of logs, such as maximum logs to fetch.\\nThe Maximum logs/events to query setting specifies the maximum number of logs/events to query.\\nThe Query Timeout setting specifies the amount of time before the query terminates due to a timeout.\\nThe maximum number of logs that are retained in memory. Logs/events cached in memory are available for immediate analysis via drill-down capabilities.\\nThis is very important because the cached logs and events are the only ones available when performing a drill-down Investigation from the Dashboard.\\nThe maximum number of aggregate logs and events to cache in memory.\\nThis is very important as the cached aggregate logs and events are the only ones available when performing a drill-down Investigation from the Dashboard.\\nRegional Settings tab\\n. The Regional Settings tab supports regionalization of date and number formats. These formats are controlled from the Regional Settings tab.\\nProperty\\nDescription\\nCultures\\nThere are many standard cultures available for selection from the Cultures drop-down box. Selecting a culture changes the date and\\xa0time and number formats below.\\nIf you select a language that is not installed on the Client Console host machine, you may see unexpected results in alpha characters that are part of the date and time formats.\\nDate &\\xa0Time Formats\\nThe Date and Time format is set automatically according to the Culture selected. However, these formats can be modified manually after selecting the Culture.\\nIf the date and time show unexpected characters, ensure that the language you selected in the Culture setting is installed on the Client Console host machine.\\nNumber Formats\\nThe Number format is set automatically according to the Culture selected. However, this format can be modified manually after selecting the Culture.\\nTime Zone Settings\\nThe time zones to use as the defaults for Notifications and Reports.\\nRegional Settings tab\\n. The Regional Settings tab supports regionalization of date and number formats. These formats are controlled from the Regional Settings tab.\\nProperty, Description\\nCultures, There are many standard cultures available for selection from the Cultures drop-down box. Selecting a culture changes the date and\\xa0time and number formats below.If you select a language that is not installed on the Client Console host machine, you may see unexpected results in alpha characters that are part of the date and time formats.\\nDate &\\xa0Time Formats, The Date and Time format is set automatically according to the Culture selected. However, these formats can be modified manually after selecting the Culture.If the date and time show unexpected characters, ensure that the language you selected in the Culture setting is installed on the Client Console host machine.\\nNumber Formats, The Number format is set automatically according to the Culture selected. However, this format can be modified manually after selecting the Culture.\\nTime Zone Settings, The time zones to use as the defaults for Notifications and Reports.\\nThere are many standard cultures available for selection from the Cultures drop-down box. Selecting a culture changes the date and\\xa0time and number formats below.\\nIf you select a language that is not installed on the Client Console host machine, you may see unexpected results in alpha characters that are part of the date and time formats.\\nThe Date and Time format is set automatically according to the Culture selected. However, these formats can be modified manually after selecting the Culture.\\nIf the date and time show unexpected characters, ensure that the language you selected in the Culture setting is installed on the Client Console host machine.\\nReport Center tab\\n. The Report Center tab allows the user to specify a reporting memory threshold. These adjustments are controlled from the Report Center tab.\\nProperty\\nDescription\\nReporting Memory\\nSpecify the memory limit to enforce during report preparation. If a report query causes Client Console memory usage to exceed the threshold, then the report is rendered with partial data and the label (Sample Dataset) is added to the title page footer.\\nThe reporting memory can be set from 0-100%\\nMaximum application memory:\\nLogRhythm Client Console (32-bit) = 1 GB\\nLogRhythm Client Console (64-bit) = installed physical memory\\nExample scenario: 8 GB RAM\\xa0installed, 50% Reporting Memory\\nLogRhythm Client Console (32-bit) = 0.5 GB report memory threshold\\nLogRhythm Client Console (64-bit) = 4.0 GB report memory threshold\\nReport Center tab\\n. The Report Center tab allows the user to specify a reporting memory threshold. These adjustments are controlled from the Report Center tab.\\nProperty, Description\\nReporting Memory, Specify the memory limit to enforce during report preparation. If a report query causes Client Console memory usage to exceed the threshold, then the report is rendered with partial data and the label (Sample Dataset) is added to the title page footer.The reporting memory can be set from 0-100%Maximum application memory:LogRhythm Client Console (32-bit) = 1 GBLogRhythm Client Console (64-bit) = installed physical memoryExample scenario: 8 GB RAM\\xa0installed, 50% Reporting MemoryLogRhythm Client Console (32-bit) = 0.5 GB report memory thresholdLogRhythm Client Console (64-bit) = 4.0 GB report memory threshold\\nSpecify the memory limit to enforce during report preparation. If a report query causes Client Console memory usage to exceed the threshold, then the report is rendered with partial data and the label (Sample Dataset) is added to the title page footer.\\nThe reporting memory can be set from 0-100%\\nMaximum application memory:\\nLogRhythm Client Console (32-bit) = 1 GB\\nLogRhythm Client Console (64-bit) = installed physical memory\\nExample scenario: 8 GB RAM\\xa0installed, 50% Reporting Memory\\nLogRhythm Client Console (32-bit) = 0.5 GB report memory threshold\\nLogRhythm Client Console (64-bit) = 4.0 GB report memory threshold\\nGeneral tab\\n. The General tab contains additional information.\\nProperty\\nDescription\\nAuto Login\\nIf the Automatically login next time check box was selected on the login screen, this button disables it, forcing the login dialog box to appear the next time the Client Console is opened.\\nRestore Defaults\\nUse the buttons to restore settings to their default values for various components.\\nReset Deployment Monitor Layout\\nReset Alarm Viewer Layout\\nReset Log Miner Layout\\nDelete All Saved Investigations\\nDelete All Saved Tails\\nColor Themes\\nUse the default color themes or choose your own.\\nRecord Count\\nChose the number of records to be displayed in the System Monitor and Log Sources grids.\\nFilter System Log Sources from Grid Views\\nEnabling this option will prevent the display of the following log source types in Log Sources grids within the Client Console:\\nLogRhythm Data Loss Defender\\nLogRhythm File Monitor\\nLogRhythm Network Connection Monitor\\nLogRhythm Process Monitor\\nLogRhythm Registry Integrity Monitor\\nLogRhythm User Activity Monitor\\nGeneral tab\\n. The General tab contains additional information.\\nProperty, Description\\nAuto Login, If the Automatically login next time check box was selected on the login screen, this button disables it, forcing the login dialog box to appear the next time the Client Console is opened.\\nRestore Defaults, Use the buttons to restore settings to their default values for various components.Reset Deployment Monitor LayoutReset Alarm Viewer LayoutReset Log Miner LayoutDelete All Saved InvestigationsDelete All Saved Tails\\nColor Themes, Use the default color themes or choose your own.\\nRecord Count, Chose the number of records to be displayed in the System Monitor and Log Sources grids.\\nFilter System Log Sources from Grid Views, Enabling this option will prevent the display of the following log source types in Log Sources grids within the Client Console:LogRhythm Data Loss DefenderLogRhythm File MonitorLogRhythm Network Connection MonitorLogRhythm Process MonitorLogRhythm Registry Integrity MonitorLogRhythm User Activity Monitor\\nUse the buttons to restore settings to their default values for various components.\\nReset Deployment Monitor Layout\\nReset Alarm Viewer Layout\\nReset Log Miner Layout\\nDelete All Saved Investigations\\nDelete All Saved Tails\\nColor Themes\\nEnabling this option will prevent the display of the following log source types in Log Sources grids within the Client Console:\\nLogRhythm Data Loss Defender\\nLogRhythm File Monitor\\nLogRhythm Network Connection Monitor\\nLogRhythm Process Monitor\\nLogRhythm Registry Integrity Monitor\\nLogRhythm User Activity Monitor\\nClick\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nReport Center\\n', 'Add Custom Logos to Reports': 'Only\\nGlobal Admins and Restricted Admins\\nwith elevated View and Manage privileges can take this action\\n.\\nYou can customize LogRhythm reports by including your company logo and creating report templates for Log Detail and Log Summary reports.\\nEnsure you meet the following prerequisites:\\nWrite access to the Client Console config directory.\\nA standard graphics file type logo. The recommended specifications for the graphic are:\\nMax Width - 500 pixels; Max Height - 125 pixels\\nHorizontal and Vertical Resolution - 96 dpi\\nIf the graphic has different dimensions, LogRhythm may have to resize it. In that case, the results may be different from expected.\\nWrite access to the Client Console config directory.\\nWrite access to the Client Console config directory.\\nA standard graphics file type logo. The recommended specifications for the graphic are:\\nMax Width - 500 pixels; Max Height - 125 pixels\\nHorizontal and Vertical Resolution - 96 dpi\\nIf the graphic has different dimensions, LogRhythm may have to resize it. In that case, the results may be different from expected.\\nA standard graphics file type logo. The recommended specifications for the graphic are:\\nMax Width - 500 pixels; Max Height - 125 pixels\\nMax Width - 500 pixels; Max Height - 125 pixels\\nHorizontal and Vertical Resolution - 96 dpi\\nHorizontal and Vertical Resolution - 96 dpi\\nOn the main toolbar, click\\nReport Center\\n.\\nOn the File menu, click\\nOptions\\n.\\nThe Report Options window appears.\\nClick\\nCustom\\n.\\nClick\\nCustom\\n.\\nBrowse to the location of your logo graphic file.\\nSome PNG images with transparency do not appear correctly in generated reports. To avoid any issues, you should not use any custom images that contain transparency.\\nThe following are acceptable file types: BMP, JPG, TIF, and PNG\\nBrowse to the location of your logo graphic file.\\nSome PNG images with transparency do not appear correctly in generated reports. To avoid any issues, you should not use any custom images that contain transparency.\\nThe following are acceptable file types: BMP, JPG, TIF, and PNG\\nSelect the file you want and click\\nOpen\\n.\\nSelect the file you want and click\\nOpen\\n.\\nClick\\nOK\\n.\\nWhen you create a report, your custom logo appears on the cover page and in the header of each subsequent page.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nReport Center\\n', 'Create Custom Log Detail Report Templates': 'On the main toolbar, click\\nReport Center\\n.\\nClick the\\nReport Templates\\ntab.\\nOn the main toolbar, click\\nNew Report Template\\non the toolbar, and then click\\nLog Detail\\n.\\nThe Log Detail Report Template Wizard appears.\\nOn the main toolbar, click\\nNew Report Template\\non the toolbar, and then click\\nLog Detail\\n.\\nThe Log Detail Report Template Wizard appears.\\nSelect a field from the lists for Groups 1, 2, and 3 to establish a data grouping hierarchy in a report. After you select an item from a group, the next lower Group field is enabled.\\nItems you select in a Group field are automatically removed from the Available Fields lists, except Normal Date which can be selected as both a group and field.\\nIf you select Normal Date in any Group field, the Normal Date Grouping Mode field appears. Select an option or accept the default, Summarization By Day.\\nNormal Date Grouping Mode does not appear if you add Normal Date to the Selected Fields list.\\nSelect a field from the lists for Groups 1, 2, and 3 to establish a data grouping hierarchy in a report. After you select an item from a group, the next lower Group field is enabled.\\nItems you select in a Group field are automatically removed from the Available Fields lists, except Normal Date which can be selected as both a group and field.\\nIf you select Normal Date in any Group field, the Normal Date Grouping Mode field appears. Select an option or accept the default, Summarization By Day.\\nNormal Date Grouping Mode does not appear if you add Normal Date to the Selected Fields list.\\nFields you add to the Selected Fields list become the report column headings. To move items between the Available Fields list and the Selected Fields list, do one of the following:\\nDouble-click an option. It moves to the other list.\\nSelect an option, then click the appropriate arrow between the lists to move it to the other list.\\nTo move multiple options at one time:\\nSelect non-adjacent items by clicking each one while holding down the Ctrl key.\\nSelect adjacent items by clicking the first and last one while holding down the Shift key or click an item and drag up or down while holding down the mouse button.\\nAfter the items are selected, click the appropriate arrow to move them to the other list.\\nDouble-click an option. It moves to the other list.\\nSelect an option, then click the appropriate arrow between the lists to move it to the other list.\\nTo move multiple options at one time:\\nSelect non-adjacent items by clicking each one while holding down the Ctrl key.\\nSelect adjacent items by clicking the first and last one while holding down the Shift key or click an item and drag up or down while holding down the mouse button.\\nAfter the items are selected, click the appropriate arrow to move them to the other list.\\nSelect non-adjacent items by clicking each one while holding down the Ctrl key.\\nSelect adjacent items by clicking the first and last one while holding down the Shift key or click an item and drag up or down while holding down the mouse button.\\nWhen space is restricted in report column headings, i and o may used as abbreviations for Impacted and Origin. For example, Hostname (Impacted) and Hostname (Origin) may appear as iHostname and oHostname.\\nThere is a maximum number of Selected Fields allowed depending on the page layout you pick in a later window.\\nA landscape layout can have a maximum of eight fields. If you exceed eight, a warning message appears when you click Next. You must reduce the fields to eight or fewer to proceed.\\nA portrait layout can have a maximum of six fields. If you add seven or eight fields to the Selected Fields list, you may proceed, but portrait will not be an option on the Layout page.\\nThe order of the items in the Selected Fields list determines the layout and sort order of the columns in the report template. The first item in the list is sorted first and is the first column. To change the order, select an item and click the\\nChange Order\\narrows until you have the items positioned the way you want.\\nYou can reposition the columns in the upcoming Wizard Layout window, but the sort order stays the way it appears in the Selected Fields list.\\nThe order of the items in the Selected Fields list determines the layout and sort order of the columns in the report template. The first item in the list is sorted first and is the first column. To change the order, select an item and click the\\nChange Order\\narrows until you have the items positioned the way you want.\\nYou can reposition the columns in the upcoming Wizard Layout window, but the sort order stays the way it appears in the Selected Fields list.\\nClick\\nNext\\n.\\nClick\\nNext\\n.\\nOn the Sorting page, select Ascending or Descending sort order for each Group and Field item in the template. The default is ascending.\\nClick\\nNext\\n.\\nClick\\nNext\\n.\\nOn the Layout and Additional properties page, select a Layout Orientation.\\nLandscape is the default. Portrait is available if you have six or fewer fields selected for the template.\\nLandscape is the default. Portrait is available if you have six or fewer fields selected for the template.\\n(Optional)\\nTo adjust column widths in the template, select a vertical column divider and drag it left or right.\\n(Optional)\\nTo return all column widths to their original sizes, click\\nReset\\n.\\n(Optional)\\nTo change the display order of the columns, click and drag a column heading to a new location.\\nThis does not change the sort order established in the Selected Fields list.\\n(Optional)\\nTo change the display order of the columns, click and drag a column heading to a new location.\\nThis does not change the sort order established in the Selected Fields list.\\nType a name for the template.\\n(Optional)\\nEnter a description for the template.\\n(Optional)\\nIf you want the template to be available for others to use, select the\\nPublic All Users\\ncheck box.\\nPublic templates can only be deleted by the creator and Global Administrators. Private templates can only be used and deleted by the creator.\\n(Optional)\\nIf you want the template to be available for others to use, select the\\nPublic All Users\\ncheck box.\\nPublic templates can only be deleted by the creator and Global Administrators. Private templates can only be used and deleted by the creator.\\nClick\\nOK\\n.\\nYou return to the LogRhythm Reporting Center with the new template listed.\\nSelect the custom report template you want.\\nRight-click it and select\\nNew Report from Report Template\\n.\\nName and save the report when prompted.\\nLocate the report on the Reports tab and select the\\nAction\\ncheck box.\\nRight-click anywhere on the grid and select\\nRun\\n.\\nFor more information on creating and running reports, see\\nCreate Reports\\n.\\nRight-click anywhere on the grid and select\\nRun\\n.\\nFor more information on creating and running reports, see\\nCreate Reports\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nReport Center\\n', 'Create Custom Log Summary Report Templates': 'On the main toolbar, click\\nReport Center\\n.\\nClick the\\nReport Templates\\ntab.\\nOn the main toolbar, click\\nNew Report Template\\non the toolbar, and then click\\nLog Summary\\n.\\nThe Log Detail Report Template Wizard appears.\\nOn the main toolbar, click\\nNew Report Template\\non the toolbar, and then click\\nLog Summary\\n.\\nThe Log Detail Report Template Wizard appears.\\nSelect a field from the lists for Groups 1, 2, and 3 to establish a data grouping hierarchy in a report. After you select an item from a group, the next lower Group field is enabled.\\nItems you select in a Group field are automatically removed from the Available Fields lists, except Normal Date which can be selected as both a group and field.\\nIf you select Normal Date in any Group field, the Normal Date Grouping Mode field appears. Select an option or accept the default, Summarization By Day.\\nNormal Date Grouping Mode does not appear if you add Normal Date to the Selected Fields list.\\nSelect a field from the lists for Groups 1, 2, and 3 to establish a data grouping hierarchy in a report. After you select an item from a group, the next lower Group field is enabled.\\nItems you select in a Group field are automatically removed from the Available Fields lists, except Normal Date which can be selected as both a group and field.\\nIf you select Normal Date in any Group field, the Normal Date Grouping Mode field appears. Select an option or accept the default, Summarization By Day.\\nNormal Date Grouping Mode does not appear if you add Normal Date to the Selected Fields list.\\nFields you add to the Selected Fields list become the report column headings. To move items between the Available Fields list and the Selected Fields list, do one of the following:\\nDouble-click an option. It moves to the other list.\\nSelect an option, then click the appropriate arrow between the lists to move it to the other list.\\nTo move multiple options at one time:\\nSelect non-adjacent items by clicking each one while holding down the Ctrl key.\\nSelect adjacent items by clicking the first and last one while holding down the Shift key or click an item and drag up or down while holding down the mouse button.\\nAfter the items are selected, click the appropriate arrow to move them to the other list.\\nDouble-click an option. It moves to the other list.\\nSelect an option, then click the appropriate arrow between the lists to move it to the other list.\\nTo move multiple options at one time:\\nSelect non-adjacent items by clicking each one while holding down the Ctrl key.\\nSelect adjacent items by clicking the first and last one while holding down the Shift key or click an item and drag up or down while holding down the mouse button.\\nAfter the items are selected, click the appropriate arrow to move them to the other list.\\nSelect non-adjacent items by clicking each one while holding down the Ctrl key.\\nSelect adjacent items by clicking the first and last one while holding down the Shift key or click an item and drag up or down while holding down the mouse button.\\nWhen space is restricted in report column headings, i and o may used as abbreviations for Impacted and Origin. For example, Hostname (Impacted) and Hostname (Origin) may appear as iHostname and oHostname.\\nThere is a maximum number of Selected Fields allowed depending on the page layout you pick in a later window.\\nA landscape layout can have a maximum of eight fields. If you exceed eight, a warning message appears when you click Next. You must reduce the fields to eight or fewer to proceed.\\nA portrait layout can have a maximum of six fields. If you add seven or eight fields to the Selected Fields list, you may proceed, but portrait will not be an option on the Layout page.\\nThe order of the items in the Selected Fields list determines the layout and sort order of the columns in the report template. The first item in the list is sorted first and is the first column. To change the order, select an item and click the\\nChange Order\\narrows until you have the items positioned the way you want.\\nYou can reposition the columns in the upcoming Wizard Layout window, but the sort order stays the way it appears in the Selected Fields list.\\nThe order of the items in the Selected Fields list determines the layout and sort order of the columns in the report template. The first item in the list is sorted first and is the first column. To change the order, select an item and click the\\nChange Order\\narrows until you have the items positioned the way you want.\\nYou can reposition the columns in the upcoming Wizard Layout window, but the sort order stays the way it appears in the Selected Fields list.\\nCheck First Normal Date and/or Last Normal Date at the bottom of the window to add them as report columns after the Selected Fields and before any calculated fields.\\nClick\\nNext\\n.\\nThe Select Calculated Fields and Summarization window appears.\\n(Optional)\\nTo add a calculated field to the report template, select one from the list, then select an operation and click\\nAdd\\n.\\nThe calculated field is added to the grid.\\nTo delete a field after it is added, select it and click\\nRemove\\n.\\nTo add additional calculated fields, repeat the previous steps.\\nBy default, calculated fields become the last columns in the template in the order listed here. To reposition a calculated field, select it and click the appropriate\\nChange Order\\narrow.\\nIf the fields you add on this page plus the fields added on prior page exceed eight, a warning message appears when you click Next. You must reduce the total fields to eight or fewer to proceed. If the total fields equal seven or eight, the Layout page does not offer portrait as an option.\\nBy default, calculated fields become the last columns in the template in the order listed here. To reposition a calculated field, select it and click the appropriate\\nChange Order\\narrow.\\nIf the fields you add on this page plus the fields added on prior page exceed eight, a warning message appears when you click Next. You must reduce the total fields to eight or fewer to proceed. If the total fields equal seven or eight, the Layout page does not offer portrait as an option.\\nClick\\nNext\\n.\\nThe Calculated Field Sorting window appears.\\n(Optional)\\nTo sort based on calculated fields, click the\\nEnable Calculated Field Sorting\\nbox, and then select one of these options from the list and then proceed to one of the following options:\\nAll\\n. Display and summarize all the data of the selected calculated field.\\nWhen Sort Options = ALL\\nSelect an option from the Calculated Field drop-down list.\\nSelect a sort order. The default is ascending.\\nTop N\\n. Display the N highest values of the selected calculated field.\\nBottom N\\n. Display the N lowest values of the selected calculated field.\\nThe window shows additional fields depending on your Sort Options selection.\\nWhen Sort Options = Top N or Bottom N\\nSelect an option from the Calculated Fields drop-down list.\\nIn the Where N is field, select the number of highest (Top N) or lowest (Bottom N) values to display.\\nIf you want to include data that does not qualify as part of the highest or lowest values in the report template, check the\\nInclude Others\\nbox.\\nEnter a group name for the non-qualifiers or accept the default name, Others.\\nAll\\n. Display and summarize all the data of the selected calculated field.\\nWhen Sort Options = ALL\\nSelect an option from the Calculated Field drop-down list.\\nSelect a sort order. The default is ascending.\\nSelect an option from the Calculated Field drop-down list.\\nSelect a sort order. The default is ascending.\\nTop N\\n. Display the N highest values of the selected calculated field.\\nBottom N\\n. Display the N lowest values of the selected calculated field.\\nThe window shows additional fields depending on your Sort Options selection.\\nWhen Sort Options = Top N or Bottom N\\nSelect an option from the Calculated Fields drop-down list.\\nIn the Where N is field, select the number of highest (Top N) or lowest (Bottom N) values to display.\\nIf you want to include data that does not qualify as part of the highest or lowest values in the report template, check the\\nInclude Others\\nbox.\\nEnter a group name for the non-qualifiers or accept the default name, Others.\\nBottom N\\n. Display the N lowest values of the selected calculated field.\\nThe window shows additional fields depending on your Sort Options selection.\\nWhen Sort Options = Top N or Bottom N\\nSelect an option from the Calculated Fields drop-down list.\\nIn the Where N is field, select the number of highest (Top N) or lowest (Bottom N) values to display.\\nIf you want to include data that does not qualify as part of the highest or lowest values in the report template, check the\\nInclude Others\\nbox.\\nEnter a group name for the non-qualifiers or accept the default name, Others.\\nClick\\nNext\\n.\\nOn the Sorting page, select a sort order of Ascending or Descending for all the items in the template. The default is ascending.\\nClick\\nNext\\n.\\nOn the Layout and Additional properties page, select a Layout Orientation.\\nLandscape is the default. Portrait is available if you have six or fewer fields selected for the template.\\nLandscape is the default. Portrait is available if you have six or fewer fields selected for the template.\\n(Optional)\\nTo adjust column widths in the template, select a vertical column divider and drag it left or right.\\n(Optional)\\nTo return all column widths to their original sizes, click\\nReset\\n.\\n(Optional)\\nTo change the display order of the columns, click and drag a column heading to a new location.\\nThis does not change the sort order established in the Selected Fields list.\\n(Optional)\\nTo change the display order of the columns, click and drag a column heading to a new location.\\nThis does not change the sort order established in the Selected Fields list.\\nType a name for the template.\\n(Optional)\\nEnter a description for the template.\\n(Optional)\\nIf you want the template to be available for others to use, select the\\nPublic All Users\\ncheck box.\\nPublic templates can only be deleted by the creator and Global Administrators. Private templates can only be used and deleted by the creator.\\n(Optional)\\nIf you want the template to be available for others to use, select the\\nPublic All Users\\ncheck box.\\nPublic templates can only be deleted by the creator and Global Administrators. Private templates can only be used and deleted by the creator.\\nClick\\nOK\\n.\\nYou return to the LogRhythm Reporting Center with the new template listed.\\nSelect the custom report template you want.\\nRight-click it and select\\nNew Report from Report Template\\n.\\nName and save the report when prompted.\\nLocate the report on the Reports tab and select the Action check box.\\nRight-click anywhere on the grid and select\\nRun\\n.\\nFor more information on creating and running reports, see\\nCreate Reports\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nReport Center\\n', 'Create Reports': 'Use the Report Wizard to create and modify Custom Reports and to view the configuration of reports you do not have permission to modify. To create a new report\\nOn the Tools menu, click\\nReport\\n, and then click\\nReport Center\\n.\\nClick the\\nReports\\ntab.\\nOn the main toolbar, click the\\nNew\\nicon.\\nThe Report Wizard appears.\\nOn the Select Report Template page, select the report template you want and click\\nNext\\n.\\nLog Volume reports (Class = Log Management) return data for all log sources. Specifying log source criteria does not narrow the results.\\nOn the Select Report Template page, select the report template you want and click\\nNext\\n.\\nLog Volume reports (Class = Log Management) return data for all log sources. Specifying log source criteria does not narrow the results.\\nOn the Specify Log Source Criteria page, specify the Log Sources to include in the Report and click\\nNext\\n.\\nOn the Specify Additional Report Criteria page, add any filters needed to limit the data included in the report. For more information on filters, see Work with Filters.\\nFilters are not applied when running Log Volume reports (Class = Log Management). Log Management Reports are designed to ignore filters.\\nRestricted Analysts cannot create or edit a User (Impacted/Origin) by Active Directory Group filter. The User (Impacted/Origin) by Active Directory Group filter is only available to Global Administrators and Global Analysts.\\nRestricted Analysts can run objects that reference an Active Directory Group filter in saved Reports and Report Packages.\\nIf you are running a report type that summarizes data by the top N events, filter NULL values out of your data. To do this, manually create a filter where the Filter Mode is Filter Out (Is Not) and the Filter out Null values? check box is selected.\\nOn the Specify Additional Report Criteria page, add any filters needed to limit the data included in the report. For more information on filters, see Work with Filters.\\nFilters are not applied when running Log Volume reports (Class = Log Management). Log Management Reports are designed to ignore filters.\\nRestricted Analysts cannot create or edit a User (Impacted/Origin) by Active Directory Group filter. The User (Impacted/Origin) by Active Directory Group filter is only available to Global Administrators and Global Analysts.\\nRestricted Analysts can run objects that reference an Active Directory Group filter in saved Reports and Report Packages.\\nIf you are running a report type that summarizes data by the top N events, filter NULL values out of your data. To do this, manually create a filter where the Filter Mode is Filter Out (Is Not) and the Filter out Null values? check box is selected.\\nClick\\nNext\\n.\\nThe Report Wizard Details and Configuration page appears.\\nType the Report Details.\\nEnter the Report Name.\\n(Optional)\\nEnter any qualifiers to print on the report.\\nQualifiers are optional, but they allow you to print additional information, such as the sorting or selection method, the affected user group, or the sources.\\nFor example:\\nName = Summary Log Count\\nQualifier 1 = of Events\\nQualifier 2 = by Ascending Log Count\\n(Optional)\\nEnter a description to include in the report list. The description does not appear on the report.\\nEnter the Report Name.\\n(Optional)\\nEnter any qualifiers to print on the report.\\nQualifiers are optional, but they allow you to print additional information, such as the sorting or selection method, the affected user group, or the sources.\\nFor example:\\nName = Summary Log Count\\nQualifier 1 = of Events\\nQualifier 2 = by Ascending Log Count\\n(Optional)\\nEnter a description to include in the report list. The description does not appear on the report.\\nComplete the Report Configuration.\\nSelect a Report Class.\\nReport Classes\\nDescription\\nDiagnostic\\nSystem diagnostics\\nLog Management\\nLogRhythm usage and log collection\\nAudit\\nMaintenance of Entities, Hosts, Users, etc.\\nSecurity\\nSecurity and compliance-related events\\nOperations\\nError conditions\\nGeneral Purpose\\nSummarizing log counts according to Hosts, Ports, etc.\\nEvent Management\\nEvents and Alarms\\nCase Management\\nSpecify the Report Data Source (Platform Manager, Data Processor, LogMart) to use as input data. If a source appears dimmed, it is unavailable.\\nReports run against the Data Processor pull their data from the Data Indexer. Therefore, the amount of data pulled in those reports is controlled by the effective TTL of your Data Indexer. You may have 30, 60 or even 90 days of configured TTL for your indexer, but if drive free space hits 80% then the oldest index will be deleted.\\nSpecify the Report Permissions to determine the access level for the report.\\nConfigure Intelligent Indexing:\\nSelect\\nEnable Intelligent Indexing\\n, if necessary.\\nSelect\\nEnable Expiration\\n, if necessary.\\nSelect a Report Class.\\nReport Classes\\nDescription\\nDiagnostic\\nSystem diagnostics\\nLog Management\\nLogRhythm usage and log collection\\nAudit\\nMaintenance of Entities, Hosts, Users, etc.\\nSecurity\\nSecurity and compliance-related events\\nOperations\\nError conditions\\nGeneral Purpose\\nSummarizing log counts according to Hosts, Ports, etc.\\nEvent Management\\nEvents and Alarms\\nCase Management\\nSelect a Report Class.\\nReport Classes, Description\\nDiagnostic, System diagnostics\\nLog Management, LogRhythm usage and log collection\\nAudit, Maintenance of Entities, Hosts, Users, etc.\\nSecurity, Security and compliance-related events\\nOperations, Error conditions\\nGeneral Purpose, Summarizing log counts according to Hosts, Ports, etc.\\nEvent Management, Events and Alarms\\nCase Management, \\nDiagnostic\\nSpecify the Report Data Source (Platform Manager, Data Processor, LogMart) to use as input data. If a source appears dimmed, it is unavailable.\\nReports run against the Data Processor pull their data from the Data Indexer. Therefore, the amount of data pulled in those reports is controlled by the effective TTL of your Data Indexer. You may have 30, 60 or even 90 days of configured TTL for your indexer, but if drive free space hits 80% then the oldest index will be deleted.\\nSpecify the Report Data Source (Platform Manager, Data Processor, LogMart) to use as input data. If a source appears dimmed, it is unavailable.\\nReports run against the Data Processor pull their data from the Data Indexer. Therefore, the amount of data pulled in those reports is controlled by the effective TTL of your Data Indexer. You may have 30, 60 or even 90 days of configured TTL for your indexer, but if drive free space hits 80% then the oldest index will be deleted.\\nSpecify the Report Permissions to determine the access level for the report.\\nConfigure Intelligent Indexing:\\nSelect\\nEnable Intelligent Indexing\\n, if necessary.\\nSelect\\nEnable Expiration\\n, if necessary.\\nSelect\\nEnable Intelligent Indexing\\n, if necessary.\\nSelect\\nEnable Expiration\\n, if necessary.\\nTo save the Report and exit the Report Wizard, click\\nOK\\n.\\nWhen viewing a Report, you cannot modify the Report Wizard fields.\\nTo save the Report and exit the Report Wizard, click\\nOK\\n.\\nWhen viewing a Report, you cannot modify the Report Wizard fields.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nReport Center\\n', 'Create Scheduled Reports': 'To create a Scheduled Report\\nOn the Tools menu, click\\nReport\\n, and then click\\nScheduled Report Job Manager\\n.\\nThe Scheduled Reports Job Manager window opens.\\nRight-click anywhere in the grid, and then click\\nNew\\n.\\nThe Scheduled Report Job Wizard appears.\\nRight-click anywhere in the grid, and then click\\nNew\\n.\\nThe Scheduled Report Job Wizard appears.\\nSelect the report packages you want to run as part of the scheduled report job, and then click\\nNext\\n.\\nSelect the report packages you want to run as part of the scheduled report job, and then click\\nNext\\n.\\nOn the Select Recipients page, do the following:\\nSelect each of the people you want to notify about the completed report.\\nFor each recipient, select the\\nAttach Reports\\ncheck box if you want to attach the report to the notification email.\\nTo configure a custom subject line for the notification email, select the\\nEnable Custom Subject Line\\ncheck box and type the subject line. You can type up to 255 characters.\\nOn the Select Recipients page, do the following:\\nSelect each of the people you want to notify about the completed report.\\nSelect each of the people you want to notify about the completed report.\\nFor each recipient, select the\\nAttach Reports\\ncheck box if you want to attach the report to the notification email.\\nFor each recipient, select the\\nAttach Reports\\ncheck box if you want to attach the report to the notification email.\\nTo configure a custom subject line for the notification email, select the\\nEnable Custom Subject Line\\ncheck box and type the subject line. You can type up to 255 characters.\\nTo configure a custom subject line for the notification email, select the\\nEnable Custom Subject Line\\ncheck box and type the subject line. You can type up to 255 characters.\\nClick\\nNext\\n.\\nClick\\nNext\\n.\\nSpecify the Report Period and the Report Job Time Zone.\\nSpecify the Report Period and the Report Job Time Zone.\\nSpecify the Report Schedule with one of the following options:\\nUnder Recurrence Pattern, select\\nDaily\\n. Then specify which days to run the report, and the time or frequency to run the reports. The report must run at least once per week on a particular day.\\nUnder Recurrence Pattern, select\\nMonthly\\n. Then specify the monthly day and time schedule. The report runs up to once per month.\\nIf the day of the month is 29, 30, or 31, the report job will not run if the month does not have that date (for example, in February).\\nSpecify the Report Schedule with one of the following options:\\nUnder Recurrence Pattern, select\\nDaily\\n. Then specify which days to run the report, and the time or frequency to run the reports. The report must run at least once per week on a particular day.\\nUnder Recurrence Pattern, select\\nDaily\\n. Then specify which days to run the report, and the time or frequency to run the reports. The report must run at least once per week on a particular day.\\nUnder Recurrence Pattern, select\\nMonthly\\n. Then specify the monthly day and time schedule. The report runs up to once per month.\\nIf the day of the month is 29, 30, or 31, the report job will not run if the month does not have that date (for example, in February).\\nUnder Recurrence Pattern, select\\nMonthly\\n. Then specify the monthly day and time schedule. The report runs up to once per month.\\nIf the day of the month is 29, 30, or 31, the report job will not run if the month does not have that date (for example, in February).\\nSpecify the\\nExport Options.\\nExport Location\\n. Specify the directory where the report should be saved. Click Test Path to ensure the path is correct.\\nExport Format\\n. Specify the format in which the generated report should be saved.\\nCompress Reports\\n. Check the Compress Reports check box if you want the reports to be compressed.\\nFile/Folder Name\\n. Specify the file or folder name patter to use when saving the report.\\nSpecify the\\nExport Options.\\nExport Location\\n. Specify the directory where the report should be saved. Click Test Path to ensure the path is correct.\\nExport Location\\n. Specify the directory where the report should be saved. Click Test Path to ensure the path is correct.\\nExport Format\\n. Specify the format in which the generated report should be saved.\\nExport Format\\n. Specify the format in which the generated report should be saved.\\nCompress Reports\\n. Check the Compress Reports check box if you want the reports to be compressed.\\nCompress Reports\\n. Check the Compress Reports check box if you want the reports to be compressed.\\nFile/Folder Name\\n. Specify the file or folder name patter to use when saving the report.\\nFile/Folder Name\\n. Specify the file or folder name patter to use when saving the report.\\nSelect options for viewing the report in the LogRhythm Web Console.\\nView in Web\\n. Select this check box to make the report available in the Web Console.\\nAuthorized User Profiles\\n. Select one or more user profiles that can view the report.\\nIf you change the Authorized User Profiles after a report has been run, users with newly granted access cannot see the report in the Web Console. You must run the report again for it to be visible to the new user profiles.\\nDays to keep report\\n. Type the number days for the report to be available in the Web Console.\\nSelect options for viewing the report in the LogRhythm Web Console.\\nView in Web\\n. Select this check box to make the report available in the Web Console.\\nView in Web\\n. Select this check box to make the report available in the Web Console.\\nAuthorized User Profiles\\n. Select one or more user profiles that can view the report.\\nIf you change the Authorized User Profiles after a report has been run, users with newly granted access cannot see the report in the Web Console. You must run the report again for it to be visible to the new user profiles.\\nAuthorized User Profiles\\n. Select one or more user profiles that can view the report.\\nIf you change the Authorized User Profiles after a report has been run, users with newly granted access cannot see the report in the Web Console. You must run the report again for it to be visible to the new user profiles.\\nDays to keep report\\n. Type the number days for the report to be available in the Web Console.\\nDays to keep report\\n. Type the number days for the report to be available in the Web Console.\\nClick\\nNext\\n.\\nClick\\nNext\\n.\\nType a name and optional description for the new scheduled report job, and then click\\nOK\\n.\\nType a name and optional description for the new scheduled report job, and then click\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nReport Center\\n', 'Manage Scheduled Reports': 'There are a number of ways you can manage your scheduled reports.\\nOn the Tools menu, click\\nReport\\n, and then click\\nScheduled Report Job Manager\\n.\\nThe Scheduled Reports Job Manager window opens.\\nSelect the\\nAction\\ncheck box of the reports you want.\\nRight-click anywhere on the grid, click\\nAction\\n, and then do one of the following:\\nClick\\nEnable\\n.\\nClick\\nDisable\\n.\\nClick\\nRun Now\\n.\\nClick\\nDelete\\n, and then confirm that you want to delete the scheduled job.\\nClick\\nEnable\\n.\\nClick\\nDisable\\n.\\nClick\\nRun Now\\n.\\nClick\\nDelete\\n, and then confirm that you want to delete the scheduled job.\\nCustomize reports by doing any of the following:\\nAdd\\nyour company logo\\nto the report cover page and header.\\nCreate a\\ncustom log detail report template\\n.\\nCreate a\\ncustom log summary report template\\n.\\nAdd\\nyour company logo\\nto the report cover page and header.\\nAdd\\nyour company logo\\nto the report cover page and header.\\nCreate a\\ncustom log detail report template\\n.\\nCreate a\\ncustom log detail report template\\n.\\nCreate a\\ncustom log summary report template\\n.\\nCreate a\\ncustom log summary report template\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nClient Console Analyst Guide\\n/\\nReport Center\\n', 'View Reports in the Client Console': 'After you generate a report, it appears in the Report Viewer. All Reports generated during the current Client Console session appear in the left pane.\\nTo view a report\\nOn the Tools menu, click\\nReport\\n, and then click\\nReport Center\\n.\\nClick the\\nReports\\nor\\nReport Packages\\ntab.\\nSelect the\\nAction\\ncheck box of the Report or Report Packages you want to view.\\nRight-click anywhere on the grid and click\\nRun\\n.\\nThe Report Viewer appears after the Reports are generated.\\nThe Report Viewer can also be opened manually by clicking\\nTools\\non the main toolbar, clicking\\nReport\\n, then clicking\\nReport Viewer\\n.\\nRight-click anywhere on the grid and click\\nRun\\n.\\nThe Report Viewer appears after the Reports are generated.\\nThe Report Viewer can also be opened manually by clicking\\nTools\\non the main toolbar, clicking\\nReport\\n, then clicking\\nReport Viewer\\n.\\nSelect a Report to display in the pane on the right.\\nSelect a Report to display in the pane on the right.\\nWhile viewing a report, the following actions are available from the toolbar at the top of the report (from left to right):\\nExport the report to a file (Crystal Reports, Adobe Acrobat, CSV, Excel, Word, Rich Text Format, XML)\\nPrint the report\\nCopy the report\\nToggle the Parameter Panel\\nToggle Group Tree\\nNavigate to the pages\\nSearch for text\\nZoom\\nAfter the Client Console is closed, the cached reports are removed and are not accessible in the next session.\\nWhile viewing a report, the following actions are available from the toolbar at the top of the report (from left to right):\\nExport the report to a file (Crystal Reports, Adobe Acrobat, CSV, Excel, Word, Rich Text Format, XML)\\nExport the report to a file (Crystal Reports, Adobe Acrobat, CSV, Excel, Word, Rich Text Format, XML)\\nPrint the report\\nPrint the report\\nCopy the report\\nCopy the report\\nToggle the Parameter Panel\\nToggle the Parameter Panel\\nToggle Group Tree\\nToggle Group Tree\\nNavigate to the pages\\nNavigate to the pages\\nSearch for text\\nSearch for text\\nZoom\\nAfter the Client Console is closed, the cached reports are removed and are not accessible in the next session.\\nZoom\\nAfter the Client Console is closed, the cached reports are removed and are not accessible in the next session.\\nTo group reports in the Reports pane:\\nDrag and drop a column header to the space labeled Drag a column header here to group by that column.\\nExpand the toggle in the column labels to sort the reports.\\nTo group reports in the Reports pane:\\nDrag and drop a column header to the space labeled Drag a column header here to group by that column.\\nDrag and drop a column header to the space labeled Drag a column header here to group by that column.\\nExpand the toggle in the column labels to sort the reports.\\nExpand the toggle in the column labels to sort the reports.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nFind More Information\\n', 'Customer Support Guide': 'The purpose of this document is to assist the community of LogRhythm administrators and users in getting the most out of LogRhythm Support. Your LogRhythm Support Concierge Team has constructed the document for you, and asks that you make it your own by modifying your copy over time based on your experiences with LogRhythm Support.\\n', 'Support Levels': 'LogRhythm offers two support levels: Enhanced Support and Standard Support. The table below shows the coverage hours and initial target response (ITR) times.\\nCase Priority, Enhanced Support, Standard Support\\nCoverage, ITR, Coverage, ITR\\nCritical, 24x7, 2 hours, 11x5, 4 hours\\nHigh, 24x7, 4 hours, 11x5, 8 hours\\nMedium, 11x5, 8 hours, 11x5, 12 hours\\nLow, 11x5, 12 hours, 11x5, 16 hours\\nEnhanced Support provides 24x7 coverage for Critical and High cases only. Medium and Low cases are serviced during local support region hours. For case priority levels, see\\nAppendix A: Case Priority\\n.\\n\\n', 'Path for Submitting Cases': 'For fastest support during business hours, please call our Support Line. The numbers are:\\n11x5 Support\\nRegion\\nNumber\\nBusiness Days\\nBusiness Hours\\nNorth America (Toll Free)\\n+1 866-255-0862\\nMonday - Friday\\n7:00 a.m. – 6:00 p.m. MT\\nThe Americas (Direct Dial)\\n+1 720-407-3990\\nMonday - Friday\\n7:00 a.m. – 6:00 p.m. MT\\nEMEA\\n+44 (0) 844 3245898\\nMonday - Friday\\n7:00 a.m. – 6:00 p.m. GMT\\nMETA\\n+971 8000-3570-4506\\nSunday - Thursday\\n7:00 a.m. – 6:00 p.m. Gulf Time (GMT+4)\\nAPAC\\n+65 31572044\\nMonday – Friday\\n7:00 a.m. – 6:00 p.m. SGT (Singapore)\\nAlternatively, you may submit a case at any time via the LogRhythm Support Portal at\\nhttps://support.logrhythm.com\\n. If a response to your case is urgently required, please also feel free to call the support line after you’ve submitted the case and ask to be transferred to a support engineer right away. If possible, we’ll accommodate you.\\n11x5 Support\\nRegion\\nNumber\\nBusiness Days\\nBusiness Hours\\nNorth America (Toll Free)\\n+1 866-255-0862\\nMonday - Friday\\n7:00 a.m. – 6:00 p.m. MT\\nThe Americas (Direct Dial)\\n+1 720-407-3990\\nMonday - Friday\\n7:00 a.m. – 6:00 p.m. MT\\nEMEA\\n+44 (0) 844 3245898\\nMonday - Friday\\n7:00 a.m. – 6:00 p.m. GMT\\nMETA\\n+971 8000-3570-4506\\nSunday - Thursday\\n7:00 a.m. – 6:00 p.m. Gulf Time (GMT+4)\\nAPAC\\n+65 31572044\\nMonday – Friday\\n7:00 a.m. – 6:00 p.m. SGT (Singapore)\\n11x5 Support\\nRegion, Number, Business Days, Business Hours\\nNorth America (Toll Free), +1 866-255-0862, Monday - Friday, 7:00 a.m. – 6:00 p.m. MT\\nThe Americas (Direct Dial), +1 720-407-3990, Monday - Friday, 7:00 a.m. – 6:00 p.m. MT\\nEMEA, +44 (0) 844 3245898, Monday - Friday, 7:00 a.m. – 6:00 p.m. GMT\\nMETA, +971 8000-3570-4506, Sunday - Thursday, 7:00 a.m. – 6:00 p.m. Gulf Time (GMT+4)\\nAPAC, +65 31572044, Monday – Friday, 7:00 a.m. – 6:00 p.m. SGT (Singapore)\\nAlternatively, you may submit a case at any time via the LogRhythm Support Portal at\\nhttps://support.logrhythm.com\\n. If a response to your case is urgently required, please also feel free to call the support line after you’ve submitted the case and ask to be transferred to a support engineer right away. If possible, we’ll accommodate you.\\n\\nWe recommend that, at least a day or two before you might need Support, you visit the Portal home page (\\nhttps://logrhythmcommunity.force.com/CustomSelfRegister\\n) to create your account and then contact your LogRhythm Customer Relations Manager (CRM) to ask them to authorize access for you to the Support Portal.\\n\\nIf you have\\nEnhanced Support\\n, we suggest that you use the 24x7 telephone numbers exclusively.\\nFor case priority levels, see\\nAppendix A: Case Priority\\n.\\n\\n', 'Utilizing the 24x7 Feature of Your Enhanced Support Contract': 'The Enhanced Support contract gives you the flexibility to contact our support team on any day, at any time, 24/7/365.\\xa0If you have an Enhanced Support contract, please read this entire section to be sure you understand how to utilize this feature.\\nIf you come to the end of a working session with a support engineer and you wish to resume work with another support engineer in the next available region, tell your support engineer. You will need to let the engineer know whom we should contact to continue the work. Please note:\\nWe cannot guarantee that a support engineer will immediately be available in the next region.\\nMany times it is more beneficial to stay with the support engineer with whom you’ve been working rather than transferring to another engineer who will need to study the case history before being able to help you.\\nWhether you call our Support Line or submit a new case through the Support Portal, our weekend staff will be notified and will make every effort to reach back out to you within two hours for Critical cases or four hours for High cases.\\nUpdates to existing cases will NOT notify our weekend staff. So please call the Support Line to record a message in the voice mail system, and remember to include your support case number. Our weekend support team will be notified immediately, will update your case with the information you provided, and will respond to you as soon as possible to continue working with you.\\n', 'Some Other Dos and Don’ts': 'If you have a case open for a particular issue, please do not open another case for that same issue.\\nIf you’re unhappy with the progress on a case, the responsiveness of the engineer, or the engineer in general, please call our Support Line and express your concern to the Concierge.\\nIf, in the course of working on a case, it becomes evident that the title (summary field) is no longer appropriate, please ask the support engineer to change the title.\\nWhen you experience a product issue, please refrain from restarting services or rebooting systems as a means of restoring operations until a support engineer has been able to observe the problem and collect relevant data.\\n', 'Communicating with the Support Engineers': 'Please don’t hesitate to ask your support engineer at the end of a work session what the action plan is. That is, be sure you know what will be done next, by whom, and by when.\\nPlease watch for updates to your cases in your email inbox, or by checking the Support Portal.\\nWhen a LogRhythm Support Engineer sends you a message through your support case, the case management system automatically will send you an\\nadditional\\nemail message to notify you that somebody updated your case. If you would prefer not to receive that extra message:\\nOn the Support Portal homepage, select\\nMy Settings\\nfrom the pulldown menu next to your name at the top right of the page.\\nLocate the “Email Notifications” section and uncheck the boxes by “Comments on my posts” and “Comments after me.” This will\\nnot\\nimpact your Community settings.\\nClick\\nSave\\n.\\nPlease watch for updates to your cases in your email inbox, or by checking the Support Portal.\\nOn the Support Portal homepage, select\\nMy Settings\\nfrom the pulldown menu next to your name at the top right of the page.\\nLocate the “Email Notifications” section and uncheck the boxes by “Comments on my posts” and “Comments after me.” This will\\nnot\\nimpact your Community settings.\\nClick\\nSave\\n.\\nAfter receiving a case update, please respond as quickly as you can so that we may continue to work with you. You\\'re welcome to respond to case emails directly, though it is helpful to the LogRhythm Support Team if you reply through the portal instead. Two important tips for you in working with your case on the portal:\\nWhen you reply through the portal, we recommend that you provide your update in the top right box labeled \"Post\". It\\'s easier to track the discussion this way than to have nested comments.\\nUnder the \"Post\" box, there\\'s a sorting menu. It\\'s labeled with your current choice, either \"Most Recent Activity\" or \"Latest Posts\". We recommend you set it to \"Most Recent Activity.\"\\nWhen you reply through the portal, we recommend that you provide your update in the top right box labeled \"Post\". It\\'s easier to track the discussion this way than to have nested comments.\\nUnder the \"Post\" box, there\\'s a sorting menu. It\\'s labeled with your current choice, either \"Most Recent Activity\" or \"Latest Posts\". We recommend you set it to \"Most Recent Activity.\"\\n', 'What to Expect when You Submit a Case': 'If you call LogRhythm Support during business hours, one of our Support Concierges will answer your call. The Concierge will create your new support case for you, gather all necessary information from you and if possible transfer your call to an appropriate support engineer to begin work with you immediately.\\nIf you submit a case through the portal, or if you called but could not be transferred, your case will be placed into the appropriate support queue. We will do our best to have one of our support engineers contact you within four business hours to begin work.\\n', 'Specific Items to Include with Your Cases': 'Please be sure to include the following information in each case you submit. The more accurate and thorough you are, the better we will be able to route your case to the right person and the better that person will be able to address your issue quickly and effectively.\\nCorrect LogRhythm product\\nCorrect product version\\nIf you have different versions for different components involved in the issue, please indicate that in the details of your request.\\nCorrect topic\\nAccurate priority\\nPlease help us to help you best by indicating the priority fairly. For more information about case priority, please see\\nAppendix A: Case Priority\\n.\\nSummary: think of this as the title of your support case. This should tell us at a glance what problem you’re observing or question you’re asking.\\nIn the Details field, indicate:\\nwhether, how, and how much the problem is impacting your business.\\nexactly what problem you’ve observed or question you need answered. Remember to let us know when the problem occurred. Please provide as many relevant details as possible, such as specific alarms, log sources, agents, reports, and other items that were involved.\\nwhat has changed in your environment in the hours or days leading up to the problem.\\nwhether, how, and how much the problem is impacting your business.\\nexactly what problem you’ve observed or question you need answered. Remember to let us know when the problem occurred. Please provide as many relevant details as possible, such as specific alarms, log sources, agents, reports, and other items that were involved.\\nwhat has changed in your environment in the hours or days leading up to the problem.\\nIf you have a good idea which product component or components are having trouble, please attach to your case the appropriate log files (see\\nAppendix B: Log Collecting\\n). Be sure the log files have logs from at least a couple of hours before the problem was observed all the way through to the present, or the time when the problem went away.\\n', 'Appendix A: Case Priority': 'This table is intended as a guide to understanding the appropriate setting of priorities for LogRhythm Support cases. Your selection of a priority will assist LogRhythm Support in serving you better, but will not guarantee any specific response or resolution times outside of what is specified in your LogRhythm maintenance contract.\\n, PRIORITY DEFINITION - LOGRHYTHM SUPPORT\\n, Priority 1, Priority 2, Priority 3, Priority 4\\n, Critical, High, Medium, Low\\nBusiness Impact, Extensive - the entire LogRhythm product is not operational., Significant - one or more major features of the LogRhythm product are not operational or accessible., Moderate - a feature of the LogRhythm product is not working as documented., Minimal - general questions and enhancement requests.\\nTechnical Impact, Complete or Major outage or degradation of the core LogRhythm application or the user-facing Web Console., Outage or degradation of one or more core components of the LogRhythm application or the user-facing Web Console., Moderate non-production outage or production degradation., Issue has little to no impact on users or is isolated to a small number of users\\nWork-Around, There is no workaround or no acceptable workaround to effectively use or administer the LogRhythm product., There is no workaround or no acceptable workaround to effectively use or administer the impacted components of the LogRhythm product., There is\\xa0an\\xa0acceptable\\xa0workaround to use or administer the LogRhythm product., There\\xa0is an\\xa0acceptable\\xa0workaround to use or administer the LogRhythm product.\\nExamples, System down or unavailableData Processor (DP) not accepting any Agent connections, Core component down or unavailablePlatform Manager (PM)Data Indexer (DX)Web Console (WC) complete outageAdvanced Intelligence Engine (AIE)Multiple collection components down/backloggedData Collectors (DC)System Monitor Agents (SMA)Data Processors (DP)Widespread performance degradationWeb Console searches not functioningLog Sources not collectingAlarms not functioning, Single collection component down/backloggedData Collector (DC)System Monitor Agent (SMA)Data Processor (DP)Isolated issuesSlow Web Console searches for one/few usersSingle Log Sources not collectingSingle alarm drill-downs failingParsing issues (parsing gap causing issues in production)LogRhythm diagnostic events or errorsSmartResponse Plugin or Alarm troubleshootingNew Log Source configuration assistance, General questionsUpgrade guidanceDocumentation questionsParsing requests (Log Source still being on-boarded)New device requestsCommunity-supported products (Beta)Access to the Community or portals\\n\\nPRIORITY DEFINITION - LOGRHYTHM SUPPORT\\n\\nPriority 2\\nPriority 3\\nPriority 4\\n\\nHigh\\nMedium\\nLow\\nBusiness Impact\\nSignificant - one or more major features of the LogRhythm product are not operational or accessible.\\nModerate - a feature of the LogRhythm product is not working as documented.\\nMinimal - general questions and enhancement requests.\\nTechnical Impact\\nOutage or degradation of one or more core components of the LogRhythm application or the user-facing Web Console.\\nModerate non-production outage or production degradation.\\nIssue has little to no impact on users or is isolated to a small number of users\\nWork-Around\\nThere is no workaround or no acceptable workaround to effectively use or administer the impacted components of the LogRhythm product.\\nThere is\\xa0an\\xa0acceptable\\xa0workaround to use or administer the LogRhythm product.\\nThere\\xa0is an\\xa0acceptable\\xa0workaround to use or administer the LogRhythm product.\\nExamples\\nSystem down or unavailable\\nData Processor (DP) not accepting any Agent connections\\nCore component down or unavailable\\nPlatform Manager (PM)\\nData Indexer (DX)\\nWeb Console (WC) complete outage\\nAdvanced Intelligence Engine (AIE)\\nMultiple collection components down/backlogged\\nData Collectors (DC)\\nSystem Monitor Agents (SMA)\\nData Processors (DP)\\nWidespread performance degradation\\nWeb Console searches not functioning\\nLog Sources not collecting\\nAlarms not functioning\\nSingle collection component down/backlogged\\nData Collector (DC)\\nSystem Monitor Agent (SMA)\\nData Processor (DP)\\nIsolated issues\\nSlow Web Console searches for one/few users\\nSingle Log Sources not collecting\\nSingle alarm drill-downs failing\\nParsing issues (parsing gap causing issues in production)\\nLogRhythm diagnostic events or errors\\nSmartResponse Plugin or Alarm troubleshooting\\nNew Log Source configuration assistance\\nGeneral questions\\nUpgrade guidance\\nDocumentation questions\\nParsing requests (Log Source still being on-boarded)\\nNew device requests\\nCommunity-supported products (Beta)\\nAccess to the Community or portals\\n', 'Appendix B: Log Collecting': 'Alarming related issues\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Alarming and Response Manager\\\\scarm.log\\nScheduled reports and AD Sync issues\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Job Manager\\\\lrjobmgr.log\\nSQL Related issues/ Log Manager indexing /Investigation issues (See Mediator logs):\\nC:\\\\Program Files\\\\Microsoft SQL Server\\\\MSSQL10_50.MSSQLSERVER\\\\MSSQL\\\\Log\\\\ERRORLOG\\nAgent connection/collection issues:\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm System Monitor\\\\logs\\\\scsm.log\\nFile Integrity Monitor issues:\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm System Monitor\\\\logs\\\\rtfim.log, filemon.log\\nMediator connection / processing / indexing /Investigation issues:\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Mediator Server\\\\logs\\\\scmedsvr.log, scmpe.log, lps_detail.log\\nArchiving issues:\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Mediator Server\\\\logs\\\\archive.log\\nAIE issues (see AIE Logs):\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Mediator Server\\\\logs\\\\lraiedp.log\\nAgent connection/collection issues:\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm System Monitor\\\\logs\\\\scsm.log\\nFile Integrity Monitor issues:\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm System Monitor\\\\logs\\\\rtfim.log, filemon.log\\nAny AIE related issues:\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm AI Engine\\\\logs\\\\LRAIEComMgr.log, LRAIEEngine.log\\nAIE Cache Drilldown:\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm AI Engine Cache Drilldown\\\\logs\\\\LogRhythm AI Engine Cache Drilldown.log\\nAIE Notifications:\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Notification Services\\\\logs\\\\LogRhythm Notification Service.log\\nAgent connection/collection issues:\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm System Monitor\\\\logs\\\\scsm.log\\nFile Integrity Monitor issues:\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm System Monitor\\\\logs\\\\rtfim.log, filemon.log\\nIndexing/ investigation issues:\\nWindows\\nC:\\\\Program Files\\\\LogRhythm\\\\Data Indexer\\\\logs\\\\gomaintain.log, columbo.log, carpenter.log, bulldozer.log\\nC:\\\\Program Files\\\\LogRhythm\\\\Data Indexer\\\\Elasticsearch\\\\logs\\\\logrhythm.log\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Common\\\\logs\\\\LogRhythm API Gateway.log, LogRhythm Service Registry.log, LogRhythm Metrics Collection.log\\nLinux:\\n/var/log/Elasticsearch/<Your DX Name Here>.log\\n/var/log/persistent/ gomaintain.log, columbo.log, carpenter.log, bulldozer.log\\nWeb Console:\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Web Services\\\\logs\\\\ LogRhythm Case API.log, LogRhythm Threat Intelligence API.log, LogRhythm Web Console AP.log, LogRhythm Web Console UI.log, LogRhythm Web Indexer.log, LogRhythm Web Services Host API.log\\nLogRhythm Authentication Services:\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Authentication Services\\\\logs\\\\ LogRhythm Authentication API.log, LogRhythm SQL Service.log, LogRhythm Windows Authentication Service.log\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nFind More Information\\n', 'End of Life Policies for Software and Hardware': '', 'Overview': 'LogRhythm provides full engineering and technical support for the LogRhythm and Network Monitor software for 24 months after the General Availability release date. Hardware support lifetime is five years from shipment date. This document outlines LogRhythm’s policies regarding the LogRhythm hardware and software product end of life. LogRhythm reserves the right to modify this policy.\\nThe LogRhythm Solution consists of software and optional hardware, each with its own product lifecycle. Support for either is contingent upon your current maintenance agreement. The End of Life policies of any third party products resold by LogRhythm are maintained by the respective third party.\\n', 'LogRhythm Software Product Lifecycle': '', 'LogRhythm Software Products': 'LogRhythm software products may include multiple components such as the Data Processor (DP), Platform Manager (PM), Advanced Intelligence (AI) Engine, Data Indexer (DX), Network Monitor (NM), and others as defined by the software version.\\n', 'Software Product Lifecycle Definitions': 'Software Version.\\nThe version number associated with a release consists of a major, minor, and patch in the following format: major.minor.patch (7.2.3).\\nMajor Release.\\n6, 7\\nMinor Release.\\n7.10, 7.11\\nPatch.\\n7.10.1, 7.10.2, 7.10.3\\nSoftware Version.\\nThe version number associated with a release consists of a major, minor, and patch in the following format: major.minor.patch (7.2.3).\\nMajor Release.\\n6, 7\\nMajor Release.\\n6, 7\\nMinor Release.\\n7.10, 7.11\\nMinor Release.\\n7.10, 7.11\\nPatch.\\n7.10.1, 7.10.2, 7.10.3\\nPatch.\\n7.10.1, 7.10.2, 7.10.3\\nRelease.\\nAny major (e.g., 6.3 → 7.1) or minor software version (7.10 → 7.11) increment that is made available to customers.\\nRelease.\\nAny major (e.g., 6.3 → 7.1) or minor software version (7.10 → 7.11) increment that is made available to customers.\\nGeneral Availability (GA) Date.\\nThe date a software release version is made generally available to customers for installation, not including beta or early access programs.\\nGeneral Availability (GA) Date.\\nThe date a software release version is made generally available to customers for installation, not including beta or early access programs.\\nKnowledge Base (KB) Updates.\\nKnowledge base updates include:\\nNew log processing rule sets.\\nNew analytics modules that might include: Reports, Alarm Rules, AI Engine Rules, Investigations, Lists, and other supporting content\\nUpdates to existing log processing rule sets and analytics modules.\\nKnowledge Base (KB) Updates.\\nKnowledge base updates include:\\nNew log processing rule sets.\\nNew log processing rule sets.\\nNew analytics modules that might include: Reports, Alarm Rules, AI Engine Rules, Investigations, Lists, and other supporting content\\nNew analytics modules that might include: Reports, Alarm Rules, AI Engine Rules, Investigations, Lists, and other supporting content\\nUpdates to existing log processing rule sets and analytics modules.\\nUpdates to existing log processing rule sets and analytics modules.\\nEnd of Sale (EoS).\\nWhen a product release version reaches End of Sale, the version will no longer be available for sale.\\nEnd of Sale (EoS).\\nWhen a product release version reaches End of Sale, the version will no longer be available for sale.\\nEnd of Support Life (EoSL).\\nWhen a product release version reaches End of Support Life, it will no longer be supported by LogRhythm’s technical support services.\\nEnd of Support Life (EoSL).\\nWhen a product release version reaches End of Support Life, it will no longer be supported by LogRhythm’s technical support services.\\n', 'LogRhythm Software Product Support Policies': 'End of Sale (EoS).\\nLogRhythm sells and ships the current software release only. Upon the General Availability of a new release, any previous release is considered End of Sale (EoS).\\nFor example, when v7.13 becomes generally available, the v7.12 release will be considered End of Sale.\\nEnd of Support Life (EoSL).\\nSupport will work with customers on versions up to 24 months old from current release to help determine and fix issues.\\xa0If a fix/hotfix/vulnerability or patch is required, customers will be required to upgrade to a later version where the defect/vulnerability no longer exists.\\nAll log archives created by previous software versions are supported by new releases.\\n', 'LogRhythm Hardware Product Lifecycle': '', 'LogRhythm Hardware Products': 'LogRhythm hardware product lifecycle includes all products entitled as a LogRhythm appliance, including dark spares and test appliances.\\n', 'LogRhythm Hardware Product Lifecycle Definitions': 'Date of Ship (DoS).\\nThe date the hardware was shipped to the end user.\\nDate of Ship (DoS).\\nThe date the hardware was shipped to the end user.\\nHardware Generation.\\nThe generation level of the hardware.\\nThe Gen1 Hardware generation includes the LR500, LR1000, and LR2000 product series.\\nThe Gen2 Hardware generation products are all prefixed with LRX (e.g., LRX1, LRX2, and LRX3).\\nThe Gen3 Hardware generation is designated by the second number in the product code (e.g., XM4310, EM5350, and LM7310).\\nThe Gen4 Hardware generation is designated by the second number in the product code (e.g., XM4410, PM7410, and DX5410).\\nThe Gen5 Hardware generation is designated by the second number in the product code (e.g., XM4550, PM7500, and DX5500).\\nThe Gen6 Hardware generation is designated by the second number in the product code (e.g., XM4650, PM7600, and DX5600).\\nMidlife Generation Updates.\\nLogRhythm may introduce enhancements to a hardware generation, such as improved storage capacity, memory, and/or processing. Hardware updates are designed by a change in the last digit of the product code (e.g., XM4431 and DX7411).\\nHardware Generation.\\nThe generation level of the hardware.\\nThe Gen1 Hardware generation includes the LR500, LR1000, and LR2000 product series.\\nThe Gen1 Hardware generation includes the LR500, LR1000, and LR2000 product series.\\nThe Gen2 Hardware generation products are all prefixed with LRX (e.g., LRX1, LRX2, and LRX3).\\nThe Gen2 Hardware generation products are all prefixed with LRX (e.g., LRX1, LRX2, and LRX3).\\nThe Gen3 Hardware generation is designated by the second number in the product code (e.g., XM4310, EM5350, and LM7310).\\nThe Gen3 Hardware generation is designated by the second number in the product code (e.g., XM4310, EM5350, and LM7310).\\nThe Gen4 Hardware generation is designated by the second number in the product code (e.g., XM4410, PM7410, and DX5410).\\nThe Gen4 Hardware generation is designated by the second number in the product code (e.g., XM4410, PM7410, and DX5410).\\nThe Gen5 Hardware generation is designated by the second number in the product code (e.g., XM4550, PM7500, and DX5500).\\nThe Gen5 Hardware generation is designated by the second number in the product code (e.g., XM4550, PM7500, and DX5500).\\nThe Gen6 Hardware generation is designated by the second number in the product code (e.g., XM4650, PM7600, and DX5600).\\nMidlife Generation Updates.\\nLogRhythm may introduce enhancements to a hardware generation, such as improved storage capacity, memory, and/or processing. Hardware updates are designed by a change in the last digit of the product code (e.g., XM4431 and DX7411).\\nMidlife Generation Updates.\\nLogRhythm may introduce enhancements to a hardware generation, such as improved storage capacity, memory, and/or processing. Hardware updates are designed by a change in the last digit of the product code (e.g., XM4431 and DX7411).\\nEnd of Sale (EoS).\\nWhen hardware reaches End of Sale, the version will no longer be available for order. Appliances and optional peripherals may be available as inventory allows.\\nEnd of Sale (EoS).\\nWhen hardware reaches End of Sale, the version will no longer be available for order. Appliances and optional peripherals may be available as inventory allows.\\nEnd of Support Life (EoSL).\\nWhen hardware reaches End of Support Life, technical support services such as hardware debugging and hard drive replacement will no longer be available. This includes the ability to order replacement parts.\\nEnd of Support Life (EoSL).\\nWhen hardware reaches End of Support Life, technical support services such as hardware debugging and hard drive replacement will no longer be available. This includes the ability to order replacement parts.\\n', 'LogRhythm Hardware End of Life Policy': 'End of Sale (EoS).\\nLogRhythm resells and ships the current hardware generation only. Upon the introduction of a new hardware generation, any previous hardware generation is considered End of Sale (EoS). LogRhythm may allow sales of previous hardware generations and optional peripherals as inventory on hand allows.\\nFor example, when fourth hardware generation is introduced, the third-generation hardware will no longer be available for sale.\\nEnd of Support Life (EoSL).\\nHardware End of Support Life (EoSL) occurs five years after Date of Ship. All appliances supplied by LogRhythm have a maximum five-year serviceable lifetime.\\nFor a list of hardware generations and their End of Life dates, see the\\xa0End of Life Dates for Hardware Generations table in the\\nAppendix: End of Life Tables\\nsection\\xa0below.\\n', 'End of Engineering Support\\xa0for Log Sources with Log Source Optimization (LSO) Policies': 'LogRhythm has rewritten parsing rules, configuration guides, and mapping documentation for the most problematic legacy log source types as identified by LogRhythm Support and Engineering teams. We encourage customers to use the new LSO policies under the LogRhythm Default v2.0 Log Processing Policy. LogRhythm is not providing enhancements or parsing changes on the LogRhythm Default Log Processing Policy for these log source types going forward and will maintain the LogRhythm Default v2.0 Log Processing Policy.\\nMore information about log source optimization and how to use log sources is available at\\nLog Source Optimization\\n.\\nFor a list of log source types with new LSO policies, see the\\xa0End of Engineering Support for Log Source Types table in the\\nAppendix: End of Life Tables\\nsection\\xa0below.\\n', 'Appendix: End of Life Tables': '', 'End of Life Dates for SIEM Software Releases': 'Version, Original GA Release Date, Last Supported Version, End of Sale, End of Support Life\\n7.15.x, 04 January 2024, TBD, TBD, 31 January 2026\\n7.14.x, 02 October 2023, 7.14.0.107, 04 January 2024, 31 October 2025\\n7.13.x, 29 June 2023, 7.13.0.78, 02 October 2023, 31 July 2025\\n7.12.x, 03 April 2023, 7.12.0, 29 June 2023, 31 March 2025\\n7.11.x, 05 January 2023, 7.11.0.43, 03 April 2023, 28 February 2025\\n7.10.x, 28 September 2022, 7.10.0.123, 05 January 2023, 31 October 2024\\n7.9.x, 23 June 2022, 7.9.0, 28 September 2022, 31 July 2024\\n7.8.x, 11 October 2021, 7.8.0, 23 June 2022, 30 November 2024\\n7.7.x, 05 April 2021, 7.7.0, 11 October 2021, 31 May 2024\\n7.6.x, 18 November 2020, 7.6.0 HF 2, 05 April 2021, 28 February 2024\\n7.5.x, 22 July 2020, 7.5.1, 18 November 2020, 31 October 2023\\n7.4.x, 23October2018, 7.4.10, 22 July 2020, 31 March 2022\\n7.3.x, 01 February 2018, 7.3.5, 23 October 2018, 31 October 2020\\n7.2.x, 14 November 2016, 7.2.7, 01 February 2018, 31 December 2018\\n7.1.x, September 2015, 7.1.10, November 2016, December 2018\\n6.3.x, December 2014, 6.3.9, September 2015, December 2018\\n6.2.x, February 2014, 6.2.8, December 2014, December 2018\\n6.1.x, February 2013, 6.1.7, February 2014, February 2018\\nVersion\\nOriginal GA Release Date\\nLast Supported Version\\nEnd of Sale\\nEnd of Support Life\\n22 July 2020\\n7.3.x\\n01 February 2018\\n7.3.5\\n23 October 2018\\n31 October 2020\\n7.2.x\\n14 November 2016\\n7.2.7\\n01 February 2018\\n31 December 2018\\n7.1.x\\nSeptember 2015\\n7.1.10\\nNovember 2016\\nDecember 2018\\n6.3.x\\nDecember 2014\\n6.3.9\\nSeptember 2015\\nDecember 2018\\n6.2.x\\nFebruary 2014\\n6.2.8\\nDecember 2014\\nDecember 2018\\n6.1.x\\nFebruary 2013\\n6.1.7\\nFebruary 2014\\nFebruary 2018\\n', 'End of Life Dates for Network Monitor Software Releases': 'Version, Original GA Release Date, Last Supported Version, End of Sale, End of Support Life\\n4.0.x, 06 January 2020, 4.0.6, TBD, 29 February 2024\\n3.9.x, 20 December 2018, 3.9.3, 06 January 2020, 30 June 2021\\n3.8.x, 23 July 2018, 3.8.2, 20 December 2018, 30 September 2020\\n3.7.x, 27 March 2018, 3.7.1, 23 July 2018, 31 March 2020\\n3.6.x, 26 December 2017, 3.6.2, 27 March 2018, 31 January 2020\\n3.5.x, 05 September 2017, 3.5.1, 26 December 2017, 30 September 2019\\n3.4.x, 22 May 2017, 3.4.2, 05 September 2017, 30 June 2019\\n3.5.x\\n05 September 2017\\n3.5.1\\n26 December 2017\\n30 September 2019\\n3.4.x\\n22 May 2017\\n3.4.2\\n05 September 2017\\n30 June 2019\\n', 'End of Life Dates for Hardware Generations': 'Version, Original Release Date, End of Sale, End of Support Life\\nGen6, October 2023, TBD, Five years from Date of Sale\\nGen5, July 2018, TBD, Five years from Date of Sale\\nGen4, July 2014, September 2018, Five yearsfrom Date of Sale\\nGen3, March 2013, July 2016, Five yearsfrom Date of Sale\\nGen2 (LRX), August 2009, April 2013, Five yearsfrom Date of Sale\\nGen1 (LR), August 2006, November 2009, Five yearsfrom Date of Sale\\nVersion\\nOriginal Release Date\\nEnd of Sale\\nEnd of Support Life\\nGen4\\nJuly 2014\\nSeptember 2018\\nFive years\\nfrom Date of Sale\\nGen3\\nMarch 2013\\nJuly 2016\\nFive years\\nfrom Date of Sale\\nGen2 (LRX)\\nAugust 2009\\nApril 2013\\nFive years\\nfrom Date of Sale\\nGen1 (LR)\\nAugust 2006\\nNovember 2009\\nFive years\\nfrom Date of Sale\\n', 'End of Engineering Support for Log Source Types': 'Log Source Type Reaching End of Engineering, End of Engineering Date, New Log Source Optimization Policy, Effective as of KB Version, Additional Information\\nMS Windows Event Logging XML - SecurityMS Windows Event Logging - SecurityMS Windows Event Logging : Deutsch - SecurityMS Windows Event Logging : Español - SecurityMS Windows Event Logging : Français - Security, 24 March 2021, These log source types are now supported withMS Windows Event Logging XML - SecuritywithLogRhythm Default v2.0policy, KB 7.1.591.0, LSO - Windows Security Events\\nMS Windows Event Logging - SysmonMS Windows Event Logging XML - Sysmon 7.01MS Windows Event Logging XML - Sysmon 8/9/10, 24 March 2021, These log source types are now supported withMS Windows Event Logging XML - SysmonwithLogRhythm Default v2.0policy, KB 7.1.591.0, LSO - Microsoft Sysmon\\nSyslog - Palo Alto Firewall, 04 October 2021, Engineering Support is available forSyslog - Palo Alto FirewallwithLogRhythm Default v2.0policy., KB 7.1.619.0, LSO - Syslog - Palo Alto Firewall\\nSyslog - Symantec Endpoint Server, 18 October 2021, Engineering Support is available forSymantec Endpoint ServerwithLogRhythm Default v2.0policy., KB 7.1.621.0, LSO - Syslog - Symantec Endpoint Server\\nMS Windows Event Logging XML - Security\\nMS Windows Event Logging - Security\\nMS Windows Event Logging : Deutsch - Security\\nMS Windows Event Logging : Español - Security\\nMS Windows Event Logging : Français - Security\\n24 March 2021\\nMS Windows Event Logging - Sysmon\\nMS Windows Event Logging XML - Sysmon 7.01\\nMS Windows Event Logging XML - Sysmon 8/9/10\\n24 March 2021\\nSyslog - Palo Alto Firewall\\n04 October 2021\\nSyslog - Symantec Endpoint Server\\n18 October 2021\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nFind More Information\\n', 'Glossary of LogRhythm Products and Components': '\\nThe place to find the meaning of terms found in LogRhythm user guides, training materials, and other documents.\\nA, \\nActive Directory (AD) Browsers, Grids access from the Knowledge tools menu that display active directory user or group information for the domains that were previously synchronized via the manager.\\nActive Directory (AD) Domain Manager, A tool used to setup, manage, and synchronize active directory domains. It is found within the Platform Manager tab of the Deployment Manager. Synchronization can be triggered from the manager or the domains can be left enabled for the Job Manager to pick it up on its schedule synchronization process.\\nAdmin API, A REST API that communicates over HTTPS and uses JSON. The API’s available routes and methods are used primarily for performing administrative functions in the Client Console, such as modifying lists, creating entities, adding people to notification groups, and searching identities.\\nAdvanced Intelligence Engine, The LogRhythm component that performs high-level, real-time analysis of log messages forwarded by the Data Processor. The AI Engine can elevate logs using a complex pattern matching rule-set, which correlates and detects sophisticated intrusions, insider threats, operational issues, and audit or compliance issues.\\nAdvanced Intelligence Engine Rule, A Knowledge Base object that contains specific configuration to analyze if logs meet specific criteria. The Rule contains settings for Common Events, Event Suppression, Alarm/Notification settings, Expiration, and other rule properties. A rule can have up to 3 rule blocks.\\nAdvanced Intelligence Engine Rule Block, A sub component of an AI Engine Rule that defines configuration parameters for logs to meet in order for the log to be considered satisfied by the rule block. A rule can have up to 3 rule blocks. There are 9 distinct variations of rule blocks.\\nAdvanced Intelligence Engine Rule Manager, A tool that allows users to manage AI Engine rules and rule blocks. It is accessed via the administration tools menu within Deployment Manager.\\nAIE Cache Drilldown, A service that caches the results of an AIE Drill down when an alarm is triggered from the ARM to provide faster access to data. It provides a summary on the drill down logs for both the group-by and primary inspection fields.\\nAgents (LogRhythm SIEM), LogRhythm Agents, also called System Monitors, collect and forward log data to Data Processors. Agents can be installed on both Windows and UNIX platforms. They are also integrated into Site Log Forwarder (SLF) appliances and can perform file integrity monitoring.\\nAgents (NetMon), A software component that receives data from the appliance and then sends it to LogRhythm SIEM for further processing.\\nAlarm, A record indicating that an alarm rule has been triggered by an event.\\nAlarm Aggregation, A setting to restrict similar events from incurring alarms unless a specified number of them occur within a specified time span. The user can define what makes them similar by indicating which fields must have matching values.\\nAlarm Card, An Alarm record that shows Alarm details.\\nAlarm Notifications, A notification of an alarm via a notification policy: SMTP (email), SNMP, or Text Files. The person, role, or group to notify is set on the Alarm Rule Properties Notify tab. The Alarm Notification Policies are set via the Notification Policy Manager which is a distribution tool option within Deployment Manager.\\nAlarm Suppression, A setting to suppress identical alarms based on the events triggering the alarm within a given time span.\\nAlarming and Response Manager (ARM), Alarming and Response Manager. A Windows service installed in the Event Manager, which is responsible for processing Alarm rules and taking the appropriate response.\\nAlert, An event requiring immediate notification and response. Can be a single event or a combination of events (correlated events).\\nAnomaly, User or entity behavior that deviates from an established behavioral baseline for that user or entity and could indicate a security risk to your network.\\nAppliance, See LogRhythm Appliance\\nApplication (LogRhythm SIEM), A record that defines an application and its ports and protocols so that the MPE rules can identify a log origin. Applications are managed via the Application Manager accessed from the Knowledge Tools menu within Deployment Manager.\\nApplication (NetMon), Network protocols or web applications that NetMon identified using pattern matching and heuristic modeling, as well as signatures.\\nArchive Log, A log that has been archived and therefore no longer available online via the Data Processor database.\\nAutomated Decision Making, The predictive processing or strategic analysis of personal data to anticipate subject behavior (profiling).\\nAutomatic Log Source Configuration, A function that identifies devices on the network using SNMP (v1, v2c, and v3). It identifies virtual sources for Syslog, Netflow, sFlow, and SNMP Trap. It is configured from the Data Processor Properties within Deployment Manager.\\nAutomatic Remediation, A feature that provides the ability to perform remediation actions (such as killing a process) based on information received from an alarm and its first event. Remediation actions can be performed automatically or require approval at the Alarm record. It uses a plug-in architecture that executes scripts on a windows system in a scripting language such as power shell.\\nB, \\nBase Rule, Part of the MPE Rule that contains a tagged regular expression—the regex—used to identify the pattern of a log and isolate interesting pieces of metadata. Using a tagging system, these metadata strings can be directed to special fields used by LogRhythm to better interpret a log or specifically identify it. In general, base-rules identify log messages by matching the fields to a specific log format or pattern.\\nBaseline Period, The period of time used to measure user or entity behavior in order to build Behavior Models in CloudAI. The maximum length of the Baseline Period is 29 days, but shorter lengths are used in cases of limited data.\\nBeat, Elastic Beats grab log data from devices and pass it along to the LogRhythm Open Collector.\\nBehavior Feature, One of many network or host activities exhibited by a user or entity. In CloudAI, Behavior Models are built from Behavior Features observed during the Baseline Period and are used to score Behavior Features observed during the Scored Period.\\nBehavior Model, In CloudAI, a model of expected user or entity behavior derived from the combined activity across a specific subset of Behavior Features.\\nBehavior Model Anomaly Score, A number from 1 to 100, used by CloudAI, that indicates how anomalous a user or entity’s behavior was during the Scored Period when compared to the Baseline Period within a given Behavior Model.\\nBinding Corporate Rules, Personal data protection policies to be adhered to by Data Controllers or Processors that are established by the Member State around the transfer of personal data.\\nBreach Notification, The specific requirements of a breach without undue delay, but no later than 72 hours after becoming aware of the breach to Supervisory Authority. Communication of the breach to the Data Subject is required if anticipated impacts may result in high-risk to rights and freedoms of the natural person. This should also include required breach information and appropriate remediation actions to be taken.\\nC, \\nCase Card, An interface component, visible on the Cases page and Cases panel, that displays basic details about a case. It contains the controls for opening and closing cases and managing their incident statuses.\\nCase Management, A forensic tool for tracking and documenting suspicious logs and alarms that are believed to be related to the same threat.\\nCentralized Service Metrics, A service that gathers metrics on resource utilization and performance counters from each LogRhythm host. The data is collected in the Platform Manager and is viewable in Grafana.\\nClassification, A second tier group used to categorize logs and events. There is one or more Classification associated to a Classification Type. A Classification can have one or more Common Events, which are associated to an MPE Rule.\\nClassification Type, A first tier group used to categorize logs and events. There are three types: Audit, Security, and Operations. Classifications are grouped into one of these three types. There is one classification type for one or more classifications.\\nClient, Initiator of a session, such as a workstation or laptop.\\nCommon Criteria, An international standard (ISO/IEC 15408) for computer security certification.\\nCommon Event, A short, plain-language description of the log that is associated to a specific classification. There is one Classification for one or more Common Events. A Common Event is created and managed through the Knowledge Tools Common Platform Manager. Common Events are associated with MPE rules (base and sub) located within the Knowledge Tools MPE Rule Builder. There is a one to one relationship between a MPE rule and a Common Event.\\nCommon Event Migration Manager, An administration tool within Deployment Manager used to manage the changes to existing custom common event filters (such as report and investigation filters) within the users deployment which reference common events that have changed in the master LogRhythm Knowledge Base.\\nComponents, See LogRhythm Components.\\nConsolidated Compliance Framework, The CCF Compliance Automation Suite provides pre-bundled Investigations, Correlation Rules, Alarms, and Reports that are designed to support a minimum set of security requirements across multiple frameworks, regulations, legislation, and industry best practices.\\nContextualization, An action one can perform on a log to gather more information about specific fields within the log including host, port, and user.\\nCoordinated Universal Time, The primary time standard by which the world regulates clocks and time. Time zones around the world are expressed as positive or negative offsets from UTC. The hours, minutes, and seconds that UTC expresses is kept close to the mean solar time at the Earth\\'s prime meridian (zero degrees longitude) located near Greenwich, England.\\nCore LogRhythm Software, Software installed by LR Deploy. This includes: Mediator, AIE, Platform Manager, Data Processor, Data Indexer, Web Console, and others. This does not include collection agents.\\nCorrelation, An action one can perform on a log to perform an additional search based on field values within the log. For example, a user can select a log and choose to correlate on the value within the Common Event field or the values within all fields in the log. Correlation works with the Quick Search Toolbar.\\nD, \\nDashboard, A layout that contains graphs and charts in easy-to-read formats, which allows you to view high-level Events and also drill down on the data for further investigation.\\nData Controller, An organization the defines the scope, purpose, and methods of processing personal data.\\nData Indexer, LogRhythm Data Indexers (Indexer) provide persistence and search capabilities, as well as high-performance, distributed, and highly scalable indexing of machine and forensic data. Indexers can be clustered in a replicated configuration to enable high-availability, improved search performance, and support for a greater number of simultaneous users. Indexers store both the original and structured copy of data to enable search-based analytics. The DX runs Elasticsearch and is supported on Windows and Linux.\\nData Loss Defender, An Endpoint Monitoring tool that independently monitors and logs the connection and dis-connection of external data devices to the host computer where the Agent is running. It is managed from the System Monitor Agent properties within Deployment Manager.\\nData Processor, LogRhythm Data Processor (DP) are Windows Server systems running SQL Server and a single server process, the LogRhythm Mediator Server. There can be one, or many, DPs in a deployment. In medium to large deployments, Data Processors should be dedicated systems. However, in small deployments, a Data Processor can coexist on the same system as the Platform Manager. The Mediator Server takes in log messages, processes them against rules which identify the log message and determine if it will be forwarded to the EM as an Event.\\nData Protection Authority, The national authorities tasked with the protection of data and privacy through monitoring and enforcement of regulations established within the EU.\\nData Protection Impact Assessment, A risk-based assessment methodology to determine an organization’s systems and business processing that may be exposed to risk in the absence of mitigating controls.\\nData Protection Office, A new position created for an individual appointed within the organization to independently ensure adherence to policies and procedures set forth by General Data Protection Regulation in the European Union.\\nData Subject, A natural person whose data is being processed by a data controller or processor.\\nDeduplication, A process that recognizes and consolidates duplicate event data from log sources into a single, aggregate record. All raw log data is captured and archived for accuracy and compliance, while the deduplication process eliminates redundant online data and optimizes forensic search capabilities and storage utilization. Deduplication is a Log Processing Setting that can be set at the log source or log processing policy and can be overridden using a Global Log Processing Rule (GLPR).\\nDeep Packet Analytics, Allows users to write rules that will interact with network traffic as it is being processed.\\nDeep Packet Analytics Rules, Custom rules that enable users to determine flow state, access and set metadata, trigger alarms, enable capture, write log messages.\\nDeep Packet Inspection, A process whereby NetMon analyzes network data using a variety of methods, including pattern matching, heuristic modeling, signatures for session identification, application identification, and metadata extraction.\\nDeployment Manager, A utility window in the LogRhythm Console. People with LogRhythm administrator credentials use it to configure and manage LogRhythm components and functionality such as alarming and reporting.\\nDeployment Monitor, A window in the console that provides administrators with a near-real-time view of the per-formance of LogRhythm including host status, host performance metrics, database utilization, Data Processor metrics, and Data Processor volume.\\nDeployment Tool, The LogRhythm software installation tool to which the user adds each host IP in a deployment.\\nE, \\nEndpoint Monitoring, A client/server information security (IS) methodology used to audit log files generated by endpoint devices, such as laptops, smartphones, and routers.\\nEntity, A record that represents a logical grouping of LogRhythm SIEM components. It organizes the deployment in host records, network records, and the LogRhythm components. Small deployments may contain one Entity record, while large deployments that span many sites require multiple Entity records.\\nEntity Host, A record that represents a computer on a network. It is contained within an Entity. As part of log processing, hosts are identified as impacted or origin and may be represented as a Known Host if it exists as an Entity Host record. Entity Hosts are displayed in the Entities tab within Deployment Manager.\\nEntity Network, A record that represents a range of IP addresses that can have a host zone, host location, threat level and network risk level associated. It is contained within an Entity. Entity Networks are dis-played in the Entities tab within Deployment Manager.\\nEvent, A Syslog message to LogRhythm SIEM that has more immediate operational, security, or compliance relevance. Typically logs classified as errors, failures, or attacks are considered events.\\nEvent False Alarm Rating, A rate set at the Rule level via the MPE Rule and the MPE Policy Rule Editor. It is used in the RBP calculation.\\nEvent Risk Rating, A rate set at the Rule level via the MPE Policy Rule Editor. It is used in the RBP calculation.\\nF, \\nFile Integrity Monitoring, An Endpoint Monitoring tool that monitors files and directories for modifications. There are two modes: Standard and Realtime.\\nFlow, A collection of activity by a single user on a single application. The flow contains source and destination information, bytes and packet counts transferred in both directions, application identification, and many other metadata fields. Long-running flows send updates every 10 minutes by default, but you can change that value. Each flow has a unique identifier that links multiple intermediate flows together.\\nG, \\nGlobal Data Management Settings, The global settings for the deployment including configuration options for event forwarding, log processing, log deduplication, and LogMart settings; maintenance settings for compression, indexing, partition, backup paths, and Time to Live (TTL) values; as well as Classification Based Data Management (CBDM) settings and Global Classification Settings (GCS). It is found within the Platform Manager tab of the Deployment Manager.\\nGlobal Log Processing Rule, A Knowledge Base object used to provide a way to override settings defined in the Classification Based Data Management (CBDM) or standard Data Management settings (log message source and log processing policy). It provides a way to apply data management settings across all Data Processors, Log Sources, and Log Processing Policies to logs that meet specific criteria. The manager is accessed via the administration tools menu within Deployment Manager.\\nH, \\nHalf Session, A session is a bi-directional flow of packets between one client and one server. A \"half session\" defines one direction of that flow, on either the sender or receiver side.\\nHost, A single machine that has Core LogRhythm Software installed on it.\\nI, \\nIcon, A small graphic on the page, which you can select to open a dialog box or window.\\nIdentifier, An account name, a badge number, an ID, or any other piece of data that belongs uniquely to one user.\\nIdentity, A unified user. It contains a display name, email address, photo, job title, and any other identifier that belongs to that user.\\nIntelligent Indexing, Part of the Mediator/Message Processing Engine that prevents logs, events, and LogMart data that do not conform to the TTL values set in Global Maintenance Settings from being added to the online databases.\\nIntermediate Flow, An update of the communications between the client and server.\\nInvestigator, A search analysis tool that is used to query the Platform Manager, Data Processor, or LogMart databases for a given date range and with specified criteria for log source and field filters, among other settings. The results are displayed in a layout that can be configured and saved and includes various grids, charts, and graphs, including Network Visualization. The data results can be drilled into to provide more detailed information.\\nIPv6, The LogRhythm 6.0 services will support running on pure IPv6 networks as well as dual-stack (IPv4 and IPv6) networks. The LogRhythm services (Mediator, ARM, Job Manager, Agents, SQL Server) can be configured to use IPv6 address when communicating with each other.\\nJ, No terms available\\nK, \\nKnowledge Base, A LogRhythm Package that consists of a mixture of content both required and optional that is shared across a LogRhythm Deployment. It consists of the core Knowledge Base as well as modules. The core Knowledge Base includes content applicable to all deployments, such as log processing rules and policies, classifications, and common. The Knowledge Base is imported using the Knowledge Base Import Wizard accessed from the Knowledge tools menu within the console.\\nKnowledge Base Module, Pre-packaged, customizable content applicable to a specific regulation or need, such as reports, investigations, alerts, or AI Engine rules, to name a few. An example is a compliance module for PCI which would include reports, investigations, and AI Engine rules that provide data relevant in meeting PCI requirements. Modules are managed using the Knowledge Base Manager accessed from the Knowledge tools menu within the Console. Modules are imported with a Knowledge Base depending on their settings.\\nKnowledge Base Object, Defined LogRhythm items such as Alarm Rules, AI Engine Rules, Lists, Report Packages, Packaged Reports, Report Templates, FIM Policies, Investigations, Tails, and GLPRs that can be associated with a KB Module.\\nL, \\nLicense Limited, In the NetMon Data Rate chart, indicates the rate in megabits per second at which packets are being throttled/discarded according to your licensed capture rate.\\nList Manager, A tool that is used to manage lists. A list is a record of data for a given type to allow for grouping similar values together in one location that can then be used with all LogRhythm tools that allow filtering. For example, a list may include all PCI compliance related log sources or suspicious hosts or privileged users. These lists can then be used in filters within Investigator, Personal Dashboard, and Reports (to name a few) while allowing it to be created/modified from one location.\\nLocal Host, Standard hostname given to the address of the loopback network interface. Localhost is spe-cified where one would otherwise use the hostname of a computer.\\nLog, Individual log data collected by LogRhythm.\\nLog Distribution Services, A policy based solution that allows users to forward specific syslog and non-syslog log messages to an external syslog receiver over TCP or UDP. It consists of a Receiver Manager and a Policy Manager both access via the distribution tools menu within Deployment Manager.\\nLog Manager, The central processing engine for logs sent from the Agents. The Log Manager contains the Mediator service, which is responsible for log identification and classification. A Log Manager can be installed on the Event Manager appliance or it can be a separate appliance in the SIEM deployment. Large environments may need more than one Log Manager in the deployment.\\nLog Message, A raw log displayed in the Web Console\\'s Analyzer grid. Also called a raw log.\\nLog Message Source, A record that represents a single source of log data that is collected from a host. It is associated with a log source host, collection agent, and log message source type. It has specific data management and log processing settings and can have a MPE policy applied. An example source is Host 123 Microsoft Application Log.\\nLog Message Source Type, A record that represents a common data format for logs. It has a specific log format such as syslog, netflow, text file, windows event log, UDLA, Checkpoint firewall, Cisco SDEE, SNMP Trap, QualysGaurd, Nessus, or sFlow. They have MPE Rules written for them so that logs run against them will be optimally parsed. An example type is Microsoft Windows Event Log Application. They are managed via the Knowledge Tools Log Message Source Type Manager.\\nLog Miner, A summary overview and trending tool that is opened after you perform a LogMart Search with Investigator.\\nLog Processing Policy, A collection of MPE Rules designed for a specific Log Source Type such as Cisco PIX or Windows 2005 Security Event Log. Only Logs that are generated from Log Sources that have an assigned MPE Policy are processed by the MPE. There can be multiple policies for a single log source type to allow for flexibility in assigning the policy to various log sources.\\nLog Rotate, The Agent can follow log rotations while collecting from files but cannot finish reading a log file that is compressed. The result of reading a compressed file are unpredictable. Disable compression of the log sources that Agent is monitoring. Most Linux systems use the logrotate utility and its corresponding config file logrotate.conf to control this compression.\\nLog Source, See Log Message Source.\\nLog Source Type, See Log Message Source Type.\\nLogger, The NetMon Flow Output component that processes the metadata into \"flows.\"\\nLogLevel, Determines the amount of information logged to scarm.log. The number of logs you see depends on the LogLevel that is set in the Agent Advanced Properties. The log files that can be reviewed for success, error, and general log messages.\\nLogListener, Network Connection Monitor logging option to generate logs for listening TCP/UDP sockets when NetworkConnectionMonitor is enabled.\\nLogMart, A LogRhythm Database that stores log metadata rather than raw log data.\\nLogRhythm Appliance, A LogRhythm Appliance is a turn-key LogRhythm Server on custom hardware, designed and offered by LogRhythm. LogRhythm Appliances are available in PM, DP, XM (PM + DP), and SLF (Agent-only log collection machine) configurations. They are also offered in a number of sizes to meet varying collection-volume needs.\\nLogRhythm Client Console, The LogRhythm Client Console provides deployment administration and user interaction with LogRhythm with a Graphical User Interface (GUI).\\nLogRhythm CloudAI, A LogRhythm User and Entity Behavior Analytics (UEBA) service that provides visibility into insider threats, compromised accounts, and privilege abuse.\\nLogRhythm Common Components, LogRhythm Services that form the core of the deployment and need to be running on each host. These are the LogRhythm API Gateway, the LogRhythm Service Registry, and the LogRhythm Windows Authentication Service.\\nLogRhythm Components, The software and associated databases required to run the LogRhythm Solution. This includes the Platform Manager (PM), Data Processor (DP), Advanced Intelligence (AI) Engine, LogRhythm SysMon Agents, and the Client and Web Consoles.\\nLogRhythm Deployment, The collection of all hosts on a network.\\nLogRhythm Diagnostics Tool, A standalone application that consolidates collected log files, performance metrics, oversubscription information, and other data from a LogRhythm deployment into a local .zip file for immediate review, analysis, and troubleshooting.\\nLogRhythm ECHO, A standalone Windows application with web and command line interfaces that simulates a LogRhythm System Monitor Agent and allows users to replay native raw logs and PCAPs into LogRhythm for demonstration, validation, and verification purposes.\\nLogRhythm SIEM, The core LogRhythm Solution set, including Data Collection, Processing (MDI), Persistence, and AI Engine but not including LogRhythm NetMon or LogRhythm SysMon.\\nLogRhythm Metadata, Includes the fields that LogRhythm parses, derives, and calculates from collected log data. For the full list of fields and their descriptions, see the LogRhythm Schema Dictionary and Guide, available under Documentation & Downloads on the LogRhythm Community.\\nLogRhythm Metrics App, A standalone application that extracts LogRhythm LogMart, Case, and Alarm SQL Server database data to a standalone Elasticsearch instance for analysis and presentation.\\nLogRhythm NetMon, An add-on product for network monitor functionality.\\nLogRhythm NetMon Freemium, The free version of LogRhythm NetMon with reduced functionality.\\nLogRhythm Open Collector, The Open Collector brings modern logs, usually in JSON format, from cloud log sources, flat file, or other formats, into the LogRhythm SIEM. It was designed for easy mapping of those JSON fields to the LogRhythm Schema. The Open Collector uses Elastic Beats to grab the data from the device and pass it along to the Open Collector, where the normalization takes place.\\nLogRhythm Platform, The set of LogRhythm products including LogRhythm SIEM, LogRhythm XM, LogRhythm CloudAI, LogRhythm SysMon, LogRhythm NetMon, and LogRhythm NetMon Freemium. Also called the LogRhythm Threat Lifecycle Management Platform.\\nLogRhythm Platform Manager, The LogRhythm Platform Manager (PM) server is a Windows Server system running SQL Server and the LogRhythm Alarming and Response Manager (ARM) service. There is only one PM per deployment. The PM is sent logs that are determined to be important or interesting, called Events, which it maintains. The PM also contains the deployment\\'s configuration data. The ARM is a windows service responsible for processing alarm rules and taking the appropriate response, such as sending e-mails to people on a notification list.\\nLogRhythm Server, A LogRhythm Server is a Windows Server running as an EM, DP, or both. Customers typically build a Server when they have purchased a software-only solution from LogRhythm.\\nLogRhythm Solution, A fully integrated Security Information and Event Management (SIEM) solution providing log management, advanced log analysis, event management, network and user monitoring, and reporting. The LogRhythm Solution is the collection of LogRhythm components that work together to bring log management, advanced log analysis, event management, monitoring, and reporting into one integrated solution.\\nLogRhythm SysMon, An add-on product for system monitor functionality.\\nLogRhythm Threat Lifecycle Management Platform, The set of LogRhythm products including LogRhythm SIEM, LogRhythm XM, LogRhythm CloudAI, LogRhythm SysMon, LogRhythm NetMon, and LogRhythm NetMon Freemium. Also called the LogRhythm Platform.\\nLogRhythm Web Console, The LogRhythm Web Console allows you to monitor network log activity from supported browsers on desktop computers and laptops.\\nLogRhythm XM, A LogRhythm Appliance which includes an Platform Manager (PM) and Data Processor (DP). An XM can also include the Data Indexer, SysMon, and AI Engine. It is targeted for small and mid-market.\\nLR Deploy, The LogRhythm all-in-one installation service that contains the individual installers for all LogRhythm components except the database and individual system monitor agents.\\nLua, A lightweight multi-paradigm programming language designed as a scripting language with extensible semantics as a primary goal.\\nLucene Search, An open source text retrieval library released under the Apache Software License.\\nM, \\nMAC Address, A Media Access Control address (MAC address), which is a unique identifier assigned to network interfaces for communications on the physical network segment.\\nManifest File, A working list of user-inputted hosts in a LogRhythm Deployment.\\nMean Time to Detect, The average time it takes to recognize a threat that requires further analysis and response efforts.\\nMean Time to Respond, The average time it takes to respond to and ultimately resolve an incident.\\nMediator Service, A service running on the Log Manager, which is responsible for log identification and classification.\\nMemory Pool, Pre-allocated memory space with a fixed size. Pools allow for dynamic memory allocation and can help improve performance.\\nMessage Processing Engine, As part of the Log Manager\\'s Mediator service, the Message Processing Engine is responsible for log identification and classification, Event processing, and metadata processing.\\nMessage Processing Engine Policy, See Log Processing Policy\\nMessage Processing Engine Rule, A record associated to a specific log message source type with a common event, base rule regular expression, sub rules and other processing and policy settings that is used for processing logs.\\nMessage Processing Engine Rule Builder, A record associated to a specific log message source type with a common event, base rule regular expression, sub rules and other processing and policy settings that is used for processing logs.\\nMetadata, Details of a log message in a simple format within the LogRhythm databases. Metadata is parsed directly from a log message (explicit) of can be inferred from a log message (implicit).\\nMulti-host Deployment, A deployment in which any two or more hosts have LogRhythm software installed and communicating. This includes hosts with a standalone Web Console or AIE Engine.\\nMy LogRhythm, A menu in the console for users to manage preferences and properties specific to their login. This includes general preferences for personal dashboard, investigator and tail, regional settings, and color themes as well as settings for personal alarms, notification policies, person properties and password changes.\\nN, \\nNavigation Bar, The selections at the top of the page that allow you to move between Web Console pages. The currently active page is shown in blue letters.\\nNetMon Engine, The NetMon Packet Processing component that classifies data during Deep Packet Inspection.\\nNetwork Connection Monitor, An Endpoint Monitoring tool that independently monitors when network connections are opened and closed on a Windows or UNIX host where a LogRhythm Agent is running and NCM is configured. It is managed from the System Monitor Agent properties within Deployment Manager.\\nNetwork Time Protocol, A networking protocol for clock synchronization between computer systems over packet-switched, variable-latency data networks.\\nO, \\nOnline Log, A log that is stored within the Data Processor database and available for immediate search.\\nP, \\nPackaged Report, A single report built from a template that has specific log source and filter criteria that is then configured and displayed in a specified report format such as Adobe Acrobat, Crystal Reports, or Microsoft Excel. The packaged report can be run ad-hoc and viewed via the console or stored for later viewing.\\nPacket, A unit of data carried by a packet-switched network.\\nPCAP, A file format used for saving raw flow data.\\nPCAP File, An industry-standard format for containing packet capture data. PCAP data includes the raw packets for a flow. NetMon stores the raw packets from the network tap in PCAP files.\\nPersonal Dashboard, A monitoring analysis tool that is used to view data including alarms, events, statistics and various charts and graphs. It is highly configurable and allows for saving multiple layouts for view by various end users. Users can apply filters against the returned data for further refinement. The data within the tool can be drilled into to provide more detailed information.\\nPlan File, The plan.yml file produced by the Deployment Tool that contains all information needed for each host in a LogRhythm Deployment to be configured correctly.\\nPlatform, See LogRhythm Platform.\\nPlatform Manager, SeeLogRhythm Platform Manager.\\nPlaybook, A way to store and manage standard procedures, including documentation of those procedures.\\nPrivacy Impact Assessment, An analysis tool of an organization’s exposure to privacy risks based on processing of personal data and the policies put in place to protect personal data.\\nProcess Monitor, An Endpoint Monitoring tool that independently monitors when processes start and end on a Windows or UNIX host where a LogRhythm Agent is running and PM is configured on the agent. It is managed from the System Monitor Agent properties within Deployment Manager.\\nProcessed Log, A log after it has been processed through the Message Processing Engine (MPE) of the Mediator Server.\\nPseudonymization, A procedure in which most identifying fields within a data record are replaced by one or more artificial identifiers.\\nQ, \\nQuick Search Toolbar, A toolbar located at the bottom of the console window. It provides a quick and easy means of running ad-hoc investigations when the full search capabilities of Investigator aren’t required.\\nR, \\nRaw Log, A log in its original form as it was received by the LogRhythm System Monitor Agent.\\nRBP Calculator, A calculator application that helps determine the RBP values for MPE and AIE Events by allowing users to experiment with different RBP settings without impacting the LogRhythm deployment.\\nReport Center, An analysis tool in the console that provides users the ability to manage report templates, packaged reports, and report packages.\\nReport Package, A mixture of packaged reports combined into one package that has specific log source criteria. The report package can be run ad-hoc and viewed via the console or stored for later viewing. It can also be scheduled via the Scheduled Report Job Wizard.\\nReport Template, A template that can be used to build a packaged report in a detail or summary form.\\nRight to Access, A data subject’s rights to access or receive information about their personal data that a data controller or processor is utilizing. Also called Subject Access Rights.\\nRight to Erasure, A data subject’s rights to request from data controller and processors to remove of all personal data from private and/or public avenues, including online sources, copies, links, or replications.\\nRight to Object, A data subject’s rights to deny consent of processing, profiling, or automatic decision making based on their personal data by a data controller or processor.\\nRight to Rectify, A data subject’s rights to have inaccurate personal data corrected without undue delay by the data controller or processor.\\nRisk Based Priority, A calculation that results in a number between 1 and 100. It is used to determine how critical an event is based on a number of other rating and probability factors.\\nRule, See Message Processing Engine Rule.\\nRule Base, The collection of all rules developed to identify and normalize log data collected from a single log source type. Rule bases consist of multiple base rules and sub rules.\\nS, \\nScheduled Report Job Manager, A Report tool used to schedule report packages to run for a specified period on a specified date and time. The job can be set to email an existing person and/or export to a UNC path.\\nScored Period, The period of time used to measure user or entity behavior that is then compared to the Behavior Models built during the Baseline Period in CloudAI. The default length of the Scored Period is 24 hours. Data is analyzed in one-hour intervals, and the final hour shown includes data through the end of that hour.\\nSecondLook, A search analysis tool that is used to restore archived logs. The logs are reprocessed through the MPE using current settings. The logs are restored to the Online Archive Data Processor.\\nSession, A bi-directional flow of packets between one client and one server. A \"half session\" defines one direction of that flow, on either the client or server side.\\nSIEM, Security Information and Event Management.\\nSingle-host Deployment, An XM that does not have additional servers for the Web Console or AI Engine.\\nSmart Connect, The ability to connect to a Mediator either within or outside network and have configurable connection paths. Agents need to be able to connect to a Mediator using more than one IP address. If a laptop has an Agent on it, the Agent connects to the Mediator using a particular IP address. That IP address may only be accessible from in the office and on the network. When the laptop moves to a remote location, the Agent will have to connect to the using a different IP address. The secondary IP address can be the external IP address for the Mediator (Agent communications get sent to the secondary IP and get routed internally to the Mediator’s IP.\\nSmartResponse, A form of LogRhythm incident response that can be configured to automatically trigger with specific alarms or be set to trigger after passing through a chain of approvals. It reduces the need to perform common incident and investigation mitigation steps.\\nSNMP Trap Receiver, A tool that supports the collection of SNMP Traps (v1, v2c, or v3) sent from third-party network devices and systems. It collects the traps and translates them into LogRhythm logs. It is managed from the System Monitor Agent properties within Deployment Manager.\\nSOAR, Security Orchestration, Automation, and Response. SOAR automates workflows and accelerates threat qualification, investigation, and response.\\nSQL Server Trace File Converter, A LogRhythm Windows service that converts Microsoft trace files (.trc) into UTF-8 encoded text files for archival and subsequent collection by a LogRhythm System Monitor.\\nSub Rule, Part of the MPE Rule that differentiates log messages that match the same base rule using values in the log. Sub-rule tags can include a regex that only applies to the string in a specific field to identify information such as a log / event identification number, a message string, or even a user or group name.\\nSupervisory Authority, An independent public authority established by Member States within the EU to monitor the application of regulations.\\nSyslog, Syslog is a standard for logging program messages. It allows separation of the software that generates messages from the system that stores them and the software that reports and analyzes them. It also provides devices which would otherwise be unable to communicate a means to notify administrators of problems or performance. NetMon transfers data to the LogRhythm SIEM (or to a third-party system) using the Syslog protocol.\\nT, \\nTail, A monitoring analysis tool that provides real-time monitoring of log and event activity. It is an easy means of monitoring any activity based on device, log classification, or metadata contained in the log.\\nThreat Event, A potentially harmful situation for an information system that can have unwanted consequences. CloudAI classifies observations with a score of 70 or higher as threat events.\\nThreat Intelligence Service, A service that works with the LogRhythm Threat Intelligence Module to collect and analyze data published by subscription-based and open source threat data providers to alert users to threats in their environments.\\nThreat Lifecycle Management, The framework that defines security workflows addressed by LogRhythm products.\\nTransfer of Data, The transfer of personal data between entities or third-countries for strictly valid business purposes and where consent from the data subject has been obtained.\\nTrueHost, A higher-level construct of the actual server, endpoint, and device of a parsed host identifier.\\nTrueIdentity, A representation of a collection of identifiers, such as logins and email addresses, that comprise a single identity.\\nTrueTime, LogRhythm\\'s best possible determination of the actual time a log message was originally written. TrueTime is recorded in Coordinated Universal Time (UTC) down to millisecond resolution.\\nU, \\nUnidentified Log, A log that has been sent through the Message Processing Engine (MPE) that was not identified against any of the MPE Rules.\\nUser Activity Monitoring, An Endpoint Monitoring tool that is used in conjunction with FIM, DLD, Process Monitor and Network Connection Monitor to include the user information related to the log activity. It is man-aged from the System Monitor Agent properties within Deployment Manager.\\nUser Anomaly Score, A number from 1 to 100 that indicates how anomalous a user or entity’s behavior was during the Scored Period when compared to the Baseline Period in CloudAI. The User Anomaly Score is a function of all Behavior Model Anomaly Scores for that user or entity.\\nUser Profile Manager, An administration tool within Deployment Manager used to manage User Profiles. A User Profile is a configuration that defines the security role, Data Processor access and log source access for one or more user accounts.\\nV, No terms available\\nW, \\nWidget, A mini-application, such as a chart or graph, that provides content for dashboards. Widgets can be resized and repositioned in page layouts to modify existing dashboards or create new ones.\\nWindows Host Wizard, A tool that allows users to configure LogRhythm to collect Windows Event Logs. It has the ability to scan domains and allows users to import computers. It is accessed via the administration tools menu within Deployment Manager.\\nX, No terms available\\nY, No terms available\\nZ, No terms available\\n', 'A': '\\nActive Directory (AD) Browsers\\nGrids access from the Knowledge tools menu that display active directory user or group information for the domains that were previously synchronized via the manager.\\nActive Directory (AD) Domain Manager\\nA tool used to setup, manage, and synchronize active directory domains. It is found within the Platform Manager tab of the Deployment Manager. Synchronization can be triggered from the manager or the domains can be left enabled for the Job Manager to pick it up on its schedule synchronization process.\\nAdvanced Intelligence Engine\\nThe LogRhythm component that performs high-level, real-time analysis of log messages forwarded by the Data Processor. The AI Engine can elevate logs using a complex pattern matching rule-set, which correlates and detects sophisticated intrusions, insider threats, operational issues, and audit or compliance issues.\\nAdvanced Intelligence Engine Rule\\nA Knowledge Base object that contains specific configuration to analyze if logs meet specific criteria. The Rule contains settings for Common Events, Event Suppression, Alarm/Notification settings, Expiration, and other rule properties. A rule can have up to 3 rule blocks.\\nAdvanced Intelligence Engine Rule Block\\nA sub component of an AI Engine Rule that defines configuration parameters for logs to meet in order for the log to be considered satisfied by the rule block. A rule can have up to 3 rule blocks. There are 9 distinct variations of rule blocks.\\nAdvanced Intelligence Engine Rule Manager\\nA tool that allows users to manage AI Engine rules and rule blocks. It is accessed via the administration tools menu within Deployment Manager.\\nAgents (LogRhythm SIEM)\\nLogRhythm Agents, also called System Monitors, collect and forward log data to Data Processors. Agents can be installed on both Windows and UNIX platforms. They are also integrated into Site Log Forwarder (SLF) appliances and can perform file integrity monitoring.\\nAgents (NetMon)\\nA software component that receives data from the appliance and then sends it to LogRhythm SIEM for further processing.\\nAlarm\\nA record indicating that an alarm rule has been triggered by an event.\\nAlarm Aggregation\\nA setting to restrict similar events from incurring alarms unless a specified number of them occur within a specified time span. The user can define what makes them similar by indicating which fields must have matching values.\\nAlarm Card\\nAn Alarm record that shows Alarm details.\\nAlarm Notifications\\nA notification of an alarm via a notification policy: SMTP (email), SNMP, or Text Files. The person, role, or group to notify is set on the Alarm Rule Properties Notify tab. The Alarm Notification Policies are set via the Notification Policy Manager which is a distribution tool option within Deployment Manager.\\nAlarm Suppression\\nA setting to suppress identical alarms based on the events triggering the alarm within a given time span.\\nAlarming and Response Manager (ARM)\\nAlarming and Response Manager. A Windows service installed in the Event Manager, which is responsible for processing Alarm rules and taking the appropriate response.\\nAlert\\nAn event requiring immediate notification and response. Can be a single event or a combination of events (correlated events).\\nAnomaly\\nUser or entity behavior that deviates from an established behavioral baseline for that user or entity and could indicate a security risk to your network.\\nAppliance\\nSee LogRhythm Appliance\\nApplication (LogRhythm SIEM)\\nA record that defines an application and its ports and protocols so that the MPE rules can identify a log origin. Applications are managed via the Application Manager accessed from the Knowledge Tools menu within Deployment Manager.\\nApplication (NetMon)\\nNetwork protocols or web applications that NetMon identified using pattern matching and heuristic modeling, as well as signatures.\\nArchive Log\\nA log that has been archived and therefore no longer available online via the Data Processor database.\\nAutomated Decision Making\\nThe predictive processing or strategic analysis of personal data to anticipate subject behavior (profiling).\\nAutomatic Log Source Configuration\\nA function that identifies devices on the network using SNMP (v1, v2c, and v3). It identifies virtual sources for Syslog, Netflow, sFlow, and SNMP Trap. It is configured from the Data Processor Properties within Deployment Manager.\\nAutomatic Remediation\\nA feature that provides the ability to perform remediation actions (such as killing a process) based on information received from an alarm and its first event. Remediation actions can be performed automatically or require approval at the Alarm record. It uses a plug-in architecture that executes scripts on a windows system in a scripting language such as power shell.\\n', 'B': '\\nBase Rule\\nPart of the MPE Rule that contains a tagged regular expression\\n—\\nthe regex—used to identify the pattern of a log and isolate interesting pieces of metadata. Using a tagging system, these metadata strings can be directed to special fields used by LogRhythm to better interpret a log or specifically identify it. In general, base-rules identify log messages by matching the fields to a specific log format or pattern.\\nBaseline Period\\nThe period of time used to measure user or entity behavior in order to build Behavior Models in CloudAI. The maximum length of the Baseline Period is 29 days, but shorter lengths are used in cases of limited data.\\nBehavior Feature\\nOne of many network or host activities exhibited by a user or entity. In CloudAI, Behavior Models are built from Behavior Features observed during the Baseline Period and are used to score Behavior Features observed during the Scored Period.\\nBehavior Model\\nIn CloudAI, a model of expected user or entity behavior derived from the combined activity across a specific subset of Behavior Features.\\nBehavior Model Anomaly Score\\nA number from 1 to 100, used by CloudAI, that indicates how anomalous a user or entity’s behavior was during the Scored Period when compared to the Baseline Period within a given Behavior Model.\\nBinding Corporate Rules\\nPersonal data protection policies to be adhered to by Data Controllers or Processors that are established by the Member State around the transfer of personal data.\\nBreach Notification\\nThe specific requirements of a breach without undue delay, but no later than 72 hours after becoming aware of the breach to Supervisory Authority. Communication of the breach to the Data Subject is required if anticipated impacts may result in high-risk to rights and freedoms of the natural person. This should also include required breach information and appropriate remediation actions to be taken.\\n', 'C': \"\\nCase Card\\nAn interface component, visible on the Cases page and Cases panel, that displays basic details about a case. It contains the controls for opening and closing cases and managing their incident statuses.\\nCase Management\\nA forensic tool for tracking and documenting suspicious logs and alarms that are believed to be related to the same threat.\\nClassification\\nA second tier group used to categorize logs and events. There is one or more Classification associated to a Classification Type. A Classification can have one or more Common Events, which are associated to an MPE Rule.\\nClassification Type\\nA first tier group used to categorize logs and events. There are three types: Audit, Security, and Operations. Classifications are grouped into one of these three types. There is one classification type for one or more classifications.\\nClient\\nInitiator of a session, such as a workstation or laptop.\\nCommon Criteria\\nAn international standard (ISO/IEC 15408) for computer security certification.\\nCommon Event\\nA short, plain-language description of the log that is associated to a specific classification. There is one Classification for one or more Common Events. A Common Event is created and managed through the Knowledge Tools Common Platform Manager. Common Events are associated with MPE rules (base and sub) located within the Knowledge Tools MPE Rule Builder. There is a one to one relationship between a MPE rule and a Common Event.\\nCommon Event Migration Manager\\nAn administration tool within Deployment Manager used to manage the changes to existing custom common event filters (such as report and investigation filters) within the users deployment which reference common events that have changed in the master LogRhythm Knowledge Base.\\nComponents\\nSee LogRhythm Components.\\nContextualization\\nAn action one can perform on a log to gather more information about specific fields within the log including host, port, and user.\\nCoordinated Universal Time\\nThe primary time standard by which the world regulates clocks and time. Time zones around the world are expressed as positive or negative offsets from UTC. The hours, minutes, and seconds that UTC expresses is kept close to the mean solar time at the Earth's prime meridian (zero degrees longitude) located near Greenwich, England.\\nCore LogRhythm Software\\nSoftware installed by LR Deploy. This includes: Mediator, AIE, Platform Manager, Data Processor, Data Indexer, Web Console, and others. This does not include collection agents.\\nCorrelation\\nAn action one can perform on a log to perform an additional search based on field values within the log. For example, a user can select a log and choose to correlate on the value within the Common Event field or the values within all fields in the log. Correlation works with the Quick Search Toolbar.\\n\", 'D': '\\nDashboard\\nA layout that contains graphs and charts in easy-to-read formats, which allows you to view high-level Events and also drill down on the data for further investigation.\\nData Controller\\nAn organization the defines the scope, purpose, and methods of processing personal data.\\nData Loss Defender\\nAn Endpoint Monitoring tool that independently monitors and logs the connection and dis-connection of external data devices to the host computer where the Agent is running. It is managed from the System Monitor Agent properties within Deployment Manager.\\nData Processor\\nLogRhythm Data Processor (DP) are Windows Server systems running SQL Server and a single server process, the LogRhythm Mediator Server. There can be one, or many, DPs in a deployment. In medium to large deployments, Data Processors should be dedicated systems. However, in small deployments, a Data Processor can coexist on the same system as the Platform Manager. The Mediator Server takes in log messages, processes them against rules which identify the log message and determine if it will be forwarded to the EM as an Event.\\nData Protection Authority\\nThe national authorities tasked with the protection of data and privacy through monitoring and enforcement of regulations established within the EU.\\nData Protection Impact Assessment\\nA risk-based assessment methodology to determine an organization’s systems and business processing that may be exposed to risk in the absence of mitigating controls.\\nData Protection Office\\nA new position created for an individual appointed within the organization to independently ensure adherence to policies and procedures set forth by General Data Protection Regulation in the European Union.\\nData Subject\\nA natural person whose data is being processed by a data controller or processor.\\nDeduplication\\nA process that recognizes and consolidates duplicate event data from log sources into a single, aggregate record. All raw log data is captured and archived for accuracy and compliance, while the deduplication process eliminates redundant online data and optimizes forensic search capabilities and storage utilization. Deduplication is a Log Processing Setting that can be set at the log source or log processing policy and can be overridden using a Global Log Processing Rule (GLPR).\\nDeep Packet Analytics\\nAllows users to write rules that will interact with network traffic as it is being processed.\\nDeep Packet Analytics Rules\\nCustom rules that enable users to determine flow state, access and set metadata, trigger alarms, enable capture, write log messages.\\nDeep Packet Inspection\\nA process whereby NetMon analyzes network data using a variety of methods, including pattern matching, heuristic modeling, signatures for session identification, application identification, and metadata extraction.\\nDeployment Manager\\nA utility window in the LogRhythm Console. People with LogRhythm administrator credentials use it to configure and manage LogRhythm components and functionality such as alarming and reporting.\\nDeployment Monitor\\nA window in the console that provides administrators with a near-real-time view of the per-formance of LogRhythm including host status, host performance metrics, database utilization, Data Processor metrics, and Data Processor volume.\\nDeployment Tool\\nThe LogRhythm software installation tool to which the user adds each host IP in a deployment.\\n', 'E': '\\nEntity\\nA record that represents a logical grouping of LogRhythm SIEM components. It organizes the deployment in host records, network records, and the LogRhythm components. Small deployments may contain one Entity record, while large deployments that span many sites require multiple Entity records.\\nEntity Host\\nA record that represents a computer on a network. It is contained within an Entity. As part of log processing, hosts are identified as impacted or origin and may be represented as a Known Host if it exists as an Entity Host record. Entity Hosts are displayed in the Entities tab within Deployment Manager.\\nEntity Network\\nA record that represents a range of IP addresses that can have a host zone, host location, threat level and network risk level associated. It is contained within an Entity. Entity Networks are dis-played in the Entities tab within Deployment Manager.\\nEvent\\nA Syslog message to LogRhythm SIEM that has more immediate operational, security, or compliance relevance. Typically logs classified as errors, failures, or attacks are considered events.\\nEvent False Alarm Rating\\nA rate set at the Rule level via the MPE Rule and the MPE Policy Rule Editor. It is used in the RBP calculation.\\nEvent Risk Rating\\nA rate set at the Rule level via the MPE Policy Rule Editor. It is used in the RBP calculation.\\n', 'F': '\\nFile Integrity Monitoring\\nAn Endpoint Monitoring tool that monitors files and directories for modifications. There are two modes: Standard and Realtime.\\nFlow\\nA collection of activity by a single user on a single application. The flow contains source and destination information, bytes and packet counts transferred in both directions, application identification, and many other metadata fields. Long-running flows send updates every 10 minutes by default, but you can change that value. Each flow has a unique identifier that links multiple intermediate flows together.\\n', 'G': '\\nGlobal Data Management Settings\\nThe global settings for the deployment including configuration options for event forwarding, log processing, log deduplication, and LogMart settings; maintenance settings for compression, indexing, partition, backup paths, and Time to Live (TTL) values; as well as Classification Based Data Management (CBDM) settings and Global Classification Settings (GCS). It is found within the Platform Manager tab of the Deployment Manager.\\nGlobal Log Processing Rule\\nA Knowledge Base object used to provide a way to override settings defined in the Classification Based Data Management (CBDM) or standard Data Management settings (log message source and log processing policy). It provides a way to apply data management settings across all Data Processors, Log Sources, and Log Processing Policies to logs that meet specific criteria. The manager is accessed via the administration tools menu within Deployment Manager.\\n', 'H': '\\nHalf Session\\nA session is a bi-directional flow of packets between one client and one server. A \"half session\" defines one direction of that flow, on either the sender or receiver side.\\nHost\\nA single machine that has Core LogRhythm Software installed on it.\\n', 'I': '\\nIcon\\nA small graphic on the page, which you can select to open a dialog box or window.\\nIdentifier\\nAn account name, a badge number, an ID, or any other piece of data that belongs uniquely to one user.\\nIdentity\\nA unified user. It contains a display name, email address, photo, job title, and any other identifier that belongs to that user.\\nPart of the Mediator/Message Processing Engine that prevents logs, events, and LogMart data that do not conform to the TTL values set in Global Maintenance Settings from being added to the online databases.\\nIntermediate Flow\\nAn update of the communications between the client and server.\\nInvestigator\\nA search analysis tool that is used to query the Platform Manager, Data Processor, or LogMart databases for a given date range and with specified criteria for log source and field filters, among other settings. The results are displayed in a layout that can be configured and saved and includes various grids, charts, and graphs, including Network Visualization. The data results can be drilled into to provide more detailed information.\\nIPv6\\nThe LogRhythm 6.0 services will support running on pure IPv6 networks as well as dual-stack (IPv4 and IPv6) networks. The LogRhythm services (Mediator, ARM, Job Manager, Agents, SQL Server) can be configured to use IPv6 address when communicating with each other.\\n', 'J': 'No terms available\\n', 'K': '\\nKnowledge Base\\nA LogRhythm Package that consists of a mixture of content both required and optional that is shared across a LogRhythm Deployment. It consists of the core Knowledge Base as well as modules. The core Knowledge Base includes content applicable to all deployments, such as log processing rules and policies, classifications, and common. The Knowledge Base is imported using the Knowledge Base Import Wizard accessed from the Knowledge tools menu within the console.\\nKnowledge Base Module\\nPre-packaged, customizable content applicable to a specific regulation or need, such as reports, investigations, alerts, or AI Engine rules, to name a few. An example is a compliance module for PCI which would include reports, investigations, and AI Engine rules that provide data relevant in meeting PCI requirements. Modules are managed using the Knowledge Base Manager accessed from the Knowledge tools menu within the Console. Modules are imported with a Knowledge Base depending on their settings.\\nKnowledge Base Object\\nDefined LogRhythm items such as Alarm Rules, AI Engine Rules, Lists, Report Packages, Packaged Reports, Report Templates, FIM Policies, Investigations, Tails, and GLPRs that can be associated with a KB Module.\\n', 'L': '\\nLicense Limited\\nIn the NetMon Data Rate chart, indicates the rate in megabits per second at which packets are being throttled/discarded according to your licensed capture rate.\\nList Manager\\nA tool that is used to manage lists. A list is a record of data for a given type to allow for grouping similar values together in one location that can then be used with all LogRhythm tools that allow filtering. For example, a list may include all PCI compliance related log sources or suspicious hosts or privileged users. These lists can then be used in filters within Investigator, Personal Dashboard, and Reports (to name a few) while allowing it to be created/modified from one location.\\nLocal Host\\nStandard hostname given to the address of the loopback network interface. Localhost is spe-cified where one would otherwise use the hostname of a computer.\\nLog\\nIndividual log data collected by LogRhythm.\\nLog Distribution Services\\nA policy based solution that allows users to forward specific syslog and non-syslog log messages to an external syslog receiver over TCP or UDP. It consists of a Receiver Manager and a Policy Manager both access via the distribution tools menu within Deployment Manager.\\nLog Manager\\nThe central processing engine for logs sent from the Agents. The Log Manager contains the Mediator service, which is responsible for log identification and classification. A Log Manager can be installed on the Event Manager appliance or it can be a separate appliance in the SIEM deployment. Large environments may need more than one Log Manager in the deployment.\\nLog Message\\nA raw log displayed in the Web Console\\'s Analyzer grid. Also called a raw log.\\nLog Message Source\\nA record that represents a single source of log data that is collected from a host. It is associated with a log source host, collection agent, and log message source type. It has specific data management and log processing settings and can have a MPE policy applied. An example source is Host 123 Microsoft Application Log.\\nLog Message Source Type\\nA record that represents a common data format for logs. It has a specific log format such as syslog, netflow, text file, windows event log, UDLA, Checkpoint firewall, Cisco SDEE, SNMP Trap, QualysGaurd, Nessus, or sFlow. They have MPE Rules written for them so that logs run against them will be optimally parsed. An example type is Microsoft Windows Event Log Application. They are managed via the Knowledge Tools Log Message Source Type Manager.\\nA summary overview and trending tool that is opened after you perform a LogMart Search with Investigator.\\nLog Processing Policy\\nA collection of MPE Rules designed for a specific Log Source Type such as Cisco PIX or Windows 2005 Security Event Log. Only Logs that are generated from Log Sources that have an assigned MPE Policy are processed by the MPE. There can be multiple policies for a single log source type to allow for flexibility in assigning the policy to various log sources.\\nLog Rotate\\nThe Agent can follow log rotations while collecting from files but cannot finish reading a log file that is compressed. The result of reading a compressed file are unpredictable. Disable compression of the log sources that Agent is monitoring. Most Linux systems use the logrotate utility and its corresponding config file logrotate.conf to control this compression.\\nLog Source\\nSee Log Message Source.\\nLog Source Type\\nSee Log Message Source Type.\\nLogger\\nThe NetMon Flow Output component that processes the metadata into \"flows.\"\\nLogLevel\\nDetermines the amount of information logged to scarm.log. The number of logs you see depends on the LogLevel that is set in the Agent Advanced Properties. The log files that can be reviewed for success, error, and general log messages.\\nLogListener\\nNetwork Connection Monitor logging option to generate logs for listening TCP/UDP sockets when NetworkConnectionMonitor is enabled.\\nLogRhythm Appliance\\nA LogRhythm Appliance is a turn-key LogRhythm Server on custom hardware, designed and offered by LogRhythm. LogRhythm Appliances are available in PM, DP, XM (PM + DP), and SLF (Agent-only log collection machine) configurations. They are also offered in a number of sizes to meet varying collection-volume needs.\\nLogRhythm Client Console\\nThe LogRhythm Client Console provides deployment administration and user interaction with LogRhythm with a Graphical User Interface (GUI).\\nLogRhythm CloudAI\\nA LogRhythm User and Entity Behavior Analytics (UEBA) service that provides visibility into insider threats, compromised accounts, and privilege abuse.\\nLogRhythm Common Components\\nLogRhythm Services that form the core of the deployment and need to be running on each host. These are the LogRhythm API Gateway, the LogRhythm Service Registry, and the LogRhythm Windows Authentication Service.\\nLogRhythm Components\\nThe software and associated databases required to run the LogRhythm Solution. This includes the Platform Manager (PM), Data Processor (DP), Advanced Intelligence (AI) Engine, LogRhythm SysMon Agents, and the Client and Web Consoles.\\nLogRhythm Deployment\\nThe collection of all hosts on a network.\\nLogRhythm SIEM\\nThe core LogRhythm Solution set, including Data Collection, Processing (MDI), Persistence, and AI Engine but not including LogRhythm NetMon or LogRhythm SysMon.\\nLogRhythm Metadata\\nIncludes the fields that LogRhythm parses, derives, and calculates from collected log data. For the full list of fields and their descriptions, see the LogRhythm Schema Dictionary and Guide, available under Documentation & Downloads on the LogRhythm Community.\\nLogRhythm NetMon\\nAn add-on product for network monitor functionality.\\nLogRhythm NetMon Freemium\\nThe free version of LogRhythm NetMon with reduced functionality.\\nLogRhythm Platform\\nThe set of LogRhythm products including LogRhythm SIEM, LogRhythm XM, LogRhythm CloudAI, LogRhythm SysMon, LogRhythm NetMon, and LogRhythm NetMon Freemium. Also called the LogRhythm Threat Lifecycle Management Platform.\\nLogRhythm Platform Manager\\nThe LogRhythm Platform Manager (PM) server is a Windows Server system running SQL Server and the LogRhythm Alarming and Response Manager (ARM) service. There is only one PM per deployment. The PM is sent logs that are determined to be important or interesting, called Events, which it maintains. The PM also contains the deployment\\'s configuration data. The ARM is a windows service responsible for processing alarm rules and taking the appropriate response, such as sending e-mails to people on a notification list.\\nLogRhythm Server\\nA LogRhythm Server is a Windows Server running as an EM, DP, or both. Customers typically build a Server when they have purchased a software-only solution from LogRhythm.\\nLogRhythm Solution\\nA fully integrated Security Information and Event Management (SIEM) solution providing log management, advanced log analysis, event management, network and user monitoring, and reporting. The LogRhythm Solution is the collection of LogRhythm components that work together to bring log management, advanced log analysis, event management, monitoring, and reporting into one integrated solution.\\nLogRhythm SysMon\\nAn add-on product for system monitor functionality.\\nLogRhythm Threat Lifecycle Management Platform\\nThe set of LogRhythm products including LogRhythm SIEM, LogRhythm XM, LogRhythm CloudAI, LogRhythm SysMon, LogRhythm NetMon, and LogRhythm NetMon Freemium. Also called the LogRhythm Platform.\\nLogRhythm XM\\nA LogRhythm Appliance which includes an Platform Manager (PM) and Data Processor (DP). An XM can also include the Data Indexer, SysMon, and AI Engine. It is targeted for small and mid-market.\\nLua\\nA lightweight multi-paradigm programming language designed as a scripting language with extensible semantics as a primary goal.\\nLucene Search\\nAn open source text retrieval library released under the Apache Software License.\\n', 'M': \"\\nMAC Address\\nA Media Access Control address (MAC address), which is a unique identifier assigned to network interfaces for communications on the physical network segment.\\nManifest File\\nA working list of user-inputted hosts in a LogRhythm Deployment.\\nMean Time to Detect\\nThe average time it takes to recognize a threat that requires further analysis and response efforts.\\nMean Time to Respond\\nThe average time it takes to respond to and ultimately resolve an incident.\\nMediator Service\\nA service running on the Log Manager, which is responsible for log identification and classification.\\nMemory Pool\\nPre-allocated memory space with a fixed size. Pools allow for dynamic memory allocation and can help improve performance.\\nMessage Processing Engine\\nAs part of the Log Manager's Mediator service, the Message Processing Engine is responsible for log identification and classification, Event processing, and metadata processing.\\nMessage Processing Engine Policy\\nSee Log Processing Policy\\nMessage Processing Engine Rule\\nA record associated to a specific log message source type with a common event, base rule regular expression, sub rules and other processing and policy settings that is used for processing logs.\\nMessage Processing Engine Rule Builder\\nA record associated to a specific log message source type with a common event, base rule regular expression, sub rules and other processing and policy settings that is used for processing logs.\\nMetadata\\nDetails of a log message in a simple format within the LogRhythm databases. Metadata is parsed directly from a log message (explicit) of can be inferred from a log message (implicit).\\nMulti-host Deployment\\nA deployment in which any two or more hosts have LogRhythm software installed and communicating. This includes hosts with a standalone Web Console or AIE Engine.\\nMy LogRhythm\\nA menu in the console for users to manage preferences and properties specific to their login. This includes general preferences for personal dashboard, investigator and tail, regional settings, and color themes as well as settings for personal alarms, notification policies, person properties and password changes.\\n\", 'N': '\\nNavigation Bar\\nThe selections at the top of the page that allow you to move between Web Console pages. The currently active page is shown in blue letters.\\nNetMon Engine\\nThe NetMon Packet Processing component that classifies data during Deep Packet Inspection.\\nNetwork Connection Monitor\\nAn Endpoint Monitoring tool that independently monitors when network connections are opened and closed on a Windows or UNIX host where a LogRhythm Agent is running and NCM is configured. It is managed from the System Monitor Agent properties within Deployment Manager.\\nNetwork Time Protocol\\nA networking protocol for clock synchronization between computer systems over packet-switched, variable-latency data networks.\\n', 'O': '\\nOnline Log\\nA log that is stored within the Data Processor database and available for immediate search.\\n', 'P': '\\nPackaged Report\\nA single report built from a template that has specific log source and filter criteria that is then configured and displayed in a specified report format such as Adobe Acrobat, Crystal Reports, or Microsoft Excel. The packaged report can be run ad-hoc and viewed via the console or stored for later viewing.\\nPacket\\nA unit of data carried by a packet-switched network.\\nPCAP\\nA file format used for saving raw flow data.\\nPCAP File\\nAn industry-standard format for containing packet capture data. PCAP data includes the raw packets for a flow. NetMon stores the raw packets from the network tap in PCAP files.\\nPersonal Dashboard\\nA monitoring analysis tool that is used to view data including alarms, events, statistics and various charts and graphs. It is highly configurable and allows for saving multiple layouts for view by various end users. Users can apply filters against the returned data for further refinement. The data within the tool can be drilled into to provide more detailed information.\\nPlan File\\nThe plan.yml file produced by the Deployment Tool that contains all information needed for each host in a LogRhythm Deployment to be configured correctly.\\nPlatform\\nSee LogRhythm Platform.\\nPlatform Manager\\nSee\\nLogRhythm Platform Manager.\\nPrivacy Impact Assessment\\nAn analysis tool of an organization’s exposure to privacy risks based on processing of personal data and the policies put in place to protect personal data.\\nProcess Monitor\\nAn Endpoint Monitoring tool that independently monitors when processes start and end on a Windows or UNIX host where a LogRhythm Agent is running and PM is configured on the agent. It is managed from the System Monitor Agent properties within Deployment Manager.\\nProcessed Log\\nA log after it has been processed through the Message Processing Engine (MPE) of the Mediator Server.\\nPseudonymization\\nA procedure in which most identifying fields within a data record are replaced by one or more artificial identifiers.\\n', 'Q': '\\nQuick Search Toolbar\\nA toolbar located at the bottom of the console window. It provides a quick and easy means of running ad-hoc investigations when the full search capabilities of Investigator aren’t required.\\n', 'R': '\\nRaw Log\\nA log in its original form as it was received by the LogRhythm System Monitor Agent.\\nReport Center\\nAn analysis tool in the console that provides users the ability to manage report templates, packaged reports, and report packages.\\nReport Package\\nA mixture of packaged reports combined into one package that has specific log source criteria. The report package can be run ad-hoc and viewed via the console or stored for later viewing. It can also be scheduled via the Scheduled Report Job Wizard.\\nReport Template\\nA template that can be used to build a packaged report in a detail or summary form.\\nRight to Access\\nA data subject’s rights to access or receive information about their personal data that a data controller or processor is utilizing. Also called Subject Access Rights.\\nRight to Erasure\\nA data subject’s rights to request from data controller and processors to remove of all personal data from private and/or public avenues, including online sources, copies, links, or replications.\\nRight to Object\\nA data subject’s rights to deny consent of processing, profiling, or automatic decision making based on their personal data by a data controller or processor.\\nRight to Rectify\\nA data subject’s rights to have inaccurate personal data corrected without undue delay by the data controller or processor.\\nRisk Based Priority\\nA calculation that results in a number between 1 and 100. It is used to determine how critical an event is based on a number of other rating and probability factors.\\nRule\\nSee Message Processing Engine Rule.\\nRule Base\\nThe collection of all rules developed to identify and normalize log data collected from a single log source type. Rule bases consist of multiple base rules and sub rules.\\n', 'S': '\\nScheduled Report Job Manager\\nA Report tool used to schedule report packages to run for a specified period on a specified date and time. The job can be set to email an existing person and/or export to a UNC path.\\nScored Period\\nThe period of time used to measure user or entity behavior that is then compared to the Behavior Models built during the Baseline Period in CloudAI. The default length of the Scored Period is 24 hours. Data is analyzed in one-hour intervals, and the final hour shown includes data through the end of that hour.\\nSecondLook\\nA search analysis tool that is used to restore archived logs. The logs are reprocessed through the MPE using current settings. The logs are restored to the Online Archive Data Processor.\\nSession\\nA bi-directional flow of packets between one client and one server. A \"half session\" defines one direction of that flow, on either the client or server side.\\nSIEM\\nSecurity Information and Event Management.\\nSingle-host Deployment\\nAn XM that does not have additional servers for the Web Console or AI Engine.\\nSmart Connect\\nThe ability to connect to a Mediator either within or outside network and have configurable connection paths. Agents need to be able to connect to a Mediator using more than one IP address. If a laptop has an Agent on it, the Agent connects to the Mediator using a particular IP address. That IP address may only be accessible from in the office and on the network. When the laptop moves to a remote location, the Agent will have to connect to the using a different IP address. The secondary IP address can be the external IP address for the Mediator (Agent communications get sent to the secondary IP and get routed internally to the Mediator’s IP.\\nSmartResponse\\nA form of LogRhythm incident response that can be configured to automatically trigger with specific alarms or be set to trigger after passing through a chain of approvals. It reduces the need to perform common incident and investigation mitigation steps.\\nSNMP Trap Receiver\\nA tool that supports the collection of SNMP Traps (v1, v2c, or v3) sent from third-party network devices and systems. It collects the traps and translates them into LogRhythm logs. It is managed from the System Monitor Agent properties within Deployment Manager.\\nSub Rule\\nPart of the MPE Rule that differentiates log messages that match the same base rule using values in the log. Sub-rule tags can include a regex that only applies to the string in a specific field to identify information such as a log / event identification number, a message string, or even a user or group name.\\nSupervisory Authority\\nAn independent public authority established by Member States within the EU to monitor the application of regulations.\\nSyslog\\nSyslog is a standard for logging program messages. It allows separation of the software that generates messages from the system that stores them and the software that reports and analyzes them. It also provides devices which would otherwise be unable to communicate a means to notify administrators of problems or performance. NetMon transfers data to the LogRhythm SIEM (or to a third-party system) using the Syslog protocol.\\n', 'T': '\\nTail\\nA monitoring analysis tool that provides real-time monitoring of log and event activity. It is an easy means of monitoring any activity based on device, log classification, or metadata contained in the log.\\nThreat Event\\nA potentially harmful situation for an information system that can have unwanted consequences. CloudAI classifies observations with a score of 70 or higher as threat events.\\nThreat Lifecycle Management\\nThe framework that defines security workflows addressed by LogRhythm products.\\nTransfer of Data\\nThe transfer of personal data between entities or third-countries for strictly valid business purposes and where consent from the data subject has been obtained.\\n', 'U': '\\nUnidentified Log\\nA log that has been sent through the Message Processing Engine (MPE) that was not identified against any of the MPE Rules.\\nUser Activity Monitoring\\nAn Endpoint Monitoring tool that is used in conjunction with FIM, DLD, Process Monitor and Network Connection Monitor to include the user information related to the log activity. It is man-aged from the System Monitor Agent properties within Deployment Manager.\\nUser Anomaly Score\\nA number from 1 to 100 that indicates how anomalous a user or entity’s behavior was during the Scored Period when compared to the Baseline Period in CloudAI. The User Anomaly Score is a function of all Behavior Model Anomaly Scores for that user or entity.\\nUser Profile Manager\\nAn administration tool within Deployment Manager used to manage User Profiles. A User Profile is a configuration that defines the security role, Data Processor access and log source access for one or more user accounts.\\n', 'V': 'No terms available\\n', 'W': '\\nWidget\\nA mini-application, such as a chart or graph, that provides content for dashboards. Widgets can be resized and repositioned in page layouts to modify existing dashboards or create new ones.\\nWindows Host Wizard\\nA tool that allows users to configure LogRhythm to collect Windows Event Logs. It has the ability to scan domains and allows users to import computers. It is accessed via the administration tools menu within Deployment Manager.\\n', 'X': 'No terms available\\n', 'Y': 'No terms available\\n', 'Z': 'No terms available\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nFind More Information\\n', 'Open Source License Acknowledgements': '\\n\\nUsed by:\\xa0dbus\\nThis Academic Free License (the \"License\") applies to any original work of authorship (the \"Original Work\") whose owner (the \"Licensor\") has placed the following licensing notice adjacent to the copyright notice for the Original Work:\\nLicensed under the Academic Free License version 3.0\\nGrant of Copyright License. Licensor grants You a worldwide, royalty-free, non-exclusive, sublicensable license, for the duration of the copyright, to do the following:\\nto reproduce the Original Work in copies, either alone or as part of a collective work;\\nto translate, adapt, alter, transform, modify, or arrange the Original Work, thereby creating derivative works (\"Derivative Works\") based upon the Original Work;\\nto distribute or communicate copies of the Original Work and Derivative Works to the public, under any license of your choice that does not contradict the terms and conditions, including Licensor\\'s reserved rights and remedies, in this Academic Free License;\\nto perform the Original Work publicly; and\\nto display the Original Work publicly.\\nto reproduce the Original Work in copies, either alone or as part of a collective work;\\nto translate, adapt, alter, transform, modify, or arrange the Original Work, thereby creating derivative works (\"Derivative Works\") based upon the Original Work;\\nto distribute or communicate copies of the Original Work and Derivative Works to the public, under any license of your choice that does not contradict the terms and conditions, including Licensor\\'s reserved rights and remedies, in this Academic Free License;\\nto perform the Original Work publicly; and\\nto display the Original Work publicly.\\nGrant of Patent License. Licensor grants You a worldwide, royalty-free, non-exclusive, sublicensable license, under patent claims owned or controlled by the Licensor that are embodied in the Original Work as furnished by the Licensor, for the duration of the patents, to make, use, sell, offer for sale, have made, and import the Original Work and Derivative Works.\\nGrant of Source Code License. The term \"Source Code\" means the preferred form of the Original Work for making modifications to it and all available documentation describing how to modify the Original Work. Licensor agrees to provide a machine-readable copy of the Source Code of the Original Work along with each copy of the Original Work that Licensor distributes. Licensor reserves the right to satisfy this obligation by placing a machine-readable copy of the Source Code in an information repository reasonably calculated to permit inexpensive and convenient access by You for as long as Licensor continues to distribute the Original Work.\\nExclusions From License Grant. Neither the names of Licensor, nor the names of any contributors to the Original Work, nor any of their trademarks or service marks, may be used to endorse or promote products derived from this Original Work without express prior permission of the Licensor. Except as expressly stated herein, nothing in this License grants any license to Licensor\\'s trademarks, copyrights, patents, trade secrets or any other intellectual property. No patent license is granted to make, use, sell, offer for sale, have made, or import embodiments of any patent claims other than the licensed claims defined in Section 2. No license is granted to the trademarks of Licensor even if such marks are included in the Original Work. Nothing in this License shall be interpreted to prohibit Licensor from licensing under terms different from this License any Original Work that Licensor otherwise would have a right to license.\\nExternal Deployment. The term \"External Deployment\" means the use, distribution, or communication of the Original Work or Derivative Works in any way such that the Original Work or Derivative Works may be used by anyone other than You, whether those works are distributed or communicated to those persons or made available as an application intended for use over a network. As an express condition for the grants of license hereunder, You must treat any External Deployment by You of the Original Work or a Derivative Work as a distribution under section 1(c).\\nAttribution Rights. You must retain, in the Source Code of any Derivative Works that You create, all copyright, patent, or trademark notices from the Source Code of the Original Work, as well as any notices of licensing and any descriptive text identified therein as an \"Attribution Notice.\" You must cause the Source Code for any Derivative Works that You create to carry a prominent Attribution Notice reasonably calculated to inform recipients that You have modified the Original Work.\\nWarranty of Provenance and Disclaimer of Warranty. Licensor warrants that the copyright in and to the Original Work and the patent rights granted herein by Licensor are owned by the Licensor or are sublicensed to You under the terms of this License with the permission of the contributor(s) of those copyrights and patent rights. Except as expressly stated in the immediately preceding sentence, the Original Work is provided under this License on an \"AS IS\" BASIS and WITHOUT WARRANTY, either express or implied, including, without limitation, the warranties of non-infringement, merchantability or fitness for a particular purpose. THE ENTIRE RISK AS TO THE QUALITY OF THE ORIGINAL WORK IS WITH YOU. This DISCLAIMER OF WARRANTY constitutes an essential part of this License. No license to the Original Work is granted by this License except under this disclaimer.\\nLimitation of Liability. Under no circumstances and under no legal theory, whether in tort (including negligence), contract, or otherwise, shall the Licensor be liable to anyone for any indirect, special, incidental, or consequential damages of any character arising as a result of this License or the use of the Original Work including, without limitation, damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses. This limitation of liability shall not apply to the extent applicable law prohibits such limitation.\\nAcceptance and Termination. If, at any time, You expressly assented to this License, that assent indicates your clear and irrevocable acceptance of this License and all of its terms and conditions. If You distribute or communicate copies of the Original Work or a Derivative Work, You must make a reasonable effort under the circumstances to obtain the express assent of recipients to the terms of this License. This License conditions your rights to undertake the activities listed in Section 1, including your right to create Derivative Works based upon the Original Work, and doing so without honoring these terms and conditions is prohibited by copyright law and international treaty. Nothing in this License is intended to affect copyright exceptions and limitations (including \"fair use\" or \"fair dealing\"). This License shall terminate immediately and You may no longer exercise any of the rights granted to You by this License upon your failure to honor the conditions in Section 1(c).\\nTermination for Patent Action. This License shall terminate automatically and You may no longer exercise any of the rights granted to You by this License as of the date You commence an action, including a cross-claim or counterclaim, against Licensor or any licensee alleging that the Original Work infringes a patent. This termination provision shall not apply for an action alleging patent infringement by combinations of the Original Work with other software or hardware.\\nJurisdiction, Venue and Governing Law. Any action or suit relating to this License may be brought only in the courts of a jurisdiction wherein the Licensor resides or in which Licensor conducts its primary business, and under the laws of that jurisdiction excluding its conflict-of-law provisions. The application of the United Nations Convention on Contracts for the International Sale of Goods is expressly excluded. Any use of the Original Work outside the scope of this License or after its termination shall be subject to the requirements and penalties of copyright or patent law in the appropriate jurisdiction. This section shall survive the termination of this License.\\nAttorneys\\' Fees. In any action to enforce the terms of this License or seeking damages relating thereto, the prevailing party shall be entitled to recover its costs and expenses, including, without limitation, reasonable attorneys\\' fees and costs incurred in connection with such action, including any appeal of such action. This section shall survive the termination of this License.\\nMiscellaneous. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable.\\nDefinition of \"You\" in This License. \"You\" throughout this License, whether in upper or lower case, means an individual or a legal entity exercising rights under, and complying with all of the terms of, this License. For legal entities, \"You\" includes any entity that controls, is controlled by, or is under common control with you. For purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.\\nRight to Use. You may use the Original Work in all ways not otherwise restricted or conditioned by this License or by law, and Licensor promises not to interfere with or be responsible for such uses by You.\\nModification of This License. This License is Copyright © 2005 Lawrence Rosen. Permission is granted to copy, distribute, or communicate this License without modification. Nothing in this License permits You to modify this License as applied to the Original Work or to Derivative Works. However, You may modify the text of this License and copy, distribute or communicate your modified version (the \"Modified License\") and apply it to other original works of authorship subject to the following conditions: (i) You may not indicate in any way that your Modified License is the \"Academic Free License\" or \"AFL\" and you may not use those names in the name of your Modified License; (ii) You must replace the notice specified in the first paragraph above with the notice \"Licensed under <insert your license name here>\" or with a notice of your own that is not confusingly similar to the notice in this License; and (iii) You may not claim that your original works are open source software unless your Modified License has been approved by Open Source Initiative (OSI) and You comply with its license review and certification process.\\nUsed by: apache ant, apache lucene, Cassandra Driver Core, Commons BeanUtils, Commons Lang3, ContiPerf, docker-ce, Elasticsearch, elastigo, go-systemd, Grafana, Guava, Jackson, JewelCli, Joda-Time, Keyczar, log4j, log4js, log4net, Protocol Buffers, protostuff, snakeyaml, twitter bootstrap\\nVersion 2.0, January 2004\\nhttp://www.apache.org/licenses/\\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\\nDefinitions.\\n\"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.\\n\"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.\\n\"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.\\n\"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License.\\n\"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.\\n\"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.\\n\"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).\\n\"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.\\n\"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\"\\n\"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.\\n\"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.\\n\"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.\\n\"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License.\\n\"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.\\n\"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.\\n\"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).\\n\"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.\\n\"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\"\\n\"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.\\nGrant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.\\nGrant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.\\nRedistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:\\nYou must give any other recipients of the Work or Derivative Works a copy of this License; and\\nYou must cause any modified files to carry prominent notices stating that You changed the files; and\\nYou must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and\\nIf the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.\\nYou may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.\\nYou must give any other recipients of the Work or Derivative Works a copy of this License; and\\nYou must cause any modified files to carry prominent notices stating that You changed the files; and\\nYou must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and\\nIf the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.\\nYou may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.\\nSubmission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.\\nTrademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.\\nDisclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.\\nLimitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.\\nAccepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability.\\nUsed by: bzip2, d3, go md4, go w32, go-hostpool, Golang, gopsutil, gou, gtest, KeyboardJS, libzip, nginx, require.js, seelog, winsvc, zmq4\\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\\nThe names of the authors may not be used to endorse or promote products derived from this software without specific prior written permission.\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\nUsed by: logback, tangent-file\\nTHE ACCOMPANYING PROGRAM IS PROVIDED UNDER THE TERMS OF THIS ECLIPSE PUBLIC LICENSE (\"AGREEMENT\"). ANY USE, REPRODUCTION OR DISTRIBUTION OF THE PROGRAM CONSTITUTES RECIPIENT\\'S ACCEPTANCE OF THIS AGREEMENT.\\nDEFINITIONS\\n\"Contribution\" means:\\nin the case of the initial Contributor, the initial code and documentation distributed under this Agreement, and\\nin the case of each subsequent Contributor:\\nchanges to the Program, and\\nadditions to the Program;\\nwhere such changes and/or additions to the Program originate from and are distributed by that particular Contributor. A Contribution \\'originates\\' from a Contributor if it was added to the Program by such Contributor itself or anyone acting on such Contributor\\'s behalf. Contributions do not include additions to the Program which: (i) are separate modules of software distributed in conjunction with the Program under their own license agreement, and (ii) are not derivative works of the Program.\\n\"Contributor\" means any person or entity that distributes the Program.\\n\"Licensed Patents\" mean patent claims licensable by a Contributor which are necessarily infringed by the use or sale of its Contribution alone or when combined with the Program.\\n\"Program\" means the Contributions distributed in accordance with this Agreement.\\n\"Recipient\" means anyone who receives the Program under this Agreement, including all Contributors.\\n\"Contribution\" means:\\nin the case of the initial Contributor, the initial code and documentation distributed under this Agreement, and\\nin the case of each subsequent Contributor:\\nchanges to the Program, and\\nadditions to the Program;\\nchanges to the Program, and\\nadditions to the Program;\\nwhere such changes and/or additions to the Program originate from and are distributed by that particular Contributor. A Contribution \\'originates\\' from a Contributor if it was added to the Program by such Contributor itself or anyone acting on such Contributor\\'s behalf. Contributions do not include additions to the Program which: (i) are separate modules of software distributed in conjunction with the Program under their own license agreement, and (ii) are not derivative works of the Program.\\n\"Contributor\" means any person or entity that distributes the Program.\\n\"Licensed Patents\" mean patent claims licensable by a Contributor which are necessarily infringed by the use or sale of its Contribution alone or when combined with the Program.\\n\"Program\" means the Contributions distributed in accordance with this Agreement.\\n\"Recipient\" means anyone who receives the Program under this Agreement, including all Contributors.\\nGRANT OF RIGHTS\\nSubject to the terms of this Agreement, each Contributor hereby grants Recipient a non-exclusive, worldwide, royalty-free copyright license to reproduce, prepare derivative works of, publicly display, publicly perform, distribute and sublicense the Contribution of such Contributor, if any, and such derivative works, in source code and object code form.\\nSubject to the terms of this Agreement, each Contributor hereby grants Recipient a non-exclusive, worldwide, royalty-free patent license under Licensed Patents to make, use, sell, offer to sell, import and otherwise transfer the Contribution of such Contributor, if any, in source code and object code form. This patent license shall apply to the combination of the Contribution and the Program if, at the time the Contribution is added by the Contributor, such addition of the Contribution causes such combination to be covered by the Licensed Patents. The patent license shall not apply to any other combinations which include the Contribution. No hardware per se is licensed hereunder.\\nRecipient understands that although each Contributor grants the licenses to its Contributions set forth herein, no assurances are provided by any Contributor that the Program does not infringe the patent or other intellectual property rights of any other entity. Each Contributor disclaims any liability to Recipient for claims brought by any other entity based on infringement of intellectual property rights or otherwise. As a condition to exercising the rights and licenses granted hereunder, each Recipient hereby assumes sole responsibility to secure any other intellectual property rights needed, if any. For example, if a third party patent license is required to allow Recipient to distribute the Program, it is Recipient\\'s responsibility to acquire that license before distributing the Program.\\nEach Contributor represents that to its knowledge it has sufficient copyright rights in its Contribution, if any, to grant the copyright license set forth in this Agreement.\\nSubject to the terms of this Agreement, each Contributor hereby grants Recipient a non-exclusive, worldwide, royalty-free copyright license to reproduce, prepare derivative works of, publicly display, publicly perform, distribute and sublicense the Contribution of such Contributor, if any, and such derivative works, in source code and object code form.\\nSubject to the terms of this Agreement, each Contributor hereby grants Recipient a non-exclusive, worldwide, royalty-free patent license under Licensed Patents to make, use, sell, offer to sell, import and otherwise transfer the Contribution of such Contributor, if any, in source code and object code form. This patent license shall apply to the combination of the Contribution and the Program if, at the time the Contribution is added by the Contributor, such addition of the Contribution causes such combination to be covered by the Licensed Patents. The patent license shall not apply to any other combinations which include the Contribution. No hardware per se is licensed hereunder.\\nRecipient understands that although each Contributor grants the licenses to its Contributions set forth herein, no assurances are provided by any Contributor that the Program does not infringe the patent or other intellectual property rights of any other entity. Each Contributor disclaims any liability to Recipient for claims brought by any other entity based on infringement of intellectual property rights or otherwise. As a condition to exercising the rights and licenses granted hereunder, each Recipient hereby assumes sole responsibility to secure any other intellectual property rights needed, if any. For example, if a third party patent license is required to allow Recipient to distribute the Program, it is Recipient\\'s responsibility to acquire that license before distributing the Program.\\nEach Contributor represents that to its knowledge it has sufficient copyright rights in its Contribution, if any, to grant the copyright license set forth in this Agreement.\\nREQUIREMENTS\\nA Contributor may choose to distribute the Program in object code form under its own license agreement, provided that:\\nit complies with the terms and conditions of this Agreement; and\\nits license agreement:\\neffectively disclaims on behalf of all Contributors all warranties and conditions, express and implied, including warranties or conditions of title and non-infringement, and implied warranties or conditions of merchantability and fitness for a particular purpose;\\neffectively excludes on behalf of all Contributors all liability for damages, including direct, indirect, special, incidental and consequential damages, such as lost profits;\\nstates that any provisions which differ from this Agreement are offered by that Contributor alone and not by any other party; and\\nstates that source code for the Program is available from such Contributor, and informs licensees how to obtain it in a reasonable manner on or through a medium customarily used for software exchange.\\nWhen the Program is made available in source code form:\\na) it must be made available under this Agreement; and\\nb) a copy of this Agreement must be included with each copy of the Program.\\nContributors may not remove or alter any copyright notices contained within the Program.\\nEach Contributor must identify itself as the originator of its Contribution, if any, in a manner that reasonably allows subsequent Recipients to identify the originator of the Contribution.\\nA Contributor may choose to distribute the Program in object code form under its own license agreement, provided that:\\nit complies with the terms and conditions of this Agreement; and\\nits license agreement:\\neffectively disclaims on behalf of all Contributors all warranties and conditions, express and implied, including warranties or conditions of title and non-infringement, and implied warranties or conditions of merchantability and fitness for a particular purpose;\\neffectively excludes on behalf of all Contributors all liability for damages, including direct, indirect, special, incidental and consequential damages, such as lost profits;\\nstates that any provisions which differ from this Agreement are offered by that Contributor alone and not by any other party; and\\nstates that source code for the Program is available from such Contributor, and informs licensees how to obtain it in a reasonable manner on or through a medium customarily used for software exchange.\\neffectively disclaims on behalf of all Contributors all warranties and conditions, express and implied, including warranties or conditions of title and non-infringement, and implied warranties or conditions of merchantability and fitness for a particular purpose;\\neffectively excludes on behalf of all Contributors all liability for damages, including direct, indirect, special, incidental and consequential damages, such as lost profits;\\nstates that any provisions which differ from this Agreement are offered by that Contributor alone and not by any other party; and\\nstates that source code for the Program is available from such Contributor, and informs licensees how to obtain it in a reasonable manner on or through a medium customarily used for software exchange.\\nWhen the Program is made available in source code form:\\na) it must be made available under this Agreement; and\\nb) a copy of this Agreement must be included with each copy of the Program.\\nContributors may not remove or alter any copyright notices contained within the Program.\\nEach Contributor must identify itself as the originator of its Contribution, if any, in a manner that reasonably allows subsequent Recipients to identify the originator of the Contribution.\\nCOMMERCIAL DISTRIBUTION\\nCommercial distributors of software may accept certain responsibilities with respect to end users, business partners and the like. While this license is intended to facilitate the commercial use of the Program, the Contributor who includes the Program in a commercial product offering should do so in a manner which does not create potential liability for other Contributors. Therefore, if a Contributor includes the Program in a commercial product offering, such Contributor (\"Commercial Contributor\") hereby agrees to defend and indemnify every other Contributor (\"Indemnified Contributor\") against any losses, damages and costs (collectively \"Losses\") arising from claims, lawsuits and other legal actions brought by a third party against the Indemnified Contributor to the extent caused by the acts or omissions of such Commercial Contributor in connection with its distribution of the Program in a commercial product offering. The obligations in this section do not apply to any claims or Losses relating to any actual or alleged intellectual property infringement. In order to qualify, an Indemnified Contributor must: a) promptly notify the Commercial Contributor in writing of such claim, and b) allow the Commercial Contributor to control, and cooperate with the Commercial Contributor in, the defense and any related settlement negotiations. The Indemnified Contributor may participate in any such claim at its own expense.\\nFor example, a Contributor might include the Program in a commercial product offering, Product X. That Contributor is then a Commercial Contributor. If that Commercial Contributor then makes performance claims, or offers warranties related to Product X, those performance claims and warranties are such Commercial Contributor\\'s responsibility alone. Under this section, the Commercial Contributor would have to defend claims against the other Contributors related to those performance claims and warranties, and if a court requires any other Contributor to pay any damages as a result, the Commercial Contributor must pay those damages.\\nCommercial distributors of software may accept certain responsibilities with respect to end users, business partners and the like. While this license is intended to facilitate the commercial use of the Program, the Contributor who includes the Program in a commercial product offering should do so in a manner which does not create potential liability for other Contributors. Therefore, if a Contributor includes the Program in a commercial product offering, such Contributor (\"Commercial Contributor\") hereby agrees to defend and indemnify every other Contributor (\"Indemnified Contributor\") against any losses, damages and costs (collectively \"Losses\") arising from claims, lawsuits and other legal actions brought by a third party against the Indemnified Contributor to the extent caused by the acts or omissions of such Commercial Contributor in connection with its distribution of the Program in a commercial product offering. The obligations in this section do not apply to any claims or Losses relating to any actual or alleged intellectual property infringement. In order to qualify, an Indemnified Contributor must: a) promptly notify the Commercial Contributor in writing of such claim, and b) allow the Commercial Contributor to control, and cooperate with the Commercial Contributor in, the defense and any related settlement negotiations. The Indemnified Contributor may participate in any such claim at its own expense.\\nFor example, a Contributor might include the Program in a commercial product offering, Product X. That Contributor is then a Commercial Contributor. If that Commercial Contributor then makes performance claims, or offers warranties related to Product X, those performance claims and warranties are such Commercial Contributor\\'s responsibility alone. Under this section, the Commercial Contributor would have to defend claims against the other Contributors related to those performance claims and warranties, and if a court requires any other Contributor to pay any damages as a result, the Commercial Contributor must pay those damages.\\nNO WARRANTY\\nEXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, THE PROGRAM IS PROVIDED ON AN \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED INCLUDING, WITHOUT LIMITATION, ANY WARRANTIES OR CONDITIONS OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. Each Recipient is solely responsible for determining the appropriateness of using and distributing the Program and assumes all risks associated with its exercise of rights under this Agreement , including but not limited to the risks and costs of program errors, compliance with applicable laws, damage to or loss of data, programs or equipment, and unavailability or interruption of operations.\\nEXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, THE PROGRAM IS PROVIDED ON AN \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED INCLUDING, WITHOUT LIMITATION, ANY WARRANTIES OR CONDITIONS OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. Each Recipient is solely responsible for determining the appropriateness of using and distributing the Program and assumes all risks associated with its exercise of rights under this Agreement , including but not limited to the risks and costs of program errors, compliance with applicable laws, damage to or loss of data, programs or equipment, and unavailability or interruption of operations.\\nDISCLAIMER OF LIABILITY\\nEXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, NEITHER RECIPIENT NOR ANY CONTRIBUTORS SHALL HAVE ANY LIABILITY FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING WITHOUT LIMITATION LOST PROFITS), HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OR DISTRIBUTION OF THE PROGRAM OR THE EXERCISE OF ANY RIGHTS GRANTED HEREUNDER, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\\nEXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, NEITHER RECIPIENT NOR ANY CONTRIBUTORS SHALL HAVE ANY LIABILITY FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING WITHOUT LIMITATION LOST PROFITS), HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OR DISTRIBUTION OF THE PROGRAM OR THE EXERCISE OF ANY RIGHTS GRANTED HEREUNDER, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\\nGENERAL\\nIf any provision of this Agreement is invalid or unenforceable under applicable law, it shall not affect the validity or enforceability of the remainder of the terms of this Agreement, and without further action by the parties hereto, such provision shall be reformed to the minimum extent necessary to make such provision valid and enforceable.\\nIf Recipient institutes patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Program itself (excluding combinations of the Program with other software or hardware) infringes such Recipient\\'s patent(s), then such Recipient\\'s rights granted under Section 2(b) shall terminate as of the date such litigation is filed.\\nAll Recipient\\'s rights under this Agreement shall terminate if it fails to comply with any of the material terms or conditions of this Agreement and does not cure such failure in a reasonable period of time after becoming aware of such noncompliance. If all Recipient\\'s rights under this Agreement terminate, Recipient agrees to cease use and distribution of the Program as soon as reasonably practicable. However, Recipient\\'s obligations under this Agreement and any licenses granted by Recipient relating to the Program shall continue and survive.\\nEveryone is permitted to copy and distribute copies of this Agreement, but in order to avoid inconsistency the Agreement is copyrighted and may only be modified in the following manner. The Agreement Steward reserves the right to publish new versions (including revisions) of this Agreement from time to time. No one other than the Agreement Steward has the right to modify this Agreement. The Eclipse Foundation is the initial Agreement Steward. The Eclipse Foundation may assign the responsibility to serve as the Agreement Steward to a suitable separate entity. Each new version of the Agreement will be given a distinguishing version number. The Program (including Contributions) may always be distributed subject to the version of the Agreement under which it was received. In addition, after a new version of the Agreement is published, Contributor may elect to distribute the Program (including its Contributions) under the new version. Except as expressly stated in Sections 2(a) and 2(b) above, Recipient receives no rights or licenses to the intellectual property of any Contributor under this Agreement, whether expressly, by implication, estoppel or otherwise. All rights in the Program not expressly granted under this Agreement are reserved.\\nThis Agreement is governed by the laws of the State of New York and the intellectual property laws of the United States of America. No party to this Agreement will bring a legal action under this Agreement more than one year after the cause of action arose. Each party waives its rights to a jury trial in any resulting litigation.\\nIf any provision of this Agreement is invalid or unenforceable under applicable law, it shall not affect the validity or enforceability of the remainder of the terms of this Agreement, and without further action by the parties hereto, such provision shall be reformed to the minimum extent necessary to make such provision valid and enforceable.\\nIf Recipient institutes patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Program itself (excluding combinations of the Program with other software or hardware) infringes such Recipient\\'s patent(s), then such Recipient\\'s rights granted under Section 2(b) shall terminate as of the date such litigation is filed.\\nAll Recipient\\'s rights under this Agreement shall terminate if it fails to comply with any of the material terms or conditions of this Agreement and does not cure such failure in a reasonable period of time after becoming aware of such noncompliance. If all Recipient\\'s rights under this Agreement terminate, Recipient agrees to cease use and distribution of the Program as soon as reasonably practicable. However, Recipient\\'s obligations under this Agreement and any licenses granted by Recipient relating to the Program shall continue and survive.\\nEveryone is permitted to copy and distribute copies of this Agreement, but in order to avoid inconsistency the Agreement is copyrighted and may only be modified in the following manner. The Agreement Steward reserves the right to publish new versions (including revisions) of this Agreement from time to time. No one other than the Agreement Steward has the right to modify this Agreement. The Eclipse Foundation is the initial Agreement Steward. The Eclipse Foundation may assign the responsibility to serve as the Agreement Steward to a suitable separate entity. Each new version of the Agreement will be given a distinguishing version number. The Program (including Contributions) may always be distributed subject to the version of the Agreement under which it was received. In addition, after a new version of the Agreement is published, Contributor may elect to distribute the Program (including its Contributions) under the new version. Except as expressly stated in Sections 2(a) and 2(b) above, Recipient receives no rights or licenses to the intellectual property of any Contributor under this Agreement, whether expressly, by implication, estoppel or otherwise. All rights in the Program not expressly granted under this Agreement are reserved.\\nThis Agreement is governed by the laws of the State of New York and the intellectual property laws of the United States of America. No party to this Agreement will bring a legal action under this Agreement more than one year after the cause of action arose. Each party waives its rights to a jury trial in any resulting litigation.\\nUsed by: Amazon Corretto\\nGNU General Public License, version 2,\\nwith the Classpath Exception\\nThe GNU General Public License (GPL) Version 2, June 1991\\nCopyright (C) 1989, 1991 Free Software Foundation, Inc. 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA\\nEveryone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.\\nPreamble\\nThe licenses for most software are designed to take away your freedom to share and change it. By contrast, the GNU General Public License is intended to guarantee your freedom to share and change free software--to make sure the software is free for all its users. This General Public License applies to most of the Free Software Foundation\\'s software and to any other program whose authors commit to using it. (Some other Free Software Foundation software is covered by the GNU Library General Public License instead.) You can apply it to your programs, too.\\nWhen we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for this service if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs; and that you know you can do these things.\\nTo protect your rights, we need to make restrictions that forbid anyone to deny you these rights or to ask you to surrender the rights. These restrictions translate to certain responsibilities for you if you distribute copies of the software, or if you modify it.\\nFor example, if you distribute copies of such a program, whether gratis or for a fee, you must give the recipients all the rights that you have. You must make sure that they, too, receive or can get the source code. And you must show them these terms so they know their rights.\\nWe protect your rights with two steps: (1) copyright the software, and (2) offer you this license which gives you legal permission to copy, distribute and/or modify the software.\\nAlso, for each author\\'s protection and ours, we want to make certain that everyone understands that there is no warranty for this free software. If the software is modified by someone else and passed on, we want its recipients to know that what they have is not the original, so that any problems introduced by others will not reflect on the original authors\\' reputations.\\nFinally, any free program is threatened constantly by software patents. We wish to avoid the danger that redistributors of a free program will individually obtain patent licenses, in effect making the program proprietary. To prevent this, we have made it clear that any patent must be licensed for everyone\\'s free use or not licensed at all.\\nThe precise terms and conditions for copying, distribution and modification follow.\\nTERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\\n0. This License applies to any program or other work which contains a notice placed by the copyright holder saying it may be distributed under the terms of this General Public License. The \"Program\", below, refers to any such program or work, and a \"work based on the Program\" means either the Program or any derivative work under copyright law: that is to say, a work containing the Program or a portion of it, either verbatim or with modifications and/or translated into another language. (Hereinafter, translation is included without limitation in the term \"modification\".) Each licensee is addressed as \"you\".\\nActivities other than copying, distribution and modification are not covered by this License; they are outside its scope. The act of running the Program is not restricted, and the output from the Program is covered only if its contents constitute a work based on the Program (independent of having been made by running the Program). Whether that is true depends on what the Program does.\\n1. You may copy and distribute verbatim copies of the Program\\'s source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice and disclaimer of warranty; keep intact all the notices that refer to this License and to the absence of any warranty; and give any other recipients of the Program a copy of this License along with the Program. You may charge a fee for the physical act of transferring a copy, and you may at your option offer warranty protection in exchange for a fee.\\n2. You may modify your copy or copies of the Program or any portion of it, thus forming a work based on the Program, and copy and distribute such modifications or work under the terms of Section 1 above, provided that you also meet all of these conditions:\\na) You must cause the modified files to carry prominent notices stating that you changed the files and the date of any change.\\nb) You must cause any work that you distribute or publish, that in whole or in part contains or is derived from the Program or any part thereof, to be licensed as a whole at no charge to all third parties under the terms of this License.\\nc) If the modified program normally reads commands interactively when run, you must cause it, when started running for such interactive use in the most ordinary way, to print or display an announcement including an appropriate copyright notice and a notice that there is no warranty (or else, saying that you provide a warranty) and that users may redistribute the program under these conditions, and telling the user how to view a copy of this License. (Exception: if the Program itself is interactive but does not normally print such an announcement, your work based on the Program is not required to print an announcement.)\\nThese requirements apply to the modified work as a whole. If identifiable sections of that work are not derived from the Program, and can be reasonably considered independent and separate works in themselves, then this License, and its terms, do not apply to those sections when you distribute them as separate works. But when you distribute the same sections as part of a whole which is a work based on the Program, the distribution of the whole must be on the terms of this License, whose permissions for other licensees extend to the entire whole, and thus to each and every part regardless of who wrote it.\\nThus, it is not the intent of this section to claim rights or contest your rights to work written entirely by you; rather, the intent is to exercise the right to control the distribution of derivative or collective works based on the Program.\\nIn addition, mere aggregation of another work not based on the Program with the Program (or with a work based on the Program) on a volume of a storage or distribution medium does not bring the other work under the scope of this License.\\n3. You may copy and distribute the Program (or a work based on it, under Section 2) in object code or executable form under the terms of Sections 1 and 2 above provided that you also do one of the following:\\na) Accompany it with the complete corresponding machine-readable source code, which must be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange; or,\\nb) Accompany it with a written offer, valid for at least three years, to give any third party, for a charge no more than your cost of physically performing source distribution, a complete machine-readable copy of the corresponding source code, to be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange; or,\\nc) Accompany it with the information you received as to the offer to distribute corresponding source code. (This alternative is allowed only for noncommercial distribution and only if you received the program in object code or executable form with such an offer, in accord with Subsection b above.)\\nThe source code for a work means the preferred form of the work for making modifications to it. For an executable work, complete source code means all the source code for all modules it contains, plus any associated interface definition files, plus the scripts used to control compilation and installation of the executable. However, as a special exception, the source code distributed need not include anything that is normally distributed (in either source or binary form) with the major components (compiler, kernel, and so on) of the operating system on which the executable runs, unless that component itself accompanies the executable.\\nIf distribution of executable or object code is made by offering access to copy from a designated place, then offering equivalent access to copy the source code from the same place counts as distribution of the source code, even though third parties are not compelled to copy the source along with the object code.\\n4. You may not copy, modify, sublicense, or distribute the Program except as expressly provided under this License. Any attempt otherwise to copy, modify, sublicense or distribute the Program is void, and will automatically terminate your rights under this License. However, parties who have received copies, or rights, from you under this License will not have their licenses terminated so long as such parties remain in full compliance.\\n5. You are not required to accept this License, since you have not signed it. However, nothing else grants you permission to modify or distribute the Program or its derivative works. These actions are prohibited by law if you do not accept this License. Therefore, by modifying or distributing the Program (or any work based on the Program), you indicate your acceptance of this License to do so, and all its terms and conditions for copying, distributing or modifying the Program or works based on it.\\n6. Each time you redistribute the Program (or any work based on the Program), the recipient automatically receives a license from the original licensor to copy, distribute or modify the Program subject to these terms and conditions. You may not impose any further restrictions on the recipients\\' exercise of the rights granted herein. You are not responsible for enforcing compliance by third parties to this License.\\n7. If, as a consequence of a court judgment or allegation of patent infringement or for any other reason (not limited to patent issues), conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot distribute so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not distribute the Program at all. For example, if a patent license would not permit royalty-free redistribution of the Program by all those who receive copies directly or indirectly through you, then the only way you could satisfy both it and this License would be to refrain entirely from distribution of the Program.\\nIf any portion of this section is held invalid or unenforceable under any particular circumstance, the balance of the section is intended to apply and the section as a whole is intended to apply in other circumstances.\\nIt is not the purpose of this section to induce you to infringe any patents or other property right claims or to contest validity of any such claims; this section has the sole purpose of protecting the integrity of the free software distribution system, which is implemented by public license practices. Many people have made generous contributions to the wide range of software distributed through that system in reliance on consistent application of that system; it is up to the author/donor to decide if he or she is willing to distribute software through any other system and a licensee cannot impose that choice. This section is intended to make thoroughly clear what is believed to be a consequence of the rest of this License.\\n8. If the distribution and/or use of the Program is restricted in certain countries either by patents or by copyrighted interfaces, the original copyright holder who places the Program under this License may add an explicit geographical distribution limitation excluding those countries, so that distribution is permitted only in or among countries not thus excluded. In such case, this License incorporates the limitation as if written in the body of this License.\\n9. The Free Software Foundation may publish revised and/or new versions of the General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\\nEach version is given a distinguishing version number. If the Program specifies a version number of this License which applies to it and \"any later version\", you have the option of following the terms and conditions either of that version or of any later version published by the Free Software Foundation. If the Program does not specify a version number of this License, you may choose any version ever published by the Free Software Foundation.\\n10. If you wish to incorporate parts of the Program into other free programs whose distribution conditions are different, write to the author to ask for permission. For software which is copyrighted by the Free Software Foundation, write to the Free Software Foundation; we sometimes make exceptions for this. Our decision will be guided by the two goals of preserving the free status of all derivatives of our free software and of promoting the sharing and reuse of software generally.\\nNO WARRANTY\\n11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\\n12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\\nEND OF TERMS AND CONDITIONS\\nHow to Apply These Terms to Your New Programs\\nIf you develop a new program, and you want it to be of the greatest possible use to the public, the best way to achieve this is to make it free software which everyone can redistribute and change under these terms.\\nTo do so, attach the following notices to the program. It is safest to attach them to the start of each source file to most effectively convey the exclusion of warranty; and each file should have at least the \"copyright\" line and a pointer to where the full notice is found.\\nOne line to give the program\\'s name and a brief idea of what it does.\\nCopyright (C) <year> <name of author>\\nThis program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version.\\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\\nYou should have received a copy of the GNU General Public License along with this program; if not, write to the Free Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA\\nAlso add information on how to contact you by electronic and paper mail.\\nIf the program is interactive, make it output a short notice like this when it starts in an interactive mode:\\nGnomovision version 69, Copyright (C) year name of author Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type \\'show w\\'. This is free software, and you are welcome to redistribute it under certain conditions; type \\'show c\\' for details.\\nThe hypothetical commands \\'show w\\' and \\'show c\\' should show the appropriate parts of the General Public License. Of course, the commands you use may be called something other than \\'show w\\' and \\'show c\\'; they could even be mouse-clicks or menu items--whatever suits your program.\\nYou should also get your employer (if you work as a programmer) or your school, if any, to sign a \"copyright disclaimer\" for the program, if necessary. Here is a sample; alter the names:\\nYoyodyne, Inc., hereby disclaims all copyright interest in the program \\'Gnomovision\\' (which makes passes at compilers) written by James Hacker.\\nsignature of Ty Coon, 1 April 1989\\nTy Coon, President of Vice\\nThis General Public License does not permit incorporating your program into proprietary programs. If your program is a subroutine library, you may consider it more useful to permit linking proprietary applications with the library. If this is what you want to do, use the GNU Library General Public License instead of this License.\\n\"CLASSPATH\" EXCEPTION TO THE GPL\\nCertain source files distributed by Oracle America and/or its affiliates are subject to the following clarification and special exception to the GPL, but only where Oracle has expressly included in the particular source file\\'s header the words \"Oracle designates this particular file as subject to the \"Classpath\" exception as provided by Oracle in the LICENSE file that accompanied this code.\"\\nLinking this library statically or dynamically with other modules is making a combined work based on this library. Thus, the terms and conditions of the GNU General Public License cover the whole combination.\\nAs a special exception, the copyright holders of this library give you permission to link this library with independent modules to produce an executable, regardless of the license terms of these independent modules, and to copy and distribute the resulting executable under terms of your choice, provided that you also meet, for each linked independent module, the terms and conditions of the license of that module. An independent module is a module which is not derived from or based on this library. If you modify this library, you may extend this exception to your version of the library, but you are not obligated to do so. If you do not wish to do so, delete this exception statement from your version.\\nADDITIONAL INFORMATION ABOUT LICENSING\\nCertain files distributed by Oracle America, Inc. and/or its affiliates are subject to the following clarification and special exception to the GPLv2, based on the GNU Project exception for its Classpath libraries, known as the GNU Classpath Exception.\\nNote that Oracle includes multiple, independent programs in this software package. Some of those programs are provided under licenses deemed incompatible with the GPLv2 by the Free Software Foundation and others. For example, the package includes programs licensed under the Apache License, Version 2.0 and may include FreeType. Such programs are licensed to you under their original licenses.\\nOracle facilitates your further distribution of this package by adding the Classpath Exception to the necessary parts of its GPLv2 code, which permits you to use that code in combination with other independent modules not licensed under the GPLv2. However, note that this would not permit you to commingle code under an incompatible license with Oracle\\'s GPLv2 licensed code by, for example, cutting and pasting such code into a file also containing Oracle\\'s GPLv2 licensed code and then distributing the result.\\nAdditionally, if you were to remove the Classpath Exception from any of the files to which it applies and distribute the result, you would likely be required to license some or all of the other code in that distribution under the GPLv2 as well, and since the GPLv2 is incompatible with the license terms of some items included in the distribution by Oracle, removing the Classpath Exception could therefore effectively compromise your ability to further distribute the package.\\nFailing to distribute notices associated with some files may also create unexpected legal consequences.\\nProceed with caution and we recommend that you obtain the advice of a lawyer skilled in open source matters before removing the Classpath Exception or making modifications to this package which may subsequently be redistributed and/or involve the use of third party software.\\nUsed by: hammer.js, java\\nCopyright © 2013 by Jorik Tangelder (Eight Media)Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\\nThe above copyright notice and this permission notice shall be included inall copies or substantial portions of the Software.\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\nUsed by: iscroll\\nCopyright © 2008-2013 Matteo Spinelli,\\nhttp://cubiq.org\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use,copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\nOracle Binary Code License Agreement for the Java SE Platform Products and JavaFX\\nORACLE AMERICA, INC. (\"ORACLE\"), FOR AND ON BEHALF OF ITSELF AND ITS SUBSIDIARIES AND AFFILIATES UNDER COMMON CONTROL, IS WILLING TO LICENSE THE SOFTWARE TO YOU ONLY UPON THE CONDITION THAT YOU ACCEPT ALL OF THE TERMS CONTAINED IN THIS BINARY CODE LICENSE AGREEMENT AND SUPPLEMENTAL LICENSE TERMS (COLLECTIVELY \"AGREEMENT\"). PLEASE READ THE AGREEMENT CAREFULLY. BY SELECTING THE \"ACCEPT LICENSE AGREEMENT\" (OR THE EQUIVALENT) BUTTON AND/OR BY USING THE SOFTWARE YOU ACKNOWLEDGE THAT YOU HAVE READ THE TERMS AND AGREE TO THEM. IF YOU ARE AGREEING TO THESE TERMS ON BEHALF OF A COMPANY OR OTHER LEGAL ENTITY, YOU REPRESENT THAT YOU HAVE THE LEGAL AUTHORITY TO BIND THE LEGAL ENTITY TO THESE TERMS. IF YOU DO NOT HAVE SUCH AUTHORITY, OR IF YOU DO NOT WISH TO BE BOUND BY THE TERMS, THEN SELECT THE \"DECLINE LICENSE AGREEMENT\" (OR THE EQUIVALENT) BUTTON AND YOU MUST NOT USE THE SOFTWARE ON THIS SITE OR ANY OTHER MEDIA ON WHICH THE SOFTWARE IS CONTAINED.\\nDEFINITIONS. \"Software\" means the software identified above in binary form that you selected for download, install or use (in the version You selected for download, install or use) from Oracle or its authorized licensees, any other machine readable materials (including, but not limited to, libraries, source files, header files, and data files), any updates or error corrections provided by Oracle, and any user manuals, programming guides and other documentation provided to you by Oracle under this Agreement. \"General Purpose Desktop Computers and Servers\" means computers, including desktop and laptop computers, or servers, used for general computing functions under end user control (such as but not specifically limited to email, general purpose Internet browsing, and office suite productivity tools). The use of Software in systems and solutions that provide dedicated functionality (other than as mentioned above) or designed for use in embedded or function-specific software applications, for example but not limited to: Software embedded in or bundled with industrial control systems, wireless mobile telephones, wireless handheld devices, kiosks, TV/STB, Blu-ray Disc devices, telematics and network control switching equipment, printers and storage management systems, and other related systems are excluded from this definition and not licensed under this Agreement. \"Programs\" means (a) Java technology applets and applications intended to run on the Java Platform, Standard Edition platform on Java-enabled General Purpose Desktop Computers and Servers; and (b) JavaFX technology applications intended to run on the JavaFX Runtime on JavaFX-enabled General Purpose Desktop Computers and Servers. “Commercial Features” means those features identified in Table 1-1 (Commercial Features In Java SE Product Editions) of the Java SE documentation accessible at\\nhttp://www.oracle.com/technetwork/java/javase/documentation/index.html\\n. “README File” means the README file for the Software accessible at\\nhttp://www.oracle.com/technetwork/java/javase/documentation/index.html\\n.\\nLICENSE TO USE. Subject to the terms and conditions of this Agreement including, but not limited to, the Java Technology Restrictions of the Supplemental License Terms, Oracle grants you a non-exclusive, non-transferable, limited license without license fees to reproduce and use internally the Software complete and unmodified for the sole purpose of running Programs. THE LICENSE SET FORTH IN THIS SECTION 2 DOES NOT EXTEND TO THE COMMERCIAL FEATURES. YOUR RIGHTS AND OBLIGATIONS RELATED TO THE COMMERCIAL FEATURES ARE AS SET FORTH IN THE SUPPLEMENTAL TERMS ALONG WITH ADDITIONAL LICENSES FOR DEVELOPERS AND PUBLISHERS.\\nRESTRICTIONS. Software is copyrighted. Title to Software and all associated intellectual property rights is retained by Oracle and/or its licensors. Unless enforcement is prohibited by applicable law, you may not modify, decompile, or reverse engineer Software. You acknowledge that the Software is developed for general use in a variety of information management applications; it is not developed or intended for use in any inherently dangerous applications, including applications that may create a risk of personal injury. If you use the Software in dangerous applications, then you shall be responsible to take all appropriate fail-safe, backup, redundancy, and other measures to ensure its safe use. Oracle disclaims any express or implied warranty of fitness for such uses. No right, title or interest in or to any trademark, service mark, logo or trade name of Oracle or its licensors is granted under this Agreement. Additional restrictions for developers and/or publishers licenses are set forth in the Supplemental License Terms.\\nDISCLAIMER OF WARRANTY. THE SOFTWARE IS PROVIDED \"AS IS\" WITHOUT WARRANTY OF ANY KIND. ORACLE FURTHER DISCLAIMS ALL WARRANTIES, EXPRESS AND IMPLIED, INCLUDING WITHOUT LIMITATION, ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE OR NONINFRINGEMENT.\\nLIMITATION OF LIABILITY. IN NO EVENT SHALL ORACLE BE LIABLE FOR ANY INDIRECT, INCIDENTAL, SPECIAL, PUNITIVE OR CONSEQUENTIAL DAMAGES, OR DAMAGES FOR LOSS OF PROFITS, REVENUE, DATA OR DATA USE, INCURRED BY YOU OR ANY THIRD PARTY, WHETHER IN AN ACTION IN CONTRACT OR TORT, EVEN IF ORACLE HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. ORACLE\\'S ENTIRE LIABILITY FOR DAMAGES HEREUNDER SHALL IN NO EVENT EXCEED ONE THOUSAND DOLLARS (U.S. $1,000).\\nTERMINATION. This Agreement is effective until terminated. You may terminate this Agreement at any time by destroying all copies of Software. This Agreement will terminate immediately without notice from Oracle if you fail to comply with any provision of this Agreement. Either party may terminate this Agreement immediately should any Software become, or in either party\\'s opinion be likely to become, the subject of a claim of infringement of any intellectual property right. Upon termination, you must destroy all copies of Software.\\nEXPORT REGULATIONS. You agree that U.S. export control laws and other applicable export and import laws govern your use of the Software, including technical data; additional information can be found on Oracle\\'s Global Trade Compliance web site (\\nhttp://www.oracle.com/products/export\\n). You agree that neither the Software nor any direct product thereof will be exported, directly, or indirectly, in violation of these laws, or will be used for any purpose prohibited by these laws including, without limitation, nuclear, chemical, or biological weapons proliferation.\\nTRADEMARKS AND LOGOS. You acknowledge and agree as between you and Oracle that Oracle owns the ORACLE and JAVA trademarks and all ORACLE- and JAVA-related trademarks, service marks, logos and other brand designations (\"Oracle Marks\"), and you agree to comply with the Third Party Usage Guidelines for Oracle Trademarks currently located at\\nhttp://www.oracle.com/us/legal/third-party-trademarks/index.html\\n. Any use you make of the Oracle Marks inures to Oracle\\'s benefit.\\nU.S. GOVERNMENT LICENSE RIGHTS. If Software is being acquired by or on behalf of the U.S. Government or by a U.S. Government prime contractor or subcontractor (at any tier), then the Government\\'s rights in Software and accompanying documentation shall be only those set forth in this Agreement.\\nGOVERNING LAW. This agreement is governed by the substantive and procedural laws of California. You and Oracle agree to submit to the exclusive jurisdiction of, and venue in, the courts of San Francisco, or Santa Clara counties in California in any dispute arising out of or relating to this agreement.\\nSEVERABILITY. If any provision of this Agreement is held to be unenforceable, this Agreement will remain in effect with the provision omitted, unless omission would frustrate the intent of the parties, in which case this Agreement will immediately terminate.\\nINTEGRATION. This Agreement is the entire agreement between you and Oracle relating to its subject matter. It supersedes all prior or contemporaneous oral or written communications, proposals, representations and warranties and prevails over any conflicting or additional terms of any quote, order, acknowledgment, or other communication between the parties relating to its subject matter during the term of this Agreement. No modification of this Agreement will be binding, unless in writing and signed by an authorized representative of each party.\\nSUPPLEMENTAL LICENSE TERMS\\nThese Supplemental License Terms add to or modify the terms of the Binary Code License Agreement. Capitalized terms not defined in these Supplemental Terms shall have the same meanings ascribed to them in the Binary Code License Agreement. These Supplemental Terms shall supersede any inconsistent or conflicting terms in the Binary Code License Agreement, or in any license contained within the Software.\\nA. COMMERCIAL FEATURES. You may not use the Commercial Features for running Programs, Java applets or applications in your internal business operations or for any commercial or production purpose, or for any purpose other than as set forth in Sections B, C, D and E of these Supplemental Terms. If You want to use the Commercial Features for any purpose other than as permitted in this Agreement, You must obtain a separate license from Oracle.\\nB. SOFTWARE INTERNAL USE FOR DEVELOPMENT LICENSE GRANT. Subject to the terms and conditions of this Agreement and restrictions and exceptions set forth in the README File incorporated herein by reference, including, but not limited to the Java Technology Restrictions of these Supplemental Terms, Oracle grants you a non-exclusive, non-transferable, limited license without fees to reproduce internally and use internally the Software complete and unmodified for the purpose of designing, developing, and testing your Programs.\\nC. LICENSE TO DISTRIBUTE SOFTWARE. Subject to the terms and conditions of this Agreement and restrictions and exceptions set forth in the README File, including, but not limited to the Java Technology Restrictions and Limitations on Redistribution of these Supplemental Terms, Oracle grants you a non-exclusive, non-transferable, limited license without fees to reproduce and distribute the Software, provided that (i) you distribute the Software complete and unmodified and only bundled as part of, and for the sole purpose of running, your Programs, (ii) the Programs add significant and primary functionality to the Software, (iii) you do not distribute additional software intended to replace any component(s) of the Software, (iv) you do not remove or alter any proprietary legends or notices contained in the Software, (v) you only distribute the Software subject to a license agreement that: (a) is a complete, unmodified reproduction of this Agreement; or (b) protects Oracle\\'s interests consistent with the terms contained in this Agreement and that includes the notice set forth in Section H, and (vi) you agree to defend and indemnify Oracle and its licensors from and against any damages, costs, liabilities, settlement amounts and/or expenses (including attorneys\\' fees) incurred in connection with any claim, lawsuit or action by any third party that arises or results from the use or distribution of any and all Programs and/or Software. The license set forth in this Section C does not extend to the Software identified in Section G.\\nD. LICENSE TO DISTRIBUTE REDISTRIBUTABLES. Subject to the terms and conditions of this Agreement and restrictions and exceptions set forth in the README File, including but not limited to the Java Technology Restrictions and Limitations on Redistribution of these Supplemental Terms, Oracle grants you a non-exclusive, non-transferable, limited license without fees to reproduce and distribute those files specifically identified as redistributable in the README File (\"Redistributables\") provided that: (i) you distribute the Redistributables complete and unmodified, and only bundled as part of Programs, (ii) the Programs add significant and primary functionality to the Redistributables, (iii) you do not distribute additional software intended to supersede any component(s) of the Redistributables (unless otherwise specified in the applicable README File), (iv) you do not remove or alter any proprietary legends or notices contained in or on the Redistributables, (v) you only distribute the Redistributables pursuant to a license agreement that: (a) is a complete, unmodified reproduction of this Agreement; or (b) protects Oracle\\'s interests consistent with the terms contained in the Agreement and includes the notice set forth in Section H, (vi) you agree to defend and indemnify Oracle and its licensors from and against any damages, costs, liabilities, settlement amounts and/or expenses (including attorneys\\' fees) incurred in connection with any claim, lawsuit or action by any third party that arises or results from the use or distribution of any and all Programs and/or Software. The license set forth in this Section D does not extend to the Software identified in Section G.\\nE. DISTRIBUTION BY PUBLISHERS. This section pertains to your distribution of the JavaTM SE Development Kit Software (“JDK”) with your printed book or magazine (as those terms are commonly used in the industry) relating to Java technology (\"Publication\"). Subject to and conditioned upon your compliance with the restrictions and obligations contained in the Agreement, Oracle hereby grants to you a non-exclusive, nontransferable limited right to reproduce complete and unmodified copies of the JDK on electronic media (the \"Media\") for the sole purpose of inclusion and distribution with your Publication(s), subject to the following terms: (i) You may not distribute the JDK on a stand-alone basis; it must be distributed with your Publication(s); (ii) You are responsible for downloading the JDK from the applicable Oracle web site; (iii) You must refer to the JDK as JavaTM SE Development Kit; (iv) The JDK must be reproduced in its entirety and without any modification whatsoever (including with respect to all proprietary notices) and distributed with your Publication subject to a license agreement that is a complete, unmodified reproduction of this Agreement; (v) The Media label shall include the following information: “Copyright [YEAR], Oracle America, Inc. All rights reserved. Use is subject to license terms. ORACLE and JAVA trademarks and all ORACLE- and JAVA-related trademarks, service marks, logos and other brand designations are trademarks or registered trademarks of Oracle in the U.S. and other countries.” [YEAR] is the year of Oracle\\'s release of the Software; the year information can typically be found in the Software’s “About” box or screen. This information must be placed on the Media label in such a manner as to only apply to the JDK; (vi) You must clearly identify the JDK as Oracle\\'s product on the Media holder or Media label, and you may not state or imply that Oracle is responsible for any third-party software contained on the Media; (vii) You may not include any third party software on the Media which is intended to be a replacement or substitute for the JDK; (viii) You agree to defend and indemnify Oracle and its licensors from and against any damages, costs, liabilities, settlement amounts and/or expenses (including attorneys\\' fees) incurred in connection with any claim, lawsuit or action by any third party that arises or results from the use or distribution of the JDK and/or the Publication; ; and (ix) You shall provide Oracle with a written notice for each Publication; such notice shall include the following information: (1) title of Publication, (2) author(s), (3) date of Publication, and (4) ISBN or ISSN numbers. Such notice shall be sent to Oracle America, Inc., 500 Oracle Parkway, Redwood Shores, California 94065 U.S.A , Attention: General Counsel.\\nF. JAVA TECHNOLOGY RESTRICTIONS. You may not create, modify, or change the behavior of, or authorize your licensees to create, modify, or change the behavior of, classes, interfaces, or subpackages that are in any way identified as \"java\", \"javax\", \"sun\", “oracle” or similar convention as specified by Oracle in any naming convention designation.\\nG. LIMITATIONS ON REDISTRIBUTION. You may not redistribute or otherwise transfer patches, bug fixes or updates made available by Oracle through Oracle Premier Support, including those made available under Oracle\\'s Java SE Support program.\\nH. COMMERCIAL FEATURES NOTICE. For purpose of complying with Supplemental Term Section C.(v)(b) and D.(v)(b), your license agreement shall include the following notice, where the notice is displayed in a manner that anyone using the Software will see the notice:\\nUse of the Commercial Features for any commercial or production purpose requires a separate license from Oracle. “Commercial Features” means those features identified Table 1-1 (Commercial Features In Java SE Product Editions) of the Java SE documentation accessible at\\nhttp://www.oracle.com/technetwork/java/javase/documentation/index.html\\nI. SOURCE CODE. Software may contain source code that, unless expressly licensed for other purposes, is provided solely for reference purposes pursuant to the terms of this Agreement. Source code may not be redistributed unless expressly provided for in this Agreement.\\nJ. THIRD PARTY CODE. Additional copyright notices and license terms applicable to portions of the Software are set forth in the THIRDPARTYLICENSEREADME file accessible at\\nhttp://www.oracle.com/technetwork/java/javase/documentation/index.html\\n. In addition to any terms and conditions of any third party opensource/freeware license identified in the THIRDPARTYLICENSEREADME file, the disclaimer of warranty and limitation of liability provisions in paragraphs 4 and 5 of the Binary Code License Agreement shall apply to all Software in this distribution.\\nK. TERMINATION FOR INFRINGEMENT. Either party may terminate this Agreement immediately should any Software become, or in either party\\'s opinion be likely to become, the subject of a claim of infringement of any intellectual property right.\\nL. INSTALLATION AND AUTO-UPDATE. The Software\\'s installation and auto-update processes transmit a limited amount of data to Oracle (or its service provider) about those specific processes to help Oracle understand and optimize them. Oracle does not associate the data with personally identifiable information. You can find more information about the data Oracle collects as a result of your Software download at\\nhttp://www.oracle.com/technetwork/java/javase/documentation/index.html\\n.\\nFor inquiries please contact: Oracle America, Inc., 500 Oracle Parkway,\\nRedwood Shores, California 94065, USA.\\nLast updated 02 April 2013\\nUsed by: clrzmq (LGPL), dbus, gcc (LGPLv3), gmp (LGPLv3), jeromq (LGPL), libgcc (LGPL), libzmq, logback, yaml v2, zeromq (LGPLv3)\\nØMQ Free Software Licenses\\nThe ØMQ library is licensed under the GNU Lesser General Public License (see below). All add-ons and examples are published under the GNU General Public License.\\nYou get the full source code of ØMQ. You can examine the code, modify it, and share your modified code under the terms of the LGPL.\\nStatic linking exception. The copyright holders give you permission to link this library with independent modules to produce an executable, regardless of the license terms of these independent modules, and to copy and distribute the resulting executable under terms of your choice, provided that you also meet, for each linked independent module, the terms and conditions of the license of that module. An independent module is a module which is not derived from or based on this library. If you modify this library, you must extend this exception to your version of the library.\\nØMQ for Commercial Applications\\nØMQ is safe for use in close-source applications. The LGPL share-alike terms do not apply to applications built on top of ØMQ.\\nYou do not need a commercial license. The LGPL applies to ØMQ\\'s own source code, not your applications. Many commercial applications use ØMQ.\\nGNU LESSER GENERAL PUBLIC LICENSE\\n0. Additional Definitions.\\nAs used herein, “this License” refers to version 3 of the GNU Lesser General Public License, and the “GNU GPL” refers to version 3 of the GNU General Public License.\\n“The Library” refers to a covered work governed by this License, other than an Application or a Combined Work as defined below.\\nAn “Application” is any work that makes use of an interface provided by the Library, but which is not otherwise based on the Library. Defining a subclass of a class defined by the Library is deemed a mode of using an interface provided by the Library.\\nA “Combined Work” is a work produced by combining or linking an Application with the Library. The particular version of the Library with which the Combined Work was made is also called the “Linked Version”.\\nThe “Minimal Corresponding Source” for a Combined Work means the Corresponding Source for the Combined Work, excluding any source code for portions of the Combined Work that, considered in isolation, are based on the Application, and not on the Linked Version.\\nThe “Corresponding Application Code” for a Combined Work means the object code and/or source code for the Application, including any data and utility programs needed for reproducing the Combined Work from the Application, but excluding the System Libraries of the Combined Work.\\nException to Section 3 of the GNU GPL.\\nYou may convey a covered work under sections 3 and 4 of this License without being bound by section 3 of the GNU GPL.\\nConveying Modified Versions.\\nIf you modify a copy of the Library, and, in your modifications, a facility refers to a function or data to be supplied by an Application that uses the facility (other than as an argument passed when the facility is invoked), then you may convey a copy of the modified version:\\nunder this License, provided that you make a good faith effort to ensure that, in the event an Application does not supply the function or data, the facility still operates, and performs whatever part of its purpose remains meaningful, or\\nunder the GNU GPL, with none of the additional permissions of this License applicable to that copy.\\nObject Code Incorporating Material from Library Header Files.\\nThe object code form of an Application may incorporate material from a header file that is part of the Library. You may convey such object code under terms of your choice, provided that, if the incorporated material is not limited to numerical parameters, data structure layouts and accessors, or small macros, inline functions and templates (ten or fewer lines in length), you do both of the following:\\nGive prominent notice with each copy of the object code that the Library is used in it and that the Library and its use are covered by this License.\\nAccompany the object code with a copy of the GNU GPL and this license document.\\nCombined Works.\\nYou may convey a Combined Work under terms of your choice that, taken together, effectively do not restrict modification of the portions of the Library contained in the Combined Work and reverse engineering for debugging such modifications, if you also do each of the following:\\nGive prominent notice with each copy of the Combined Work that the Library is used in it and that the Library and its use are covered by this License.\\nAccompany the Combined Work with a copy of the GNU GPL and this license document.\\nFor a Combined Work that displays copyright notices during execution, include the copyright notice for the Library among these notices, as well as a reference directing the user to the copies of the GNU GPL and this license document.\\nDo one of the following:\\n0) Convey the Minimal Corresponding Source under the terms of this License, and the Corresponding Application Code in a form suitable for, and under terms that permit, the user to recombine or relink the Application with a modified version of the Linked Version to produce a modified Combined Work, in the manner specified by section 6 of the GNU GPL for conveying Corresponding Source.\\n1) Use a suitable shared library mechanism for linking with the Library. A suitable mechanism is one that (a) uses at run time a copy of the Library already present on the user\\'s computer system, and (b) will operate properly with a modified version of the Library that is interface-compatible with the Linked Version.\\nProvide Installation Information, but only if you would otherwise be required to provide such information under section 6 of the GNU GPL, and only to the extent that such information is necessary to install and execute a modified version of the Combined Work produced by recombining or relinking the Application with a modified version of the Linked Version. (If you use option 4d0, the Installation Information must accompany the Minimal Corresponding Source and Corresponding Application Code. If you use option 4d1, you must provide the Installation Information in the manner specified by section 6 of the GNU GPL for conveying Corresponding Source.)\\nCombined Libraries.\\nYou may place library facilities that are a work based on the Library side by side in a single library together with other library facilities that are not Applications and are not covered by this License, and convey such a combined library under terms of your choice, if you do both of the following:\\nAccompany the combined library with a copy of the same work based on the Library, uncombined with any other library facilities, conveyed under the terms of this License.\\nGive prominent notice with the combined library that part of it is a work based on the Library, and explaining where to find the accompanying uncombined form of the same work.\\nRevised Versions of the GNU Lesser General Public License.\\nThe Free Software Foundation may publish revised and/or new versions of the GNU Lesser General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\\nEach version is given a distinguishing version number. If the Library as you received it specifies that a certain numbered version of the GNU Lesser General Public License “or any later version” applies to it, you have the option of following the terms and conditions either of that published version or of any later version published by the Free Software Foundation. If the Library as you received it does not specify a version number of the GNU Lesser General Public License, you may choose any version of the GNU Lesser General Public License ever published by the Free Software Foundation.\\nIf the Library as you received it specifies that a proxy can decide whether future versions of the GNU Lesser General Public License shall apply, that proxy\\'s public statement of acceptance of any version is permanent authorization for you to choose that version for the Library.\\nUsed by: libsodium\\nCopyright (c) 2013-2015\\nFrank Denis <j at pureftpd dot org>\\nPermission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies.\\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\\nUsed by: SQL JDBC 4.0\\n.\\nCopyright © 2014 Microsoft\\nAll rights reserved.\\nThese license terms are an agreement between Microsoft Corporation (or based on where you live, one of its affiliates) and you. Please read them. They apply to the software named above, which includes the media on which you received it, if any. The terms also apply to any Microsoft\\nupdates,\\nsupplements,\\nInternet-based services, and\\nsupport services\\nfor this software, unless other terms accompany those items. If so, those terms apply.\\nBY USING THE SOFTWARE, YOU ACCEPT THESE TERMS. IF YOU DO NOT ACCEPT THEM, DO NOT USE THE SOFTWARE.\\nIf you comply with these license terms, you have the rights below.\\nINSTALLATION AND USE RIGHTS. You may install and use any number of copies of the software on your devices. You may also install the software in a hosted environment.\\nADDITIONAL LICENSING REQUIREMENTS AND/OR USE RIGHTS.\\nDistributable Code.\\nRight to Use and Distribute. You are permitted to distribute the software in programs you develop if you comply with the terms below:\\nYou may copy and distribute the object code form of the software (“Distributable Code”) in programs you develop. You may not modify the software.\\nYou may permit distributors of your programs to copy and distribute the Distributable Code as part of those programs.\\nYou may copy and distribute the object code form of the software (“Distributable Code”) in programs you develop. You may not modify the software.\\nYou may permit distributors of your programs to copy and distribute the Distributable Code as part of those programs.\\nDistribution Requirements. For any Distributable Code you distribute, you must\\nadd significant primary functionality to it in your programs;\\nrequire distributors and external end users to agree to terms that protect it at least as much as this agreement;\\ndisplay your valid copyright notice on your programs; and indemnify, defend, and hold harmless Microsoft from any claims, including attorneys’ fees, related to the distribution or use of your programs.\\nadd significant primary functionality to it in your programs;\\nrequire distributors and external end users to agree to terms that protect it at least as much as this agreement;\\ndisplay your valid copyright notice on your programs; and indemnify, defend, and hold harmless Microsoft from any claims, including attorneys’ fees, related to the distribution or use of your programs.\\nDistribution Restrictions. You may not\\nalter any copyright, trademark or patent notice in the Distributable Code;\\nuse Microsoft’s trademarks in your programs’ names or in a way that suggests your programs come from or are endorsed by Microsoft;\\ninclude Distributable Code in malicious, deceptive or unlawful programs; or\\nmodify or distribute the source code of any Distributable Code so that any part of it becomes subject to an Excluded License. An Excluded License is one that requires, as a condition of use, modification or distribution, that\\nthe code be disclosed or distributed in source code form; or\\nothers have the right to modify it.\\nalter any copyright, trademark or patent notice in the Distributable Code;\\nuse Microsoft’s trademarks in your programs’ names or in a way that suggests your programs come from or are endorsed by Microsoft;\\ninclude Distributable Code in malicious, deceptive or unlawful programs; or\\nmodify or distribute the source code of any Distributable Code so that any part of it becomes subject to an Excluded License. An Excluded License is one that requires, as a condition of use, modification or distribution, that\\nthe code be disclosed or distributed in source code form; or\\nothers have the right to modify it.\\nSCOPE OF LICENSE. The software is licensed, not sold. This agreement only gives you some rights to use the software. Microsoft reserves all other rights. Unless applicable law gives you more rights despite this limitation, you may use the software only as expressly permitted in this agreement. In doing so, you must comply with any technical limitations in the software that only allow you to use it in certain ways. You may not\\nthe results of any benchmark tests of the software to any third party without Microsoft’s prior written approval;\\nreverse engineer, decompile or disassemble the software, except and only to the extent that applicable law expressly permits, despite this limitation;\\npublish the software for others to copy;\\nrent, lease or lend the software; or\\nTRANSFER TO A THIRD PARTY. The first user of the software may transfer it and this agreement directly to a third party. Before the transfer, that party must agree that this agreement applies to the transfer and use of the software. The first user must uninstall the software before transferring it separately from the device. The first user may not retain any copies.\\nEXPORT RESTRICTIONS. The software is subject to United States export laws and regulations. You must comply with all domestic and international export laws and regulations that apply to the software. These laws include restrictions on destinations, end users and end use. For additional information, see\\nwww.microsoft.com/exporting\\n.\\nSUPPORT SERVICES. Because this software is “as is,” we may not provide support services for it.\\nENTIRE AGREEMENT. This agreement, and the terms for supplements, updates, Internet-based services and support services that you use, are the entire agreement for the software and support services.\\nAPPLICABLE LAW.\\nUnited States. If you acquired the software in the United States, Washington state law governs the interpretation of this agreement and applies to claims for breach of it, regardless of conflict of laws principles. The laws of the state where you live govern all other claims, including claims under state consumer protection laws, unfair competition laws, and in tort.\\nOutside the United States. If you acquired the software in any other country, the laws of that country apply.\\nLEGAL EFFECT. This agreement describes certain legal rights. You may have other rights under the laws of your country. You may also have rights with respect to the party from whom you acquired the software. This agreement does not change your rights under the laws of your country if the laws of your country do not permit it to do so.\\nDISCLAIMER OF WARRANTY. THE SOFTWARE IS LICENSED “AS-IS.” YOU BEAR THE RISK OF USING IT. MICROSOFT GIVES NO EXPRESS WARRANTIES, GUARANTEES OR CONDITIONS. YOU MAY HAVE ADDITIONAL CONSUMER RIGHTS UNDER YOUR LOCAL LAWS WHICH THIS AGREEMENT CANNOT CHANGE. TO THE EXTENT PERMITTED UNDER YOUR LOCAL LAWS, MICROSOFT EXCLUDES THE IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.\\nLIMITATION ON AND EXCLUSION OF REMEDIES AND DAMAGES. YOU CAN RECOVER FROM MICROSOFT AND ITS SUPPLIERS ONLY DIRECT DAMAGES UP TO U.S. $5.00. YOU CANNOT RECOVER ANY OTHER DAMAGES, INCLUDING CONSEQUENTIAL, LOST PROFITS, SPECIAL, INDIRECT OR INCIDENTAL DAMAGES.\\nThis limitation applies to\\nrelated to the software, services, content (including code) on third party Internet sites, or third party programs, and\\nclaims for breach of contract, breach of warranty, guarantee or condition, strict liability, negligence, or other tort to the extent permitted by applicable law.\\nIt also applies even if Microsoft knew or should have known about the possibility of the damages. The above limitation or exclusion may not apply to you because your country may not allow the exclusion or limitation of incidental, consequential or other damages.\\nPlease note: As this software is distributed in Quebec, Canada, some of the clauses in this agreement are provided below in French.\\nRemarque : Ce logiciel étant distribué au Québec, Canada, certaines des clauses dans ce contrat sont fournies ci-dessous en français.\\nEXONÉRATION DE GARANTIE. Le logiciel visé par une licence est offert « tel quel ». Toute utilisation de ce logiciel est à votre seule risque et péril. Microsoft n’accorde aucune autre garantie expresse. Vous pouvez bénéficier de droits additionnels en vertu du droit local sur la protection des consommateurs, que ce contrat ne peut modifier. La ou elles sont permises par le droit locale, les garanties implicites de qualité marchande, d’adéquation à un usage particulier et d’absence de contrefaçon sont exclues.\\nLIMITATION DES DOMMAGES-INTÉRÊTS ET EXCLUSION DE RESPONSABILITÉ POUR LES DOMMAGES. Vous pouvez obtenir de Microsoft et de ses fournisseurs une indemnisation en cas de dommages directs uniquement à hauteur de 5,00 $ US. Vous ne pouvez prétendre à aucune indemnisation pour les autres dommages, y compris les dommages spéciaux, indirects ou accessoires et pertes de bénéfices.\\nCette limitation concerne :\\ntout ce qui est relié au logiciel, aux services ou au contenu (y compris le code) figurant sur des sites Internet tiers ou dans des programmes tiers ; et\\nles réclamations au titre de violation de contrat ou de garantie, ou au titre de responsabilité stricte, de négligence ou d’une autre faute dans la limite autorisée par la loi en vigueur.\\nElle s’applique également, même si Microsoft connaissait ou devrait connaître l’éventualité d’un tel dommage. Si votre pays n’autorise pas l’exclusion ou la limitation de responsabilité pour les dommages indirects, accessoires ou de quelque nature que ce soit, il se peut que la limitation ou l’exclusion ci-dessus ne s’appliquera pas à votre égard.\\nEFFET JURIDIQUE. Le présent contrat décrit certains droits juridiques. Vous pourriez avoir d’autres droits prévus par les lois de votre pays. Le présent contrat ne modifie pas les droits que vous confèrent les lois de votre pays si celles-ci ne le permettent pas.\\nThis license governs use of the accompanying software. If you use the software, you accept this license. If you do not accept the license, do not use the software.\\nDefinitions\\nThe terms \"reproduce,\" \"reproduction,\" \"derivative works,\" and \"distribution\" have the same meaning here as under U.S. copyright law.\\nA \"contribution\" is the original software, or any additions or changes to the software.\\nA \"contributor\" is any person that distributes its contribution under this license.\\n\"Licensed patents\" are a contributor\\'s patent claims that read directly on its contribution.\\nThe terms \"reproduce,\" \"reproduction,\" \"derivative works,\" and \"distribution\" have the same meaning here as under U.S. copyright law.\\nA \"contribution\" is the original software, or any additions or changes to the software.\\nA \"contributor\" is any person that distributes its contribution under this license.\\n\"Licensed patents\" are a contributor\\'s patent claims that read directly on its contribution.\\nGrant of Rights\\n(A) Copyright Grant- Subject to the terms of this license, including the license conditions and limitations in section 3, each contributor grants you a non-exclusive, worldwide, royalty-free copyright license to reproduce its contribution, prepare derivative works of its contribution, and distribute its contribution or any derivative works that you create.\\n(B) Patent Grant- Subject to the terms of this license, including the license conditions and limitations in section 3, each contributor grants you a non-exclusive, worldwide, royalty-free license under its licensed patents to make, have made, use, sell, offer for sale, import, and/or otherwise dispose of its contribution in the software or derivative works of the contribution in the software.\\n(A) Copyright Grant- Subject to the terms of this license, including the license conditions and limitations in section 3, each contributor grants you a non-exclusive, worldwide, royalty-free copyright license to reproduce its contribution, prepare derivative works of its contribution, and distribute its contribution or any derivative works that you create.\\n(B) Patent Grant- Subject to the terms of this license, including the license conditions and limitations in section 3, each contributor grants you a non-exclusive, worldwide, royalty-free license under its licensed patents to make, have made, use, sell, offer for sale, import, and/or otherwise dispose of its contribution in the software or derivative works of the contribution in the software.\\nConditions and Limitations\\n(A) No Trademark License- This license does not grant you rights to use any contributors\\' name, logo, or trademarks.\\n(B) If you bring a patent claim against any contributor over patents that you claim are infringed by the software, your patent license from such contributor to the software ends automatically.\\n(C) If you distribute any portion of the software, you must retain all copyright, patent, trademark, and attribution notices that are present in the software.\\n(D) If you distribute any portion of the software in source code form, you may do so only under this license by including a complete copy of this license with your distribution. If you distribute any portion of the software in compiled or object code form, you may only do so under a license that complies with this license.\\n(E) The software is licensed \"as-is.\" You bear the risk of using it. The contributors give no express warranties, guarantees or conditions. You may have additional consumer rights under your local laws which this license cannot change. To the extent permitted under your local laws, the contributors exclude the implied warranties of merchantability, fitness for a particular purpose and non-infringement.\\n(A) No Trademark License- This license does not grant you rights to use any contributors\\' name, logo, or trademarks.\\n(B) If you bring a patent claim against any contributor over patents that you claim are infringed by the software, your patent license from such contributor to the software ends automatically.\\n(C) If you distribute any portion of the software, you must retain all copyright, patent, trademark, and attribution notices that are present in the software.\\n(D) If you distribute any portion of the software in source code form, you may do so only under this license by including a complete copy of this license with your distribution. If you distribute any portion of the software in compiled or object code form, you may only do so under a license that complies with this license.\\n(E) The software is licensed \"as-is.\" You bear the risk of using it. The contributors give no express warranties, guarantees or conditions. You may have additional consumer rights under your local laws which this license cannot change. To the extent permitted under your local laws, the contributors exclude the implied warranties of merchantability, fitness for a particular purpose and non-infringement.\\nUsed by: alertify, angular, chai, coffee-script, connect-assets, death, ejs, ejs-locals, erroable, express, express-train, findadate, font awesome, gls, go uuid, gogoprotobuf, goji, InfluxDB, InfluxDB Java, jquery, kalendae, karma, karma-chrome-launcher, karma-coffee-preprocessor, karma-coverage, karma-firefox-launcher, karma-html2js-preprocessor, karma-jasmine, karma-mocha, karma-phantomjs-launcher, karma-requirejs, karma-script-launcher, lodash, mocha, moloch, newtonsoft.json, nib, node-dev, npmedge, passport, passport-http, passport-local, passport.socketio, placeholders.js, simple injector, socket.io, socket.io-client, spinners, stylus, superagent, tedious\\nAll rights reserved.\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\nUsed by: moment\\nCopyright © 2011-2013 Tim Wood, Iskren Chernev, Moment.js contributors\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use,copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\nUsed by: Consul, czmq\\nDefinitions\\n1.1. “Contributor”\\nmeans each individual or legal entity that creates, contributes to the creation of, or owns Covered Software.\\n1.2. “Contributor Version”\\nmeans the combination of the Contributions of others (if any) used by a Contributor and that particular Contributor’s Contribution.\\n1.3. “Contribution”\\nmeans Covered Software of a particular Contributor.\\n1.4. “Covered Software”\\nmeans Source Code Form to which the initial Contributor has attached the notice in Exhibit A, the Executable Form of such Source Code Form, and Modifications of such Source Code Form, in each case including portions thereof.\\n1.5. “Incompatible With Secondary Licenses”\\nmeans\\nthat the initial Contributor has attached the notice described in Exhibit B to the Covered Software; or\\nthat the Covered Software was made available under the terms of version 1.1 or earlier of the License, but not also under the terms of a Secondary License.\\n1.6. “Executable Form”\\nmeans any form of the work other than Source Code Form.\\n1.7. “Larger Work”\\nmeans a work that combines Covered Software with other material, in a separate file or files, that is not Covered Software.\\n1.8. “License”\\nmeans this document.\\n1.9. “Licensable”\\nmeans having the right to grant, to the maximum extent possible, whether at the time of the initial grant or subsequently, any and all of the rights conveyed by this License.\\n1.10. “Modifications”\\nmeans any of the following:\\nany file in Source Code Form that results from an addition to, deletion from, or modification of the contents of Covered Software; or\\nany new file in Source Code Form that contains any Covered Software.\\n1.11. “Patent Claims” of a Contributor\\nmeans any patent claim(s), including without limitation, method, process, and apparatus claims, in any patent Licensable by such Contributor that would be infringed, but for the grant of the License, by the making, using, selling, offering for sale, having made, import, or transfer of either its Contributions or its Contributor Version.\\n1.12. “Secondary License”\\nmeans either the GNU General Public License, Version 2.0, the GNU Lesser General Public License, Version 2.1, the GNU Affero General Public License, Version 3.0, or any later versions of those licenses.\\n1.13. “Source Code Form”\\nmeans the form of the work preferred for making modifications.\\n1.14. “You” (or “Your”)\\nmeans an individual or a legal entity exercising rights under this License. For legal entities, “You” includes any entity that controls, is controlled by, or is under common control with You. For purposes of this definition, “control” means (a) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (b) ownership of more than fifty percent (50%) of the outstanding shares or beneficial ownership of such entity.\\n1.1. “Contributor”\\nmeans each individual or legal entity that creates, contributes to the creation of, or owns Covered Software.\\n1.2. “Contributor Version”\\nmeans the combination of the Contributions of others (if any) used by a Contributor and that particular Contributor’s Contribution.\\n1.3. “Contribution”\\nmeans Covered Software of a particular Contributor.\\n1.4. “Covered Software”\\nmeans Source Code Form to which the initial Contributor has attached the notice in Exhibit A, the Executable Form of such Source Code Form, and Modifications of such Source Code Form, in each case including portions thereof.\\n1.5. “Incompatible With Secondary Licenses”\\nmeans\\nthat the initial Contributor has attached the notice described in Exhibit B to the Covered Software; or\\nthat the Covered Software was made available under the terms of version 1.1 or earlier of the License, but not also under the terms of a Secondary License.\\n1.6. “Executable Form”\\nmeans any form of the work other than Source Code Form.\\n1.7. “Larger Work”\\nmeans a work that combines Covered Software with other material, in a separate file or files, that is not Covered Software.\\n1.8. “License”\\nmeans this document.\\n1.9. “Licensable”\\nmeans having the right to grant, to the maximum extent possible, whether at the time of the initial grant or subsequently, any and all of the rights conveyed by this License.\\n1.10. “Modifications”\\nmeans any of the following:\\nany file in Source Code Form that results from an addition to, deletion from, or modification of the contents of Covered Software; or\\nany new file in Source Code Form that contains any Covered Software.\\n1.11. “Patent Claims” of a Contributor\\nmeans any patent claim(s), including without limitation, method, process, and apparatus claims, in any patent Licensable by such Contributor that would be infringed, but for the grant of the License, by the making, using, selling, offering for sale, having made, import, or transfer of either its Contributions or its Contributor Version.\\n1.12. “Secondary License”\\nmeans either the GNU General Public License, Version 2.0, the GNU Lesser General Public License, Version 2.1, the GNU Affero General Public License, Version 3.0, or any later versions of those licenses.\\n1.13. “Source Code Form”\\nmeans the form of the work preferred for making modifications.\\n1.14. “You” (or “Your”)\\nmeans an individual or a legal entity exercising rights under this License. For legal entities, “You” includes any entity that controls, is controlled by, or is under common control with You. For purposes of this definition, “control” means (a) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (b) ownership of more than fifty percent (50%) of the outstanding shares or beneficial ownership of such entity.\\nLicense Grants and Conditions\\n2.1. Grants\\nEach Contributor hereby grants You a world-wide, royalty-free, non-exclusive license:\\nunder intellectual property rights (other than patent or trademark) Licensable by such Contributor to use, reproduce, make available, modify, display, perform, distribute, and otherwise exploit its Contributions, either on an unmodified basis, with Modifications, or as part of a Larger Work; and\\nunder Patent Claims of such Contributor to make, use, sell, offer for sale, have made, import, and otherwise transfer either its Contributions or its Contributor Version.\\n2.2. Effective Date\\nThe licenses granted in Section 2.1 with respect to any Contribution become effective for each Contribution on the date the Contributor first distributes such Contribution.\\n2.3. Limitations on Grant Scope\\nThe licenses granted in this Section 2 are the only rights granted under this License. No additional rights or licenses will be implied from the distribution or licensing of Covered Software under this License. Notwithstanding Section 2.1(b) above, no patent license is granted by a Contributor:\\nfor any code that a Contributor has removed from Covered Software; or\\nfor infringements caused by: (i) Your and any other third party’s modifications of Covered Software, or (ii) the combination of its Contributions with other software (except as part of its Contributor Version); or\\nunder Patent Claims infringed by Covered Software in the absence of its Contributions.\\nThis License does not grant any rights in the trademarks, service marks, or logos of any Contributor (except as may be necessary to comply with the notice requirements in Section 3.4).\\n2.4. Subsequent Licenses\\nNo Contributor makes additional grants as a result of Your choice to distribute the Covered Software under a subsequent version of this License (see Section 10.2) or under the terms of a Secondary License (if permitted under the terms of Section 3.3).\\n2.5. Representation\\nEach Contributor represents that the Contributor believes its Contributions are its original creation(s) or it has sufficient rights to grant the rights to its Contributions conveyed by this License.\\n2.6. Fair Use\\nThis License is not intended to limit any rights You have under applicable copyright doctrines of fair use, fair dealing, or other equivalents.\\n2.7. Conditions\\nSections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in Section 2.1.\\n2.1. Grants\\nEach Contributor hereby grants You a world-wide, royalty-free, non-exclusive license:\\nunder intellectual property rights (other than patent or trademark) Licensable by such Contributor to use, reproduce, make available, modify, display, perform, distribute, and otherwise exploit its Contributions, either on an unmodified basis, with Modifications, or as part of a Larger Work; and\\nunder Patent Claims of such Contributor to make, use, sell, offer for sale, have made, import, and otherwise transfer either its Contributions or its Contributor Version.\\n2.2. Effective Date\\nThe licenses granted in Section 2.1 with respect to any Contribution become effective for each Contribution on the date the Contributor first distributes such Contribution.\\n2.3. Limitations on Grant Scope\\nThe licenses granted in this Section 2 are the only rights granted under this License. No additional rights or licenses will be implied from the distribution or licensing of Covered Software under this License. Notwithstanding Section 2.1(b) above, no patent license is granted by a Contributor:\\nfor any code that a Contributor has removed from Covered Software; or\\nfor infringements caused by: (i) Your and any other third party’s modifications of Covered Software, or (ii) the combination of its Contributions with other software (except as part of its Contributor Version); or\\nunder Patent Claims infringed by Covered Software in the absence of its Contributions.\\nThis License does not grant any rights in the trademarks, service marks, or logos of any Contributor (except as may be necessary to comply with the notice requirements in Section 3.4).\\n2.4. Subsequent Licenses\\nNo Contributor makes additional grants as a result of Your choice to distribute the Covered Software under a subsequent version of this License (see Section 10.2) or under the terms of a Secondary License (if permitted under the terms of Section 3.3).\\n2.5. Representation\\nEach Contributor represents that the Contributor believes its Contributions are its original creation(s) or it has sufficient rights to grant the rights to its Contributions conveyed by this License.\\n2.6. Fair Use\\nThis License is not intended to limit any rights You have under applicable copyright doctrines of fair use, fair dealing, or other equivalents.\\n2.7. Conditions\\nSections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in Section 2.1.\\nResponsibilities\\n3.1. Distribution of Source Form\\nAll distribution of Covered Software in Source Code Form, including any Modifications that You create or to which You contribute, must be under the terms of this License. You must inform recipients that the Source Code Form of the Covered Software is governed by the terms of this License, and how they can obtain a copy of this License. You may not attempt to alter or restrict the recipients’ rights in the Source Code Form.\\n3.2. Distribution of Executable Form\\nIf You distribute Covered Software in Executable Form then:\\nsuch Covered Software must also be made available in Source Code Form, as described in Section 3.1, and You must inform recipients of the Executable Form how they can obtain a copy of such Source Code Form by reasonable means in a timely manner, at a charge no more than the cost of distribution to the recipient; and\\nYou may distribute such Executable Form under the terms of this License, or sublicense it under different terms, provided that the license for the Executable Form does not attempt to limit or alter the recipients’ rights in the Source Code Form under this License.\\n3.3. Distribution of a Larger Work\\nYou may create and distribute a Larger Work under terms of Your choice, provided that You also comply with the requirements of this License for the Covered Software. If the Larger Work is a combination of Covered Software with a work governed by one or more Secondary Licenses, and the Covered Software is not Incompatible With Secondary Licenses, this License permits You to additionally distribute such Covered Software under the terms of such Secondary License(s), so that the recipient of the Larger Work may, at their option, further distribute the Covered Software under the terms of either this License or such Secondary License(s).\\n3.4. Notices\\nYou may not remove or alter the substance of any license notices (including copyright notices, patent notices, disclaimers of warranty, or limitations of liability) contained within the Source Code Form of the Covered Software, except that You may alter any license notices to the extent required to remedy known factual inaccuracies.\\n3.5. Application of Additional Terms\\nYou may choose to offer, and to charge a fee for, warranty, support, indemnity or liability obligations to one or more recipients of Covered Software. However, You may do so only on Your own behalf, and not on behalf of any Contributor. You must make it absolutely clear that any such warranty, support, indemnity, or liability obligation is offered by You alone, and You hereby agree to indemnify every Contributor for any liability incurred by such Contributor as a result of warranty, support, indemnity or liability terms You offer. You may include additional disclaimers of warranty and limitations of liability specific to any jurisdiction.\\n3.1. Distribution of Source Form\\nAll distribution of Covered Software in Source Code Form, including any Modifications that You create or to which You contribute, must be under the terms of this License. You must inform recipients that the Source Code Form of the Covered Software is governed by the terms of this License, and how they can obtain a copy of this License. You may not attempt to alter or restrict the recipients’ rights in the Source Code Form.\\n3.2. Distribution of Executable Form\\nIf You distribute Covered Software in Executable Form then:\\nsuch Covered Software must also be made available in Source Code Form, as described in Section 3.1, and You must inform recipients of the Executable Form how they can obtain a copy of such Source Code Form by reasonable means in a timely manner, at a charge no more than the cost of distribution to the recipient; and\\nYou may distribute such Executable Form under the terms of this License, or sublicense it under different terms, provided that the license for the Executable Form does not attempt to limit or alter the recipients’ rights in the Source Code Form under this License.\\n3.3. Distribution of a Larger Work\\nYou may create and distribute a Larger Work under terms of Your choice, provided that You also comply with the requirements of this License for the Covered Software. If the Larger Work is a combination of Covered Software with a work governed by one or more Secondary Licenses, and the Covered Software is not Incompatible With Secondary Licenses, this License permits You to additionally distribute such Covered Software under the terms of such Secondary License(s), so that the recipient of the Larger Work may, at their option, further distribute the Covered Software under the terms of either this License or such Secondary License(s).\\n3.4. Notices\\nYou may not remove or alter the substance of any license notices (including copyright notices, patent notices, disclaimers of warranty, or limitations of liability) contained within the Source Code Form of the Covered Software, except that You may alter any license notices to the extent required to remedy known factual inaccuracies.\\n3.5. Application of Additional Terms\\nYou may choose to offer, and to charge a fee for, warranty, support, indemnity or liability obligations to one or more recipients of Covered Software. However, You may do so only on Your own behalf, and not on behalf of any Contributor. You must make it absolutely clear that any such warranty, support, indemnity, or liability obligation is offered by You alone, and You hereby agree to indemnify every Contributor for any liability incurred by such Contributor as a result of warranty, support, indemnity or liability terms You offer. You may include additional disclaimers of warranty and limitations of liability specific to any jurisdiction.\\nInability to Comply Due to Statute or Regulation\\nIf it is impossible for You to comply with any of the terms of this License with respect to some or all of the Covered Software due to statute, judicial order, or regulation then You must: (a) comply with the terms of this License to the maximum extent possible; and (b) describe the limitations and the code they affect. Such description must be placed in a text file included with all distributions of the Covered Software under this License. Except to the extent prohibited by statute or regulation, such description must be sufficiently detailed for a recipient of ordinary skill to be able to understand it.\\nIf it is impossible for You to comply with any of the terms of this License with respect to some or all of the Covered Software due to statute, judicial order, or regulation then You must: (a) comply with the terms of this License to the maximum extent possible; and (b) describe the limitations and the code they affect. Such description must be placed in a text file included with all distributions of the Covered Software under this License. Except to the extent prohibited by statute or regulation, such description must be sufficiently detailed for a recipient of ordinary skill to be able to understand it.\\nTermination\\n5.1. The rights granted under this License will terminate automatically if You fail to comply with any of its terms. However, if You become compliant, then the rights granted under this License from a particular Contributor are reinstated (a) provisionally, unless and until such Contributor explicitly and finally terminates Your grants, and (b) on an ongoing basis, if such Contributor fails to notify You of the non-compliance by some reasonable means prior to 60 days after You have come back into compliance. Moreover, Your grants from a particular Contributor are reinstated on an ongoing basis if such Contributor notifies You of the non-compliance by some reasonable means, this is the first time You have received notice of non-compliance with this License from such Contributor, and You become compliant prior to 30 days after Your receipt of the notice.\\n5.2. If You initiate litigation against any entity by asserting a patent infringement claim (excluding declaratory judgment actions, counter-claims, and cross-claims) alleging that a Contributor Version directly or indirectly infringes any patent, then the rights granted to You by any and all Contributors for the Covered Software under Section 2.1 of this License shall terminate.\\n5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user license agreements (excluding distributors and resellers) which have been validly granted by You or Your distributors under this License prior to termination shall survive termination.\\n5.1. The rights granted under this License will terminate automatically if You fail to comply with any of its terms. However, if You become compliant, then the rights granted under this License from a particular Contributor are reinstated (a) provisionally, unless and until such Contributor explicitly and finally terminates Your grants, and (b) on an ongoing basis, if such Contributor fails to notify You of the non-compliance by some reasonable means prior to 60 days after You have come back into compliance. Moreover, Your grants from a particular Contributor are reinstated on an ongoing basis if such Contributor notifies You of the non-compliance by some reasonable means, this is the first time You have received notice of non-compliance with this License from such Contributor, and You become compliant prior to 30 days after Your receipt of the notice.\\n5.2. If You initiate litigation against any entity by asserting a patent infringement claim (excluding declaratory judgment actions, counter-claims, and cross-claims) alleging that a Contributor Version directly or indirectly infringes any patent, then the rights granted to You by any and all Contributors for the Covered Software under Section 2.1 of this License shall terminate.\\n5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user license agreements (excluding distributors and resellers) which have been validly granted by You or Your distributors under this License prior to termination shall survive termination.\\nDisclaimer of Warranty\\nCovered Software is provided under this License on an “as is” basis, without warranty of any kind, either expressed, implied, or statutory, including, without limitation, warranties that the Covered Software is free of defects, merchantable, fit for a particular purpose or non-infringing. The entire risk as to the quality and performance of the Covered Software is with You. Should any Covered Software prove defective in any respect, You (not any Contributor) assume the cost of any necessary servicing, repair, or correction. This disclaimer of warranty constitutes an essential part of this License. No use of any Covered Software is authorized under this License except under this disclaimer.\\nCovered Software is provided under this License on an “as is” basis, without warranty of any kind, either expressed, implied, or statutory, including, without limitation, warranties that the Covered Software is free of defects, merchantable, fit for a particular purpose or non-infringing. The entire risk as to the quality and performance of the Covered Software is with You. Should any Covered Software prove defective in any respect, You (not any Contributor) assume the cost of any necessary servicing, repair, or correction. This disclaimer of warranty constitutes an essential part of this License. No use of any Covered Software is authorized under this License except under this disclaimer.\\nLimitation of Liability\\nUnder no circumstances and under no legal theory, whether tort (including negligence), contract, or otherwise, shall any Contributor, or anyone who distributes Covered Software as permitted above, be liable to You for any direct, indirect, special, incidental, or consequential damages of any character including, without limitation, damages for lost profits, loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses, even if such party shall have been informed of the possibility of such damages. This limitation of liability shall not apply to liability for death or personal injury resulting from such party’s negligence to the extent applicable law prohibits such limitation. Some jurisdictions do not allow the exclusion or limitation of incidental or consequential damages, so this exclusion and limitation may not apply to You.\\nUnder no circumstances and under no legal theory, whether tort (including negligence), contract, or otherwise, shall any Contributor, or anyone who distributes Covered Software as permitted above, be liable to You for any direct, indirect, special, incidental, or consequential damages of any character including, without limitation, damages for lost profits, loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses, even if such party shall have been informed of the possibility of such damages. This limitation of liability shall not apply to liability for death or personal injury resulting from such party’s negligence to the extent applicable law prohibits such limitation. Some jurisdictions do not allow the exclusion or limitation of incidental or consequential damages, so this exclusion and limitation may not apply to You.\\nLitigation\\nAny litigation relating to this License may be brought only in the courts of a jurisdiction where the defendant maintains its principal place of business and such litigation shall be governed by laws of that jurisdiction, without reference to its conflict-of-law provisions. Nothing in this Section shall prevent a party’s ability to bring cross-claims or counter-claims.\\nAny litigation relating to this License may be brought only in the courts of a jurisdiction where the defendant maintains its principal place of business and such litigation shall be governed by laws of that jurisdiction, without reference to its conflict-of-law provisions. Nothing in this Section shall prevent a party’s ability to bring cross-claims or counter-claims.\\nMiscellaneous\\nThis License represents the complete agreement concerning the subject matter hereof. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable. Any law or regulation which provides that the language of a contract shall be construed against the drafter shall not be used to construe this License against a Contributor.\\nThis License represents the complete agreement concerning the subject matter hereof. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable. Any law or regulation which provides that the language of a contract shall be construed against the drafter shall not be used to construe this License against a Contributor.\\nVersions of the License\\n10.1. New Versions\\nMozilla Foundation is the license steward. Except as provided in Section 10.3, no one other than the license steward has the right to modify or publish new versions of this License. Each version will be given a distinguishing version number.\\n10.2. Effect of New Versions\\nYou may distribute the Covered Software under the terms of the version of the License under which You originally received the Covered Software, or under the terms of any subsequent version published by the license steward.\\n10.3. Modified Versions\\nIf you create software not governed by this License, and you want to create a new license for such software, you may create and use a modified version of this License if you rename the license and remove any references to the name of the license steward (except to note that such modified license differs from this License).\\n10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses\\nIf You choose to distribute Source Code Form that is Incompatible With Secondary Licenses under the terms of this version of the License, the notice described in Exhibit B of this License must be attached.\\nExhibit A - Source Code Form License Notice\\nThis Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at\\nhttp://mozilla.org/MPL/2.0/\\n.\\nIf it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice.\\nYou may add additional accurate notices of copyright ownership.\\nExhibit B - “Incompatible With Secondary Licenses” Notice\\nThis Source Code Form is “Incompatible With Secondary Licenses”, as defined by the Mozilla Public License, v. 2.0.\\n10.1. New Versions\\nMozilla Foundation is the license steward. Except as provided in Section 10.3, no one other than the license steward has the right to modify or publish new versions of this License. Each version will be given a distinguishing version number.\\n10.2. Effect of New Versions\\nYou may distribute the Covered Software under the terms of the version of the License under which You originally received the Covered Software, or under the terms of any subsequent version published by the license steward.\\n10.3. Modified Versions\\nIf you create software not governed by this License, and you want to create a new license for such software, you may create and use a modified version of this License if you rename the license and remove any references to the name of the license steward (except to note that such modified license differs from this License).\\n10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses\\nIf You choose to distribute Source Code Form that is Incompatible With Secondary Licenses under the terms of this version of the License, the notice described in Exhibit B of this License must be attached.\\nExhibit A - Source Code Form License Notice\\nThis Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at\\nhttp://mozilla.org/MPL/2.0/\\n.\\nIf it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice.\\nYou may add additional accurate notices of copyright ownership.\\nExhibit B - “Incompatible With Secondary Licenses” Notice\\nThis Source Code Form is “Incompatible With Secondary Licenses”, as defined by the Mozilla Public License, v. 2.0.\\nNinject is intended to be used in both open-source and commercial environments. To allow its use in as many situations as possible, Ninject is dual-licensed. You may choose to use Ninject under either the Apache License, Version 2.0, or the Microsoft Public License (Ms-PL). These licenses are essentially identical, but you are encouraged to evaluate both to determine which best fits your intended use.\\nUsed by: nodejs\\nCopyright Joyent, Inc. and other Node contributors. All rights reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\nThis license applies to all parts of Node that are\\nnot\\nexternally maintained libraries.\\nThe externally maintained libraries used by Node are:\\n- V8, located at deps/v8. V8\\'s license follows:\\nThis license applies to all parts of V8 that are not externally maintained libraries. The externally maintained libraries used by V8 are:\\n- PCRE test suite, located in test/mjsunit/third_party/regexp-pcre.js. This is based on the test suite from PCRE-7.3, which is copyrighted by the University of Cambridge and Google, Inc. The copyright notice and license are embedded in regexp-pcre.js.\\n- Layout tests, located in test/mjsunit/third_party. These are based on layout tests from\\nwebkit.org\\nwhich are copyrighted by Apple Computer, Inc. and released under a 3-clause BSD license.\\n- Strongtalk assembler, the basis of the files assembler-arm-inl.h,\\nassembler-arm.cc\\n, assembler-arm.h, assembler-ia32-inl.h,\\nassembler-ia32.cc\\n, assembler-ia32.h, assembler-x64-inl.h,\\nassembler-x64.cc\\n, assembler-x64.h, assembler-mips-inl.h,\\nassembler-mips.cc\\n, assembler-mips.h,\\nassembler.cc\\nand assembler.h.\\nThis code is copyrighted by Sun Microsystems Inc. and released under a 3-clause BSD license.\\n- Valgrind client API header, located at third_party/valgrind/valgrind.h\\nThis is release under the BSD license.\\nFor additional licenses on externally maintained libraries, see\\nhttps://raw.github.com/joyent/node/master/LICENSE\\n.\\nThe OpenSSL toolkit stays under a dual license, i.e. both the conditions of the OpenSSL License and the original SSLeay license apply to the toolkit. See below for the actual license texts. Actually both licenses are BSD-style Open Source licenses. In case of any license issues related to OpenSSL please contact\\nopenssl-core@openssl.org\\n.\\nOpenSSL License\\nCopyright © 1998-2011 The OpenSSL Project. All rights reserved.\\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\\nAll advertising materials mentioning features or use of this software must display the following acknowledgment:\\n\"This product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit. (\\nhttp://www.openssl.org/\\n)\"\\n\"This product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit. (\\nhttp://www.openssl.org/\\n)\"\\nThe names \"OpenSSL Toolkit\" and \"OpenSSL Project\" must not be used to endorse or promote products derived from this software without prior written permission. For written permission, please contact\\nopenssl-core@openssl.org\\n.\\nProducts derived from this software may not be called \"OpenSSL\" nor may \"OpenSSL\" appear in their names without prior written permission of the OpenSSL Project.\\nRedistributions of any form whatsoever must retain the following acknowledgment:\\n\"This product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit (\\nhttp://www.openssl.org/\\n)\"\\n\"This product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit (\\nhttp://www.openssl.org/\\n)\"\\nTHIS SOFTWARE IS PROVIDED BY THE OpenSSL PROJECT ``AS IS\\'\\' AND ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE OpenSSL PROJECT OR ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n====================================================================\\nThis product includes cryptographic software written by Eric Young (eay@\\ncryptsoft.com\\n).\\nThis product includes software written by Tim Hudson (tjh@\\ncryptsoft.com\\n).\\nUsed by: font awesome\\nVersion 1.1 - 26 February 2007\\nPREAMBLE\\nThe goals of the Open Font License (OFL) are to stimulate worldwide development of collaborative font projects, to support the font creation efforts of academic and linguistic communities, and to provide a free and open framework in which fonts may be shared and improved in partnership with others.\\nThe OFL allows the licensed fonts to be used, studied, modified and redistributed freely as long as they are not sold by themselves. The fonts, including any derivative works, can be bundled, embedded, redistributed and/or sold with any software provided that any reserved names are not used by derivative works. The fonts and derivatives, however, cannot be released under any other type of license. The requirement for fonts to remain under this license does not apply to any document created using the fonts or their derivatives.\\nDEFINITIONS\\n\"Font Software\" refers to the set of files released by the Copyright Holder(s) under this license and clearly marked as such. This may include source files, build scripts and documentation.\\n\"Reserved Font Name\" refers to any names specified as such after the copyright statement(s).\\n\"Original Version\" refers to the collection of Font Software components as distributed by the Copyright Holder(s).\\n\"Modified Version\" refers to any derivative made by adding to, deleting, or substituting — in part or in whole — any of the components of the Original Version, by changing formats or by porting the Font Software to a new environment.\\n\"Author\" refers to any designer, engineer, programmer, technical writer or other person who contributed to the Font Software.\\nPERMISSION & CONDITIONS\\nPermission is hereby granted, free of charge, to any person obtaining a copy of the Font Software, to use, study, copy, merge, embed, modify, redistribute, and sell modified and unmodified copies of the Font Software, subject to the following conditions:\\nNeither the Font Software nor any of its individual components, in Original or Modified Versions, may be sold by itself.\\nOriginal or Modified Versions of the Font Software may be bundled, redistributed and/or sold with any software, provided that each copy contains the above copyright notice and this license. These can be included either as stand-alone text files, human-readable headers or in the appropriate machine-readable metadata fields within text or binary files as long as those fields can be easily viewed by the user.\\nNo Modified Version of the Font Software may use the Reserved Font Name(s) unless explicit written permission is granted by the corresponding Copyright Holder. This restriction only applies to the primary font name as presented to the users.\\nThe name(s) of the Copyright Holder(s) or the Author(s) of the Font Software shall not be used to promote, endorse or advertise any Modified Version, except to acknowledge the contribution(s) of the Copyright Holder(s) and the Author(s) or with their explicit written permission.\\nThe Font Software, modified or unmodified, in part or in whole, must be distributed entirely under this license, and must not be distributed under any other license. The requirement for fonts to remain under this license does not apply to any document created using the Font Software.\\nTERMINATION\\nThis license becomes null and void if any of the above conditions are not met.\\nDISCLAIMER\\nTHE FONT SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF COPYRIGHT, PATENT, TRADEMARK, OR OTHER RIGHT. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\\nINCLUDING ANY GENERAL, SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF THE USE OR INABILITY TO USE THE FONT SOFTWARE OR FROM OTHER DEALINGS IN THE FONT SOFTWARE.\\nUsed by: zmq\\nCopyright © 2011 TJ Holowaychuk\\nCopyright © 2010, 2011 Justin Tulloss\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n/* zlib.h -- interface of the \\'zlib\\' general purpose compression library\\nversion 1.2.8, April 28th, 2013\\nCopyright © 1995-2013 Jean-loup Gailly and Mark Adler\\nThis software is provided \\'as-is\\', without any express or implied warranty. In no event will the authors be held liable for any damages arising from the use of this software. Permission is granted to anyone to use this software for any purpose, including commercial applications, and to alter it and redistribute it freely, subject to the following restrictions:\\nThe origin of this software must not be misrepresented; you must not claim that you wrote the original software. If you use this software in a product, an acknowledgment in the product documentation would be appreciated but is not required.\\nAltered source versions must be plainly marked as such, and must not be misrepresented as being the original software.\\nThis notice may not be removed or altered from any source distribution.\\nJean-loup Gailly Mark Adler\\njloup@gzip.org\\nmadler@alumni.caltech.edu\\n*/\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nFind More Information\\n', 'Upgrade FAQ and Determining the Correct Upgrade Path': '', \"Where Is LogRhythm's Software and Hardware End of Life Policy?\": 'Our EOL policy for hardware and software can be found on our\\nDocuments\\nsite. Here you will find details on the various LogRhythm versions.\\nYou will notice a few key callouts in the document:\\nEnd of Sale (EoS).\\nWhen a product release version reaches End of Sale, the version will no longer be available for sale.\\nEnd of Sale (EoS).\\nWhen a product release version reaches End of Sale, the version will no longer be available for sale.\\nEnd of Support Life (EoSL).\\nWhen a product release version reaches End of Support Life, it will no longer be supported by LogRhythm’s technical support services.\\nEnd of Support Life (EoSL).\\nWhen a product release version reaches End of Support Life, it will no longer be supported by LogRhythm’s technical support services.\\nThis document also\\nexplains the differences between major and minor patches, which will help you in identifying\\xa0the version you are running.\\n', 'Importance of Keeping Up to Date': 'Like all software, it is important to keep up to date with versions. With each version release, there are often security updates, patches, defects resolved and, of course, new features. In order for our Support and Engineering teams to engage and assist, the deployment needs to be on a supported version of the product.\\n', 'Where Can I Request an Upgrade License?': 'Please visit our website and fill in the\\nlicense request form\\n. You will need it before you upgrade. Our Fulfillment team will generate and send it to you by email.\\n', 'Where Can I Find Upgrade Information, Documentation, and Files?': 'Customers with a current support contract are able to download upgrades from our\\nDocuments and Downloads\\nsection on the Community site. You can either upgrade yourself using the guides or engage our Professional Services team to perform the upgrade. More on this follows.\\n', 'How Can I Upgrade?': \"You have a couple of options for upgrading your deployment:\\nYou can follow the lengthy upgrade documentation on our Community site to perform the upgrade yourself. Please pay particular attention to the upgrade paths. If you run into any challenges when upgrading, please log a support case though the Support Portal. Our global support team will be happy to help you.\\nOur Professional Services team can perform the upgrade for you as a billable service.\\nIf you don't already have an open project with Professional Services, please contact your Customer Success Manager or your account representative to scope and purchase this service.\\nIf you have an open project, please work with your assigned Project Manager to determine if this upgrade can be worked into your existing scope and schedule. If you don't know your Project Manager, please use one of the following aliases.\\nIf you don't already have an open project with Professional Services, please contact your Customer Success Manager or your account representative to scope and purchase this service.\\nIf you have an open project, please work with your assigned Project Manager to determine if this upgrade can be worked into your existing scope and schedule. If you don't know your Project Manager, please use one of the following aliases.\\nRegion, Email Address\\nNorth and South America, projectmgmt@logrhythm.com\\nEurope, Middle East, and India, projectmgmt.emea@logrhythm.com\\nAsia and Australia, projectmgmt.apj@logrhythm.com\\nprojectmgmt@logrhythm.com\\nEurope, Middle East, and India\\nprojectmgmt.emea@logrhythm.com\\nAsia and Australia\\nprojectmgmt.apj@logrhythm.com\\n\", 'How Do I Determine What Version of SIEM or Network Monitor I Am Running?': '', 'SIEM': 'SIEM Version, Upgrade Path, Description, Supported Hardware\\n5.x, 6.2.5, If you are on a version prior to 6.3, please contact your CSM atcsm@logrhythm.comto determine your upgrade path., Gen 1 and Gen 2\\n6.0.x to 6.3.3, 6.3.9, If you are on a version prior to 6.3, please contact your CSM atcsm@logrhythm.comto determine your upgrade path., Gen 2 and Gen 3\\n6.3.4 to 6.3.9, 7.4.10, Due to switching from SQL to Elasticsearch, you will not be able to keep your current online data., Gen 3 and Gen 4\\n7.1.x, 7.2.7, Due to upgrading the version of Elasticsearch between these versions, you will need to wait for the duration of your current TTL (30-90 days) for all 7.1 (ES 1) indices to TTL out (ES 1 indices will work on ES 2.3 /7.2). If you do not wish to keep your Elasticsearch indices, you may upgrade just the databases to 7.4.10, then continue to 7.8.0, Gen 3 and Gen 4\\n7.2.x, 7.4.10, Due to upgrading the version of Elasticsearch between these versions, you will need to wait for all 7.2. (ES 2.3) indices to TTL out (ES 2.3 indices will work on ES 5.5.6 /7.4). If you do not wish to keep your Elasticsearch indices, you may upgrade the database only to 7.4.10, then continue to 7.8.0., Gen 3, Gen 4, and Gen 5\\n7.3.x, 7.4.10, You do not need to upgrade anything other than the databases prior to upgrading to 7.8.0., Gen 3, Gen 4 and Gen 5\\n7.4.10 to 7.12.x, 7.13.0, Fully supported upgrade path., Gen 4 and Gen 5\\n7.4.10 to 7.13.x, 7.14.0, Fully supported upgrade path., Gen 4, Gen 5, and Gen 6\\n\\nFollowing is a visual of the SIEM table. To determine the versions you need to upgrade to get to the latest SIEM version, find the version of LogRhythm SIEM you are running and follow the arrows.\\n\\n', 'NetMon': 'For NetMon, we have a table that details the paths.\\nTo find the version of the SIEM you are running, use the previous SIEM table.\\nTo find your NetMon version, use the following NetMon table.\\nTo find the version you need to go to next, browse the Upgrade Path column in the\\xa0NetMon table.\\nFor older versions, you may need to perform a hop2 upgrade to a version before being able to proceed to the next/latest version.\\nTo find the version you need to go to next, browse the Upgrade Path column in the\\xa0NetMon table.\\nFor older versions, you may need to perform a hop2 upgrade to a version before being able to proceed to the next/latest version.\\nNetMon Version, Upgrade Path, Description\\nVersions earlier than 2.6.1, Not supported, An upgrade path for versions earlier than 2.6.1 is not recommended. To upgrade, perform a new installation with version 4.0.3.\\nVersions 2.6.1 to 2.8.1, Upgrade to 2.8.2, A CentOS dependency requires you to upgrade to 2.8.2 before continuing the upgrade process.\\nVersions 2.8.2 to 3.2.1, Upgrade to 3.2.2, A CentOS 7.2 upgrade requires you to upgrade to 3.2.2 before continuing the upgrade process.\\nVersion 3.2.2, Upgrade to 3.2.3, A user interface change requires to upgrade to 3.2.3 before continuing the upgrade process.\\nVersion 3.2.3, Upgrade to 3.6.1, In previous versions of NetMon, upgrading to the newest version could reset your custom engine configuration settings to the NetMon defaults. Starting in NetMon 3.6.1 and in all future releases, upgrades will not change your custom settings back to the default valuesNetMon 3.6.2 was a critical security update, and all users running older versions of NetMon should upgrade to 3.6.2 or later as soon as possible.\\nVersions\\xa03.6.1 to 3.9.3, Upgrade to 4.0.1, If upgrading from a pre-3.9.1 release, a new security certificate is included with the install. In this case, the upgrade page does not automatically refresh after the system reboots. The upgrade usually takes about 15 minutes, after which you must manually refresh your browser and log in to NetMon again,The upgrade to NetMon 4.0.1 is a best-effort migration of existing Elasticsearch 1.7 data into Elasticsearch 7.2.Re-indexing Elasticsearch 1.7 data to Elasticsearch 7.2 takes significant time up to several hours per 10 GB of metadata, depending on the size of the indices.\\nVersions 4.0.1 to 4.0.4, Upgrade to 4.0.5, If you are upgrading from NetMon 3.6.1 - 3.9.3 and performed the intermediate upgrade step to NetMon 4.0.1, you must wait until the 4.0.1 nm-reindexer process finishes before upgrading to 4.0.5. The 4.0.1 nm-reindexer process migrates the previous Elasticsearch 1.7 indices to the Elasticsearch 7.2 index format.\\nVersion 4.0.5, Upgrade to 4.0.6, If you are running version 4.0.1 - 4.0.4, upgrade directly to 4.0.5 before upgrading to 4.0.6. If you are running NetMon 3.6.1 - 3.9.3, you must first upgrade to version 4.0.1 before continuing the upgrade to 4.0.5, then upgrade to 4.0.6.\\nNetMon Version\\nUpgrade Path\\nDescription\\nVersions earlier than 2.6.1\\nNot supported\\nAn upgrade path for versions earlier than 2.6.1 is not recommended. To upgrade, perform a new installation with version 4.0.3.\\nVersions 2.6.1 to 2.8.1\\nUpgrade to 2.8.2\\nA CentOS dependency requires you to upgrade to 2.8.2 before continuing the upgrade process.\\nVersions 2.8.2 to 3.2.1\\nUpgrade to 3.2.2\\nA CentOS 7.2 upgrade requires you to upgrade to 3.2.2 before continuing the upgrade process.\\nVersion 3.2.2\\nUpgrade to 3.2.3\\nA user interface change requires to upgrade to 3.2.3 before continuing the upgrade process.\\nVersion 3.2.3\\nUpgrade to 3.6.1\\nIn previous versions of NetMon, upgrading to the newest version could reset your custom engine configuration settings to the NetMon defaults. Starting in NetMon 3.6.1 and in all future releases, upgrades will not change your custom settings back to the default values\\nNetMon 3.6.2 was a critical security update, and all users running older versions of NetMon should upgrade to 3.6.2 or later as soon as possible.\\nVersions\\xa03.6.1 to 3.9.3\\nUpgrade to 4.0.1\\nIf upgrading from a pre-3.9.1 release, a new security certificate is included with the install. In this case, the upgrade page does not automatically refresh after the system reboots. The upgrade usually takes about 15 minutes, after which you must manually refresh your browser and log in to NetMon again,\\nThe upgrade to NetMon 4.0.1 is a best-effort migration of existing Elasticsearch 1.7 data into Elasticsearch 7.2.\\nRe-indexing Elasticsearch 1.7 data to Elasticsearch 7.2 takes significant time up to several hours per 10 GB of metadata, depending on the size of the indices.\\nVersions 4.0.1 to 4.0.4\\nUpgrade to 4.0.5\\nIf you are upgrading from NetMon 3.6.1 - 3.9.3 and performed the intermediate upgrade step to NetMon 4.0.1, you must wait until the 4.0.1 nm-reindexer process finishes before upgrading to 4.0.5. The 4.0.1 nm-reindexer process migrates the previous Elasticsearch 1.7 indices to the Elasticsearch 7.2 index format.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n', 'Which Generation of LR Appliance or Software Equivalent Am I Running?': '', 'LogRhythm Appliance': 'Version, Original Release Date, End of Sale, End of Support Life, Appliances Included\\nGen 6, October 2023, TBD, Five years from Date of Sale, The Gen6 Hardware generation is designated by the\\nGen5, July 2018, TBD, Five years from Date of Sale, The Gen5 Hardware generation is designated by the second number in the product code (e.g., XM4550, PM7500, DX5500).\\nGen4, July 2014, September 2018, Five yearsfrom Date of Sale, The Gen4 Hardware generation is designated by the second number in the product code (e.g., XM4410, PM7410, DX5410).\\nGen3, March 2013, July 2016, Five yearsfrom Date of Sale, The Gen3 Hardware generation is designated by the second number in the product code (e.g., XM4310, EM5350, LM7310).\\nGen2 (LRX), August 2009, April 2013, Five yearsfrom Date of Sale, The Gen2 Hardware generation products are all prefixed with LRX (e.g.,LRX1,LRX2, andLRX3)\\nGen1 (LR), August 2006, November 2009, Five yearsfrom Date of Sale, The Gen1 Hardware generation includes the LR500, LR1000, and LR2000 product series.\\nThe Gen5 Hardware generation is designated by the second number in the product code (e.g., XM4\\n5\\n50, PM7\\n5\\n00, DX5\\n5\\n00).\\nThe Gen4 Hardware generation is designated by the second number in the product code (e.g., XM4\\n4\\n10, PM7\\n4\\n10, DX5\\n4\\n10).\\nThe Gen3 Hardware generation is designated by the second number in the product code (e.g., XM4\\n3\\n10, EM5\\n3\\n50, LM7\\n3\\n10).\\n', 'LogRhythm Software': 'In this scenario, the customer provides the hardware, virtual machine, or cloud infrastructure to install the LogRhythm software. For software installs, we have supported specification in our install guides. These align to the hardware models mentioned previously. Please ensure that the specifications support the latest versions.\\n', 'How Do I Get to the Latest Version? What Are My Upgrade Paths?': 'To find the version of the SIEM you are running, use the previous LogRhythm Appliance\\xa0table.\\nTo find your SIEM version, use the following SIEM\\xa0table.\\nTo find the version you need, browse the Upgrade Path column in the SIEM table.\\nFor older versions, you may need to perform a hop2 upgrade to a version before being able to proceed to the next/latest version.\\nTo find the version you need, browse the Upgrade Path column in the SIEM table.\\nFor older versions, you may need to perform a hop2 upgrade to a version before being able to proceed to the next/latest version.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nGet Started with LogRhythm SIEM\\n', 'Assign LogRhythm Licenses': 'Licenses determine how many Data Processors can operate in the LogRhythm installation and how many Messages Per Second (MPS) can be processed by the Data Processors. The licenses are assigned to a data processor through the Data Processor Properties dialog box.\\n', 'Import LogRhythm Licenses': 'Only Global Admins or Restricted Admins with elevated View and Manage privileges can take this action.\\nIf you need to update your LogRhythm license, you can import a new license file. You must update your license when:\\nYou upgrade to a new LogRhythm version that is not supported by the current license.\\nYour evaluation period expires.\\nYou purchase a new license or add-on components.\\nTo import a license file, do the following:\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nOn the File menu, click\\nImport License File\\n.\\nBrowse to and select your license file, and then click\\nOpen\\n.\\n', 'License a Data Processor': 'You must be logged in as an Administrator to take this action.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nData Processors\\ntab.\\nRight-click a Data Processor to license, and then click\\nProperties\\n.\\nThe Data Processor Properties dialog box appears.\\nClick\\nLicensing Wizard\\n.\\nFollow the steps of the wizard to complete the process.\\nClick\\nOK\\nwhen the process is complete.\\n', 'Remove a License from a Data Processor': 'You must be logged in as an Administrator to take this action.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nData Processor\\ntab.\\nRight-click a Data Processor to unlicense, and then click\\nProperties\\n.\\nThe Data Processor Properties dialog box appears.\\nClick\\nRemove License\\n.\\nNo confirmation prompt appears.\\nClick\\nOK\\n.\\n', 'Assign System Monitor Licenses': 'You must be logged in as an Administrator to take this action.\\nLogRhythm Agent licenses can be assigned and reclaimed via the System Monitors tab of the Deployment Manager:\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nSystem Monitors\\ntab.\\nTo license a LogRhythm Agent:\\nSelect the\\nAction\\ncheck box for the Agent you wish to license.\\nRight-click the entry.\\nClick\\nActions\\n, click\\nLicense\\n, and then select one of the following:\\nSystem Monitor Lite\\nSystem Monitor Pro\\nSystem Monitor Collector\\nTo license a LogRhythm Agent:\\nSelect the\\nAction\\ncheck box for the Agent you wish to license.\\nRight-click the entry.\\nClick\\nActions\\n, click\\nLicense\\n, and then select one of the following:\\nSystem Monitor Lite\\nSystem Monitor Pro\\nSystem Monitor Collector\\nSystem Monitor Lite\\nSystem Monitor Pro\\nSystem Monitor Collector\\nTo remove a LogRhythm Agent License:\\nSelect the\\nAction\\ncheck box for the Agent you wish to unlicense.\\nRight-click the entry.\\nClick\\nActions\\n, and then click\\nUnlicense\\n.\\nTo remove a LogRhythm Agent License:\\nSelect the\\nAction\\ncheck box for the Agent you wish to unlicense.\\nRight-click the entry.\\nClick\\nActions\\n, and then click\\nUnlicense\\n.\\n', 'View LogRhythm License Report': 'The License Report shows a list of licenses grouped by type, along with values for the total quantity purchased, the number assigned, and the remaining available. The report is grouped by expiration date. Licenses that expire fall within a sub-report for that expiration date. This also includes the License Metering Report, which shows MPS rates and overages for the period.\\nTo view a license report:\\nOn the Help menu, click\\nAbout LogRhythm\\n.\\nClick\\nLicense Report\\n.\\nThe Report Viewer appears.\\nThe report can be printed or exported as a Crystal Report, PDF, Excel, Word, or RTF file.\\nThe Report Viewer appears.\\nThe report can be printed or exported as a Crystal Report, PDF, Excel, Word, or RTF file.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nGet Started with LogRhythm SIEM\\n', 'Complete the New Deployment Wizard': 'The first time you log in to the Client Console after an appliance is installed/configured, or after a new software installation, the New Deployment Wizard guides you through the initial configuration steps. The wizard prompts you for information to initialize the Platform Manager (PM) and locate specific files that are loaded into the system to begin the configuration of LogRhythm.\\nAll new deployments should only be completed by LogRhythm authorized staff. Failure to do so could leave your system in an unsupported state.\\nOn the first screen, complete the following:\\nWindows host name for Platform Manager\\n. In this field, enter the host name where the Platform Manager is located. To find the host name:\\nSearch\\nMy Computer\\non your machine, right-click it, and select\\nProperties\\n.\\nCopy the Full Computer Name up to the first period where the domain name starts.\\nIP Address for the Platform Manager\\n. In this field, enter the IP address where the Platform Manager is located. Appliances are shipped with two Network Interface Cards (NICs). Typically, each NIC serves a purpose: one for Client Console connections and one for database intercommunication. The IP address entered here serves as a Client Console connection interface.\\nThe default port number used by the Platform Manager is 1433. To configure a different port number, use the following syntax in the IP Address for the Platform Manager field:<IPADDRESS;PORT #> 1.100.1.92;50 - Separate the IP number and the Port number with a semicolon.\\nThe Platform Manager is also a Data Processor (e.g. an XM appliance)\\n. Select this check box if the Platform Manager is also a Data Processor. To make this determination:\\nIf the appliance type is an XM, the Platform Manager and all other LogRhythm components are contained in a single appliance. Ensure the check box is selected.\\nIf the Platform Manager is on a separate Platform Manager appliance, clear the check box.\\nThe Platform Manager is also an AI Engine Server\\n. Select this check box if the Platform Manager is also an AI Engine Server. To make this determination:\\nIf the AI Engine Server is on the Platform Manager (such as a standalone Platform Manager or an XM), select the check box.\\nIf the AI Engine Server is on a separate AI Engine appliance, clear the check box.\\nLogMart DB Server Override\\n. This setting is disabled as the IP address of LogMart machine is always the same as the IP address of the Platform Manager machine.\\nThis option is to be used only under the supervision of LogRhythm Inc. Professional Services.\\nThe Platform Manager is also a Job Manager Server.\\nSelect this check box if the Platform Manager is also a Job Manager. To make this determination:\\nIf the appliance type is an XM, the Platform Manager and all other LogRhythm components are contained in a single appliance. Ensure the check box is selected.\\nIf you installed the Job Manager is on a separate appliance, leave the check box cleared and then complete the following:\\nWindows Host name for Job Manager.\\nIn this field, enter the host name where the Platform Manager is located. To find the host name:\\nSearch\\nMy Computer\\non your machine, right-click it, and select\\nProperties\\n.\\nCopy the Full Computer Name up to the first period where the domain name starts.\\nIP Address for Job Manager.\\nIn this field, enter the IP address where the Job Manager is located.\\nLogRhythm License File\\n. Use this field to load the LogRhythm License file provided by LogRhythm Support after the purchase and shipment of the appliance(s).\\nClick the ellipsis [...] button on the right side of the field.\\nLocate and select the master license file.\\nClick\\nOpen\\n.\\nThe path and file name appear in the LogRhythm License File text box.\\nThis file is required to access and configure LogRhythm.\\nWindows host name for Platform Manager\\n. In this field, enter the host name where the Platform Manager is located. To find the host name:\\nSearch\\nMy Computer\\non your machine, right-click it, and select\\nProperties\\n.\\nCopy the Full Computer Name up to the first period where the domain name starts.\\nSearch\\nMy Computer\\non your machine, right-click it, and select\\nProperties\\n.\\nCopy the Full Computer Name up to the first period where the domain name starts.\\nIP Address for the Platform Manager\\n. In this field, enter the IP address where the Platform Manager is located. Appliances are shipped with two Network Interface Cards (NICs). Typically, each NIC serves a purpose: one for Client Console connections and one for database intercommunication. The IP address entered here serves as a Client Console connection interface.\\nThe default port number used by the Platform Manager is 1433. To configure a different port number, use the following syntax in the IP Address for the Platform Manager field:<IPADDRESS;PORT #> 1.100.1.92;50 - Separate the IP number and the Port number with a semicolon.\\nIP Address for the Platform Manager\\n. In this field, enter the IP address where the Platform Manager is located. Appliances are shipped with two Network Interface Cards (NICs). Typically, each NIC serves a purpose: one for Client Console connections and one for database intercommunication. The IP address entered here serves as a Client Console connection interface.\\nThe Platform Manager is also a Data Processor (e.g. an XM appliance)\\n. Select this check box if the Platform Manager is also a Data Processor. To make this determination:\\nIf the appliance type is an XM, the Platform Manager and all other LogRhythm components are contained in a single appliance. Ensure the check box is selected.\\nIf the Platform Manager is on a separate Platform Manager appliance, clear the check box.\\nIf the appliance type is an XM, the Platform Manager and all other LogRhythm components are contained in a single appliance. Ensure the check box is selected.\\nIf the Platform Manager is on a separate Platform Manager appliance, clear the check box.\\nThe Platform Manager is also an AI Engine Server\\n. Select this check box if the Platform Manager is also an AI Engine Server. To make this determination:\\nIf the AI Engine Server is on the Platform Manager (such as a standalone Platform Manager or an XM), select the check box.\\nIf the AI Engine Server is on a separate AI Engine appliance, clear the check box.\\nIf the AI Engine Server is on the Platform Manager (such as a standalone Platform Manager or an XM), select the check box.\\nIf the AI Engine Server is on a separate AI Engine appliance, clear the check box.\\nLogMart DB Server Override\\n. This setting is disabled as the IP address of LogMart machine is always the same as the IP address of the Platform Manager machine.\\nThis option is to be used only under the supervision of LogRhythm Inc. Professional Services.\\nLogMart DB Server Override\\n. This setting is disabled as the IP address of LogMart machine is always the same as the IP address of the Platform Manager machine.\\nThe Platform Manager is also a Job Manager Server.\\nSelect this check box if the Platform Manager is also a Job Manager. To make this determination:\\nIf the appliance type is an XM, the Platform Manager and all other LogRhythm components are contained in a single appliance. Ensure the check box is selected.\\nIf you installed the Job Manager is on a separate appliance, leave the check box cleared and then complete the following:\\nWindows Host name for Job Manager.\\nIn this field, enter the host name where the Platform Manager is located. To find the host name:\\nSearch\\nMy Computer\\non your machine, right-click it, and select\\nProperties\\n.\\nCopy the Full Computer Name up to the first period where the domain name starts.\\nIP Address for Job Manager.\\nIn this field, enter the IP address where the Job Manager is located.\\nIf the appliance type is an XM, the Platform Manager and all other LogRhythm components are contained in a single appliance. Ensure the check box is selected.\\nIf you installed the Job Manager is on a separate appliance, leave the check box cleared and then complete the following:\\nWindows Host name for Job Manager.\\nIn this field, enter the host name where the Platform Manager is located. To find the host name:\\nSearch\\nMy Computer\\non your machine, right-click it, and select\\nProperties\\n.\\nCopy the Full Computer Name up to the first period where the domain name starts.\\nIP Address for Job Manager.\\nIn this field, enter the IP address where the Job Manager is located.\\nWindows Host name for Job Manager.\\nIn this field, enter the host name where the Platform Manager is located. To find the host name:\\nSearch\\nMy Computer\\non your machine, right-click it, and select\\nProperties\\n.\\nCopy the Full Computer Name up to the first period where the domain name starts.\\nSearch\\nMy Computer\\non your machine, right-click it, and select\\nProperties\\n.\\nCopy the Full Computer Name up to the first period where the domain name starts.\\nIP Address for Job Manager.\\nIn this field, enter the IP address where the Job Manager is located.\\nLogRhythm License File\\n. Use this field to load the LogRhythm License file provided by LogRhythm Support after the purchase and shipment of the appliance(s).\\nClick the ellipsis [...] button on the right side of the field.\\nLocate and select the master license file.\\nClick\\nOpen\\n.\\nThe path and file name appear in the LogRhythm License File text box.\\nThis file is required to access and configure LogRhythm.\\nClick the ellipsis [...] button on the right side of the field.\\nLocate and select the master license file.\\nClick\\nOpen\\n.\\nThe path and file name appear in the LogRhythm License File text box.\\nThis file is required to access and configure LogRhythm.\\nThe path and file name appear in the LogRhythm License File text box.\\nClick\\nOK\\n.\\nSelect LogRhythm Knowledge Base File\\n. Use this field to load the Knowledge Base into the Client Console.\\nClick the ellipsis [...] button on the right side of the field.\\nLocate and select the Knowledge Base file.\\nClick\\nOpen\\n.\\nThe path and file name appear in the Select LogRhythm Knowledge Base File text box.\\nClick\\nOK\\n.\\nClick the ellipsis [...] button on the right side of the field.\\nLocate and select the Knowledge Base file.\\nClick\\nOpen\\n.\\nThe path and file name appear in the Select LogRhythm Knowledge Base File text box.\\nClick\\nOK\\n.\\nSelect Data Processor Licensing Mode:\\nSoftware (n available licenses)\\n. Select this option to identify a software-only purchase.\\nAppliance (n available licenses)\\n. Select this option to identify a software and appliance purchase.\\nData Processor messages per second (n available licenses)\\n. Select this option to use a Messages Per Second license.\\nSoftware (n available licenses)\\n. Select this option to identify a software-only purchase.\\nAppliance (n available licenses)\\n. Select this option to identify a software and appliance purchase.\\nData Processor messages per second (n available licenses)\\n. Select this option to use a Messages Per Second license.\\nClick\\nNext\\n.\\nSelect the Log Source Licensing Mode.\\nLimited (n available Licenses)\\n. Select this option to assign a limited quantity of log source packs to this Data Processor.\\nUnlimited (n available licenses)\\n. Select this option to assign an unlimited log source license.\\nLimited (n available Licenses)\\n. Select this option to assign a limited quantity of log source packs to this Data Processor.\\nUnlimited (n available licenses)\\n. Select this option to assign an unlimited log source license.\\nClick\\nOK\\n.\\nThe New Knowledge Base Deployment Wizard appears.\\nDeploy the Knowledge Base by selecting one of the three following options:\\nI have Internet access and want to automatically download the KB (recommended).\\nProxy Server Address\\n. Enter the Proxy Server Address for the KB Download.\\nProxy Server Port\\n. Enter the port number for the server.\\nSelect the\\nProxy Server Requires Authentication\\ncheck box.\\nEnter the appropriate credentials and host name, if necessary.\\nClick\\nOK\\n.\\nThe Knowledge Base downloads.\\nClick\\nOK\\n. Proceed to the I have already manually downloaded the KB. Select this option to manually import the Knowledge Base file section.\\nI do not have Internet access or want to manually download the KB.\\nThe Manual Knowledge Base Download message box appears.\\nPerform one of the following:\\nExport Knowledge Base Request File\\n. Select this option to export a Knowledge Base request file and upload it to the\\nLogRhythm Community\\n:\\nClick\\nOK\\nand download the file to your drive.\\nThe Export Successful page appears.\\nClick\\nOK\\n.\\nThe Knowledge Base Not Loaded page appears.\\nClick\\nOK\\n.\\nThe Client Console closes.\\nContact Customer Support\\n. Select this option to obtain the Knowledge Base file from Customer Support:\\nFrom a computer with Internet access, access the\\nLogRhythm Community\\n.\\nGo to the\\nDownloads\\nsection to access the latest version of the Knowledge Base.\\nThe request screen appears.\\nChoose from the following:\\nUpload the Request File downloaded from the Client Console.\\nEnter the License ID, the Deployment ID, and the Product Version in the appropriate fields.\\nClick\\nGet Knowledge Base\\n.\\nSave the Knowledge Base file and transfer it to the computer on which you are loading the Client Console.\\nRestart the Client Console and follow the instructions in the following section.\\nI have already manually downloaded the KB. Select this option to manually import the Knowledge Base file.\\nI have Internet access and want to automatically download the KB (recommended).\\nProxy Server Address\\n. Enter the Proxy Server Address for the KB Download.\\nProxy Server Port\\n. Enter the port number for the server.\\nSelect the\\nProxy Server Requires Authentication\\ncheck box.\\nEnter the appropriate credentials and host name, if necessary.\\nClick\\nOK\\n.\\nThe Knowledge Base downloads.\\nClick\\nOK\\n. Proceed to the I have already manually downloaded the KB. Select this option to manually import the Knowledge Base file section.\\nProxy Server Address\\n. Enter the Proxy Server Address for the KB Download.\\nProxy Server Port\\n. Enter the port number for the server.\\nSelect the\\nProxy Server Requires Authentication\\ncheck box.\\nEnter the appropriate credentials and host name, if necessary.\\nClick\\nOK\\n.\\nThe Knowledge Base downloads.\\nClick\\nOK\\n. Proceed to the I have already manually downloaded the KB. Select this option to manually import the Knowledge Base file section.\\nI do not have Internet access or want to manually download the KB.\\nThe Manual Knowledge Base Download message box appears.\\nPerform one of the following:\\nExport Knowledge Base Request File\\n. Select this option to export a Knowledge Base request file and upload it to the\\nLogRhythm Community\\n:\\nClick\\nOK\\nand download the file to your drive.\\nThe Export Successful page appears.\\nClick\\nOK\\n.\\nThe Knowledge Base Not Loaded page appears.\\nClick\\nOK\\n.\\nThe Client Console closes.\\nContact Customer Support\\n. Select this option to obtain the Knowledge Base file from Customer Support:\\nFrom a computer with Internet access, access the\\nLogRhythm Community\\n.\\nGo to the\\nDownloads\\nsection to access the latest version of the Knowledge Base.\\nThe request screen appears.\\nChoose from the following:\\nUpload the Request File downloaded from the Client Console.\\nEnter the License ID, the Deployment ID, and the Product Version in the appropriate fields.\\nClick\\nGet Knowledge Base\\n.\\nSave the Knowledge Base file and transfer it to the computer on which you are loading the Client Console.\\nRestart the Client Console and follow the instructions in the following section.\\nPerform one of the following:\\nExport Knowledge Base Request File\\n. Select this option to export a Knowledge Base request file and upload it to the\\nLogRhythm Community\\n:\\nClick\\nOK\\nand download the file to your drive.\\nThe Export Successful page appears.\\nClick\\nOK\\n.\\nThe Knowledge Base Not Loaded page appears.\\nClick\\nOK\\n.\\nThe Client Console closes.\\nContact Customer Support\\n. Select this option to obtain the Knowledge Base file from Customer Support:\\nFrom a computer with Internet access, access the\\nLogRhythm Community\\n.\\nGo to the\\nDownloads\\nsection to access the latest version of the Knowledge Base.\\nThe request screen appears.\\nChoose from the following:\\nUpload the Request File downloaded from the Client Console.\\nEnter the License ID, the Deployment ID, and the Product Version in the appropriate fields.\\nClick\\nGet Knowledge Base\\n.\\nSave the Knowledge Base file and transfer it to the computer on which you are loading the Client Console.\\nRestart the Client Console and follow the instructions in the following section.\\nExport Knowledge Base Request File\\n. Select this option to export a Knowledge Base request file and upload it to the\\nLogRhythm Community\\n:\\nClick\\nOK\\nand download the file to your drive.\\nThe Export Successful page appears.\\nClick\\nOK\\n.\\nThe Knowledge Base Not Loaded page appears.\\nClick\\nOK\\n.\\nThe Client Console closes.\\nClick\\nOK\\nand download the file to your drive.\\nThe Export Successful page appears.\\nClick\\nOK\\n.\\nThe Knowledge Base Not Loaded page appears.\\nClick\\nOK\\n.\\nThe Client Console closes.\\nContact Customer Support\\n. Select this option to obtain the Knowledge Base file from Customer Support:\\nFrom a computer with Internet access, access the\\nLogRhythm Community\\n.\\nGo to the\\nDownloads\\nsection to access the latest version of the Knowledge Base.\\nThe request screen appears.\\nChoose from the following:\\nUpload the Request File downloaded from the Client Console.\\nEnter the License ID, the Deployment ID, and the Product Version in the appropriate fields.\\nClick\\nGet Knowledge Base\\n.\\nSave the Knowledge Base file and transfer it to the computer on which you are loading the Client Console.\\nRestart the Client Console and follow the instructions in the following section.\\nFrom a computer with Internet access, access the\\nLogRhythm Community\\n.\\nGo to the\\nDownloads\\nsection to access the latest version of the Knowledge Base.\\nThe request screen appears.\\nChoose from the following:\\nUpload the Request File downloaded from the Client Console.\\nEnter the License ID, the Deployment ID, and the Product Version in the appropriate fields.\\nUpload the Request File downloaded from the Client Console.\\nEnter the License ID, the Deployment ID, and the Product Version in the appropriate fields.\\nClick\\nGet Knowledge Base\\n.\\nSave the Knowledge Base file and transfer it to the computer on which you are loading the Client Console.\\nRestart the Client Console and follow the instructions in the following section.\\nI have already manually downloaded the KB. Select this option to manually import the Knowledge Base file.\\nClick\\nOK\\n.\\nThe Knowledge Base Import Wizard appears and starts unpacking and validating the Knowledge Base file. The file is checked for compatibility with your current deployment and is prepared for import. This may take several minutes. Upon completion, the message Knowledge Base unpacked appears in the status.\\nTo import the Knowledge Base, click\\nOK\\n.\\nThe Knowledge Base Updated message box appears.\\nClick\\nOK\\n.\\nOn the Knowledge Base Import Wizard, click\\nClose\\n.\\nThe Missing Platform Manager Platform error message appears.\\nClick\\nOK\\n.\\nIn the Platform Manager Properties dialog box, click the\\nBrowse\\nicon next to the Platform box.\\nIn the Platform Selector table, select the row corresponding to your appliance and click\\nOK\\n.\\nEnter an email address in the Email From Address field and click\\nOK\\n.\\nThe Missing Data Processor Platform error message appears.\\nClick\\nOK\\n.\\nIn the Data Processor Properties dialog box, click the\\nBrowse\\nicon next to the Platform box.\\nIn the Platform Selector table, select the row corresponding to your appliance and click\\nOK\\n.\\nThe Restart Component dialog box appears.\\nClick\\nOK\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nGet Started with LogRhythm SIEM\\n', 'Configure NetMon to Integrate with the Web Console': 'The Web Console can optionally be configured to integrate with multiple LogRhythm NetMon deployments. In order for this integration to work:\\nThe NetMon host needs to be accessible from the server that the Web Console is hosted on.\\nNetMon must be configured to send syslogs to LogRhythm services.\\nNetMon must be configured as a log source.\\nIf your API key is reset in NetMon, the Web Console is unable to access NetMon until the key is updated in the Client Console.\\nFor more information about integration, see the\\nClient Console Administrator Guide\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nGet Started with LogRhythm SIEM\\n', 'Log in to the Client Console': '', 'Start the Client Console': 'To start the LogRhythm Client Console:\\nOn the Start menu, click\\nAll Programs\\n, click\\nLogRhythm\\n, and then click\\nLogRhythm Console\\n.\\nIf configured for your deployment, a security banner appears.\\nIf the banner appears, read the message and click\\nOK\\nto access the LogRhythm Client Console.\\nIn the Login dialog box, enter your credentials, and then click\\nOK\\n.\\nIf this is an upgrade or existing deployment, the LogRhythm Client Console appears and you are ready to work in LogRhythm.\\nIf this is a new deployment, the New Deployment Wizard appears to complete the configuration. Note that all LogRhythm appliances are shipped preloaded with a license and Knowledge Base files. Complete the\\nNew Deployment Wizard\\n.\\nIf this is an upgrade or existing deployment, the LogRhythm Client Console appears and you are ready to work in LogRhythm.\\nIf this is a new deployment, the New Deployment Wizard appears to complete the configuration. Note that all LogRhythm appliances are shipped preloaded with a license and Knowledge Base files. Complete the\\nNew Deployment Wizard\\n.\\n', 'Client Console Display Settings on Windows Server 2012 R2': 'When the Client Console is running on Windows Server 2012 R2, some tabs and subtabs in certain Client Console windows may not appear if the display settings in the operating system are not set correctly. To avoid these issues, do the following ensure that the magnification for Windows is set to the default value, which is 100%.\\nOpen\\nControl Panel\\n, then click\\nDisplay\\n.\\nEnsure that\\nSmaller – 100%\\nis selected, then click\\nApply\\n.\\nLog out of Windows and log back in.\\n', 'Complete the Login Window': 'After you launch the LogRhythm Client Console, the Login window appears.\\xa0Use the information in the following table to complete the fields in the Login window.\\nField, Description\\nServer, Enter the host name of the LogRhythm Platform Manager server. If the Platform Manager is on the local system, as it is for XM and PM configuration Appliances, the loopback address (127.0.0.1) or localhost can be used.\\nDatabase, Enter the name of the Platform Manager Database. This is usually the default setting of LogRhythmEMDB.\\nLogin with Windows Account, Select to use your Active Directory credentials associated with your Windows account.\\nUser ID, Enter the user name that was created by adding a Login to a Person Record. By default, LogRhythmAdmin and LogRhythmAnalyst users are created at install.\\nPassword, Enter the password for the User ID.\\nEncrypt allcommunications, Check to encrypt communications between the Client Console and the Platform Manager and Data Processors. Be aware that the Client Console can encounter a noticeable decline in performance while this setting is enabled due to the encryption overhead.\\nLogin automatically next time, Select to use the same information on the next login without showing the Login window.To disable the automatic login, go to the My LogRhythm menu, clickMy Preferences, click theGeneraltab, and then clickDisablein the Auto Login section.\\nSelect to use the same information on the next login without showing the Login window.\\nTo disable the automatic login, go to the My LogRhythm menu, click\\nMy Preferences\\n, click the\\nGeneral\\ntab, and then click\\nDisable\\nin the Auto Login section.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nGet Started with LogRhythm SIEM\\n', 'Log in to the Web Console': 'Prerequisites\\nA computer running Google Chrome (version 54 or higher is recommended), Mozilla Firefox (version 50.0.1 or higher is recommended), or Internet Explorer 11.\\nThe Web Console is not supported on tablets, mobile devices, or touch screens.\\nLogRhythm Enterprise login credentials.\\nThe IP address or Server name where the Platform Manager Database resides.\\nThe Web Console must be properly configured with an SSL Public Key, SSL Private Key, and, for Smart Card access only, Certificate Authority Trust.\\nFor more information, see the\\nLogRhythm Software Installation Guide or Upgrade Guide\\n.\\nCookies must be enabled on your browser to log in to the Web Console. If you are having trouble logging in to the Web Console, ensure cookies are enabled, and restart your browser.\\nIf you are using Microsoft Edge, it is also recommended that you disable the page prediction feature on the Settings > View Advanced Settings page.\\nIn the address bar of a supported browser, type the following:\\nA secure URL prefix (\\nhttps://\\n).\\nThe host name, fully qualified domain name, or IP address of the server hosting the Web Console. Localhost only works if you are on the web server.\\n8443 for the port. Your LogRhythm administrator may have configured a different port when installing the Web Console. If the port was changed to 443, you do not need to include the default 443 number in the address bar.\\nIf your organization has more than one Web Console deployment, you can log in to any of them, but search results are only available in the deployment you ran the search in.\\nFor example,\\nhttps://servername:8443/\\nA secure URL prefix (\\nhttps://\\n).\\nThe host name, fully qualified domain name, or IP address of the server hosting the Web Console. Localhost only works if you are on the web server.\\n8443 for the port. Your LogRhythm administrator may have configured a different port when installing the Web Console. If the port was changed to 443, you do not need to include the default 443 number in the address bar.\\nIf your organization has more than one Web Console deployment, you can log in to any of them, but search results are only available in the deployment you ran the search in.\\nFor example,\\nhttps://servername:8443/\\n8443 for the port. Your LogRhythm administrator may have configured a different port when installing the Web Console. If the port was changed to 443, you do not need to include the default 443 number in the address bar.\\nIf your organization has more than one Web Console deployment, you can log in to any of them, but search results are only available in the deployment you ran the search in.\\nFor example,\\nhttps://servername:8443/\\nSign in using one of the following methods, according to what your administrator has configured:\\nEnter LogRhythm credentials.\\nOn the Sign-in screen, type your LogRhythm account credentials. To be able to log in to the Web Console, your user password cannot:\\nContain a space character.\\nContain an apostrophe.\\nContain a single quote, double-quote, or semicolon.\\nStart with the $ or @ character.\\nIf your password includes any of the restricted characters, it needs to be changed before you can log in to the Web Console.\\nClick\\nSign in\\n.\\nUse a Smart Card.\\nInsert your Smart Card into the reader.\\nSelect your corresponding certificate.\\nLogRhythm can authenticate Smart Cards provisioned in either of the following ways:\\nThe LogRhythm account name matches the common name (CN) stored in the subject of the Smart Card certificate.\\nThe LogRhythm account has been associated with a defined User Principal Name (UPN) that matches the UPN stored as a subject alternative name on the Smart Card certificate.\\nType the PIN associated with your Smart Card. Click\\nOK\\n.\\nYou are required to have a LogRhythm account before your Smart Card gives you access to the Web Console. If you are authenticated by Smart Card, but do not have corresponding authorization to access LogRhythm, you cannot be logged in. Instead, you are presented with a screen indicating that you were authenticated but are not authorized to access LogRhythm. Contact the LogRhythm administrator to request access.\\nSmart Card functionality is managed solely through the corresponding certificate authority and the browser. LogRhythm does not control the interface, workflow, authentication of certificates, or validation of Smart Card user accounts and PINs. If your Smart Card is misconfigured, LogRhythm cannot provide assistance.\\nType a one-time password (OTP).\\nOn the Sign-in screen, type your LogRhythm account credentials.\\nClick\\nSign in\\n.\\nIf you haven’t already done so, set up a multi-factor authentication device.\\nDownload an authentication tool, such as Google Authenticator, Microsoft Authenticator, or Authy, onto your smartphone.\\nScan the QR code displayed by the Web Console using the camera on your mobile device.\\nType the code generated by your multi-factor authentication application.\\nClick\\nSign in\\n.\\nIf you misconfigure your multi-factor authentication application or lose the device it is configured on, this feature can be reset through the Client Console. Open the Deployment Manager, click the\\nPeople\\ntab, and right-click your user name. Then click\\nReset Multi-Factor Authentication\\n. On the next login, you are prompted to associate your account with a new multi-factor authentication device.\\nLogRhythm’s multi-factor authentication uses time-based authentication. This method requires that the two device clocks be synchronized. If the server where the authentication is being performed has a different time, then the authentication does not work until the clock is corrected. However, this feature works regardless of time zone differences.\\nEnter LogRhythm credentials.\\nOn the Sign-in screen, type your LogRhythm account credentials. To be able to log in to the Web Console, your user password cannot:\\nContain a space character.\\nContain an apostrophe.\\nContain a single quote, double-quote, or semicolon.\\nStart with the $ or @ character.\\nIf your password includes any of the restricted characters, it needs to be changed before you can log in to the Web Console.\\nClick\\nSign in\\n.\\nOn the Sign-in screen, type your LogRhythm account credentials. To be able to log in to the Web Console, your user password cannot:\\nContain a space character.\\nContain an apostrophe.\\nContain a single quote, double-quote, or semicolon.\\nStart with the $ or @ character.\\nIf your password includes any of the restricted characters, it needs to be changed before you can log in to the Web Console.\\nContain a space character.\\nContain an apostrophe.\\nContain a single quote, double-quote, or semicolon.\\nStart with the $ or @ character.\\nIf your password includes any of the restricted characters, it needs to be changed before you can log in to the Web Console.\\nClick\\nSign in\\n.\\nUse a Smart Card.\\nInsert your Smart Card into the reader.\\nSelect your corresponding certificate.\\nLogRhythm can authenticate Smart Cards provisioned in either of the following ways:\\nThe LogRhythm account name matches the common name (CN) stored in the subject of the Smart Card certificate.\\nThe LogRhythm account has been associated with a defined User Principal Name (UPN) that matches the UPN stored as a subject alternative name on the Smart Card certificate.\\nType the PIN associated with your Smart Card. Click\\nOK\\n.\\nYou are required to have a LogRhythm account before your Smart Card gives you access to the Web Console. If you are authenticated by Smart Card, but do not have corresponding authorization to access LogRhythm, you cannot be logged in. Instead, you are presented with a screen indicating that you were authenticated but are not authorized to access LogRhythm. Contact the LogRhythm administrator to request access.\\nSmart Card functionality is managed solely through the corresponding certificate authority and the browser. LogRhythm does not control the interface, workflow, authentication of certificates, or validation of Smart Card user accounts and PINs. If your Smart Card is misconfigured, LogRhythm cannot provide assistance.\\nInsert your Smart Card into the reader.\\nSelect your corresponding certificate.\\nLogRhythm can authenticate Smart Cards provisioned in either of the following ways:\\nThe LogRhythm account name matches the common name (CN) stored in the subject of the Smart Card certificate.\\nThe LogRhythm account has been associated with a defined User Principal Name (UPN) that matches the UPN stored as a subject alternative name on the Smart Card certificate.\\nSelect your corresponding certificate.\\nLogRhythm can authenticate Smart Cards provisioned in either of the following ways:\\nThe LogRhythm account name matches the common name (CN) stored in the subject of the Smart Card certificate.\\nThe LogRhythm account name matches the common name (CN) stored in the subject of the Smart Card certificate.\\nThe LogRhythm account has been associated with a defined User Principal Name (UPN) that matches the UPN stored as a subject alternative name on the Smart Card certificate.\\nThe LogRhythm account has been associated with a defined User Principal Name (UPN) that matches the UPN stored as a subject alternative name on the Smart Card certificate.\\nType the PIN associated with your Smart Card. Click\\nOK\\n.\\nYou are required to have a LogRhythm account before your Smart Card gives you access to the Web Console. If you are authenticated by Smart Card, but do not have corresponding authorization to access LogRhythm, you cannot be logged in. Instead, you are presented with a screen indicating that you were authenticated but are not authorized to access LogRhythm. Contact the LogRhythm administrator to request access.\\nSmart Card functionality is managed solely through the corresponding certificate authority and the browser. LogRhythm does not control the interface, workflow, authentication of certificates, or validation of Smart Card user accounts and PINs. If your Smart Card is misconfigured, LogRhythm cannot provide assistance.\\nType the PIN associated with your Smart Card. Click\\nOK\\n.\\nYou are required to have a LogRhythm account before your Smart Card gives you access to the Web Console. If you are authenticated by Smart Card, but do not have corresponding authorization to access LogRhythm, you cannot be logged in. Instead, you are presented with a screen indicating that you were authenticated but are not authorized to access LogRhythm. Contact the LogRhythm administrator to request access.\\nSmart Card functionality is managed solely through the corresponding certificate authority and the browser. LogRhythm does not control the interface, workflow, authentication of certificates, or validation of Smart Card user accounts and PINs. If your Smart Card is misconfigured, LogRhythm cannot provide assistance.\\nType a one-time password (OTP).\\nOn the Sign-in screen, type your LogRhythm account credentials.\\nClick\\nSign in\\n.\\nIf you haven’t already done so, set up a multi-factor authentication device.\\nDownload an authentication tool, such as Google Authenticator, Microsoft Authenticator, or Authy, onto your smartphone.\\nScan the QR code displayed by the Web Console using the camera on your mobile device.\\nType the code generated by your multi-factor authentication application.\\nClick\\nSign in\\n.\\nIf you misconfigure your multi-factor authentication application or lose the device it is configured on, this feature can be reset through the Client Console. Open the Deployment Manager, click the\\nPeople\\ntab, and right-click your user name. Then click\\nReset Multi-Factor Authentication\\n. On the next login, you are prompted to associate your account with a new multi-factor authentication device.\\nLogRhythm’s multi-factor authentication uses time-based authentication. This method requires that the two device clocks be synchronized. If the server where the authentication is being performed has a different time, then the authentication does not work until the clock is corrected. However, this feature works regardless of time zone differences.\\nType a one-time password (OTP).\\nOn the Sign-in screen, type your LogRhythm account credentials.\\nOn the Sign-in screen, type your LogRhythm account credentials.\\nClick\\nSign in\\n.\\nClick\\nSign in\\n.\\nIf you haven’t already done so, set up a multi-factor authentication device.\\nDownload an authentication tool, such as Google Authenticator, Microsoft Authenticator, or Authy, onto your smartphone.\\nScan the QR code displayed by the Web Console using the camera on your mobile device.\\nIf you haven’t already done so, set up a multi-factor authentication device.\\nDownload an authentication tool, such as Google Authenticator, Microsoft Authenticator, or Authy, onto your smartphone.\\nDownload an authentication tool, such as Google Authenticator, Microsoft Authenticator, or Authy, onto your smartphone.\\nScan the QR code displayed by the Web Console using the camera on your mobile device.\\nScan the QR code displayed by the Web Console using the camera on your mobile device.\\nType the code generated by your multi-factor authentication application.\\nType the code generated by your multi-factor authentication application.\\nClick\\nSign in\\n.\\nIf you misconfigure your multi-factor authentication application or lose the device it is configured on, this feature can be reset through the Client Console. Open the Deployment Manager, click the\\nPeople\\ntab, and right-click your user name. Then click\\nReset Multi-Factor Authentication\\n. On the next login, you are prompted to associate your account with a new multi-factor authentication device.\\nLogRhythm’s multi-factor authentication uses time-based authentication. This method requires that the two device clocks be synchronized. If the server where the authentication is being performed has a different time, then the authentication does not work until the clock is corrected. However, this feature works regardless of time zone differences.\\nClick\\nSign in\\n.\\nIf you misconfigure your multi-factor authentication application or lose the device it is configured on, this feature can be reset through the Client Console. Open the Deployment Manager, click the\\nPeople\\ntab, and right-click your user name. Then click\\nReset Multi-Factor Authentication\\n. On the next login, you are prompted to associate your account with a new multi-factor authentication device.\\nLogRhythm’s multi-factor authentication uses time-based authentication. This method requires that the two device clocks be synchronized. If the server where the authentication is being performed has a different time, then the authentication does not work until the clock is corrected. However, this feature works regardless of time zone differences.\\nThe Web Console opens in the browser.\\nTo log out of the Web Console,\\xa0Click the\\nUser\\nicon.\\nTo log out of the Web Console,\\xa0Click the\\nUser\\nicon.\\nIn the dialog box, click\\nLogout\\n.\\nAfter logging out, users who had authenticated with a Smart Card / Common Access Card should quit their browser to ensure that the client certificate is fully unloaded from the browser cache.\\nIn the dialog box, click\\nLogout\\n.\\nAfter logging out, users who had authenticated with a Smart Card / Common Access Card should quit their browser to ensure that the client certificate is fully unloaded from the browser cache.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nGet Started with LogRhythm SIEM\\n', 'Verify the Web Console Connection Status': 'When you are logged in to the Web Console, you can verify its connectivity to the Web Console server. On the upper-right side of the Web Console, a status indicator displays \"Live Data\" with a blue dot next to it. If the Web Console cannot establish a connection, the status indicator displays\\xa0 \"Reconnecting\" or \"Disconnected.\" When the Web Console is connected, any Processing Rate gauges, Trend charts, or Top X controls displayed on the Dashboards page updates automatically, unless you pause the live data stream.\\n\\n', 'Pause the Live Data Stream': 'At times, you may want to temporarily pause live data from streaming into the Web Console. For example, if alarms are triggering at a rapid pace, you may want to pause the connection so that new alarms do not push out previous alarms. This allows you time to investigate an issue. When you are ready to receive live data again, you can restart the data connection. All data is queued in the indexer cache and available when you resume.\\nThe pause function is only applicable to the currently displayed page. For example:\\nIf the Alarms page is displayed, the Pause button stops new alarm cards from displaying.\\nIf the Dashboards page is displayed, the Pause button stops live data from updating any processing rate gauges, trend charts, and TopX controls.\\nTo use the Pause and Resume function:\\nIn the upper-right of the screen, near the status indicator, click the\\nPause\\nicon to pause the live data stream.\\nThe icon changes to a Resume icon. No live data is lost. It remains in the indexer cache until you are ready to receive it.\\nClick the\\nResume\\nicon to resume the live data stream.\\nLogging off and back in to the Web Console also resumes the data stream.\\nClick the\\nResume\\nicon to resume the live data stream.\\nLogging off and back in to the Web Console also resumes the data stream.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nInclusions Library\\n', 'Component Operating System Support': 'The content on this page is only intended for use as an excerpt on other pages. Do not use this information out of context as seen here. Return to the\\nNextGen SIEM Homepage\\nand find the information you need there.\\nThis section describes operating systems and LogRhythm component compatibility for LogRhythm 7.4. The following table defines the LogRhythm support levels used in subsequent tables.\\nCertified Support (CS), Limited Support (LS), Unsupported (US)\\nFully tested per LogRhythm quality assurance processes., Limited testing, but likely to work based on engineering assessment and/or field verification., Not tested.\\nLogRhythm patches bugs., LogRhythm may patch bugs., LogRhythm does not patch bugs.\\nFull LogRhythm Technical Support., Limited LogRhythm Technical Support., No LogRhythm Technical Support.\\n\\n\\n\\n\\n\\n\\nThe following table shows the support levels for LogRhythm components on various 64-bit operating systems.\\nAny operating system not included in the following table is not supported.\\nLogRhythm 7.4 Operating System Support Levels\\n64-bit Operating System, Data Indexer, Data Processor, Platform Manager, AI Engine, LogRhythm API, Web Console, Client Console, Open Collector\\nWindows 7, US, LS, LS, US, US, US, CS, US\\nWindows 8/8.1, US, US, US, US, US, US, LS, US\\nWindows 10, US, US, US, US, US, US, CS, US\\nWindows Server 2008, US, US, US, US, US, US, CS, US\\nWindows Server 2008 R2, CS1, CS, US, CS, CS, CS, CS, US\\nWindows Server 2012, US, US, US, US, US, US, LS, US\\nWindows Server 2012 R2, CS1, CS, CS, CS, CS, CS, CS, US\\nWindows Server 2016, CS1, CS, CS, CS, CS, CS, CS, US\\nWindows Server 2016 Core, US, US, US, US, US, US, US, US\\nWindows Server 2019, US, US, US, US, US, US, US, US\\nCentOS 7.x Minimal, CS, US, US, US, US, US, US, US\\nCentOS 7.6 or greater, CS, US, US, US, US, US, US, CS\\nCoreOS, US, US, US, US, US, US, US, CS\\nRHEL 7, CS, US, US, US, US, US, US, US\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n1\\nThe Data Indexer is only supported on Windows operating systems for Gen3 appliances.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.10.0 GA Release Notes - 29 September 2022': '', 'Upgrade Considerations': 'Upgrade considerations for all 7.10.x releases are available on the\\nLogRhythm Release Notes\\nmain page.\\nLogRhythm 7.9.0 introduced support for Microsoft SQL Server 2019 and Windows Server 2019 on standard deployments.\\nIf your deployment is running SQL Server 2016 Standard or Windows Server 2016, there is no need to upgrade to\\n2019\\n.\\nFor more information on the optional upgrades, see:\\nUpgrade SQL Server 2016 to SQL Server 2019\\nUpgrade Windows Server 2016 to Windows Server 2019\\n', 'New Features': 'Functional Group, Feature, Description\\nCustomer Enhancement, AI Engine Unique Values Rule Block, Explanation:AI Engine Events now include Host information. This reduces misfires from AI Engine Unique Values rule blocks and provides correct logs in drilldown results.Benefit:The system is more stable and enables users to spend more time on threat detection and response.Relevant Documentation Updates:N/A\\nPlatform Administration, Admin API, Explanation:The Admin API library now includes the Associate Pending Log Source endpoint.This enables SIEM administrators to manage pending or modify existing System Monitor Agents through the API.Benefit:The Admin API reduces administrative overhead and expedites workflow by automating routine tasks.Relevant Documentation Updates:Administration API Endpoints\\nPlatform Administration, Alarm API, Explanation:The Alarm API library now includes the Get Alarm URL endpoint.This enables SIEM administrators to retrieve alarm URLs which were configured in Platform Manager through the API.Benefit:The Alarm API allows users to retrieve alarm information without a database connection.Relevant Documentation Updates:Alarm API Endpoints\\nPlatform Administration, Metrics API, Explanation:The LogRhythm REST API now includes the Metrics API component. This enables SIEM API users to retrieve log volume and log indices TTL information from the Data Indexer.Benefit:The Metrics API allows customers to return log volume and index information when given a specified time and date to expedite workflow.Relevant Documentation Updates:Metrics API\\nSecurity and Reliability, Web Console, Explanation:LogRhythm implemented new CSFR token security protocols during Web Console login.Benefit:Enhanced security in Web Console.Relevant Documentation Updates:N/A\\nExplanation:\\nAI Engine Events now include Host information. This reduces misfires from AI Engine Unique Values rule blocks and provides correct logs in drilldown results.\\nBenefit:\\nThe system is more stable and enables users to spend more time on threat detection and response.\\nRelevant Documentation Updates:\\nN/A\\nExplanation:\\nThe Admin API library now includes the Associate Pending Log Source endpoint.\\nThis enables SIEM administrators to manage pending or modify existing System Monitor Agents through the API.\\nBenefit:\\nThe Admin API reduces administrative overhead and expedites workflow by automating routine tasks.\\nRelevant Documentation Updates:\\nAdministration API Endpoints\\nExplanation:\\nThe Alarm API library now includes the Get Alarm URL endpoint.\\nThis enables SIEM administrators to retrieve alarm URLs which were configured in Platform Manager through the API.\\nBenefit:\\nThe Alarm API allows users to retrieve alarm information without a database connection.\\nRelevant Documentation Updates:\\nAlarm API Endpoints\\nExplanation:\\nThe LogRhythm REST API now includes the Metrics API component. This enables SIEM API users to retrieve log volume and log indices TTL information from the Data Indexer.\\nBenefit:\\nThe Metrics API allows customers to return log volume and index information when given a specified time and date to expedite workflow.\\nRelevant Documentation Updates:\\nMetrics API\\nExplanation:\\nLogRhythm implemented new CSFR token security protocols during Web Console login.\\nBenefit:\\nEnhanced security in Web Console.\\nRelevant Documentation Updates:\\nN/A\\n', 'Improvements': 'LogRhythm updated Node.js to version 17.7.2 for the Web Console UI and API Gateway, and version 16.14.0 for the True Identity Sync Client (TISC).\\n', 'Deprecated Features': 'LogRhythm 7.8 was the last published version of the SOAP API. LogRhythm is deprecating the SOAP API in favor of more effective and sustainable integration through RESTful APIs. While the SOAP API is still usable in 7.9, we encourage customers and partners using the SOAP API to migrate their integrations to REST APIs. For more information on REST integration, see our\\nREST API\\ndocumentation\\n.\\n', 'Resolved Issues': 'Bug #, Ticket #, Component, Description\\nDE10313, 375644, 361311, 342465, 370475, 386903, 387430, 388696, 390743, 390909, 390242, 423994, 394392, 395676, 400836, 420977, 443424, AI Engine, AIE Unique Value Rules no longer misfire.\\nDE15530, N/A, AI Engine, The AI Engine now successfully processes rules even if there is a high event rate.\\nDE14535, 434663, APIs, The Alarm API no longer experiences delays when processing queries using the default configuration settings.\\nDE15699, 442916, APIs, The Alarm API \"Get Events by alarmid\" response now correctly returns the origin and impacted host name.\\nDE15757, 443327, 446262, APIs, The Search API no longer experiences SQL-related connection issues when executing endpoints.\\nDE14135, 431553, 431855, 433193,440085, 440826, 449771, Client Console, Changes to LDS Receiver syslog ports are now correctly saved.\\nDE15358, 441361, 439108, Client Console, Running the \"API - Office 365 Message Tracking\" LogMart investigation in the client console no longer produces an error.\\nDE12608, 415307, 420234, Client Console: Agents, Searching System Monitor Agent Properties log sources now correctly returns all log sources from the current agent.\\nDE12581, 414797, 416678, 419401,431664, 434279, Client Console: Log Sources, Users can now correctly filter out the retired log sources when filtering by Log Source Type.\\nDE12212, 423003, Client Console: User, Restricted Admin accounts created by other Restricted Admin accounts now have the correct permissions.\\nDE11342, 393176, 407121, Data Indexer, Drill downs on AIE rules now function correctly regardless of the filter criteria.\\nDE15053, 439238, Data Indexer, Investigations using the \"Host List\" type with IP Range values are now executed correctly.\\nDE15650, 411653, 415039, 445170, Infrastructure: Database Scripts & Upgrade Scripts, CMDB and LogMart databases can now be backed up in Disaster Recovery deployments.\\nDE13779, 421468, Job Manager: Scheduled Reporting, Job Manager reports are no longer skipped in certain circumstances when multiple reports are scheduled.\\nDE13453, 418253, 424344, Mediator, SNMP Trap, sFlow, and Netflow collection is now permitted with a System Monitor Collector license.\\nDE14792, N/A, Mediator, The Mediator no longer attempts to connect to ports that have been removed.\\nDE14851, 436667, Mediator, SSL warnings no longer appear in the Mediator logs in certain situations after restarting the service.\\nDE1039, 369152, Web Console, Older log files are now routinely cleared out from the Windows Auth Service and SQL Service.\\nDE11663, 406403, 406587, 412875,418654, 412776, 426312,433452, Web Console: Case Management, Clicking Case Evidence logs now correctly opens an Analyze page showing the logs selected.\\nDE15617, 446045, Web Console: Lucene Helper, Autosuggest values are now correctly selected by clicking as well as the Enter key in the Lucene Filter.\\nDE15058, 437267, 438827, Web Console: Reports, The Web Console no longer produces an error in certain situations when generating a report with over 1,000 log source items.\\nDE11124, 394474, 403654, Web Console UI, Links sent in Case and Alarm notification emails now correctly redirect to port 443 instead of 8443.\\nDE12836, 404593, 413007, 418078,420857, 435880, Web Console UI, Search and drill down operations in the Web Console now correctly complete or display an error as soon as the result is available.\\n375644, 361311, 342465, 370475, 386903, 387430, 388696, 390743, 390909, 390242, 423994, 394392, 395676, 400836, 420977, 443424\\n', 'Resolved Issues - Security': 'Security-related issues resolved with this release are available for customers to view on the\\nCommunity\\n.\\n', 'Known Issues': 'The following issues have each been found and reported by multiple users.\\nBug #, Found In Version, Components, Description, Release Notes\\nDE1871, 7.3.3, AI Engine, Under conditions of load, AI Engine Rules that are written incorrectly can cause significant issues throughout the entire AIE\\xa0server., Expected Results:\\xa0Poorly written AIE Rules should be suspended until they are altered and re-enabled.Workaround:\\xa0Rewrite the AIE Rule for\\xa0better performance.\\xa0Often, this involves adding filters, reducing log sources, and\\xa0modifying the logic. Tuning an AIE Rule requires expertise, so contact LogRhythm Training, Professional Services, or a Sales Engineer to assist if necessary. Additional solutions to identify and monitor poorly performing rules are being developed for a\\xa0future release.\\nDE1759, 7.3.4, AI Engine, When the AIE service starts up, errors\\xa0are\\xa0generated multiple\\xa0times\\xa0in\\xa0the\\xa0AIE\\xa0Engine\\xa0log., Expected Results:\\xa0These errors should not be generated in the AIE Engine log, but AIE\\xa0is\\xa0working\\xa0and\\xa0alarms\\xa0are\\xa0firing.Workaround:\\xa0There is currently no workaround for this issue.\\nDE1606, 7.3.5, AI Engine, When an AIE Rule with two rule blocks has an evaluation period of 0 seconds, the rule does not trigger\\xa0as expected., Expected Results:\\xa0AIE Rule Blocks should fire when they are triggered at the same time.Workaround:\\xa0As the behavior of simultaneous events is unpredictable\\xa0and the use case for a 0-time interval is rare, LogRhythm does not plan to change this behavior at this time. To avoid the issue, set the evaluation period to 1 second.\\nDE1324, 7.4.3, AI Engine, In certain circumstances, there may be a discrepancy between the AIE event date/time and\\xa0the date/time of the message(s) triggering the AIE rule, causing the AIE event to show a future date/time., Expected Results: The date and time of the AIE Event should not have a future time.Workaround: There is no workaround for this issue.\\nDE1288, 7.4.6, AI Engine, When an AIE Rule uses the Host (Impacted) or Host (Origin) in the Group By block, the rule misfires., Expected Results:\\xa0AIE Rules should not fire if the rule block relationship is not met.Workaround:\\xa0Change the Host (origin) or Host (impacted) fields to IP Address, and the AIE Rule works as expected.\\nDE10501, 7.4.7, AI Engine, The Retire\\xa0logs in the C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm AI Engine\\\\HostInferenceLogs directory are not being removed after the defined number of expiration days., Expected Results: Logs in this directory should be purged after the number of days defined for expiration has passed, defaulted to 7 days.Workaround:\\xa0 Manually remove these files to prevent the C drive from filling up.\\nDE10301, 7.4.8, AI Engine, Adding an AIE rule using the UTC time zone produces an error., Expected Results:Should be able to define an AIE rule\\'s date and time using the UTC time zone.Workaround:There is currently no workaround for this issue.\\nDE10397, 7.4.8, AI Engine, In certain circumstances, when an AIE Rule is evaluating an Observed block followed by a Not Observed block, alarms\\xa0fire even if there are logs that indicate the second block was Observed., Expected Results:\\xa0Alarms should\\xa0not fire if a log is received for a Not Observed block.Workaround:\\xa0While there is currently no workaround, LogRhythm is investigating this issue for a future release.\\nDE10946, 7.4.9, AI Engine, When an AIE Alarm has an action including a SmartResponse Plugin, the execution is slow., Expected Results:\\xa0Alarms should execute quickly as expected with other AIE Alarms.Workaround:\\xa0There is currently no workaround for this issue.\\nDE11051, 7.4.9, AI Engine, In certain circumstances, the AIE Engine does not consistently trigger alarms for Log Not Observed., Expected Results: The AIE Engine should trigger alarms for Log Not Observed.Workaround: There is currently no workaround for this issue.\\nDE14530DE14531, 7.9.0, AI Engine, There is no input validation for the MAC Address field in the SIEM, which means that a MAC Address could be in multiple different formats., Expected Results:Input normalization for MAC Addresses, requiring them to be entered in the accepted format.Workaround:Use data masking rules to transform the MAC addresses to the colon delimited format.\\nDE1087, 7.3.5, AI Engine, AI Engine rule group changes are not reflected in the Web Console until Web Services is restarted., Expected Results: Web Services does not need to be restarted to have a rule group change show up.Workaround: Restart Web Services.\\nDE11098, 7.4.9, Alarming, When using a SMTP server with SSL authentication, the Alarming and Response Manager fails to send alarm notifications., Expected Results:\\xa0The Alarming and Response Manager should able to send alarm notifications using any SMTP server and SSL authentication.Workaround:\\xa0There is currently no workaround for this issue.\\nDE10937, 7.4.10, Alarming, If an SRP is retired, the Alarming and Response Manager (ARM) does not recognize this and could cause the C: drive to fill\\xa0with errors trying to execute the SRP if the logging level on the ARM is set high., Expected Results: The Alarming and Response Manager should be aware of a change of status of the SRPs and should not continue to attempt to execute them.Workaround: Lower the logging level on the ARM to help mitigate this, but contact LogRhythm Technical Support if assistance is needed to retire the SRP.\\nDE14950, 7.8.0, Alarming, When a restricted administrator runs a search on recent alarms, system alarms will not show up. However, they do in the web console., Expected Results:Recent alarms should be visible when searching in the client console.Workaround:There is currently no workaround for this issue.\\nDE6072, 7.3.4, APIs, When using a 512-bit RSA-signed certificate, Case API and Admin API do not start due to an incomplete\\xa0implementation of TLS 1.2.\\xa0This typically happens when a GPO pushes the certificate to the server., Expected Results: Case API and Admin API should start when using any size certificate.Workaround:\\xa0Remove\\xa0the\\xa0server\\xa0from\\xa0the\\xa0domain and reboot it.\\xa0Verify that the\\xa0512-bit\\xa0certificate has\\xa0been\\xa0removed, re-run the installers, and reboot. To\\xa0avoid\\xa0this issue, do not join the domain\\xa0again\\xa0or\\xa0the\\xa0certificate will\\xa0be\\xa0pushed\\xa0out\\xa0again.\\xa0In addition, create a new certificate that\\xa0uses a 384-bit (or less) hash or exclude the impacted system from the GPO that pushes\\xa0the\\xa0certificate.\\nDE1869, 7.4.7, APIs, In certain circumstances the Admin API log generates multiple invalid argument errors without providing context., Expected Results: When the Admin API log generates errors, it should provide some context within the error message.Workaround: There is currently no workaround for this issue.\\nDE10200, 7.4.9, APIs, PowerShell scripts utilizing the Case and Admin APIs may stop working upon upgrade to 7.4.9 or later.\\xa0This is due to an additional semicolon at the end of the valid content-type value., Expected Results: The extra semicolon, which is an optional valid separator in a content-type header, should not prevent scripts from working upon upgrade.Workaround:While there is currently no workaround, LogRhythm is investigating this issue for a future release.\\nDE13070, 7.7.0, APIs, Changing Log Levels via the Configuration Manager for the Web Services does not change the Log Level for the \\'LogRhythm Admin API.log\\', which means the request and responses being made to the platform can\\'t be seen., Expected Results:The Log Level should be changed by updating the Log Level in Configuration Manager.Workaround: There is currently no workaround for this issue.\\nDE7632, 7.1.3, Client Console, Entities cannot be deleted from within the Client Console., Expected Results: Entities\\xa0should be retireable\\xa0and able to be hidden from view.Workaround: Contact Technical Support to assist you in removing entities that are no longer needed.\\nDE7612, 7.1.7, Client Console, Reports exported to .csv format are not formatted correctly. The headers are duplicated in each row as name/value pairs., Expected Results:\\xa0When exporting reports in .csv format, the column headers should not be repeated on each row.Workaround:\\xa0The report needs to be formatted to remove columns that show the column headers. In addition, LogRhythm data can be exported using Log Distribution Services (LDS).\\nDE1829, 7.3.3, Client Console, There may be inconsistencies in the way a log parses through MPE processing and within the MPE Rule Builder. A log that parses without issue in the Rule Builder may not parse when run through MPE processing.\\xa0This could be caused by rule match timeouts., Expected Results: The processing of a log should be the same whether it is parsed in Rule Builder or MPE.Workaround: Change the sub-rule to use a different tag, such as <Tag1>.\\xa0If you are experiencing this issue, ensure that you are not using a custom Log Processing Policy and that there are no MPE timeouts.\\xa0If issues persist, contact Technical Support and reference this bug number\\xa0(DE1829) or its sister defect\\xa0(DE1651).\\nDE3195, 7.3.4, Client Console, When running a search in either the Client or Web Console, users see an error: Error fetching data - Gateway timeout., Expected Results:\\xa0When a search times out, a message should inform users and instruct them\\xa0to re-run the search with a longer timeout.Workaround:\\xa0Increase the timeout on the query and re-run it.\\nDE5185, 7.3.4, Client Console, The Network (Impacted) field does not display on reports where it is included as a column, even though data appears in that field., Expected Results:\\xa0All chosen fields should appear\\xa0on the report if they contain data.Workaround:\\xa0Running the report as an investigation yields the expected results in the Network (Impacted) column. LogRhythm is\\xa0actively working on a solution to this issue in\\xa0a future release.\\nDE4049, 7.4.6, Client Console, When running a report that contains User Origin Identity or User Impacted Identity fields, the report runs and provides data, but the Identity fields are\\xa0not\\xa0populated., Expected Results: Identity data should appear\\xa0in reports that contain those fields.Workaround: Run an investigation to provide the same information.\\nDE3932, 7.4.7, Client Console, After disabling Log Source Virtualization for a log source, users are unable to perform certain tasks on the System Monitor from which the log source is collected., Expected Results:\\xa0Disabling Log Source Virtualization should not change the behavior of the System Monitor.Workaround: This issue is caused by the scsm.ini file not being updated immediately.\\xa0To work around it, refresh the Log Sources tab in the Client Console to\\xa0force the .ini file to refresh.\\nDE3839, 7.4.8, Client Console, In certain circumstances after running a Second Look restore, an error appears stating there is an issue with the Min and Max Ticks., Expected Results:\\xa0 Second Look restore should run without issues.Workaround:\\xa0 There is currently no workaround for this issue.\\nDE10678, 7.4.8, Client Console, The Log Management Usage Auditing Event Detail, Event List, and Logon & Logoff Events reports are rendering in UTC date/time format instead of the local time., Expected Results:Reports should all display in the local time zone or that specified in the\\xa0report configuration.Workaround:\\xa0 There is currently no workaround for this issue.\\nDE10621, 7.4.9, Client Console, When an existing report template that includes the Normal Date field is edited, the Normal Date field disappears from the template until\\xa0it is added again., Expected Results:\\xa0When editing a report template, existing fields should remain unless they are explicitly removed.Workaround:\\xa0When editing a report template that contains the Normal Date field, add that field back to the template prior to saving it.\\nDE11798, 7.4.10, Client Console, When exporting a large number of logs using the Send all Logs option from the Log Viewer in Client Console, the Console freezes., Expected Results: The Console should not freeze when exporting logs.Workaround: Export selected logs instead of all logs to allow the export to complete.\\nDE11499, 7.5.1, Client Console, When DNStoIP is enabled on the Data Processor and the DNS name doesn\\'t have a host record, the host field shows only the IP address without the host name.\\xa0 This impacts only the Client Console and is displayed correctly in the Web Console., Expected Results: The hostname should be displayed the same for both Web and Client Consoles.Workaround: View the record in the Web Console.\\nDE11056, 7.6.0, Client Console, When investigating results in the Client Console, the Unconfigured TopX configuration menu does not appear upon right-click., Expected Results: When right-clicking the Unconfigured TopX section in the investigation results, a menu appears to allow for configuration of results.Workaround: Utilize the Web Console to view results in a widget-type format.\\nDE12893, 7.6.0, Client Console, Active Directory users that are linked to User Profiles may not be updated after moving the user to a different Active Directory group., Expected Results: Users that are moved between Active Directory groups should update upon the move.Workaround: There is no workaround for this issue other than manually updating the profiles.\\nDE12510, 7.7.0, Client Console, When importing a new SmartResponse Plugin to the Client Console, permissions have to be explicitly granted to the user account that imported the plugin., Expected Results: The user importing the SmartResponse Plugin should have permissions granted automatically.Workaround: Go into the User Profile Manager and grant access to the newly imported SmartResponse Plugin.\\nDE13422, 7.7.0, Client Console, The entity delete functionality is very fragile, often failing with a generic error., Expected Results: The entity delete functionality works without any issues.Workaround:There is currently no workaround for this issue.\\nDE11717, 7.4.0, Client Console, When the Knowledge Base is synced, customized Log Source Type settings in the Windows Host Wizard revert to default., Expected Results: When custom settings are selected, they should persist through a Knowledge Base update.Workaround: Reselect the Log Source Type settings prior to doing a Windows Host Wizard scan.\\nDE10628, 7.4.8, Client Console, Duplicate Active Directory groups and users are being created because OU filters are not being used when scanning domains., Expected Results: No duplicate entries should be created.Workaround: There is currently no workaround for this issue.\\nDE12489, 7.4.9, Common Components, In rare circumstances, Alarms may not be available in the Web Console or will stop triggering. Typically, this occurs\\xa0directly after a configuration change to the ARM service., Expected Results: Alarms should continue to trigger and be displayed in the Web Console.Workaround: Contact Technical Support for assistance, as there could be many reasons for this behavior beyond this defect.\\xa0Support will help determine the root cause.\\nDE10768, 7.4.9, Common Components, In certain circumstances, the Data Processor runs slowly and the non-paged pool uses significant system memory.\\xa0This can cause a large unprocessed logs queue or other backlog in the system., Expected Results: The non-paged pool should not increase and cause system performance issues.Workaround:\\xa0Restart the LogRhythm API Gateway service.\\nDE10569, 7.4.10, Common Components, In certain circumstances, when the Platform Manager reboots, the Data Processor and Data Indexer are not able to connect to consul\\xa0and logs may not be indexed., Expected Results: The Data Processor and Data Indexer should connect to Service Registry after a reboot of the Platform Manager.Workaround: Manually restart the API Gateway and Service Registry services on the Data Indexer and Data Processor after a reboot of\\xa0the Platform Manager.\\nDE11733, 7.6.0, Common Components, When running the LogRhythm Infrastructure Installer (LRII), you may receive the\\xa0error: No plan file found in LogRhythm Service Registry KV store.\\xa0This is caused by the plan file not fully updating into the Consul KV store, and only happens in certain environments., Expected Results:\\xa0LRII\\xa0should be able to run multiple times without affecting the plan file.Workaround: For assistance with this issue, contact LogRhythm Technical Support.\\nDE12153, 7.6.0, Common Components, In some cases after a Data Indexer install, the Service Registry may not be able to communicate with the Platform Manager, causing alarms and errors in the Service Registry log., Expected Results: Communication to the Platform Manager should be maintained after an install.Workaround: Restart Service Registry on each node in the cluster after the installation is complete.\\nDE14729, 7.6.0, Common Components, Grafana does not categorize Mediators per cluster Log Indexing since moving to 7.6., Expected Results: Filter should show data processor stats for only the selected cluster.Workaround: Contact LogRhythm support for a new Mediator.json file.\\nDE3385, 7.3.2, Data Indexer, The DX Diagnostic logs are firing too often., Expected Results:The Diagnostic logs should be tuned to alarm less frequently.Workaround:There is currently no workaround for this issue.\\nDE2689, 7.4.4, Data Indexer, When the Data Indexer cluster health changes from green to yellow during EMDB list maintenance, alarms for Indexer\\xa0Cluster\\xa0Health\\xa0Excessive Warnings are generated.\\xa0This can cause concern when there is no\\xa0actual\\xa0issue on the system., Expected Results: An alarm should only generate when the cluster health changes to red.Workaround:\\xa0Edit\\xa0the\\xa0impacted\\xa0alarm\\xa0to\\xa0suppress\\xa0for\\xa024\\xa0hours\\xa0or\\xa0disable\\xa0that\\xa0alarm.\\nDE2753, 7.4.5, Data Indexer, When re-running the LogRhythm Infrastructure Installer (LRII) after the initial upgrade, the LogRhythm DX - Cluster Templating Service (consul-template) may remain in a paused state and not start up., Expected Results: All services, regardless of version, should start after an upgrade.Workaround: Re-run the Data Indexer component installer.\\nDE11822, 7.5.0, Data Indexer, The C:\\\\Windows\\\\Temp directory may become full with jtds.tmp files if the Carpenter service continually recycles.\\xa0 This can happen if using an SRP with List Management., Expected Results: Temporary files should not be left on disk.Workaround: Contact Technical Support for assistance with the workaround for this issue.\\nDE11765, 7.5.1, Data Indexer, In certain circumstances, Elasticsearch uses more memory than the set limit, causing performance issues on the server., Expected Results:\\xa0Elasticsearch should abide by the memory limit that is set.Workaround: For a workaround, contact LogRhythm Technical Support.\\nDE11934, 7.6.0, Data Indexer, In certain circumstances, customers with warm node indices may experience failed searches against those\\xa0indices.\\xa0This is due to Columbo being unable to close certain warm indices., Expected Results: Columbo should handle the warm node indices correctly and allow searches.Workaround: For assistance with this workaround, contact LogRhythm Technical Support.\\nDE12207, 7.6.0.HF2, Data Indexer, In some circumstances, installing the 7.6.0 Hotfix 2 upgrade will install a second instance of the Data Indexer., Expected Results: The Data Indexer should be removed and re-added instead of adding a second instance.Workaround: Uninstall both versions of the Data Indexer, ensure there or no hung .msi processes in the Task Manager, then re-install the 7.6.0 Hotfix 2 version.\\nDE13150, 7.7.0, Data Indexer, In certain circumstances after upgrading to 7.7.0, the Carpenter service causes port exhaustion and the service must be restarted., Expected Results: The Carpenter service should not cause port exhaustion.Workaround: Create a scheduled task to restart the Carpenter service each day.\\nDE12218, 7.6.0, Data Indexer, The Transporter can fail to fully start after restart at UTC midnight, causing indexing and performance issues. (This issue only impacts Linux clusters.), Expected Results: The Transporter should continue to run after a restart signal is sent.Workaround: Restart the Transporter service.\\nDE12201DE16040, 7.6.0, Data Indexer, Data is being indexed in lower case, ignoring the case of the original logs., Expected Results: Data should be stored in the format in which it was sent.Workaround: There is currently no workaround for this issue.\\nDE13480, N/A, Data Indexer, Alarm drilldowns fail as a result of changes to daylight savings in Chile. The failure is temporary and only lasts a few hours., Expected Results: Searching should work.Workaround: Either wait for the issue to naturally pass or manually adjust system clocks.\\nDE14719, 7.6.0, Data Indexer, In a deployment with DX7500 (2XDX), bulldozer reports the error message \"Configuration of elasticsearch topology differs from active elasticsearch topology\"., Expected Results: Bulldozer should handle 2XDX nodes correctly.Workaround: There is currently no workaround for this issue.\\nDE15289, N/A, Infrastructure, Weekday maintenance is taking much longer than expected., Expected Results: The weekday maintenance task should perform in a reasonable amount of time.Workaround: There is currently no workaround for this issue.\\nDE260DE9367, 7.4.7, Installation Components, In certain circumstances, customers may receive an alarm for a missed heartbeat on the AI Engine.\\xa0This can stem from a deadlock on resources in SQL., Expected Results: SQL deadlock issues should not cause a missed heartbeat.Workaround: While there is no\\xa0known workaround, LogRhythm is actively investigating this issue for a solution.\\nDE15601, 7.9.0, Installation Components, DR SQL transaction logs are filling the L: drive when unable to sync to secondary nodes., Expected Results: Transaction logs should be truncated by frequent scheduled backups throughout the day.Workaround: There is currently no workaround for this issue.\\nDE9995, 7.4.6, Job Manager, Scheduled reports are sent to a disabled account if an email is attached to the disabled account., Expected Results: Scheduled reports should not be sent to disabled accounts.Workaround: There is currently no workaround for this issue.\\nDE1013, 7.4.7, Job Manager, Reports are not completing when a large set of data is required.\\xa0This is due to a limitation within Crystal Reports., Expected Results: The Client Console should provide an alternate way to retrieve the data if Crystal Reports is not able to render it.Workaround: Decrease the amount of data the report is trying to retrieve or export the data instead.\\nDE10013, 7.4.7, Job Manager, When running a report against the Data Processor data source with a time period that contains only warm indices, the report returns no data., Expected Results: Searching against warm indices should return results whether the results are in hot or warm nodes.Workaround: Contact Technical Support for assistance with this workaround.\\nDE11701, 7.4.10, Job Manager, When exporting reports as .csv files, there are duplications of headers and footers that cause the report to be much larger in size than when run in the Console., Expected Results: Exported reports should not duplicate header and footer lines.Workaround: Export the report in another format or remove the extra lines from the .csv.\\nDE11892, 7.6.0, Job Manager, When re-enabling a disabled Active Directory user, the user\\'s LogRhythm login is not re-enabled., Expected Results: When a disabled user is re-enabled, the user\\'s login should also be enabled during the next AD Synchronization.Workaround: Manually enable the user\\'s login after the AD sync.\\nDE1879, 2.4, LogRhythm Diagnostics Tool, The LogRhythm Diagnostics Report shows the last backup information incorrectly., Expected Results:\\xa0The report should show the accurate last backup time for each database.Workaround:\\xa0Review the backup information in SQL Server Management Studio.\\nDE1968, 7.2.5, Mediator, Processing of Archive .bin files is sometimes delayed during heavy load and can back up at the Mediator, filling the hard drive., Expected Results:\\xa0Archives should process, seal, and move out of the Unprocessed Archives folder as long as the processing rate is at or below the system specification.Workaround:\\xa0Evaluate system sizing and consider an expansion to meet active load demands. In some systems, increasing the ArchiveSize setting in the Data Processor Advanced Properties to 51200 (from the default value of 10240) can help process archive files faster.\\xa0If necessary, move large files out of the Unprocessed Archives folder to another drive and slowly feed them back in when the system is successfully processing the live data. A more permanent solution to this issue will be provided\\xa0in a future release.\\nDE1640, 7.3.5, Mediator, The AIE Data Provider service does not start up correctly unless the Mediator service is also stopped and restarted.\\xa0Because logging is inconsistent, users\\xa0may not know that the service has failed to start properly., Expected Results:\\xa0The AIE Data Provider service should start consistently and as expected. Failures should be consistently logged to alert when the service\\xa0did not start correctly.Workaround:\\xa0Restart the Mediator service to allow the AIE Data Provider service to start. A more permanent solution to this issue is being evaluated for\\xa0a future release.\\nDE10182, 7.4.10, Mediator, If the network share that is used to store Inactive Archives becomes unavailable, the Mediator goes into a suspended state., Expected Results: The Mediator continues to process and move archive files to inactive when the connection is restored.Workaround: Ensure that the account the Mediator service is running has permission to access the network location.\\nDE13301, 7.4.10, Mediator, In certain circumstances when\\xa0Entity Archive settings are turned on, customers may receive the following error:**ERROR** Failed to locate or create inactive subdirectory: The given key was not present in the dictionary.. Inactive archive files will be temporarily stored at the root of the system drive (C:\\\\ in most cases). This error must be corrected in order for inactive archives to be stored at the specified location., Expected Results: Entity archiving should function without errors.Workaround: There is currently no workaround for this issue.\\nDE11496, 7.5.1, Mediator, In certain circumstances, the Mediator will attempt to seal the same archive file twice.\\xa0 This causes errors in the scmedsvr.log file., Expected results: The Mediator should only attempt to seal the archive file once.Workaround: There is no workaround for this issue.\\nDE15089, 7.9.0, Metrics Collection, Telemetry metrics parsing errors from Datadog are present in the metrics collection file., Expected Results:Datadog\\'s telemetry metrics parsing errors should not be present in the metrics collection file.Workaround:There is currently no workaround for this issue.\\nDE11101, 7.4.10, Smart Response Plugin, In certain circumstances, a SmartResponse action may fail to execute with an error: No System Monitor Associated with execution target., Expected Results:\\xa0 The SmartResponse Plugin should execute after selecting the System Monitor Agent.Workaround:There is currently no workaround for this issue.\\nDE12597, 7.5.0, Smart Response Plugin, When grouping two values in a SmartResponse Plugin, users receive an error that they do not have access to the Config file., Expected Results: Grouping values in SmartResponse Plugins should be allowed.Workaround: There is no workaround for this issue.\\nDE11820, 7.6.0, Smart Response Plugin, When utilizing multiple SmartResponse Plugins as part of the actions for an AIE Rule, inconsistent results may occur., Expected Results: SmartResponse Plugins should fire each time the AIE Rule is triggered.Workaround: There is no workaround for this issue.\\nDE10867, 1.2.0.10, TrueIdentity Sync Client, The TrueIdentity Sync Client will not connect to the Microsoft Active Directory LDAP server on port 636 using LDAP., Expected Results: The TrueIdentity Sync Client should be able to connect using LDAP via port 636.Workaround: Use port 389 instead and ensure the proper certificates are in place for security.\\nDE5312, 7.4.3, TrueIdentity Sync Client, The OU/DC filter in the TrueIdentity Sync Client does not allow white space., Expected Results: White space should be allowed in the OU/DC filter.Workaround: While there is no workaround for this issue, LogRhythm is\\xa0investigating a resolution for a future release.\\nDE39, 7.4.5, TrueIdentity Sync Client, The TrueIdentity Sync may fail if attempting to run\\xa0with a large number of users (greater than approximately 10,000)., Expected Results:\\xa0The TrueIdentity Sync Client should work for any number of users.Workaround:\\xa0While there is no workaround for this issue, the next release of the Sync Client will be able to support\\xa0larger AD environments.\\nDE1334, 7.3.3, Web Console, Customers who have integrated NetMon into the Web Console\\xa0may encounter a condition where the PCAP has aged out, but the user interface\\xa0indicates that it is still available. Attempting to download the PCAP results in an unclassified failure message., Expected Results:\\xa0When users try to download a PCAP that is no longer available on disk, the error message should provide that detail instead of an unclassified failure.Workaround:\\xa0The error message will be changed in a future release. There are two simple troubleshooting steps to identify if the PCAP exists or if other issues are occurring in the integration: Log in to NetMon\\xa0directly and verify if the selected PCAP has already aged out or should be available on disk. Recreate the API key for the selected NetMon\\xa0and update the NetMon configuration in the Deployment Manager.\\nDE1238, 7.4.2, Web Console, When copying a Top X widget to another dashboard, all configuration is lost after saving and refreshing the target dashboard., Expected Results:\\xa0When copying widgets, all settings should remain.Workaround:\\xa0Users can add a new widget to the dashboard and configure it manually to work around this issue. This issue is still being actively investigated and will be resolved in a future release.\\nDE7263, 7.4.2, Web Console, When exporting the results of an Investigation to .csv\\xa0from the Web Console Analyzer Grid, the date values in the first and last rows are exported as UNIX-formatted large integers rather than simple dates., Expected Results:\\xa0All data contained in the .csv export should be valid and match the data displayed in the Web Console.Workaround:\\xa0Export the same investigation from the Client Console or manually adjust the first and last date post export. LogRhythm is investigating a solution to this issue.\\nDE514, 7.4.3, Web Console, When viewing TrueIdentity records in the Web Console, 1,000 records are shown at once. Scrolling past that initial 1,000 records produces the error\\xa0message: Failed to fetch Identities: Bad Request., Expected Results:\\xa0Users should be able to scroll through all TrueIdentity records in the Web Console.Workaround:\\xa0Using filters to find specific data in the TrueIdentity page prevents the error message from showing and helps find data more quickly. LogRhythm is\\xa0working on a resolution for a future release.\\nDE1198, 7.4.6, Web Console, When downloading large NetMon PCAPs from the Web Console, there may be\\xa0delays\\xa0to the initial\\xa0download,\\xa0increased\\xa0memory usage, or\\xa0timeouts., Expected Results: The Web Console\\xa0should not time out when downloading large PCAP files.Workaround: Change the time out setting in the Configuration Manager.\\nDE10403, 7.4.9, Web Console, The Web Console Current Processing Rate widget does\\xa0not show the correct processing rate.\\xa0It does\\xa0not include messages older than 3 minutes in the rate determined., Expected Results: The Current Processing Rate widget\\xa0should show all logs\\xa0being processed.Workaround: Resolve any log source issues that are causing old logs to be ingested, or use Grafana or Performance Counters to check the current processing rate.\\nDE10442, 7.4.9, Web Console, When viewing NetMon logs in the Web Console using Internet Explorer, the Download PCAP button does not appear., Expected Results:\\xa0The Download PCAP button should appear\\xa0when reviewing NetMon logs.Workaround:\\xa0Reload the frame with the Download PCAP button to activate it.\\nDE11463, 7.6.0, Web Console, When the browser window is zoomed out, the Node-Link Graph on the Web Console dashboards may display an error Failed to establish logs subscription with the Web Console API.\\xa0 This is not related to the zoom functionality within the Node-Link Graph itself., Expected Results:\\xa0The Node-Link Graph should function regardless of the browser zoom level.Workaround:\\xa0 Return the browser to 100% zoom and refresh the Web Console.\\nDE11863, 7.6.0, Web Console, When running AIE Events drill down from an AIE events dashboard, the Analyze Dashboard filter does not reset properly., Expected Results: The Analyze Dashboard filter should reset.Workaround: In User Settings set the Drilldown setting to Open in Page.\\nDE11929, 7.6.0, Web Console, When using a Direction filter in the Web Console dashboard and\\xa0drilling into any of the TopX widgets, the data shown in the Analyzer Grid contains logs that do not match the dashboard filter., Expected Results: Drilling into data on a dashboard should not change the dashboard filter criteria.Workaround:\\xa0Reapply the dashboard filter.\\nDE12003, 7.6.0, Web Console, When drilling into widget items, previous filter options are being used., Expected Results: After closing a previous drilldown tab, the next drill down into a widget item should not show the older filters.Workaround: After drilling in a filter, refresh the web page. The next drill down into a widget item uses the correct filter.\\nDE12521, 7.6.0, Web Console, When pausing live data in the Web Console, the Analyzer grid continues to update with new events., Expected Results: The Analyzer grid should not\\xa0update with new events when paused.Workaround: There is currently no workaround for this issue.\\nDE12714, 7.6.0, Web Console, In the Web Console, if the last selected Analyzer page dashboard has a filter, drill down results are hidden., Expected Results:\\xa0drill down results should not be hidden.Workaround:\\xa0Select Default Analyze Dashboard\\nDE12908, 7.6.0, Web Console, Event logs are not appearing in the Web Console dashboard., Expected Results: Event data should appear in the dashboard.Workaround: There is currently no workaround for this issue.\\nDE13079, 7.6.0, Web Console, When running a search or drill down in the Web Console, the operation does not return results or terminate as intended., Expected Results: The search and drill down operations should return results upon completion or terminate.Workaround: Reload the page.\\nDE12544, 7.7.0, Web Console, The Timeline View widget is periodically displaying no results., Expected Results:The Timeline View widget works as normal.Workaround:There is currently no workaround for this issue.\\nDE12624, 7.7.0, Web Console, When using the Check Visible option in Alarms after upgrading to 7.7.0, the checked count does not reset properly., Expected Results: The checked count should reset.Workaround: After performing an action, select the Uncheck All option to reset the checked count.\\nDE13128, 7.7.0, Web Console, When running a search or drill down in the Web Console, the operation does not return results or terminate as intended., Expected Results: The search and drill down operations should return results upon completion or terminate.Workaround: Reload the page.\\nDE12852, 7.5.0, Web Console, Searching the Log Message field for a term containing a hyphen breaks the search into parts rather than searching for the full term as an exact match., Expected Results: Searching for terms should yield results for exact matches and not \\'AND\\' the words separated by hyphens.Workaround: There is currently no workaround for this issue.\\nDE12185, 7.5.0, Web Console, Lucene widget filtering is applied globally to the entire opened dashboard when a drilldown or time slice is initiated., Expected Results: \\xa0Lucene filtering should only apply to the widget from which it originated, Other widgets on the page will still lack the drilldown or time slice,Workaround: There is currently no workaround for this issue.\\nDE15763, 7.9.0, Web Console, The “Component Status” widget is not showing the component name correctly, instead it is showing as an icon., Expected Results: \\xa0Component names should be shown.Workaround: Hover over the icon to see the Component Name.\\nBug #\\nFound In Version\\nComponents\\nDescription\\nRelease Notes\\nExpected Results\\n:\\xa0Poorly written AIE Rules should be suspended until they are altered and re-enabled.\\nWorkaround\\n:\\xa0Rewrite the AIE Rule for\\xa0better performance.\\xa0Often, this involves adding filters, reducing log sources, and\\xa0modifying the logic. Tuning an AIE Rule requires expertise, so contact LogRhythm Training, Professional Services, or a Sales Engineer to assist if necessary. Additional solutions to identify and monitor poorly performing rules are being developed for a\\xa0future release.\\nExpected Results\\n:\\xa0These errors should not be generated in the AIE Engine log, but AIE\\xa0is\\xa0working\\xa0and\\xa0alarms\\xa0are\\xa0firing.\\nWorkaround\\n:\\xa0There is currently no workaround for this issue.\\nExpected Results\\n:\\xa0AIE Rule Blocks should fire when they are triggered at the same time.\\nWorkaround\\n:\\xa0As the behavior of simultaneous events is unpredictable\\xa0and the use case for a 0-time interval is rare, LogRhythm does not plan to change this behavior at this time. To avoid the issue, set the evaluation period to 1 second.\\nExpected Results\\n: The date and time of the AIE Event should not have a future time.\\nWorkaround\\n: There is no workaround for this issue.\\nExpected Results\\n:\\xa0AIE Rules should not fire if the rule block relationship is not met.\\nWorkaround\\n:\\xa0Change the Host (origin) or Host (impacted) fields to IP Address, and the AIE Rule works as expected.\\nExpected Results\\n: Logs in this directory should be purged after the number of days defined for expiration has passed, defaulted to 7 days.\\nWorkaround\\n:\\xa0 Manually remove these files to prevent the C drive from filling up.\\nExpected Results:\\nShould be able to define an AIE rule\\'s date and time using the UTC time zone.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nExpected Results\\n:\\xa0Alarms should\\xa0not fire if a log is received for a Not Observed block.\\nWorkaround\\n:\\xa0While there is currently no workaround, LogRhythm is investigating this issue for a future release.\\nExpected Results\\n:\\xa0Alarms should execute quickly as expected with other AIE Alarms.\\nWorkaround\\n:\\xa0There is currently no workaround for this issue.\\nExpected Results\\n: The AIE Engine should trigger alarms for Log Not Observed.\\nWorkaround\\n: There is currently no workaround for this issue.\\nDE14530\\nDE14531\\nExpected Results:\\nInput normalization for MAC Addresses, requiring them to be entered in the accepted format.\\nWorkaround:\\nUse data masking rules to transform the MAC addresses to the colon delimited format.\\nExpected Results\\n: Web Services does not need to be restarted to have a rule group change show up.\\nWorkaround\\n: Restart Web Services.\\nExpected Results\\n:\\xa0The Alarming and Response Manager should able to send alarm notifications using any SMTP server and SSL authentication.\\nWorkaround\\n:\\xa0There is currently no workaround for this issue.\\nExpected Results\\n: The Alarming and Response Manager should be aware of a change of status of the SRPs and should not continue to attempt to execute them.\\nWorkaround\\n: Lower the logging level on the ARM to help mitigate this, but contact LogRhythm Technical Support if assistance is needed to retire the SRP.\\nExpected Results:\\nRecent alarms should be visible when searching in the client console.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nExpected Results\\n: Case API and Admin API should start when using any size certificate.\\nWorkaround\\n:\\xa0Remove\\xa0the\\xa0server\\xa0from\\xa0the\\xa0domain and reboot it.\\xa0Verify that the\\xa0512-bit\\xa0certificate has\\xa0been\\xa0removed, re-run the installers, and reboot. To\\xa0avoid\\xa0this issue, do not join the domain\\xa0again\\xa0or\\xa0the\\xa0certificate will\\xa0be\\xa0pushed\\xa0out\\xa0again.\\xa0In addition, create a new certificate that\\xa0uses a 384-bit (or less) hash or exclude the impacted system from the GPO that pushes\\xa0the\\xa0certificate.\\nExpected Results\\n: When the Admin API log generates errors, it should provide some context within the error message.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: The extra semicolon, which is an optional valid separator in a content-type header, should not prevent scripts from working upon upgrade.\\nWorkaround\\n:\\nWhile there is currently no workaround, LogRhythm is investigating this issue for a future release\\n.\\nExpected Results:\\nThe Log Level should be changed by updating the Log Level in Configuration Manager.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: Entities\\xa0should be retireable\\xa0and able to be hidden from view.\\nWorkaround\\n: Contact Technical Support to assist you in removing entities that are no longer needed.\\nExpected Results\\n:\\xa0When exporting reports in .csv format, the column headers should not be repeated on each row.\\nWorkaround\\n:\\xa0The report needs to be formatted to remove columns that show the column headers. In addition, LogRhythm data can be exported using Log Distribution Services (LDS).\\nExpected Results\\n: The processing of a log should be the same whether it is parsed in Rule Builder or MPE.\\nWorkaround\\n: Change the sub-rule to use a different tag, such as <Tag1>.\\xa0If you are experiencing this issue, ensure that you are not using a custom Log Processing Policy and that there are no MPE timeouts.\\xa0If issues persist, contact Technical Support and reference this bug number\\xa0(DE1829) or its sister defect\\xa0(DE1651).\\nExpected Results\\n:\\xa0When a search times out, a message should inform users and instruct them\\xa0to re-run the search with a longer timeout.\\nWorkaround\\n:\\xa0Increase the timeout on the query and re-run it.\\nExpected Results\\n:\\xa0All chosen fields should appear\\xa0on the report if they contain data.\\nWorkaround\\n:\\xa0Running the report as an investigation yields the expected results in the Network (Impacted) column. LogRhythm is\\xa0actively working on a solution to this issue in\\xa0a future release.\\nExpected Results\\n: Identity data should appear\\xa0in reports that contain those fields.\\nWorkaround\\n: Run an investigation to provide the same information.\\nExpected Results\\n:\\xa0Disabling Log Source Virtualization should not change the behavior of the System Monitor.\\nWorkaround\\n: This issue is caused by the scsm.ini file not being updated immediately.\\xa0To work around it, refresh the Log Sources tab in the Client Console to\\xa0force the .ini file to refresh.\\nExpected Results\\n:\\xa0 Second Look restore should run without issues.\\nWorkaround\\n:\\xa0 There is currently no workaround for this issue.\\nExpected Results:\\nReports should all display in the local time zone or that specified in the\\xa0report configuration.\\nWorkaround\\n:\\xa0 There is currently no workaround for this issue.\\nExpected Results\\n:\\xa0When editing a report template, existing fields should remain unless they are explicitly removed.\\nWorkaround\\n:\\xa0When editing a report template that contains the Normal Date field, add that field back to the template prior to saving it.\\nExpected Results\\n: The Console should not freeze when exporting logs.\\nWorkaround\\n: Export selected logs instead of all logs to allow the export to complete.\\nExpected Results\\n: The hostname should be displayed the same for both Web and Client Consoles.\\nWorkaround\\n: View the record in the Web Console.\\nExpected Results\\n: When right-clicking the Unconfigured TopX section in the investigation results, a menu appears to allow for configuration of results.\\nWorkaround\\n: Utilize the Web Console to view results in a widget-type format.\\nExpected Results\\n: Users that are moved between Active Directory groups should update upon the move.\\nWorkaround\\n: There is no workaround for this issue other than manually updating the profiles.\\nExpected Results\\n: The user importing the SmartResponse Plugin should have permissions granted automatically.\\nWorkaround\\n: Go into the User Profile Manager and grant access to the newly imported SmartResponse Plugin.\\nExpected Results\\n: The entity delete functionality works without any issues.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nExpected Results\\n: When custom settings are selected, they should persist through a Knowledge Base update.\\nWorkaround\\n: Reselect the Log Source Type settings prior to doing a Windows Host Wizard scan.\\nDuplicate Active Directory groups and users are being created because OU filters are not being used when scanning domains.\\nExpected Results\\n: No duplicate entries should be created.\\nWorkaround\\n: There is currently no workaround for this issue.\\nDE12489\\nExpected Results\\n: Alarms should continue to trigger and be displayed in the Web Console.\\nWorkaround\\n: Contact Technical Support for assistance, as there could be many reasons for this behavior beyond this defect.\\xa0Support will help determine the root cause.\\nExpected Results\\n: The non-paged pool should not increase and cause system performance issues.\\nWorkaround\\n:\\xa0Restart the LogRhythm API Gateway service.\\nExpected Results\\n: The Data Processor and Data Indexer should connect to Service Registry after a reboot of the Platform Manager.\\nWorkaround\\n: Manually restart the API Gateway and Service Registry services on the Data Indexer and Data Processor after a reboot of\\xa0the Platform Manager.\\nExpected Results\\n:\\xa0LRII\\xa0should be able to run multiple times without affecting the plan file.\\nWorkaround\\n: For assistance with this issue, contact LogRhythm Technical Support.\\nExpected Results\\n: Communication to the Platform Manager should be maintained after an install.\\nWorkaround\\n: Restart Service Registry on each node in the cluster after the installation is complete.\\nExpected Results\\n: Filter should show data processor stats for only the selected cluster.\\nWorkaround\\n: Contact LogRhythm support for a new Mediator.json file.\\nExpected Results:\\nThe Diagnostic logs should be tuned to alarm less frequently.\\nWorkaround\\n:\\nThere is currently no workaround for this issue\\n.\\nExpected Results\\n: An alarm should only generate when the cluster health changes to red.\\nWorkaround\\n:\\xa0Edit\\xa0the\\xa0impacted\\xa0alarm\\xa0to\\xa0suppress\\xa0for\\xa024\\xa0hours\\xa0or\\xa0disable\\xa0that\\xa0alarm.\\nExpected Results\\n: All services, regardless of version, should start after an upgrade.\\nWorkaround\\n: Re-run the Data Indexer component installer.\\nExpected Results\\n: Temporary files should not be left on disk.\\nWorkaround\\n: Contact Technical Support for assistance with the workaround for this issue.\\nExpected Results\\n:\\xa0Elasticsearch should abide by the memory limit that is set.\\nWorkaround\\n: For a workaround, contact LogRhythm Technical Support.\\nExpected Results\\n: Columbo should handle the warm node indices correctly and allow searches.\\nWorkaround\\n: For assistance with this workaround, contact LogRhythm Technical Support.\\nExpected Results\\n: The Data Indexer should be removed and re-added instead of adding a second instance.\\nWorkaround\\n: Uninstall both versions of the Data Indexer, ensure there or no hung .msi processes in the Task Manager, then re-install the 7.6.0 Hotfix 2 version.\\nExpected Results\\n: The Carpenter service should not cause port exhaustion.\\nWorkaround\\n: Create a scheduled task to restart the Carpenter service each day.\\nExpected Results\\n: The Transporter should continue to run after a restart signal is sent.\\nWorkaround\\n: Restart the Transporter service.\\nDE12201\\nDE16040\\nExpected Results\\n: Data should be stored in the format in which it was sent.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: Searching should work.\\nWorkaround\\n: Either wait for the issue to naturally pass or manually adjust system clocks.\\nExpected Results\\n: Bulldozer should handle 2XDX nodes correctly.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: The weekday maintenance task should perform in a reasonable amount of time.\\nWorkaround\\n: There is currently no workaround for this issue.\\nDE260\\nDE9367\\nExpected Results\\n: SQL deadlock issues should not cause a missed heartbeat.\\nWorkaround\\n: While there is no\\xa0known workaround, LogRhythm is actively investigating this issue for a solution.\\nExpected Results\\n: Transaction logs should be truncated by frequent scheduled backups throughout the day.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: Scheduled reports should not be sent to disabled accounts.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: The Client Console should provide an alternate way to retrieve the data if Crystal Reports is not able to render it.\\nWorkaround\\n: Decrease the amount of data the report is trying to retrieve or export the data instead.\\nExpected Results\\n: Searching against warm indices should return results whether the results are in hot or warm nodes.\\nWorkaround\\n: Contact Technical Support for assistance with this workaround.\\nExpected Results\\n: Exported reports should not duplicate header and footer lines.\\nWorkaround\\n: Export the report in another format or remove the extra lines from the .csv.\\nExpected Results\\n: When a disabled user is re-enabled, the user\\'s login should also be enabled during the next AD Synchronization.\\nWorkaround\\n: Manually enable the user\\'s login after the AD sync.\\nExpected Results\\n:\\xa0The report should show the accurate last backup time for each database.\\nWorkaround\\n:\\xa0Review the backup information in SQL Server Management Studio.\\nExpected Results\\n:\\xa0Archives should process, seal, and move out of the Unprocessed Archives folder as long as the processing rate is at or below the system specification.\\nWorkaround\\n:\\xa0Evaluate system sizing and consider an expansion to meet active load demands. In some systems, increasing the ArchiveSize setting in the Data Processor Advanced Properties to 51200 (from the default value of 10240) can help process archive files faster.\\xa0If necessary, move large files out of the Unprocessed Archives folder to another drive and slowly feed them back in when the system is successfully processing the live data. A more permanent solution to this issue will be provided\\xa0in a future release.\\nExpected Results\\n:\\xa0The AIE Data Provider service should start consistently and as expected. Failures should be consistently logged to alert when the service\\xa0did not start correctly.\\nWorkaround\\n:\\xa0Restart the Mediator service to allow the AIE Data Provider service to start. A more permanent solution to this issue is being evaluated for\\xa0a future release.\\nExpected Results\\n: The Mediator continues to process and move archive files to inactive when the connection is restored.\\nWorkaround\\n: Ensure that the account the Mediator service is running has permission to access the network location.\\nIn certain circumstances when\\xa0Entity Archive settings are turned on, customers may receive the following error:\\n**ERROR** Failed to locate or create inactive subdirectory: The given key was not present in the dictionary.. Inactive archive files will be temporarily stored at the root of the system drive (C:\\\\ in most cases). This error must be corrected in order for inactive archives to be stored at the specified location.\\nExpected Results\\n: Entity archiving should function without errors.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected results\\n: The Mediator should only attempt to seal the archive file once.\\nWorkaround\\n: There is no workaround for this issue.\\nExpected Results:\\nDatadog\\'s telemetry metrics parsing errors should not be present in the metrics collection file.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nExpected Results\\n:\\xa0 The SmartResponse Plugin should execute after selecting the System Monitor Agent.\\nWorkaround\\n:\\nThere is currently no workaround for this issue\\n.\\nExpected Results\\n: Grouping values in SmartResponse Plugins should be allowed.\\nWorkaround\\n: There is no workaround for this issue.\\nExpected Results\\n: SmartResponse Plugins should fire each time the AIE Rule is triggered.\\nWorkaround\\n: There is no workaround for this issue.\\nExpected Results\\n: The TrueIdentity Sync Client should be able to connect using LDAP via port 636.\\nWorkaround\\n: Use port 389 instead and ensure the proper certificates are in place for security.\\nExpected Results\\n: White space should be allowed in the OU/DC filter.\\nWorkaround\\n: While there is no workaround for this issue, LogRhythm is\\xa0investigating a resolution for a future release.\\nExpected Results\\n:\\xa0The TrueIdentity Sync Client should work for any number of users.\\nWorkaround\\n:\\xa0While there is no workaround for this issue, the next release of the Sync Client will be able to support\\xa0larger AD environments.\\nExpected Results\\n:\\xa0When users try to download a PCAP that is no longer available on disk, the error message should provide that detail instead of an unclassified failure.\\nWorkaround\\n:\\xa0The error message will be changed in a future release. There are two simple troubleshooting steps to identify if the PCAP exists or if other issues are occurring in the integration: Log in to NetMon\\xa0directly and verify if the selected PCAP has already aged out or should be available on disk. Recreate the API key for the selected NetMon\\xa0and update the NetMon configuration in the Deployment Manager.\\nExpected Results\\n:\\xa0When copying widgets, all settings should remain.\\nWorkaround\\n:\\xa0Users can add a new widget to the dashboard and configure it manually to work around this issue. This issue is still being actively investigated and will be resolved in a future release.\\nExpected Results\\n:\\xa0All data contained in the .csv export should be valid and match the data displayed in the Web Console.\\nWorkaround\\n:\\xa0Export the same investigation from the Client Console or manually adjust the first and last date post export. LogRhythm is investigating a solution to this issue.\\nExpected Results\\n:\\xa0Users should be able to scroll through all TrueIdentity records in the Web Console.\\nWorkaround\\n:\\xa0Using filters to find specific data in the TrueIdentity page prevents the error message from showing and helps find data more quickly. LogRhythm is\\xa0working on a resolution for a future release.\\nExpected Results\\n: The Web Console\\xa0should not time out when downloading large PCAP files.\\nWorkaround\\n: Change the time out setting in the Configuration Manager.\\nExpected Results\\n: The Current Processing Rate widget\\xa0should show all logs\\xa0being processed.\\nWorkaround\\n: Resolve any log source issues that are causing old logs to be ingested, or use Grafana or Performance Counters to check the current processing rate.\\nExpected Results\\n:\\xa0The Download PCAP button should appear\\xa0when reviewing NetMon logs.\\nWorkaround\\n:\\xa0Reload the frame with the Download PCAP button to activate it.\\nExpected Results\\n:\\xa0The Node-Link Graph should function regardless of the browser zoom level.\\nWorkaround\\n:\\xa0 Return the browser to 100% zoom and refresh the Web Console.\\nExpected Results\\n: The Analyze Dashboard filter should reset.\\nWorkaround\\n: In User Settings set the Drilldown setting to Open in Page.\\nExpected Results\\n: Drilling into data on a dashboard should not change the dashboard filter criteria.\\nWorkaround\\n:\\xa0Reapply the dashboard filter.\\nExpected Results\\n: After closing a previous drilldown tab, the next drill down into a widget item should not show the older filters.\\nWorkaround\\n: After drilling in a filter, refresh the web page. The next drill down into a widget item uses the correct filter.\\nExpected Results\\n: The Analyzer grid should not\\xa0update with new events when paused.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n:\\xa0drill down results should not be hidden.\\nWorkaround\\n:\\xa0Select Default Analyze Dashboard\\nExpected Results\\n: Event data should appear in the dashboard.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: The search and drill down operations should return results upon completion or terminate.\\nWorkaround\\n: Reload the page.\\nExpected Results:\\nThe Timeline View widget works as normal.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nExpected Results\\n: The checked count should reset.\\nWorkaround\\n: After performing an action, select the Uncheck All option to reset the checked count.\\nExpected Results\\n: The search and drill down operations should return results upon completion or terminate.\\nWorkaround\\n: Reload the page.\\nExpected Results\\n: Searching for terms should yield results for exact matches and not \\'AND\\' the words separated by hyphens.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: \\xa0Lucene filtering should only apply to the widget from which it originated, Other widgets on the page will still lack the drilldown or time slice,\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: \\xa0Component names should be shown.\\nWorkaround\\n: Hover over the icon to see the Component Name.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.10.0.123 Release Notes - 11 October 2022': '', '': 'This guide describes the issue that has been fixed in LogRhythm 7.10.0, as well as the upgrade procedure from 7.10.0 GA to 7.10.0.123\\nThis patch release includes an updated installer for the LogRhythm Web Services. The updated components provided in 7.10.0.123 were added to the 7.10.0 GA release downloads on October 11, 2022. If you upgraded to 7.10.0 GA using software downloaded before October 11, apply this patch as soon as possible. If you upgraded using 7.10.0 GA software downloaded after October 11, you do not need to apply this patch.\\n', 'Resolved Issues': 'Bug #, Ticket #, Component, Description\\nDE16479, 451885, 452076, 452086, 452081, 451971, 451880, 452082, Web Console, The Web Console no longer intermittently disconnects users after 7.10 upgrade.\\nThe Web Console no longer intermittently disconnects users after 7.10 upgrade.\\n', 'Download the Upgrade Components': 'The 7.10.0.123 release includes an updated installer for the Web Services. The new installer can be downloaded from the LogRhythm Community.\\nLog in to the\\nCommunity\\n.\\nOn the main menu bar, click\\nDocumentation & Downloads\\n, and then click\\nSIEM\\n.\\nClick\\nNextGen SIEM\\n, and then click\\n7.10.0 GA Downloads\\n.\\nUnder 7.10.0 GA Downloads, download the\\nLogRhythm Install Wizard\\n.\\n', 'Upgrade the 7.10.0 Deployment': 'Run the LogRhythm Install Wizard just as you would to upgrade a deployment.\\nOpen the Install Wizard directory, and right-click the\\nLogRhythmInstallWizard.exe\\nyou downloaded in the steps above.\\nClick\\nRun as administrator\\n.\\nThe LogRhythm Install Wizard 7.10.0 appears.\\nClick\\nNext\\n.\\nThe LogRhythm Install Wizard Confirmation dialog box appears.\\nClick\\nYes\\n.\\nThe License Agreement appears.\\nSelect the check box to accept the terms in the license agreement, and then click\\nNext\\n.\\nOn the configuration page, select the\\nWeb Console\\nconfiguration.\\nUnder Optional Applications, deselect\\nLRD Agent\\n,\\xa0and then click\\nInstall\\n.\\nWhen the installer is finished, verify that the Web services are running.\\n', 'Verify Updated Component Version': 'When you are finished applying the patch, verify the updated component version.\\nFrom the Windows Start menu, open\\nControl Panel\\n.\\nClick\\nPrograms,\\nand then click\\nPrograms and Features\\nor\\nAdd/Remove Programs\\nto verify the version of the following component on all appliances or servers:\\nComponent, Original Version, Updated Version\\nLogRhythm Web Services, 7.10.0.121, 7.10.0.123\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.10.0.124 Release Notes - 6 March 2023': '', '': 'This guide describes an issue that has been fixed in LogRhythm 7.10, as well as the upgrade procedure from 7.10.x to 7.10.0.124.\\nThis patch release includes an updated installer for the LogRhythm Mediator service. The updated components provided in 7.10.0.124 were added to the 7.10.0 GA release downloads on March 6, 2023. If you upgraded using 7.10.0 GA software downloaded after March 6, you do not need to apply this patch.\\n', 'Resolved Issues': 'Bug #, Ticket #, Component, Description\\nENG-27655, 455756, 458679, Mediator, The Mediator is now correctly reading RealtimeQueue.dat files without requiring a restart.\\n', 'Download the Upgrade Components': 'The 7.10.0.124 release includes an updated installer for the Mediator. The new installer can be downloaded from the LogRhythm Community.\\nLog in to the\\nCommunity\\n.\\nOn the main menu bar, click\\nDocumentation & Downloads\\n, and then click\\nSIEM\\n.\\nClick\\nNextGen SIEM\\n, and then click\\n7.10.0 GA Downloads\\n.\\nUnder 7.10.0 GA Downloads, download the\\nLogRhythm Install Wizard\\n.\\n', 'Upgrade the 7.10.0 Deployment': 'Run the LogRhythm Install Wizard just as you would to upgrade a deployment.\\nOpen the Install Wizard directory, and right-click the\\nLogRhythmInstallWizard.exe\\nyou downloaded in the steps above.\\nClick\\nRun as administrator\\n.\\nThe LogRhythm Install Wizard 7.10.0 appears.\\nClick\\nNext\\n.\\nThe LogRhythm Install Wizard Confirmation dialog box appears.\\nClick\\nYes\\n.\\nThe License Agreement appears.\\nSelect the check box to accept the terms in the license agreement, and then click\\nNext\\n.\\nOn the configuration page, select the\\nData Processor\\nconfiguration.\\nUnder Optional Applications, deselect\\nLRD Agent\\n,\\xa0and then click\\nInstall\\n.\\nWhen the installer is finished, verify that the Web services are running.\\n', 'Verify Updated Component Version': 'When you are finished applying the patch, verify the updated component version.\\nFrom the Windows Start menu, open\\nControl Panel\\n.\\nClick\\nPrograms,\\nand then click\\nPrograms and Features\\nor\\nAdd/Remove Programs\\nto verify the version of the following component on all appliances or servers:\\nComponent\\nOriginal Version\\nUpdated Version\\nLogRhythm Mediator\\n7.10.0.8004\\n7.10.0.8005\\nClick\\nPrograms,\\nand then click\\nPrograms and Features\\nor\\nAdd/Remove Programs\\nto verify the version of the following component on all appliances or servers:\\nComponent, Original Version, Updated Version\\nLogRhythm Mediator, 7.10.0.8004, 7.10.0.8005\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.11.0 GA Release Notes - 5 January 2023': '', 'Upgrade Considerations': 'Upgrade considerations for all 7.11.x releases are available on the\\nLogRhythm Release Notes\\nmain page.\\nLogRhythm 7.9.0 introduced support for Microsoft SQL Server 2019 and Windows Server 2019 on standard deployments.\\nIf your deployment is running SQL Server 2016 Standard or Windows Server 2016, there is no need to upgrade to\\n2019\\n.\\nFor more information on the optional upgrades, see:\\nUpgrade SQL Server 2016 to SQL Server 2019\\nUpgrade Windows Server 2016 to Windows Server 2019\\n', 'New Features': 'Functional Group, Feature, Description\\nPlatform Administration, Admin API, Explanation:The Admin API library now includes new log source virtualization and MPE rule management endpoints.Benefit:The Admin API reduces administrative overhead and expedites workflow by automating routine tasks.Relevant Documentation Updates:Administration API Endpoints\\nPlatform Administration, Enhanced Auditing, Explanation:LogRhythm 7.11 introduces built-in auditing tables to the EMDB. The tables capture and log administrative activity, providing a historical record for auditing administrative changes.Benefit:Customers can now audit administrative changes made to LogRhythm configurations. They can also set up alerts to closely monitor critical configurations.Relevant Documentation Updates:Enhanced Auditing\\nMessage Processing Engine, MPE Rule Sharing, Explanation:SIEM Admins can now use MPE Rule Builder to import MPE rules created by other users without having to make manual modifications.Benefit:SIEM Admins can now share and import existing MPE rules from Community and other sources.Relevant Documentation Updates:Import and Export MPE Rules\\nLogRhythm Cloud, SecondLook as a Service(SLaaS for Windows), Explanation:LR Cloud SREs can now configure SecondLook as a Windows service for LR Cloud customers.Benefit:LR Cloud customers can configure, save, and execute SecondLook searches from the Web Console.Relevant Documentation Updates:SecondLook\\nData Processor, LogRhythm Console, Load Balanced Agent Groups, Explanation:Customers can now assign Agents to a specific load balanced group. The Agents are no longer required to connect to the same set of Data Processors, and load balanced child log sources function correctly. Adding new load balanced log sources or Agents to a group triggers an automatic Agent configuration update.Benefit:Organizing load balanced agents is easier.Relevant Documentation Updates:Load Balanced Agent Groups\\nSecurity and Reliability, Authentication Service, Explanation:LogRhythm implemented new JWT token security protocols in Authentication Service.Benefit:Enhanced security in Authentication Service.Relevant Documentation Updates:N/A\\nExplanation:\\nThe Admin API library now includes new log source virtualization and MPE rule management endpoints.\\nBenefit:\\nThe Admin API reduces administrative overhead and expedites workflow by automating routine tasks.\\nRelevant Documentation Updates:\\nAdministration API Endpoints\\nExplanation:\\nLogRhythm 7.11 introduces built-in auditing tables to the EMDB. The tables capture and log administrative activity, providing a historical record for auditing administrative changes.\\nBenefit:\\nCustomers can now audit administrative changes made to LogRhythm configurations. They can also set up alerts to closely monitor critical configurations.\\nRelevant Documentation Updates:\\nEnhanced Auditing\\nExplanation:\\nSIEM Admins can now use MPE Rule Builder to import MPE rules created by other users without having to make manual modifications.\\nBenefit:\\nSIEM Admins can now share and import existing MPE rules from Community and other sources.\\nRelevant Documentation Updates:\\nImport and Export MPE Rules\\nSecondLook as a Service\\n(SLaaS for Windows)\\nExplanation:\\nLR Cloud SREs can now configure SecondLook as a Windows service for LR Cloud customers.\\nBenefit:\\nLR Cloud customers can configure, save, and execute SecondLook searches from the Web Console.\\nRelevant Documentation Updates:\\nSecondLook\\nExplanation:\\nCustomers can now assign Agents to a specific load balanced group. The Agents are no longer required to connect to the same set of Data Processors, and load balanced child log sources function correctly. Adding new load balanced log sources or Agents to a group triggers an automatic Agent configuration update.\\nBenefit:\\nOrganizing load balanced agents is easier.\\nRelevant Documentation Updates:\\nLoad Balanced Agent Groups\\nExplanation:\\nLogRhythm implemented new JWT token security protocols in Authentication Service.\\nBenefit:\\nEnhanced security in Authentication Service.\\nRelevant Documentation Updates:\\nN/A\\n', 'Improvements': 'Added an option that allows the System Monitor Agent handles count to reset when the Mediator is restarted. For more information, see the Flat File Settings Tab table in\\nAdd a Single Log Source\\n.\\n', 'Deprecated Features': 'LogRhythm 7.8 was the last published version of the SOAP API. LogRhythm is deprecating the SOAP API in favor of more effective and sustainable integration through RESTful APIs. While the SOAP API is still usable in 7.9, we encourage customers and partners using the SOAP API to migrate their integrations to REST APIs. For more information on REST integration, see our\\nREST API\\ndocumentation\\n.\\n', 'Resolved Issues': 'Bug #, Ticket #, Component, Description\\nENG-10781(DE15454), 440713, APIs, Data retrieved by the Alarm API no longer presents out of order in certain situations.\\nENG-11098(DE15540), N/A, Automatic Remediation Engine, Smart Responses will no longer time out due to the stored procedures used by the ARM.\\nENG-10811(DE16240), 447860, 452400, 452554, Client Console, The Log Volume Report no longer produces an error stating that values are too large in certain situations.\\nENG-10923(DE11938), 405024, 444224, Client Console, Collecting logs via the Windows Host Wizard no longer assigns the wrong log sources in certain situations.\\nENG-10792(DE11015), 392225, 391496, 391011, 390671, 390442, 382674, Infrastructure: Database Scripts & Upgrade Scripts, The SQL database auto-growth settings no longer cause performance impacts and database fragmentation in certain situations.\\nENG-10807(DE16434), 451493, LR Cloud, Newly-created LR Cloud users are now visible to restricted admins by default.\\nENG-11084(DE11496), 396944, 413307, 424141, 415807, 426425, 449506, 449623, 450874, Mediator, The Mediator now correctly only seals the archive file once.\\nENG-10928(DE12546), 412596, 429205, Mediator, The agent handles count now correctly resets when the Mediator is restarted.\\nENG-11099(DE14771), 436942, 446452, Mediator, Saving MPE rules in the development status no longer causes updates within the MPE engine and soft resets.\\nENG-10853(DE16607), 450985, Mediator, An error message is no longer generated in the archive.log file in certain situations.\\nENG-11077(DE11622), 399555, Web Console, New AD users are now granted the correct permissions when being synced into LogRhythm via the AD Group Based Authorization.\\nENG-11107(DE14649), 434551, Disaster Recovery, Disaster Recovery (DR) Failovers no longer fail to receive DNS updates if the DR site uses a secondary domain controller with batched replication.\\nENG-10781\\n(DE15454)\\nENG-11098\\n(DE15540)\\nENG-10811\\n(DE16240)\\nENG-10923\\n(DE11938)\\nENG-10792\\n(DE11015)\\nENG-10807\\n(DE16434)\\nENG-11084\\n(DE11496)\\nENG-10928\\n(DE12546)\\nENG-11099\\n(DE14771)\\nENG-10853\\n(DE16607)\\nENG-11077\\n(DE11622)\\nENG-11107\\n(DE14649)\\n', 'Resolved Issues - Security': 'Security-related issues resolved with this release are available for customers to view on the\\nCommunity\\n.\\n', 'Known Issues': \"The following issues have each been found and reported by multiple users.\\nBug #, Found In Version, Components, Description, Release Notes\\nENG-23205(DE11499), 7.5.1, Client Console, When DNStoIP is enabled on the Data Processor and the DNS name doesn't have a host record, the host field shows only the IP address without the host name.\\xa0 This impacts only the Client Console and is displayed correctly in the Web Console., Expected Results: The hostname should be displayed the same for both Web and Client Consoles.Workaround: View the record in the Web Console.\\nENG-11120(DE13422), 7.7.0, Client Console, The entity delete functionality is very fragile, often failing with a generic error., Expected Results: The entity delete functionality should work without any issues.Workaround:There is currently no workaround for this issue.\\nENG-11165(DE16414), 7.9, Client Console, Client console search queries including the Host IP Address criteria are timing out in large databases., Expected Results:Log source searches should be completed without performance issues.Workaround:There is currently no workaround for this issue.\\nENG-22882(DE10768), 7.4.9, Common Components, In certain circumstances, the Data Processor runs slowly and the non-paged pool uses significant system memory.\\xa0This can cause a large unprocessed logs queue or other backlog in the system., Expected Results: The non-paged pool should not increase and cause system performance issues.Workaround:\\xa0Restart the LogRhythm API Gateway service.\\nENG-11108(DE12153), 7.6.0, Common Components, In some cases after a Data Indexer install, the Service Registry may not be able to communicate with the Platform Manager, causing alarms and errors in the Service Registry log., Expected Results: Communication to the Platform Manager should be maintained after an install.Workaround: Restart Service Registry on each node in the cluster after the installation is complete.\\nENG-22881(DE12218), 7.6.0, Data Indexer, The Transporter can fail to fully start after restart at UTC midnight, causing indexing and performance issues. (This issue only impacts Linux clusters.), Expected Results: The Transporter should continue to run after a restart signal is sent.Workaround: Restart the Transporter service.\\nENG-11175(DE16040), 7.6.0, Data Indexer, Data is being indexed in lower case, ignoring the case of the original logs., Expected Results: Data should be stored in the format in which it was sent.Workaround: There is currently no workaround for this issue.\\nENG-22862(DE13480), N/A, Data Indexer, Alarm drilldowns fail as a result of changes to daylight savings in Chile. The failure is temporary and only lasts a few hours., Expected Results: Searching should work.Workaround: Either wait for the issue to naturally pass or manually adjust system clocks.\\nENG-11150(DE15289), N/A, Infrastructure, Weekday maintenance is taking much longer than expected., Expected Results: The weekday maintenance task should perform in a reasonable amount of time.Workaround: There is currently no workaround for this issue.\\nENG-11173(DE15601), 7.9.0, Installation Components, DR SQL transaction logs are filling the L: drive when unable to sync to secondary nodes., Expected Results: Transaction logs should be truncated by frequent scheduled backups throughout the day.Workaround: There is currently no workaround for this issue.\\nENG-11142(DE15089), 7.9.0, Metrics Collection, Telemetry metrics parsing errors from Datadog are present in the metrics collection file., Expected Results:Datadog's telemetry metrics parsing errors should not be present in the metrics collection file.Workaround:There is currently no workaround for this issue.\\nENG-22873(DE12714), 7.6.0, Web Console, In the Web Console, if the last selected Analyzer page dashboard has a filter, drill down results are hidden., Expected Results:\\xa0drill down results should not be hidden.Workaround:\\xa0Select Default Analyze Dashboard\\nENG-11135(DE13128), 7.7.0, Web Console, When running a search or drill down in the Web Console, the operation does not return results or terminate as intended., Expected Results: The search and drill down operations should return results upon completion or terminate.Workaround: Reload the page.\\nENG-11134(DE13442), 7.7.0, Web Console, In some cases the Web Console services will not get the updated EMDB IP and will continually fail to connect to SQL until it is manually restarted., Expected Results: Services should restart or recheck the EMDB IP in service registry if it cannot connect to SQL server.Workaround: Restart Service Registry and SQL services.\\nENG-22863(DE14276), 7.7.0, Web Console, When using a Lucene filter in a Web Console widget, users are unable to filter widget time ranges for originUser., Expected Results:The Lucene filter should be able to filter time ranges.Workaround: Remove the time filter from the widget to show all data.\\nENG-11166(DE15763), 7.9.0, Web Console, The “Component Status” widget is not showing the component name correctly, instead it is showing as an icon., Expected Results: \\xa0Component names should be shown.Workaround: Hover over the icon to see the Component Name.\\nBug #\\nFound In Version\\nComponents\\nDescription\\nRelease Notes\\nENG-23205\\n(DE11499)\\nExpected Results\\n: The hostname should be displayed the same for both Web and Client Consoles.\\nWorkaround\\n: View the record in the Web Console.\\nENG-11120\\n(DE13422)\\nExpected Results\\n: The entity delete functionality should work without any issues.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nENG-11165\\n(DE16414)\\nExpected Results:\\nLog source searches should be completed without performance issues.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nENG-22882\\n(DE10768)\\nExpected Results\\n: The non-paged pool should not increase and cause system performance issues.\\nWorkaround\\n:\\xa0Restart the LogRhythm API Gateway service.\\nENG-11108\\n(DE12153)\\nExpected Results\\n: Communication to the Platform Manager should be maintained after an install.\\nWorkaround\\n: Restart Service Registry on each node in the cluster after the installation is complete.\\nENG-22881\\n(DE12218)\\nExpected Results\\n: The Transporter should continue to run after a restart signal is sent.\\nWorkaround\\n: Restart the Transporter service.\\nENG-11175\\n(DE16040)\\nExpected Results\\n: Data should be stored in the format in which it was sent.\\nWorkaround\\n: There is currently no workaround for this issue.\\nENG-22862\\n(DE13480)\\nExpected Results\\n: Searching should work.\\nWorkaround\\n: Either wait for the issue to naturally pass or manually adjust system clocks.\\nENG-11150\\n(DE15289)\\nExpected Results\\n: The weekday maintenance task should perform in a reasonable amount of time.\\nWorkaround\\n: There is currently no workaround for this issue.\\nENG-11173\\n(DE15601)\\nExpected Results\\n: Transaction logs should be truncated by frequent scheduled backups throughout the day.\\nWorkaround\\n: There is currently no workaround for this issue.\\nENG-11142\\n(DE15089)\\nExpected Results:\\nDatadog's telemetry metrics parsing errors should not be present in the metrics collection file.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nENG-22873\\n(DE12714)\\nExpected Results\\n:\\xa0drill down results should not be hidden.\\nWorkaround\\n:\\xa0Select Default Analyze Dashboard\\nENG-11135\\n(DE13128)\\nExpected Results\\n: The search and drill down operations should return results upon completion or terminate.\\nWorkaround\\n: Reload the page.\\nENG-11134\\n(DE13442)\\nExpected Results\\n: Services should restart or recheck the EMDB IP in service registry if it cannot connect to SQL server.\\nWorkaround\\n: Restart Service Registry and SQL services.\\nENG-22863\\n(DE14276)\\nExpected Results:\\nThe Lucene filter should be able to filter time ranges.\\nWorkaround\\n: Remove the time filter from the widget to show all data.\\nENG-11166\\n(DE15763)\\nExpected Results\\n: \\xa0Component names should be shown.\\nWorkaround\\n: Hover over the icon to see the Component Name.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.11.0.43 Release Notes - 6 March 2023': '', '': 'This guide describes an issue that has been fixed in LogRhythm 7.11, as well as the upgrade procedure from 7.11.x to 7.11.0.43.\\nThis patch release includes an updated installer for the LogRhythm Mediator service. The updated components provided in 7.11.0.43 were added to the 7.11.0 GA release downloads on March 6, 2023.\\xa0If you upgraded using 7.11.0 GA software downloaded after March 6, you do not need to apply this patch.\\n', 'Resolved Issues': 'Bug #, Ticket #, Component, Description\\nENG-27656, 455756, 458679, Mediator, The Mediator is now correctly reading RealtimeQueue.dat files without requiring a restart.\\n455756, 458679\\n', 'Download the Upgrade Components': 'The 7.11.0.43 release includes an updated installer for the Mediator. The new installer can be downloaded from the LogRhythm Community.\\nLog in to the\\nCommunity\\n.\\nOn the main menu bar, click\\nDocumentation & Downloads\\n, and then click\\nSIEM\\n.\\nClick\\nNextGen SIEM\\n, and then click\\n7.11.0 GA Downloads\\n.\\nUnder 7.11.0 GA Downloads, download the\\nLogRhythm Install Wizard\\n.\\n', 'Upgrade the 7.11.0 Deployment': 'Run the LogRhythm Install Wizard just as you would to upgrade a deployment.\\nOpen the Install Wizard directory, and right-click the\\nLogRhythmInstallWizard.exe\\nyou downloaded in the steps above.\\nClick\\nRun as administrator\\n.\\nThe LogRhythm Install Wizard 7.11.0 appears.\\nClick\\nNext\\n.\\nThe LogRhythm Install Wizard Confirmation dialog box appears.\\nClick\\nYes\\n.\\nThe License Agreement appears.\\nSelect the check box to accept the terms in the license agreement, and then click\\nNext\\n.\\nOn the configuration page, select the\\nData Processor\\nconfiguration.\\nUnder Optional Applications, deselect\\nLRD Agent\\n,\\xa0and then click\\nInstall\\n.\\nWhen the installer is finished, verify that the Web services are running.\\n', 'Verify Updated Component Version': 'When you are finished applying the patch, verify the updated component version.\\nFrom the Windows Start menu, open\\nControl Panel\\n.\\nClick\\nPrograms,\\nand then click\\nPrograms and Features\\nor\\nAdd/Remove Programs\\nto verify the version of the following component on all appliances or servers:\\nComponent\\nOriginal Version\\nUpdated Version\\nLogRhythm Mediator\\n7.11.0.8011\\n7.11.0.8012\\nClick\\nPrograms,\\nand then click\\nPrograms and Features\\nor\\nAdd/Remove Programs\\nto verify the version of the following component on all appliances or servers:\\nComponent, Original Version, Updated Version\\nLogRhythm Mediator, 7.11.0.8011, 7.11.0.8012\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.12.0 GA Release Notes - 3 April 2023': 'Introducing LogRhythm SIEM 7.12! In this version, we\\nimproved the process for collecting and monitoring new security data sources. We streamlined these administrative tasks to give users more time to respond to and investigate detected threats.\\nBrief explanations of the updates are grouped into the following sections:\\nAnalyst Experience\\nAutomation\\nData Collection\\nAutomatic Restored Archive Maintenance\\nSecondLook Role-based Access Controls (RBAC)\\nKey highlights include:\\nEnhanced Log Collection with LogRhythm OC Admin\\nLog Source Virtualization Management with the Admin API\\nLog Source Visibility in the Web Console\\nSections on maintenance and upgrades:\\nUpgrade Considerations\\nResolved Issues\\nKnown Issues\\n', 'Analyst Experience': 'In the last release, LR SIEM 7.11, LogRhythm introduced\\nSecondLook\\nin the Web Console for LogRhythm Cloud customers who purchased archive storage. This new SecondLook UI lets LogRhythm Cloud customers configure and run SecondLook restores directly from the Web Console. In 7.12, we added a quick search function that allows users to retrieve completed SecondLook restore results with the click of a button.\\nAn inactive search icon is now displayed in the actions column of each restore. When the restore status moves from In Progress to Completed, the icon activates.\\n\\n\\nSelect the icon to quickly run a search for the logs restored by SecondLook.\\n\\n\\nEach search is pre-populated with the filter criteria used in the corresponding saved SecondLook restore settings, and it works like all other searches. T\\nhe history of past searches is updated whenever you click the SecondLook quick search icon, giving you easy access to modify pre-populated filters.\\n\\n', 'Automation': 'Over the past several SIEM versions, LogRhythm has released additional endpoints for the Admin API that enable integration and automation workflows for log source and agent onboarding. Version 7.12 further extends these capabilities by adding endpoints that allow you to programmatically:\\nRetrieve additional log source details, including:\\nLast Log Message\\nSilent Log Source configurations\\nSystem Monitor name\\nSystem Monitor ID\\nLast Log Message\\nSilent Log Source configurations\\nSystem Monitor name\\nSystem Monitor ID\\nCreate and update virtual log sources from a template\\nUpdate existing log source virtualization templates\\nManage log processing policies\\nManage log source types\\nFor more details on all the available endpoints, refer to the\\nAPI Documentation\\n. New to the API and wondering how to get started? Learn more on the\\nCommunity\\n!\\n', 'Data Collection': \"Version 7.12 improves log source onboarding workflows with log source visibility in the Web Console and enhancements to the Open Collector's\\nOC Admin\\n.\\n\", 'Added Beats Support in OC Admin': 'Collecting data from API log sources is faster and easier with OC Admin. In 7.12, we added support to the following LogRhythm Beats:\\nPrisma\\nSymantec Web Secure Service (WSS)\\nMicrosoft Graph API\\nCarbon Black Cloud\\nCisco AMP\\nDUO\\nProofpoint\\n', 'Open Collector Administration': 'Monitoring collectors across the enterprise just became easier. LogRhythm SIEM 7.12 introduces light administration capabilities within OC Admin.\\nLive statistics (CPU, memory, network, storage, and processes consumption) are available for the containers running on a given Open Collector host.\\n\\nOn the Open Collector Manage page, customers can perform a series of actions on the Beats and Open Collector components, including: starting and stopping, importing and exporting configurations, exporting logs as files, and viewing high-level configurations or real time logs in the UI.\\n\\n\\nFinally, we added support for exporting and tracking Open Collector and Beats internal logs in real time.\\n\\n', 'Log Sources Page in the Web Console': 'In the Web Console, global and restricted administrators now have a Log Sources option in the Administration menu.\\nOn the Log Sources page, administrators can quickly check the status and health of log sources in the Web Console. They can easily see if a log source is active or retired, along with the timestamp of the last log received.\\nThe\\nLog Source Grid\\nshows a dynamic display of log sources based on the access granted to the user.\\nThe Log Source Grid helps administrators immediately identify problematic log sources with Silent Log Source highlighting. In environments that contain thousands of log sources, admins can filter down to view just the log sources that matter. Filters include:\\nName\\nEntity\\nLog Source Type\\nLog Source Host\\nCollection Agent\\nSilent Log Source status\\nLast Log Message\\nName\\nEntity\\nLog Source Type\\nLog Source Host\\nCollection Agent\\nSilent Log Source status\\nLast Log Message\\n\\n', 'Automatic Restored Archive Maintenance': 'Administrators can now configure\\nAutomatic Maintenance\\nof restored archives in LogRhythm SIEM 7.12. In the Configuration Manager, they can toggle automatic maintenance on or off. They can also set time to live (TTL) and maximum disk utilization parameters. When enabled, restored archive indices on the Data Indexer (indices labeled \"logsar-\") will be deleted based on whichever condition is met first - the specified TTL or the maximum disk utilization. When the maximum disk utilization condition is triggered, the oldest restored index is deleted first.\\n\\n', 'SecondLook Role-based Access Controls (RBAC)': 'For LogRhythm Cloud customers, role-based access controls now provide more granular options for allowing access to\\nSecondLook\\n. Within a user profile, administrators can grant a user access to the SecondLook tool in the Client Console, in the Web Console, or in both consoles.\\n\\n', 'Upgrade Considerations': 'Upgrade considerations for all 7.12.x releases are available on the\\nLogRhythm Release Notes\\nmain page.\\nLogRhythm 7.9.0 introduced support for Microsoft SQL Server 2019 and Windows Server 2019 on standard deployments.\\nIf your deployment is running SQL Server 2016 Standard or Windows Server 2016, there is no need to upgrade to\\n2019\\n.\\nFor more information on the optional upgrades, see:\\nUpgrade SQL Server 2016 to SQL Server 2019\\nUpgrade Windows Server 2016 to Windows Server 2019\\n', 'Resolved Issues': '\\nBug #, Component, Description\\nENG-6389, AI Engine, An issue with AIE Alarms being delayed or not firing at all for some users after an upgrade to 7.10 has been resolved.\\nENG-23628, AI Engine, Importing an AIE rule as a Restricted Admin no longer produces an error message in certain situations.\\nENG-25735, AI Engine, AIE Alarms no longer experience delays in firing in certain situations.\\nENG-10785(DE16001), APIs, Data visible in the Web Console is no longer missing from API calls in certain situations.\\nENG-11138(DE14716), APIs, The Alarm API DB query timeout is now configurable.\\nENG-11180(DE16701), APIs, The Alarm API no longer produces an error in certain situations when trying to update the status of multiple alarms.\\nENG-23714, APIs, The Search API no longer produces SQL Exception errors in certain situations.\\nENG-23726, APIs, The Alarm API no longer interferes with and causes timeouts in the Alarming Response Manager.\\nENG-23684, APIs, The Search API no longer fails with SQL Exceptions in certain situations.\\nENG-11120(DE13422), Client Console, The entity delete functionality no longer results in an error in certain situations.\\nENG-11136(DE13599), Client Console, Restricted Admins/Analysts can no longer view and select log sources to which they were not given permissions in certain situations.\\nENG-23205(DE11499), Client Console, When DNStoIP is enabled on the Data Processor and the DNS name doesn\\'t have a host record, the host field now correctly shows the host name in both the Client Console and Web Console.\\nENG-23240, Data Indexer, The Transporter no longer fails to index when a field is larger than the maximum length allowed.\\nENG-23988, LR Cloud, The creator of a user record can now correctly see all records they have created.\\nENG-11208(DE16564), Mediator, Duplicate entity \"Fullnames\" no longer cause the Mediator to fail to start in certain situations.\\nENG-22883(DE16816), Mediator, The MemoryThresholdSuspend feature is now optional and disabled by default to prevent unnecessary suspensions.\\nENG-23094, Mediator, The Mediator now correctly reads RealtimeQueue.dat files.\\nENG-10811(DE16240), Reporting, The Log Volume Report no longer produces an error stating that values are too large in certain situations.\\nENG-22879(DE16706), Reporting, Report fields are no longer truncated in certain situations.\\nENG-23352(DE15428), System Monitor Agents, Upgrading an agent via the System Monitor Package Manager no longer creates unnecessary scheduled tasks.\\nENG-23240, Transporter, The Transporter no longer displays an error message relating to immense terms in log fields in certain situations.\\nENG-11166(DE15763), Web Console, The “Component Status” widget now shows the component name correctly.\\nENG-22873(DE12714), Web Console, Drill down results in the Web Console are no longer hidden when the last selected Analyzer page dashboard has a filter.\\nENG-22886(DE16590), Web Console, Web Console SSO no longer produces an error when trying to sign on in certain situations.\\nENG-24283, Web Console, Executing a saved search after clicking \"Edit\" on the saved search no longer returns incorrect results.\\nENG-22866(DE12262), Web Console, The Web Console no longer automatically applies contextualization on User (Origin) or User (Impacted) fields.\\nENG-10785\\n(DE16001)\\nENG-11138\\n(DE14716)\\nENG-11180\\n(DE16701)\\nENG-11120\\n(DE13422)\\nENG-11136\\n(DE13599)\\nENG-23205\\n(DE11499)\\nENG-11208\\n(DE16564)\\nENG-22883\\n(DE16816)\\nENG-23094\\nENG-10811\\n(DE16240)\\nThe Log Volume Report no longer produces an error stating that values are too large in certain situations.\\nENG-22879\\n(DE16706)\\nENG-23352\\n(DE15428)\\nENG-11166\\n(DE15763)\\nENG-22873\\n(DE12714)\\nENG-22886\\n(DE16590)\\nENG-22866\\n(DE12262)\\nThe Web Console no longer automatically applies contextualization on User (Origin) or User (Impacted) fields.\\n', 'Resolved Issues - Security': 'Security-related issues resolved with this release are available for customers to view on the\\nCommunity\\n.\\n', 'Known Issues': \"The following issues have each been found and reported by multiple users.\\n\\nBug #, Found In Version, Components, Description, Release Notes\\nENG-11165(DE16414), 7.9, Client Console, Client console search queries including the Host IP Address criteria are timing out in large databases., Expected Results:Log source searches should be completed without performance issues.Workaround:There is currently no workaround for this issue.\\nENG-22882(DE10768), 7.4.9, Common Components, In certain circumstances, the Data Processor runs slowly and the non-paged pool uses significant system memory.\\xa0This can cause a large unprocessed logs queue or other backlog in the system., Expected Results: The non-paged pool should not increase and cause system performance issues.Workaround:\\xa0Restart the LogRhythm API Gateway service.\\nENG-11108(DE12153), 7.6.0, Common Components, In some cases after a Data Indexer install, the Service Registry may not be able to communicate with the Platform Manager, causing alarms and errors in the Service Registry log., Expected Results: Communication to the Platform Manager should be maintained after an install.Workaround: Restart Service Registry on each node in the cluster after the installation is complete.\\nENG-22881(DE12218), 7.6.0, Data Indexer, The Transporter can fail to fully start after restart at UTC midnight, causing indexing and performance issues. (This issue only impacts Linux clusters.), Expected Results: The Transporter should continue to run after a restart signal is sent.Workaround: Restart the Transporter service.\\nENG-11175(DE16040), 7.6.0, Data Indexer, Data is being indexed in lower case, ignoring the case of the original logs., Expected Results: Data should be stored in the format in which it was sent.Workaround: There is currently no workaround for this issue.\\nENG-22862(DE13480), N/A, Data Indexer, Alarm drilldowns fail as a result of changes to daylight savings in Chile. The failure is temporary and only lasts a few hours., Expected Results: Searching should work.Workaround: Either wait for the issue to naturally pass or manually adjust system clocks.\\nENG-11150(DE15289), N/A, Infrastructure, Weekday maintenance is taking much longer than expected., Expected Results: The weekday maintenance task should perform in a reasonable amount of time.Workaround: There is currently no workaround for this issue.\\nENG-11173(DE15601), 7.9.0, Installation Components, DR SQL transaction logs are filling the L: drive when unable to sync to secondary nodes., Expected Results: Transaction logs should be truncated by frequent scheduled backups throughout the day.Workaround: There is currently no workaround for this issue.\\nENG-11142(DE15089), 7.9.0, Metrics Collection, Telemetry metrics parsing errors from Datadog are present in the metrics collection file., Expected Results:Datadog's telemetry metrics parsing errors should not be present in the metrics collection file.Workaround:There is currently no workaround for this issue.\\nENG-22863(DE14276), 7.7.0, Web Console, When using a Lucene filter in a Web Console widget, users are unable to filter widget time ranges for originUser., Expected Results:The Lucene filter should be able to filter time ranges.Workaround: Remove the time filter from the widget to show all data.\\nBug #\\nFound In Version\\nComponents\\nDescription\\nRelease Notes\\nENG-11165\\n(DE16414)\\nExpected Results:\\nLog source searches should be completed without performance issues.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nENG-22882\\n(DE10768)\\nExpected Results\\n: The non-paged pool should not increase and cause system performance issues.\\nWorkaround\\n:\\xa0Restart the LogRhythm API Gateway service.\\nENG-11108\\n(DE12153)\\nExpected Results\\n: Communication to the Platform Manager should be maintained after an install.\\nWorkaround\\n: Restart Service Registry on each node in the cluster after the installation is complete.\\nENG-22881\\n(DE12218)\\nExpected Results\\n: The Transporter should continue to run after a restart signal is sent.\\nWorkaround\\n: Restart the Transporter service.\\nENG-11175\\n(DE16040)\\nExpected Results\\n: Data should be stored in the format in which it was sent.\\nWorkaround\\n: There is currently no workaround for this issue.\\nENG-22862\\n(DE13480)\\nExpected Results\\n: Searching should work.\\nWorkaround\\n: Either wait for the issue to naturally pass or manually adjust system clocks.\\nENG-11150\\n(DE15289)\\nExpected Results\\n: The weekday maintenance task should perform in a reasonable amount of time.\\nWorkaround\\n: There is currently no workaround for this issue.\\nENG-11173\\n(DE15601)\\nExpected Results\\n: Transaction logs should be truncated by frequent scheduled backups throughout the day.\\nWorkaround\\n: There is currently no workaround for this issue.\\nENG-11142\\n(DE15089)\\nExpected Results:\\nDatadog's telemetry metrics parsing errors should not be present in the metrics collection file.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nENG-22863\\n(DE14276)\\nExpected Results:\\nThe Lucene filter should be able to filter time ranges.\\nWorkaround\\n: Remove the time filter from the widget to show all data.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.13.0 GA Release Notes - 29 June 2023': 'Introducing LogRhythm SIEM 7.13! In this version, we\\xa0significantly improved processing performance with the System Monitor JSON Engine and Data Processor Pooling.\\nBrief explanations of the updates are grouped into the following sections:\\nAnalyst Experience\\nAnalyst Experience\\nAutomation\\nAutomation\\nData Collection\\nData Collection\\nPlatform\\nPlatform\\nKey highlights include:\\nData Processor Pooling\\nData Processor Pooling\\nSystem Monitor JSON Engine\\nSystem Monitor JSON Engine\\nSecondLook in Web Console\\nSecondLook in Web Console\\nSections on maintenance and upgrades:\\nResolved Issues\\nResolved Issues\\nKnown Issues\\nKnown Issues\\nWe’ve updated our LogRhythm SIEM Documentation. You can now select documentation associated with a specific version (starting with 7.12.0). Click on the version picker in the upper-right corner on the\\nSIEM\\nand\\nInstallations and Upgrades\\nlanding pages.\\n', 'Analyst Experience': '', 'SecondLook in Web Console': 'Customers want to retain their data, and they need an easy way to find their older data. With LogRhythm 7.13, customers who use our self-hosted SIEM option now have access to SecondLook. After installing and configuring SecondLook, customers can query data and search through archives directly from the Web Console. Without having to pivot between the Web Console and Client Console, customers save valuable time. Using SecondLook also means searches are passed off to a dedicated service for a more reliable user experience.\\nInitiating a SecondLook search.\\nFor installation and configuration details, see\\nInstall SecondLook API\\n.\\n', 'Automation': 'With new features, come new REST API endpoints! LogRhythm 7.13 further extends the automation capabilities of the Admin API so that you can programmatically:\\nConfigure, update, and retrieve System Monitor DP Pooling settings.\\nConfigure, update, and retrieve System Monitor DP Pooling settings.\\nConfigure, update, and retrieve System Monitor Load Balanced Group settings.\\nConfigure, update, and retrieve System Monitor Load Balanced Group settings.\\nConfigure, update, and retrieve log source Watch File Rename on Rollover settings.\\nConfigure, update, and retrieve log source Watch File Rename on Rollover settings.\\nFor more details on all the available endpoints, see our\\nREST API Documentation\\n.\\nNew to the API and wondering how to get started? Learn more on the\\nCommunity\\n!\\n', 'Data Collection': '', 'Data Processor Pooling': 'Data Processor pooling makes it easy for administrators to distribute log volume across a pool of Data Processors and create well-balanced Data Indexer clusters. With DP pooling, administrators can quickly define DP pools and assign Agents to them. Agents then auto-distribute their logs across the DP pool. Administrators can also turn off DP pooling by switching an Agent to pinned mode.\\nSystem Monitor Agents are the workhorses that collect and ship data to Data Processors. But there was not a good way to load balance these System Monitor Agents across multiple Data Processors — until now.\\nWith version 7.13, LogRhythm introduces\\nData Processor Pooling\\n, a new feature that lets administrators define a pool of one or more Data Processors to allow a single Agent to collectively send its data to a group of Data Processors. When an Agent is assigned a DP pool, the Agent will spread the logs across the Data Processors. This removes the need to manually review Agent volumes and adjust which Data Processors the Agents are sending to, saving you time.\\nDefining a Data Processor pool.\\n\\nAssigning a Data Processor to a pool.\\n\\nAssigning a System Monitor to a pool.\\n', 'System Monitor JSON Engine': 'The 7.13 System Monitor is now embedded with a native JSON parsing engine. This significantly improves processing performance and removes the need to work with JQ query language. With the new architecture, Beats can be rerouted from the Open Collector parsing engine to the new parsing engine on the System Monitor. This simplifies sizing, deployment, and troubleshooting of the platform. For more information, see\\nConfigure Beats for JSON Parsing\\n.\\nEnabling JSON parsing on a System Monitor Agent.\\n', 'View System Monitor Agents in the Web Console': \"In the Web Console, global and restricted administrators now have an Agents option in the Administration menu.\\nOn the Agents page, administrators can quickly check the status and health of System Monitors right in the Web Console. They can easily see a System Monitor's status and the timestamp of the last heartbeat received.\\nThe\\nAgents Grid\\nshows a dynamic display of agents based on the access granted to the user.\\nRestricted administrators can only view the effective System Monitors defined in their user profile.\\nThe Agents Grid helps administrators immediately identify problematic Agents with Last Heartbeat highlighting. In environments that contain thousands of Agents, admins can filter down to view just the Agents that matter. Filters include:\\nName\\nName\\nHost\\nHost\\nEntity\\nEntity\\nType\\nType\\nNumber of Log Source\\nNumber of Log Source\\nVersion\\nVersion\\nStatus\\nStatus\\nData Processor\\nData Processor\\nLast Heartbeat\\nLast Heartbeat\\nApplying a filter on the Agents Grid.\\n\", 'Platform': 'Over time, operating systems become outdated, making past versions unsupported. With the release of 7.13, LogRhythm is supporting and installing Microsoft Server 2022, Microsoft SQL Server 2019, and Rocky Linux. For customers that prefer the open-source version of Linux, Data Indexers and Open Collector support Rocky Linux 9 and RHEL 9. For customers with RHEL licenses, LogRhythm SIEM supports RHEL 9. For information, see the Component Operating System Support section in\\nReview the Requirements for a New LogRhythm Deployment\\n.\\nWe’ve also added additional support for System Monitor, which includes Windows 2022, Windows 11, Rocky Linux 9, and RHEL 9. For information, see\\nLogRhythm System Monitor Compatibility and Functionality\\n.\\n', 'Resolved Issues': 'Bug #, Component, Description\\nENG-11205(DE16679), Active Directory, Active Directory syncs no longer fail when a user account has two usernames.\\nENG-35407, AI Engine, AI Engine rules no longer experience significant delays when firing in certain situations.\\nENG-22876(DE16824), APIs, Changing the alarm status in the Case API no longer results in an error in certain situations.\\nENG-11199(DE16890), APIs, Alarm Status update requests no longer fail in LRCloud deployments in certain situations.\\nENG-23824, Client Console, The Deployment Manager option is no longer shown to Restricted Analysts.\\nENG-11160(DE15875), Client Console, LogMart maintenance now correctly reflects changes made to LogMart_TTL.\\nENG-24715, Client Console, SSL/TLS can now be enabled on the Platform Manager Properties tab to prevent SSL/TLS notification failure.\\nENG-24954, Client Console, The MaxMessageCount for a log source can now accept values up to 50,000.\\nENG-11141(DE14874), Reporting, The Log Volume by Log Source report\\'s Bytes/Packets and Sent/Rcvd filters now execute successfully.\\nENG-31775, SecondLook, The SecondLook API log no longer displays incorrect \"Object reference\" errors.\\nENG-36167, SecondLook, Saving a SecondLook configuration with a retired log source no longer fails.\\nENG-34885, SecondLook, SecondLook drill-downs and searches no longer give inaccurate results in certain situations due to local machine time zone discrepancies.\\nENG-34260, SecondLook, The SecondLook API no longer produces an incorrect \"out of memory\" error in certain situations when executing a search.\\nENG-36544, System Monitor, The AutoCorrectionMSEvtPosLogic flag is now OFF by default in the scsm.exe.config file to prevent unnecessary errors.\\nENG-34772, System Monitor, Starting a System Monitor agent in \"unidirectional mode\" no longer produces a socket error in certain situations.\\nENG-22863(DE14276), Web Console, The Lucene filter now correctly filters time ranges.\\nENG-11143(DE15241), Web Console, The Web Console no longer crashes in certain situations when attempting to search by log source.\\nENG-11161(DE15810), Web Console, The time range filter now works correctly and populates widgets when applied to the trend chart.\\nENG-11140(DE14882), Web Console, The User (Origin), User (Impacted), and User (Identity) fields on widgets now correctly show results when the widget or dashboard timeframe is changed.\\nENG-11162(DE16404), Web Console, Location-based widget filters are now applied correctly.\\nENG-11192(DE16711), Web Console, The Dashboard navigation bar no longer appears abnormally large in the Google Chrome browser.\\nENG-23301, Web Console, Web Console CSV exports of log investigations are no longer partially blank in certain situations.\\nENG-25994(DE11929), Web Console, Web Console Dashboard drill-downs now correctly abide by set filters.\\nENG-26562, Web Console, CAC card authentication now correctly works for Web Console logins.\\nENG-30099, Web Console, Custom time ranges no longer fail to work correctly on Dashboard widgets in certain situations.\\nENG-30493, Web Console, The Web Console night mode cursor color has been changed so that it is visible at all times.\\nENG-32795, Web Console, The Web Console night mode Lucene filter box has been changed to match the rest of the night mode UI.\\nBug #\\nComponent\\nDescription\\nENG-11205\\n(DE16679)\\nActive Directory\\nActive Directory syncs no longer fail when a user account has two usernames.\\nENG-35407\\nAI Engine\\nAI Engine rules no longer experience significant delays when firing in certain situations.\\nENG-22876\\n(DE16824)\\nAPIs\\nChanging the alarm status in the Case API no longer results in an error in certain situations.\\nENG-11199\\n(DE16890)\\nAPIs\\nAlarm Status update requests no longer fail in LRCloud deployments in certain situations.\\nENG-23824\\nClient Console\\nThe Deployment Manager option is no longer shown to Restricted Analysts.\\nENG-11160\\n(DE15875)\\nClient Console\\nLogMart maintenance now correctly reflects changes made to LogMart_TTL.\\nENG-24715\\nClient Console\\nSSL/TLS can now be enabled on the Platform Manager Properties tab to prevent SSL/TLS notification failure.\\nENG-24954\\nClient Console\\nThe MaxMessageCount for a log source can now accept values up to 50,000.\\nENG-11141\\n(DE14874)\\nReporting\\nThe Log Volume by Log Source report\\'s Bytes/Packets and Sent/Rcvd filters now execute successfully.\\nENG-31775\\nSecondLook\\nThe SecondLook API log no longer displays incorrect \"Object reference\" errors.\\nENG-36167\\nSecondLook\\nSaving a SecondLook configuration with a retired log source no longer fails.\\nENG-34885\\nSecondLook\\nSecondLook drill-downs and searches no longer give inaccurate results in certain situations due to local machine time zone discrepancies.\\nENG-34260\\nSecondLook\\nThe SecondLook API no longer produces an incorrect \"out of memory\" error in certain situations when executing a search.\\nENG-36544\\nSystem Monitor\\nThe AutoCorrectionMSEvtPosLogic flag is now OFF by default in the scsm.exe.config file to prevent unnecessary errors.\\nENG-34772\\nSystem Monitor\\nStarting a System Monitor agent in \"unidirectional mode\" no longer produces a socket error in certain situations.\\nENG-22863\\n(DE14276)\\nWeb Console\\nThe Lucene filter now correctly filters time ranges.\\nENG-11143\\n(DE15241)\\nWeb Console\\nThe Web Console no longer crashes in certain situations when attempting to search by log source.\\nENG-11161\\n(DE15810)\\nWeb Console\\nThe time range filter now works correctly and populates widgets when applied to the trend chart.\\nENG-11140\\n(DE14882)\\nWeb Console\\nThe User (Origin), User (Impacted), and User (Identity) fields on widgets now correctly show results when the widget or dashboard timeframe is changed.\\nENG-11162\\n(DE16404)\\nWeb Console\\nLocation-based widget filters are now applied correctly.\\nENG-11192\\n(DE16711)\\nWeb Console\\nThe Dashboard navigation bar no longer appears abnormally large in the Google Chrome browser.\\nENG-23301\\nWeb Console\\nWeb Console CSV exports of log investigations are no longer partially blank in certain situations.\\nENG-25994\\n(DE11929)\\nWeb Console\\nWeb Console Dashboard drill-downs now correctly abide by set filters.\\nENG-26562\\nWeb Console\\nCAC card authentication now correctly works for Web Console logins.\\nENG-30099\\nWeb Console\\nCustom time ranges no longer fail to work correctly on Dashboard widgets in certain situations.\\nENG-30493\\nWeb Console\\nThe Web Console night mode cursor color has been changed so that it is visible at all times.\\nENG-32795\\nWeb Console\\nThe Web Console night mode Lucene filter box has been changed to match the rest of the night mode UI.\\n', 'Resolved Issues - Security': 'Security-related issues resolved with this release are available for customers to view on the\\nCommunity\\n.\\n', 'Known Issues': \"The following issues have each been found and reported by multiple users.\\nBug #, Found In Version, Components, Description, Release Notes\\nENG-11165(DE16414), 7.9, Client Console, Client console search queries including the Host IP Address criteria are timing out in large databases., Expected Results:Log source searches should be completed without performance issues.Workaround:There is currently no workaround for this issue.\\nENG-22882(DE10768), 7.4.9, Common Components, In certain circumstances, the Data Processor runs slowly and the non-paged pool uses significant system memory.\\xa0This can cause a large unprocessed logs queue or other backlog in the system., Expected Results: The non-paged pool should not increase and cause system performance issues.Workaround:\\xa0Restart the LogRhythm API Gateway service.\\nENG-11108(DE12153), 7.6.0, Common Components, In some cases after a Data Indexer install, the Service Registry may not be able to communicate with the Platform Manager, causing alarms and errors in the Service Registry log., Expected Results: Communication to the Platform Manager should be maintained after an install.Workaround: Restart Service Registry on each node in the cluster after the installation is complete.\\nENG-22881(DE12218), 7.6.0, Data Indexer, The Transporter can fail to fully start after restart at UTC midnight, causing indexing and performance issues. (This issue only impacts Linux clusters.), Expected Results: The Transporter should continue to run after a restart signal is sent.Workaround: Restart the Transporter service.\\nENG-11175(DE16040), 7.6.0, Data Indexer, Data is being indexed in lower case, ignoring the case of the original logs., Expected Results: Data should be stored in the format in which it was sent.Workaround: There is currently no workaround for this issue.\\nENG-22862(DE13480), N/A, Data Indexer, Alarm drilldowns fail as a result of changes to daylight savings in Chile. The failure is temporary and only lasts a few hours., Expected Results: Searching should work.Workaround: Either wait for the issue to naturally pass or manually adjust system clocks.\\nENG-11150(DE15289), N/A, Infrastructure, Weekday maintenance is taking much longer than expected., Expected Results: The weekday maintenance task should perform in a reasonable amount of time.Workaround: There is currently no workaround for this issue.\\nENG-11173(DE15601), 7.9.0, Installation Components, DR SQL transaction logs are filling the L: drive when unable to sync to secondary nodes., Expected Results: Transaction logs should be truncated by frequent scheduled backups throughout the day.Workaround: There is currently no workaround for this issue.\\nENG-11142(DE15089), 7.9.0, Metrics Collection, Telemetry metrics parsing errors from Datadog are present in the metrics collection file., Expected Results:Datadog's telemetry metrics parsing errors should not be present in the metrics collection file.Workaround:There is currently no workaround for this issue.\\nBug #\\nFound In Version\\nComponents\\nDescription\\nRelease Notes\\nENG-11165\\n(DE16414)\\n7.9\\nClient Console\\nClient console search queries including the Host IP Address criteria are timing out in large databases.\\nExpected Results:\\nLog source searches should be completed without performance issues.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nENG-22882\\n(DE10768)\\n7.4.9\\nCommon Components\\nIn certain circumstances, the Data Processor runs slowly and the non-paged pool uses significant system memory.\\xa0This can cause a large unprocessed logs queue or other backlog in the system.\\nExpected Results\\n: The non-paged pool should not increase and cause system performance issues.\\nWorkaround\\n:\\xa0Restart the LogRhythm API Gateway service.\\nENG-11108\\n(DE12153)\\n7.6.0\\nCommon Components\\nIn some cases after a Data Indexer install, the Service Registry may not be able to communicate with the Platform Manager, causing alarms and errors in the Service Registry log.\\nExpected Results\\n: Communication to the Platform Manager should be maintained after an install.\\nWorkaround\\n: Restart Service Registry on each node in the cluster after the installation is complete.\\nENG-22881\\n(DE12218)\\n7.6.0\\nData Indexer\\nThe Transporter can fail to fully start after restart at UTC midnight, causing indexing and performance issues. (This issue only impacts Linux clusters.)\\nExpected Results\\n: The Transporter should continue to run after a restart signal is sent.\\nWorkaround\\n: Restart the Transporter service.\\nENG-11175\\n(DE16040)\\n7.6.0\\nData Indexer\\nData is being indexed in lower case, ignoring the case of the original logs.\\nExpected Results\\n: Data should be stored in the format in which it was sent.\\nWorkaround\\n: There is currently no workaround for this issue.\\nENG-22862\\n(DE13480)\\nN/A\\nData Indexer\\nAlarm drilldowns fail as a result of changes to daylight savings in Chile. The failure is temporary and only lasts a few hours.\\nExpected Results\\n: Searching should work.\\nWorkaround\\n: Either wait for the issue to naturally pass or manually adjust system clocks.\\nENG-11150\\n(DE15289)\\nN/A\\nInfrastructure\\nWeekday maintenance is taking much longer than expected.\\nExpected Results\\n: The weekday maintenance task should perform in a reasonable amount of time.\\nWorkaround\\n: There is currently no workaround for this issue.\\nENG-11173\\n(DE15601)\\n7.9.0\\nInstallation Components\\nDR SQL transaction logs are filling the L: drive when unable to sync to secondary nodes.\\nExpected Results\\n: Transaction logs should be truncated by frequent scheduled backups throughout the day.\\nWorkaround\\n: There is currently no workaround for this issue.\\nENG-11142\\n(DE15089)\\n7.9.0\\nMetrics Collection\\nTelemetry metrics parsing errors from Datadog are present in the metrics collection file.\\nExpected Results:\\nDatadog's telemetry metrics parsing errors should not be present in the metrics collection file.\\nWorkaround:\\nThere is currently no workaround for this issue.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.13.0.76 Release Notes - 17 July 2023': 'This guide describes two issues that were fixed in LogRhythm 7.13, as well as the upgrade procedure from 7.13.x to 7.13.0.76.\\nThe updated components provided in 7.13.0.76 were added to the 7.13.0 GA release downloads on July 17, 2023.\\xa0If you upgraded using 7.13.0 GA software downloaded after July 17, you do not need to apply this patch.\\n', 'Resolved Issues': 'Bug #, Component, Description\\nENG-38290, Reporting, The Log Volume Report no longer shows inflated MPS and EPS numbers.\\nENG-38710, Data Indexer, Components such as Bulldozer, Carpenter, and GoMaintain can now correctly acquire API consul locks as expected.\\nBug #\\nComponent\\nDescription\\nENG-38290\\nReporting\\nThe Log Volume Report no longer shows inflated MPS and EPS numbers.\\nENG-38710\\nData Indexer\\nComponents such as Bulldozer, Carpenter, and GoMaintain can now correctly acquire API consul locks as expected.\\n', 'Download the Upgrade Components': 'The 7.13.0.76 release includes an updated installer. The new installer can be downloaded from the LogRhythm Community.\\nLog in to the\\nCommunity\\n.\\nLog in to the\\nCommunity\\n.\\nOn the main menu bar, click\\nDocumentation & Downloads\\n, and then click\\nSIEM\\n.\\nOn the main menu bar, click\\nDocumentation & Downloads\\n, and then click\\nSIEM\\n.\\nClick\\nNextGen SIEM\\n, and then click\\n7.13.0 GA Downloads\\n.\\nClick\\nNextGen SIEM\\n, and then click\\n7.13.0 GA Downloads\\n.\\nUnder 7.13.0 GA Downloads, download the\\nLogRhythm Install Wizard\\n.\\nUnder 7.13.0 GA Downloads, download the\\nLogRhythm Install Wizard\\n.\\n', 'Upgrade the 7.13.0 Deployment': 'Run the LogRhythm Install Wizard just as you would to upgrade a deployment.\\nOpen the Install Wizard directory, and right-click the\\nLogRhythmInstallWizard.exe\\nyou downloaded in the steps above.\\nOpen the Install Wizard directory, and right-click the\\nLogRhythmInstallWizard.exe\\nyou downloaded in the steps above.\\nClick\\nRun as administrator\\n.\\nThe LogRhythm Install Wizard 7.13.0 appears.\\nClick\\nRun as administrator\\n.\\nThe LogRhythm Install Wizard 7.13.0 appears.\\nClick\\nNext\\n.\\nThe LogRhythm Install Wizard Confirmation dialog box appears.\\nClick\\nNext\\n.\\nThe LogRhythm Install Wizard Confirmation dialog box appears.\\nClick\\nYes\\n.\\nThe License Agreement appears.\\nClick\\nYes\\n.\\nThe License Agreement appears.\\nSelect the check box to accept the terms in the license agreement, and then click\\nNext\\n.\\nSelect the check box to accept the terms in the license agreement, and then click\\nNext\\n.\\nOn the configuration page, select the\\nData Processor\\nconfiguration.\\nOn the configuration page, select the\\nData Processor\\nconfiguration.\\nUnder Optional Applications, deselect\\nLRD Agent\\n,\\xa0and then click\\nInstall\\n.\\nUnder Optional Applications, deselect\\nLRD Agent\\n,\\xa0and then click\\nInstall\\n.\\nWhen the installer is finished, verify that the Web services are running.\\nWhen the installer is finished, verify that the Web services are running.\\n', '(Optional.)Upgrade Databases': 'To resolve issue ENG-38290, your LogRhythm database must be upgraded. If you are a user of the Log Volume Report and need this issue to be resolved in your environment, you must take this step as well.\\nFor instructions on how to run the LogRhythm Database Upgrade tool, refer to the topic\\nUpgrade LogRhythm Databases\\n.\\nTo avoid running the entire Database Upgrade tool, you can simply execute the Logrhythm.LogMart.sql file manually. Updating LogMart alone is sufficient to resolve the issue with the Log Volume Report.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.13.0.78 Release Notes - 2 August 2023': 'This guide describes an issue that was fixed in LogRhythm 7.13, as well as steps that need to be taken if you are a user of LogRhythm Disaster Recovery solutions.\\nThe updated components provided in 7.13.0.78 were added to the 7.13.0 GA release downloads on August 2, 2023.\\xa0If you upgraded using 7.13.0 GA software downloaded after August 2, you do not need to apply this patch.\\n', 'Resolved Issues': 'Bug #, Component, Description\\nENG-40105, Databases, The database install tool now correctly installs SQL Standard as opposed to SQL Enterprise.\\nBug #\\nComponent\\nDescription\\nENG-40105\\nDatabases\\nThe database install tool now correctly installs SQL Standard as opposed to SQL Enterprise.\\nTo resolve this issue, the installer for 7.13 has been updated to include SQL Standard edition rather than SQL Enterprise. Unless you are a user of LogRhythm Disaster Recovery solutions, using SQL Enterprise has no negative effect on your deployment and no further action needs to be taken. If you use (or plan to use) LogRhythm Disaster Recovery solutions, please see the section below,\\nDisaster Recovery SQL Downgrades\\n.\\n', 'Disaster Recovery SQL Downgrades': 'Issue ENG-40105 only impacts users of LogRhythm Disaster Recovery solutions. If you use (or plan to use) LogRhythm Disaster Recovery, your SQL server needs to be manually downgraded from Enterprise to Standard. We recommend that this process be performed by LogRhythm Customer Support or Professional Services.\\nFor information on contacting LogRhythm Support, refer to the\\nLogRhythm Customer Support Guide\\n.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.14.0 GA Release Notes - 2 October 2023': 'Introducing LogRhythm SIEM 7.14! In this version, we introduce Open Collector and Beat management within the Web Console along with many other great features.\\xa0LogRhythm is focused on making log collection easy. In this version, we start by streamlining the Open Collector and Beat log sources. With streamlined onboarding workflows and under-the-hood product enhancements, you can focus less on SIEM administration and more on security.\\n', 'Key Highlights': 'Manage Open Collectors and Beats in Web Console\\nManage Open Collectors and Beats in Web Console\\nResource Center\\nResource Center\\nSend Logs to Axon from the System Monitor Agent\\nSend Logs to Axon from the System Monitor Agent\\n', 'Maintenance': 'Enhancements & Resolved Issues\\nEnhancements & Resolved Issues\\nKnown Issues\\nKnown Issues\\n', 'Open Collector and Beat Management in Web Console': 'LogRhythm Administrators want an easy and streamlined workflow to onboard and manage Open Collector. LogRhythm SIEM 7.14 brings this functionality to the Web Console!\\nIntegrate Open Collector with the SIEM\\nand use the Web Console to deploy\\nBeats and collect their log sources\\n.\\nWith this complete workflow all contained within the Web Console, security teams can now focus more on security and less on configuration. In this release the following Beats can be on-boarded and managed directly within the Web Console, cutting administration time in half.\\nAWS S3\\nAWS S3\\nAzure Event Hub\\nAzure Event Hub\\nCarbon Black Cloud\\nCarbon Black Cloud\\nCisco AMP\\nCisco AMP\\nDuo Authentication Security\\nDuo Authentication Security\\nKafka\\nKafka\\nMicrosoft Graph API\\nMicrosoft Graph API\\nPrisma Cloud\\nPrisma Cloud\\nProofpoint\\nProofpoint\\nPubSub\\nPubSub\\nSymantec WSS\\nSymantec WSS\\nLogRhythm SIEM 7.14 makes it easy to collect from cloud log sources with the new workflow and management all contained in the web console.\\n', 'Open Collector and Beat Management in the Admin API': 'With new features, come new\\nREST API endpoints\\n! LogRhythm 7.14 further extends the automation capabilities of the Admin API so that you can programmatically:\\nManage Beats\\nManage Beats\\nManage Open Collector\\nManage Open Collector\\nManage DP Pooling\\nManage DP Pooling\\nAdd Log Source and Agent parameters\\nAdd Log Source and Agent parameters\\nNew to the API and wondering how to get started? Learn more about the\\nCommunity\\n!\\n', 'Resource Center': 'The LogRhythm SIEM’s new\\nResource Center\\noffers Analysts quick access to important LogRhythm resources like Community, Documentation and Support. Additionally, the Onboarding section gives new users in-app tutorials to help them get comfortable with the LogRhythm Web Console. And finally, the Announcements section will be introduced in the Resource Center so customers are aware of the latest updates and critical information from LogRhythm.\\nThe example guide teaches users how to use LogRhythm SIEM without having to leave the Web Console.\\n', 'Send Logs to Axon from the System Monitor Agent': 'As LogRhythm Axon’s popularity increases, we want to make migration easier for customers switching to Axon. LogRhythm SIEM 7.14 gives users the power to\\nforward a copy of their logs to Axon\\n. Customers can easily do a proof of concept in Axon while still maintaining their current LogRhythm SIEM deployment. For customers who choose to migrate to Axon, onboarding to the new platform will be a smooth transition. While Axon has its own Agent, this speeds up the ability to get logs into Axon by sending logs to both the Data Processor and Axon. Previously only available in limited situations, now all customers can leverage both platforms!\\nThe Axon Settings tab of the System Monitor Agent Properties makes it easy to start forwarding logs to your Axon tenant.\\n', 'LogRhythm Cloud (LRC) Deployment Statistics': 'With the introduction of the\\nDeployment Statistics\\n, LogRhythm Cloud customers can now get more insight on their deployment. Quickly access important information such as current MPS, average log size, and details regarding archives (if applicable).\\n\\n', 'Enhancements & Resolved Issues': 'Bug #, Component, Description\\nENG-41695, Active Directory, After upgrading to version 7.13, users no longer see AD sync errors or duplicate users in the People tab. Also, there are no error messages or warnings in the Job Manager log.\\nENG-42830, Admin API, When using the Admin API, the isSilentLogSourceEnabled value is now set according to the input parameter value in the API request.\\nENG-40026, Agents, When SSLStream cannot send logs to the Mediator, the Agent does not show the sent message in the log.\\nENG-40728, Agents: Office 365 Log Collection, Office 365 log collection no longer stops even when volume is reduced.\\nENG-41720, Agents: UDP Syslog Log Collection, After updating to version 7.14, customers can override the ReceiveBuffer Limit to prevent data loss and log drop issues for UDP Syslog log collection.\\nENG-25247, AI Engine: Communication Manager, When the AI Engine Communication Manager starts, it can now connect to the EMDB and configure the file successfully.\\nENG-30203, AI Engine, Connecting to the AI Engine Communication Manager enables the AI Engine Data Provider to store data in the suspended state of the LogRhythm Mediator Server until the Data Provider is restarted. Even if the initial connection between the AIE Data Provider and the AIE Communication Manager is lost due to network problems, the data will be saved and reconnected.\\nENG-30391, AI Engine, AIE alarms that are triggered by any log source Entity now display the correct Entity name.\\nENG-33005, AI Engine, The AI Engine now starts after a rule update as expected.\\nENG-39736, AI Engine: MPE Rules, When opening or creating sub-rules, the MPE rule is no longer automatically saved. This allows users to complete multiple sub-rule changes before saving the MPE rule and causing the Mediator Service to restart. (Applies to 7.14 release only.)\\nENG-22946, Alarm API, When using the Alarms API, the alarms results now respect the query request direction (ascending or descending order options).\\nENG-25680, Alarm API, When using wildcard or pattern-matching filters in the Alarm API, alarm results are now displayed as expected.\\nENG-32809, Alarm API, When using the Alarm API Endpoint Get: lr-alarm-api/alarms, Alarm API no longer returns duplicate alarms.\\nENG-22882, APIs, The API Gateway no longer causes the non-paged pool memory to increase when it does not receive a response from an endpoint, and the Data Processor now performs as expected without a backlog.\\nENG-30864, Client Console: Log Sources, When LR Enhanced Audit files are used to execute the LR_sqlaudit_create_leastprivuser.sql script, the AIERruleToEngine UDLA log source is now set without any issues.\\nENG-38703, Client Console, When using the Client Console, the Syslog timestamp UTC offset calculation is now correct.\\nENG-38371, Client Console: Agents, The recommended value and default value for OriginalMessage are now set to True for an Agent in the Advanced Properties of the Client Console.\\nENG-42809, Client Console: User Profile Manager, Changes can now be applied to all users in the User Profile Manager of the Client Console.\\nENG-38564, Common Components, Common components now automatically recover and function as expected after network outage.\\nENG-37278, Database Upgrade Tool, When using the Database Upgrade Tool update from 7.10 to 7.12, the user no longer receives errors and the DB upgrade works properly despite the dashboard changes.\\nENG-22881, Data Indexer: Transporter, Transporter now fully starts after receiving service restart command at UTC midnight.\\nENG-47326, Data Indexer: Transporter, The Transporter no longer fails to index when a field is larger than the maximum length allowed. With 7.14 release, users can now change the MaxLuceneStringLength parameter. (Default = 32700, Min = 30000, Max = 32767)\\nENG-33067, Data Processor, Added a new TTL setting that allows customers to stop archiving old logs that are older than the TTL time period.\\nENG-11125, Documentation, Reference Architecture documentation has been updated to include relevant information.\\nENG-48514, Documentation, Removed host URL links from API documentation because information on endpoints is now published ondocs.logrhythm.com.\\nENG-30183, Infrastructure: Database Scripts and Upgrade Scripts, When running database script, cluster creation now occurs in order as IP addresses become available.\\nENG-11173, Installation Components, DR SQL transaction logs no longer fill the L: drive when unable to sync to secondary nodes.\\nENG-24714, Job Manager, When using Gmail’s SMTP server with SSL enabled, the Job Manager now sends scheduled reports as expected.\\nENG-41949, Job Manager, After using the Job Manager to sync the Active Directory, new AD users that were created in the People tab from the Group configured in Profile Manager are now displayed correctly.\\nENG-11142, Metrics Collection Service, The metrics collection file no longer contains telemetric parsing errors from Datadog.\\nENG-41117, LR Cloud: Enhanced Auditing, Shadow tables are no longer dropped and recreated during upgrade.\\nENG-31744, Open Collector/Beats, The User Principal Name field is now parsed from Azure Defender logs.\\nENG-27104, Threat Intelligence Service, When using the Threat Intelligence Service custom STIX/TAXII feed, users can now configure the data of NumofBackDaysData according to their requirements.\\nENG-34698, Threat Intelligence Service, When using Threat Intelligence Service, after configuring the custom provider, the correct list file is available under the list default folder (C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Job Manager\\\\config\\\\list_import\\\\).\\nENG-40039, Threat Intelligence Service, When using the Threat Intelligence Service, feeds after July 25, 2023, are now downloading.\\nENG-27216, Web Console, When a time range is applied to the dashboard filter in the Web Console, the widget now displays data relevant to that time range.\\nENG-31396, Web Console, While using the Web Console, the Typeahead filters now display the correct column values.\\nENG-35070, Web Console: UI, When using the Web Console, after editing a dashboard and applying a longer filter in the Dashboard Filter field, the dashboard filter is displayed in a shortened form.\\nENG-39264, Web Console, In larger deployments that upgraded to 7.12, the Web Console no longer has the rate limiting issues that were causing users to experience instability in their environments.\\nENG-41022, Web Console, While using Web Console, after typing an open or closed parenthesis character \"(\", \")\" or brackets \"[\", \"]\", the Known Values Browser does not close out anymore. It displays results accordingly.\\nBug #\\nComponent\\nDescription\\nENG-41695\\nActive Directory\\nAfter upgrading to version 7.13, users no longer see AD sync errors or duplicate users in the People tab. Also, there are no error messages or warnings in the Job Manager log.\\nENG-42830\\nAdmin API\\nWhen using the Admin API, the isSilentLogSourceEnabled value is now set according to the input parameter value in the API request.\\nENG-40026\\nAgents\\nWhen SSLStream cannot send logs to the Mediator, the Agent does not show the sent message in the log.\\nENG-40728\\nAgents: Office 365 Log Collection\\nOffice 365 log collection no longer stops even when volume is reduced.\\nENG-41720\\nAgents: UDP Syslog Log Collection\\nAfter updating to version 7.14, customers can override the ReceiveBuffer Limit to prevent data loss and log drop issues for UDP Syslog log collection.\\nENG-25247\\nAI Engine: Communication Manager\\nWhen the AI Engine Communication Manager starts, it can now connect to the EMDB and configure the file successfully.\\nENG-30203\\nAI Engine\\nConnecting to the AI Engine Communication Manager enables the AI Engine Data Provider to store data in the suspended state of the LogRhythm Mediator Server until the Data Provider is restarted. Even if the initial connection between the AIE Data Provider and the AIE Communication Manager is lost due to network problems, the data will be saved and reconnected.\\nENG-30391\\nAI Engine\\nAIE alarms that are triggered by any log source Entity now display the correct Entity name.\\nENG-33005\\nAI Engine\\nThe AI Engine now starts after a rule update as expected.\\nENG-39736\\nAI Engine: MPE Rules\\nWhen opening or creating sub-rules, the MPE rule is no longer automatically saved. This allows users to complete multiple sub-rule changes before saving the MPE rule and causing the Mediator Service to restart. (Applies to 7.14 release only.)\\nENG-22946\\nAlarm API\\nWhen using the Alarms API, the alarms results now respect the query request direction (ascending or descending order options).\\nENG-25680\\nAlarm API\\nWhen using wildcard or pattern-matching filters in the Alarm API, alarm results are now displayed as expected.\\nENG-32809\\nAlarm API\\nWhen using the Alarm API Endpoint Get: lr-alarm-api/alarms, Alarm API no longer returns duplicate alarms.\\nENG-22882\\nAPIs\\nThe API Gateway no longer causes the non-paged pool memory to increase when it does not receive a response from an endpoint, and the Data Processor now performs as expected without a backlog.\\nENG-30864\\nClient Console: Log Sources\\nWhen LR Enhanced Audit files are used to execute the LR_sqlaudit_create_leastprivuser.sql script, the AIERruleToEngine UDLA log source is now set without any issues.\\nENG-38703\\nClient Console\\nWhen using the Client Console, the Syslog timestamp UTC offset calculation is now correct.\\nENG-38371\\nClient Console: Agents\\nThe recommended value and default value for OriginalMessage are now set to True for an Agent in the Advanced Properties of the Client Console.\\nENG-42809\\nClient Console: User Profile Manager\\nChanges can now be applied to all users in the User Profile Manager of the Client Console.\\nENG-38564\\nCommon Components\\nCommon components now automatically recover and function as expected after network outage.\\nENG-37278\\nDatabase Upgrade Tool\\nWhen using the Database Upgrade Tool update from 7.10 to 7.12, the user no longer receives errors and the DB upgrade works properly despite the dashboard changes.\\nENG-22881\\nData Indexer: Transporter\\nTransporter now fully starts after receiving service restart command at UTC midnight.\\nENG-47326\\nData Indexer: Transporter\\nThe Transporter no longer fails to index when a field is larger than the maximum length allowed. With 7.14 release, users can now change the MaxLuceneStringLength parameter. (Default = 32700, Min = 30000, Max = 32767)\\nENG-33067\\nData Processor\\nAdded a new TTL setting that allows customers to stop archiving old logs that are older than the TTL time period.\\nENG-11125\\nDocumentation\\nReference Architecture documentation has been updated to include relevant information.\\nENG-48514\\nDocumentation\\nRemoved host URL links from API documentation because information on endpoints is now published on\\ndocs.logrhythm.com\\n.\\nENG-30183\\nInfrastructure: Database Scripts and Upgrade Scripts\\nWhen running database script, cluster creation now occurs in order as IP addresses become available.\\nENG-11173\\nInstallation Components\\nDR SQL transaction logs no longer fill the L: drive when unable to sync to secondary nodes.\\nENG-24714\\nJob Manager\\nWhen using Gmail’s SMTP server with SSL enabled, the Job Manager now sends scheduled reports as expected.\\nENG-41949\\nJob Manager\\nAfter using the Job Manager to sync the Active Directory, new AD users that were created in the People tab from the Group configured in Profile Manager are now displayed correctly.\\nENG-11142\\nMetrics Collection Service\\nThe metrics collection file no longer contains telemetric parsing errors from Datadog.\\nENG-41117\\nLR Cloud: Enhanced Auditing\\nShadow tables are no longer dropped and recreated during upgrade.\\nENG-31744\\nOpen Collector/Beats\\nThe User Principal Name field is now parsed from Azure Defender logs.\\nENG-27104\\nThreat Intelligence Service\\nWhen using the Threat Intelligence Service custom STIX/TAXII feed, users can now configure the data of NumofBackDaysData according to their requirements.\\nENG-34698\\nThreat Intelligence Service\\nWhen using Threat Intelligence Service, after configuring the custom provider, the correct list file is available under the list default folder (C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Job Manager\\\\config\\\\list_import\\\\).\\nENG-40039\\nThreat Intelligence Service\\nWhen using the Threat Intelligence Service, feeds after July 25, 2023, are now downloading.\\nENG-27216\\nWeb Console\\nWhen a time range is applied to the dashboard filter in the Web Console, the widget now displays data relevant to that time range.\\nENG-31396\\nWeb Console\\nWhile using the Web Console, the Typeahead filters now display the correct column values.\\nENG-35070\\nWeb Console: UI\\nWhen using the Web Console, after editing a dashboard and applying a longer filter in the Dashboard Filter field, the dashboard filter is displayed in a shortened form.\\nENG-39264\\nWeb Console\\nIn larger deployments that upgraded to 7.12, the Web Console no longer has the rate limiting issues that were causing users to experience instability in their environments.\\nENG-41022\\nWeb Console\\nWhile using Web Console, after typing an open or closed parenthesis character \"(\", \")\" or brackets \"[\", \"]\", the Known Values Browser does not close out anymore. It displays results accordingly.\\n', 'Resolved Issues - Security': 'Security-related issues resolved with this release are available for customers to view on the\\nCommunity\\n.\\n', 'Known Issues': 'The following issues have each been found and reported by multiple users.\\nBug #, Found In Version, Components, Description, Release Notes\\nENG-24726, 7.10, AI Engine, When drilling down on an alarm with Host (Impacted) in the Group By field, the action fails and returns the following error:\"LogRhythm encountered an error reading the extended AI Engine metadata for this Event. It might be an unexpected non-printable character in a textual field. Please make a copy of the Log Message field (Raw Log Data) of this Event and contact LogRhythm Customer Support\", Expected Results:Drill down results should appear without returning an error.Workaround:There is currently no workaround for this issue.\\nENG-43218, N/A, Alarm API, When using the XSOAR integration with Alarm API, requests periodically return a 500 internal server error., Expected Results:The integration should work without returning an error.Workaround:Retry the request until it succeeds.\\nENG-38849, N/A, Knowledge Base, When parsing logs associated with Syslog Linux Host, the Mediator returns the following error message:“Regex rule match timed out.”, Expected Results:The regex rule should parse successfully without timing out.Workaround:There is currently no workaround for this issue.\\nENG-47026, 7.13, Search API, After upgrading to 7.13, the LogRhythmWebUI password reverts to default, and Search API fails to log in., Expected Results:When LogRhythmWebUI password is changed, it should not revert to default when upgrading.Workaround:There is currently no workaround for this issue.\\nENG-38594, 7.11, SmartResponse Plugins, When SmartResponse Plugin scripts are modified but not triggered for 7 days, the custom changes are deleted and the SRP reverts to default settings., Expected Results:When SRP scripts are modified, the changes should be retained.Workaround:There is currently no workaround for this issue.\\nENG-36041, 7.87.12, Tools: TIS, The PhishTank TIS feed contains an unusually long URL that prevents the List Indicies in the Data Indexer from updating and causes drill down searches to fail., Expected Results:Drill down results should appear without returning an error.Workaround:Replacing the list file with a manually sanitized file will temporarily resolve the issue, until it happens again.\\nENG-41651, 7.127.13, Web Console, After upgrading to 7.12 or 7.13, the CAC authorization used to log in to the Web Console stops working., Expected Results:The CAC authorization should work when logging in to the Web Console.Workaround:There is currently no workaround for this issue.\\nBug #\\nFound In Version\\nComponents\\nDescription\\nRelease Notes\\nENG-24726\\n7.10\\nAI Engine\\nWhen drilling down on an alarm with Host (Impacted) in the Group By field, the action fails and returns the following error:\\n\"LogRhythm encountered an error reading the extended AI Engine metadata for this Event. It might be an unexpected non-printable character in a textual field. Please make a copy of the Log Message field (Raw Log Data) of this Event and contact LogRhythm Customer Support\"\\nExpected Results:\\nDrill down results should appear without returning an error.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nENG-43218\\nN/A\\nAlarm API\\nWhen using the XSOAR integration with Alarm API, requests periodically return a 500 internal server error.\\nExpected Results:\\nThe integration should work without returning an error.\\nWorkaround:\\nRetry the request until it succeeds.\\nENG-38849\\nN/A\\nKnowledge Base\\nWhen parsing logs associated with Syslog Linux Host, the Mediator returns the following error message:\\n“Regex rule match timed out.”\\nExpected Results:\\nThe regex rule should parse successfully without timing out.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nENG-47026\\n7.13\\nSearch API\\nAfter upgrading to 7.13, the LogRhythmWebUI password reverts to default, and Search API fails to log in.\\nExpected Results:\\nWhen LogRhythmWebUI password is changed, it should not revert to default when upgrading.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nENG-38594\\n7.11\\nSmartResponse Plugins\\nWhen SmartResponse Plugin scripts are modified but not triggered for 7 days, the custom changes are deleted and the SRP reverts to default settings.\\nExpected Results:\\nWhen SRP scripts are modified, the changes should be retained.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nENG-36041\\n7.8\\n7.12\\nTools: TIS\\nThe PhishTank TIS feed contains an unusually long URL that prevents the List Indicies in the Data Indexer from updating and causes drill down searches to fail.\\nExpected Results:\\nDrill down results should appear without returning an error.\\nWorkaround:\\nReplacing the list file with a manually sanitized file will temporarily resolve the issue, until it happens again.\\nENG-41651\\n7.12\\n7.13\\nWeb Console\\nAfter upgrading to 7.12 or 7.13, the CAC authorization used to log in to the Web Console stops working.\\nExpected Results:\\nThe CAC authorization should work when logging in to the Web Console.\\nWorkaround:\\nThere is currently no workaround for this issue.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.14.0.107 Release Notes - 18 October 2023': 'This guide describes two issues that were fixed in LogRhythm 7.14, as well as the upgrade procedure from 7.14.x to 7.14.0.107.\\nThe updated components provided in 7.14.0.107 were added to the 7.14.0 GA release downloads on October 18, 2023.\\xa0If you upgraded using 7.14.0 GA software downloaded after October 18, you do not need to apply this patch.\\n', 'Resolved Issues': 'Bug #, Component, Description\\nENG-49714, Web Console, Users can now create Cloud to Cloud (C2C) log sources in the Web Console and view them in the Log Source grid without receiving timeout errors.\\nENG-49515, Infrastructure: Databases, InfluxDB no longer causes spikes in resource usage that impacted the performance of other processes.\\nBug #\\nComponent\\nDescription\\nENG-49714\\nWeb Console\\nUsers can now create Cloud to Cloud (C2C) log sources in the Web Console and view them in the Log Source grid without receiving timeout errors.\\nENG-49515\\nInfrastructure: Databases\\nInfluxDB no longer causes spikes in resource usage that impacted the performance of other processes.\\n', 'Download the Upgrade Components': 'The 7.14.0.107 release includes an updated installer. The new installer can be downloaded from the LogRhythm Community.\\nLog in to the\\nCommunity\\n.\\nLog in to the\\nCommunity\\n.\\nOn the main menu bar, click\\nDocumentation & Downloads\\n, and then click\\nSIEM\\n.\\nOn the main menu bar, click\\nDocumentation & Downloads\\n, and then click\\nSIEM\\n.\\nClick\\nNextGen SIEM\\n, and then click\\n7.14.0 GA Downloads\\n.\\nClick\\nNextGen SIEM\\n, and then click\\n7.14.0 GA Downloads\\n.\\nUnder 7.14.0 GA Downloads, download the\\nLogRhythm Install Wizard\\n.\\nUnder 7.14.0 GA Downloads, download the\\nLogRhythm Install Wizard\\n.\\n', 'Upgrade the 7.14.0 Deployment': 'Run the LogRhythm Install Wizard just as you would to upgrade a deployment.\\nOpen the Install Wizard directory, and right-click the\\nLogRhythmInstallWizard.exe\\nyou downloaded in the steps above.\\nOpen the Install Wizard directory, and right-click the\\nLogRhythmInstallWizard.exe\\nyou downloaded in the steps above.\\nClick\\nRun as administrator\\n.\\nThe LogRhythm Install Wizard 7.14.0 appears.\\nClick\\nRun as administrator\\n.\\nThe LogRhythm Install Wizard 7.14.0 appears.\\nClick\\nNext\\n.\\nThe LogRhythm Install Wizard Confirmation dialog box appears.\\nClick\\nNext\\n.\\nThe LogRhythm Install Wizard Confirmation dialog box appears.\\nClick\\nYes\\n.\\nThe License Agreement appears.\\nClick\\nYes\\n.\\nThe License Agreement appears.\\nSelect the check box to accept the terms in the license agreement, and then click\\nNext\\n.\\nSelect the check box to accept the terms in the license agreement, and then click\\nNext\\n.\\nOn the configuration page, select the\\nData Processor\\nconfiguration.\\nOn the configuration page, select the\\nData Processor\\nconfiguration.\\nUnder Optional Applications, deselect\\nLRD Agent\\n,\\xa0and then click\\nInstall\\n.\\nUnder Optional Applications, deselect\\nLRD Agent\\n,\\xa0and then click\\nInstall\\n.\\nWhen the installer is finished, verify that the Web services are running.\\nWhen the installer is finished, verify that the Web services are running.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.14.1 Release Notes - 13 November 2023': 'This guide describes issues that were fixed in LogRhythm 7.14, as well as the upgrade procedure from 7.14.x to 7.14.1.\\nThe updated components provided in 7.14.1 were added to the 7.14 GA release downloads on November 13, 2023.\\xa0If you upgraded using 7.14 GA software downloaded after November 13, you do not need to apply this patch.\\n', 'Resolved Issues': 'Bug #, Component, Description\\nENG-47660, Web Console: Search, When creating a Log Source Root Entity filter in Web Console Search, child entities are no longer listed in the value drop down list.\\nENG-47981, Web Console: Log Export, When exporting logs from the Web Console, the time zone in the Log Date column now matches the user’s time zone.\\nENG-48115, Web Console: Filter, Restricted Admin and Restricted Analyst accounts can now use the Log Source Filter in the Web Console.\\nENG-48229, Common Components, When verifying a large number of hosts via LogRhythm Infrastructure Installer (LRII), users no longer receive timeout errors.\\nBug #\\nComponent\\nDescription\\nENG-47660\\nWeb Console: Search\\nWhen creating a Log Source Root Entity filter in Web Console Search, child entities are no longer listed in the value drop down list.\\nENG-47981\\nWeb Console: Log Export\\nWhen exporting logs from the Web Console, the time zone in the Log Date column now matches the user’s time zone.\\nENG-48115\\nWeb Console: Filter\\nRestricted Admin and Restricted Analyst accounts can now use the Log Source Filter in the Web Console.\\nENG-48229\\nCommon Components\\nWhen verifying a large number of hosts via LogRhythm Infrastructure Installer (LRII), users no longer receive timeout errors.\\n', 'Download the Upgrade Components': 'The 7.14.1 release includes an updated installer. The new installer can be downloaded from the LogRhythm Community.\\nLog in to the\\nCommunity\\n.\\nLog in to the\\nCommunity\\n.\\nOn the main menu bar, click\\nDocumentation & Downloads\\n, and then click\\nSIEM\\n.\\nOn the main menu bar, click\\nDocumentation & Downloads\\n, and then click\\nSIEM\\n.\\nClick\\nNextGen SIEM\\n, and then click\\n7.14 GA Downloads\\n.\\nClick\\nNextGen SIEM\\n, and then click\\n7.14 GA Downloads\\n.\\nUnder 7.14 GA Downloads, download the\\nLogRhythm Install Wizard\\n.\\nUnder 7.14 GA Downloads, download the\\nLogRhythm Install Wizard\\n.\\n', 'Upgrade the 7.14 Deployment': 'Run the LogRhythm Install Wizard just as you would to upgrade a deployment.\\nOpen the Install Wizard directory, and right-click the\\nLogRhythmInstallWizard.exe\\nyou downloaded in the steps above.\\nOpen the Install Wizard directory, and right-click the\\nLogRhythmInstallWizard.exe\\nyou downloaded in the steps above.\\nClick\\nRun as administrator\\n.\\nThe LogRhythm Install Wizard 7.14 appears.\\nClick\\nRun as administrator\\n.\\nThe LogRhythm Install Wizard 7.14 appears.\\nClick\\nNext\\n.\\nThe LogRhythm Install Wizard Confirmation dialog box appears.\\nClick\\nNext\\n.\\nThe LogRhythm Install Wizard Confirmation dialog box appears.\\nClick\\nYes\\n.\\nThe License Agreement appears.\\nClick\\nYes\\n.\\nThe License Agreement appears.\\nSelect the check box to accept the terms in the license agreement, and then click\\nNext\\n.\\nSelect the check box to accept the terms in the license agreement, and then click\\nNext\\n.\\nOn the configuration page, select the\\nData Processor\\nconfiguration.\\nOn the configuration page, select the\\nData Processor\\nconfiguration.\\nUnder Optional Applications, deselect\\nLRD Agent\\n,\\xa0and then click\\nInstall\\n.\\nUnder Optional Applications, deselect\\nLRD Agent\\n,\\xa0and then click\\nInstall\\n.\\nWhen the installer is finished, verify that the Web services are running.\\nWhen the installer is finished, verify that the Web services are running.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.15.0 GA Release Notes - 4 January 2024': 'Getting data into your LogRhythm instance is crucial, and LogRhythm is intensely focused on making that easy to do. LogRhythm SIEM 7.15 builds on the innovation we delivered in the previous releases.\\nWhat’s new in SIEM 7.15:\\nSimplified onboarding for Windows Event logs\\nSimplified onboarding for Windows Event logs\\nImproved analyst workflow when reviewing alarm notifications\\nImproved analyst workflow when reviewing alarm notifications\\nNew LogRhythm SIEM in-app tutorials\\nNew LogRhythm SIEM in-app tutorials\\nAdditional Beats supported in the Web Console\\nAdditional Beats supported in the Web Console\\nNew and updated log sources\\nNew and updated log sources\\n', 'Key Highlights': 'Onboard New Log Source in the Web Console\\nOnboard New Log Source in the Web Console\\nPlatform Enhancements\\nPlatform Enhancements\\nIn-Platform Resource Center Tutorials\\nIn-Platform Resource Center Tutorials\\nLog Source Enhancements\\nLog Source Enhancements\\n', 'Maintenance': 'Enhancements & Resolved Issues\\nEnhancements & Resolved Issues\\nKnown Issues\\nKnown Issues\\n', 'Onboard New Log Sources in the Web Console': 'Onboarding new log sources should be easy. That’s why we’ve expanded the number of Beats LogRhythm Administrators\\ncan manage from the Web Console\\n. By onboarding log sources in the Web Console, you can save time and cut your Beat Administration workload in half. In this latest release, LogRhythm now supports management for six additional Beats including:\\nGmail Message Tracking\\nGmail Message Tracking\\nGSuite\\nGSuite\\nOkta\\nOkta\\nDarktrace\\nDarktrace\\nSophos\\nSophos\\nQualys FIM\\nQualys FIM\\n\\n', 'Platform Enhancements': 'Managing a SIEM platform isn’t always easy, so our team has made your experience even better. LogRhythm 7.15 features platform improvements that enhance your workflows, save you time, and reduce the number of steps your team takes to complete a task.\\n', 'Migration Path to Rocky Linux': 'As CentOS 7 reaches the end of life from the Red Hat organization, we understand the importance of providing an alternative operating system to migrate Data Indexer (DX) and Open Collector (OC) machines. That’s why LogRhythm created a\\ndetailed guide for migrating to Rocky Linux\\n. This migration path offers customers continued support from the OS vendor to address security and bug fixes.\\n', 'Automatic Flat File Path Population for Windows Event Logs': 'To make the workflow and tasks easier for LogRhythm SIEM users, we’ve changed a setting to auto-populate the flat file path for Windows Event Log-based log sources. For example, when users add Windows PowerShell or Windows SysMon Event logs, LogRhythm SIEM now auto-updates that field. This update saves users time and provides a more streamlined experience.\\n\\n', 'Web Console Log Export in Users’ Local Time': 'LogRhythm has made it easier to convert time zones when exporting logs from the Web Console to a CSV file. Customers can now export CSV files in their local time zone versus having to convert from the Coordinated Universal Time (UTC) time zone. Now users don’t have to go through the cumbersome conversion process to identify the correct time, improving their experience with the SIEM platform.\\n\\n', 'URL Links in Alarm Notifications': 'Navigating to an alarm from a notification is easier than ever. Our team improved the experience to direct you to alarm details even if you previously weren’t logged into the Web Console. After clicking a URL in a notification and logging into the Web Console, LogRhythm now automatically routes you to the correct alarm. This update saves you time and removes the hassle of searching for important notifications.\\n', 'In-Platform Resource Center Tutorials': 'In SIEM 7.15, we’re continuing to improve the\\nResource Center\\n. We’ve added in-app tutorials to help new users quickly understand how to leverage the power of LogRhythm. Our newest tutorials are listed in the Onboarding section of the Resource Center. Onboarding topics include Dashboards, Searches, Case Management, Alarm Management, and Beat Management. These topics will help a new LogRhythm SIEM Analyst or Administrator understand the key principles of LogRhythm SIEM. With the Resource Center, users can quickly view in-app Announcements and Onboarding tutorials and easily access Documentation, Community, and Support.\\n', 'Log Source Enhancements': 'We are constantly enhancing our ability to help our customers collect and receive value from log sources in their environment. A big part of that is constantly making updates to our parsing policies via KB updates.\\nWe get it, technology changes at a rapid pace. This often means LogRhythm needs to revisit log sources we already support and help customers derive more value by accounting for changes and quickly evolving.\\nLogRhythm is continuing to review our supported log sources and make updates to strengthen our correlation and analysis. Our new and enhanced methods of ingestion include:\\nSource, LogRhythm Enhancement\\nFortinet FortiNAC, New log support for FortiNAC, which protects against IoT threats, extends control to third-party devices, and orchestrates automatic responses to a wide range of networking events.\\nstrongSwan VPN, New log support for strongSwan, which is a complete IPsec solution providing encryption and authentication to servers and clients.\\nF5 BIG-IP System, New log support for BIG-IP System, which is a set of application delivery products that work together to ensure high availability, improved performance, application security, and access control.\\nTenable OT, New policies help prevent classification errors and provide more consistent parsing of log source data for Tenable Operational Technology (OT). And new MPE rules parse log metadata to the correct schema fields and classify highly complex log source data.\\nQRadar, New log support for QRadar Network Security, which is used to detect hidden threats on your networks with deep, broad visibility and advanced analytics.\\nMimecast, Updated policies and workflow for collecting logs from Mimecast.\\nImperva Database Activity Monitor (DAM), Updated policies help prevent classification errors and provide more consistent parsing of log source data for Imperva Database Activity Monitor (DAM). Andd new MPE rules parse log metadata to the correct schema fields and classify highly complex log source data.\\nPalo Alto Cortex Data Lake, Updated policies for schema changes to help prevent classification errors and provide more consistent parsing of log source data for Palo Alto Networks® Cortex Data Lake, which provides cloud-based, centralized log storage and aggregation for your on-premise, virtual (private cloud and public cloud) firewalls, for Prisma Access, and for cloud-delivered services such as Cortex XDR.\\nSource\\nLogRhythm Enhancement\\nFortinet FortiNAC\\nNew log support for FortiNAC, which protects against IoT threats, extends control to third-party devices, and orchestrates automatic responses to a wide range of networking events.\\nstrongSwan VPN\\nNew log support for strongSwan, which is a complete IPsec solution providing encryption and authentication to servers and clients.\\nF5 BIG-IP System\\nNew log support for BIG-IP System, which is a set of application delivery products that work together to ensure high availability, improved performance, application security, and access control.\\nTenable OT\\nNew policies help prevent classification errors and provide more consistent parsing of log source data for Tenable Operational Technology (OT). And new MPE rules parse log metadata to the correct schema fields and classify highly complex log source data.\\nQRadar\\nNew log support for QRadar Network Security, which is used to detect hidden threats on your networks with deep, broad visibility and advanced analytics.\\nMimecast\\nUpdated policies and workflow for collecting logs from Mimecast.\\nImperva Database Activity Monitor (DAM)\\nUpdated policies help prevent classification errors and provide more consistent parsing of log source data for Imperva Database Activity Monitor (DAM). Andd new MPE rules parse log metadata to the correct schema fields and classify highly complex log source data.\\nPalo Alto Cortex Data Lake\\nUpdated policies for schema changes to help prevent classification errors and provide more consistent parsing of log source data for Palo Alto Networks® Cortex Data Lake, which provides cloud-based, centralized log storage and aggregation for your on-premise, virtual (private cloud and public cloud) firewalls, for Prisma Access, and for cloud-delivered services such as Cortex XDR.\\n\\n', 'Enhancements & Resolved Issues': 'Bug #, Component, Description\\nENG-48893, Active Directory, SQL script was updated to delete duplicate AD users.\\nENG-49732, Agents, Transparent framing logs are now processed as expected.\\nENG-51112, Agents, Log collection works as expected without establishing multiple connections to each beat, and scsm.ini files are no longer becoming corrupt on Agents.\\nENG-49544, Agents: Beats Collection, Log collection works as expected without establishing multiple connections to each beat.\\nENG-49540, Agents: GCP SCC Log Collection, Agent hostname is no longer parsed into sname.\\nENG-48506, Agents: Licenses, After purchasing and importing new licenses into SIEM, customers can now view their new licenses after they have been installed.\\nENG-50963, Agents: Linux, Linux agents are now working as intended.\\nENG-47116, Agents: MSGraph API Log Collection, Parsing improvement for logs ingested via the MSGraph API Beat.\\nENG-48257, Agents: Office 365 Log Collection, When multiple O365 Message Tracking log sources are configured on a single System Monitor Agent, the logs are now organized under the correct log source.\\nENG-48448, Agents: Qualys Log Collection, Log collection from a Qualys log source now works as expected.\\nENG-37629, Agents: Windows Event Log Collection, When adding a Windows Event Log source manually or when using the Windows Host Wizard, the target file path automatically populates. If a path cannot be populated, the user is prompted to populate it and is given the proper format.\\nENG-11167, AI Engine, When evaluation frequency is set to 20 minutes or longer, AIE rules are now reliably triggering alarms.\\nENG-35141, AI Engine: MPE Rules, The MPE Rule Builder no longer hyperlinks text.\\nENG-49323, AI Engine: MPE Rules, Users no longer get an error when sorting custom MPE Rules with Rule Sorter.\\nENG-50440, AI Engine: MPE Rules, Users no longer get an error when sorting custom MPE Rules with Rule Sorter.\\nENG-49660, Client Console, When users click “Compare With” in SysMon Version History, they no longer receive an error.\\nENG-50411, Client Console, Users can now create a new root entity without receiving timeout errors.\\nENG-36384, Configuration Manager, The Configuration Manager now correctly references UEBA settings instead of CloudAI.\\nENG-52641, DP Pooling, Logs are now spread more evenly among Data Processors within a DP Pool.\\nENG-52545, Documentation, Added callout to REST API docs confirming that only Global Admins can access third-party applications.\\nENG-52546, Documentation, Updated the first line of Deployment Monitor documentation to specify Global Admins.\\nENG-52751, Documentation, Updated documentation covering how to upgrade the Data Indexer to mitigate upgrade failures.\\nENG-50491, Infrastructure: Database Scripts and Upgrade Scripts, Running LRII to upgrade a deployment no longer fails or returns errors when overwriting a backup file.\\nENG-51491, Mediator, The Mediator cache refresh logic was adjusted in large LRCloud deployments with many System Monitor Agents and Data Processors. The new logic mitigates overloading the deployment with too many cache refreshes.\\nENG-42221, Search API, The Search API no longer fails when the LogRhythmWebUI account password is changed to a non-default password.\\nENG-47026, Search API, The Search API no longer fails when the LogRhythmWebUI account password is changed to a non-default password.\\nENG-49316, SecondLook, When a SecondLook search is executed on the Web Console, the saved search now shows the correct owner name.\\nENG-23073, SysMon, Windows agents no longer stop sending heartbeats or logs after a Mediator reconnection.\\nENG-32389, SysMon, Multiple enhancements have been made to improve the performance of the Linux Agent.\\nENG-41674, SysMon, Memory issue in Windows agent is now fixed by reducing the TCP and TLS file sizes in the suspense folder.\\nENG-42344, SysMon, Setting the Host EntityID to 0 in the System Monitor Agent configuration no longer keeps the Agent from connecting to the Data Processor. Instead, the setting reverts back to the original EntityID.\\nENG-48483, SysMon, Log collection works as expected without establishing multiple connections to each beat.\\nENG-41830, Tools, The LogRhythm Diagnostics Agent no longer consumes memory when it has not been configured.\\nENG-24178, Web Indexer, On high log volume systems, the Web Indexer no longer fails with “Out of Memory heap” exception.\\nENG-47915, Web Console, The Log Sources list now displays properly in the Web Console UI.\\nENG-26705, Web Console, On systems with a large number of log sources, the Web Console dashboard now loads without displaying errors.\\nENG-31933, Web Console, The Web Console Analyzer no longer displays a deleted set of logs, nor does it display blank values when logs are present.\\nENG-11135, Web Console, When performing a search or AIE drill down in the Web Console, users no longer need to refresh the page to view the results.\\nENG-11145, Web Console, After users make changes to the Web Console Settings, the updated settings now persist when navigating throughout the user interface.\\nENG-11166, Web Console, The \"Component Status\" widget now correctly shows the component name along with other values in the \"Component Widget\" status in version 7.9.\\nENG-22874, Web Console, When users click on an alarm link in an external application like an email notification, the link now opens the alarm page after required credentials have been verified.\\nENG-40010, Web Console, When a Restricted Admin has permissions to manage an Entity in management settings, they can now create a dashboard for that Entity in the Web Console.\\nBug #\\nComponent\\nDescription\\nENG-48893\\nActive Directory\\nSQL script was updated to delete duplicate AD users.\\nENG-49732\\nAgents\\nTransparent framing logs are now processed as expected.\\nENG-51112\\nAgents\\nLog collection works as expected without establishing multiple connections to each beat, and scsm.ini files are no longer becoming corrupt on Agents.\\nENG-49544\\nAgents: Beats Collection\\nLog collection works as expected without establishing multiple connections to each beat.\\nENG-49540\\nAgents: GCP SCC Log Collection\\nAgent hostname is no longer parsed into sname.\\nENG-48506\\nAgents: Licenses\\nAfter purchasing and importing new licenses into SIEM, customers can now view their new licenses after they have been installed.\\nENG-50963\\nAgents: Linux\\nLinux agents are now working as intended.\\nENG-47116\\nAgents: MSGraph API Log Collection\\nParsing improvement for logs ingested via the MSGraph API Beat.\\nENG-48257\\nAgents: Office 365 Log Collection\\nWhen multiple O365 Message Tracking log sources are configured on a single System Monitor Agent, the logs are now organized under the correct log source.\\nENG-48448\\nAgents: Qualys Log Collection\\nLog collection from a Qualys log source now works as expected.\\nENG-37629\\nAgents: Windows Event Log Collection\\nWhen adding a Windows Event Log source manually or when using the Windows Host Wizard, the target file path automatically populates. If a path cannot be populated, the user is prompted to populate it and is given the proper format.\\nENG-11167\\nAI Engine\\nWhen evaluation frequency is set to 20 minutes or longer, AIE rules are now reliably triggering alarms.\\nENG-35141\\nAI Engine: MPE Rules\\nThe MPE Rule Builder no longer hyperlinks text.\\nENG-49323\\nAI Engine: MPE Rules\\nUsers no longer get an error when sorting custom MPE Rules with Rule Sorter.\\nENG-50440\\nAI Engine: MPE Rules\\nUsers no longer get an error when sorting custom MPE Rules with Rule Sorter.\\nENG-49660\\nClient Console\\nWhen users click “Compare With” in SysMon Version History, they no longer receive an error.\\nENG-50411\\nClient Console\\nUsers can now create a new root entity without receiving timeout errors.\\nENG-36384\\nConfiguration Manager\\nThe Configuration Manager now correctly references UEBA settings instead of CloudAI.\\nENG-52641\\nDP Pooling\\nLogs are now spread more evenly among Data Processors within a DP Pool.\\nENG-52545\\nDocumentation\\nAdded callout to REST API docs confirming that only Global Admins can access third-party applications.\\nENG-52546\\nDocumentation\\nUpdated the first line of Deployment Monitor documentation to specify Global Admins.\\nENG-52751\\nDocumentation\\nUpdated documentation covering how to upgrade the Data Indexer to mitigate upgrade failures.\\nENG-50491\\nInfrastructure: Database Scripts and Upgrade Scripts\\nRunning LRII to upgrade a deployment no longer fails or returns errors when overwriting a backup file.\\nENG-51491\\nMediator\\nThe Mediator cache refresh logic was adjusted in large LRCloud deployments with many System Monitor Agents and Data Processors. The new logic mitigates overloading the deployment with too many cache refreshes.\\nENG-42221\\nSearch API\\nThe Search API no longer fails when the LogRhythmWebUI account password is changed to a non-default password.\\nENG-47026\\nSearch API\\nThe Search API no longer fails when the LogRhythmWebUI account password is changed to a non-default password.\\nENG-49316\\nSecondLook\\nWhen a SecondLook search is executed on the Web Console, the saved search now shows the correct owner name.\\nENG-23073\\nSysMon\\nWindows agents no longer stop sending heartbeats or logs after a Mediator reconnection.\\nENG-32389\\nSysMon\\nMultiple enhancements have been made to improve the performance of the Linux Agent.\\nENG-41674\\nSysMon\\nMemory issue in Windows agent is now fixed by reducing the TCP and TLS file sizes in the suspense folder.\\nENG-42344\\nSysMon\\nSetting the Host EntityID to 0 in the System Monitor Agent configuration no longer keeps the Agent from connecting to the Data Processor. Instead, the setting reverts back to the original EntityID.\\nENG-48483\\nSysMon\\nLog collection works as expected without establishing multiple connections to each beat.\\nENG-41830\\nTools\\nThe LogRhythm Diagnostics Agent no longer consumes memory when it has not been configured.\\nENG-24178\\nWeb Indexer\\nOn high log volume systems, the Web Indexer no longer fails with “Out of Memory heap” exception.\\nENG-47915\\nWeb Console\\nThe Log Sources list now displays properly in the Web Console UI.\\nENG-26705\\nWeb Console\\nOn systems with a large number of log sources, the Web Console dashboard now loads without displaying errors.\\nENG-31933\\nWeb Console\\nThe Web Console Analyzer no longer displays a deleted set of logs, nor does it display blank values when logs are present.\\nENG-11135\\nWeb Console\\nWhen performing a search or AIE drill down in the Web Console, users no longer need to refresh the page to view the results.\\nENG-11145\\nWeb Console\\nAfter users make changes to the Web Console Settings, the updated settings now persist when navigating throughout the user interface.\\nENG-11166\\nWeb Console\\nThe \"Component Status\" widget now correctly shows the component name along with other values in the \"Component Widget\" status in version 7.9.\\nENG-22874\\nWeb Console\\nWhen users click on an alarm link in an external application like an email notification, the link now opens the alarm page after required credentials have been verified.\\nENG-40010\\nWeb Console\\nWhen a Restricted Admin has permissions to manage an Entity in management settings, they can now create a dashboard for that Entity in the Web Console.\\n', 'Resolved Issues - Security': 'Security-related issues resolved with this release are available for customers to view in the\\nCommunity\\n.\\n', 'Known Issues': 'The following issues have each been found and reported by multiple users.\\nBug #, Found In Version, Components, Description, Release Notes\\nENG-43218, N/A, Alarm API, When using the XSOAR integration with Alarm API, requests periodically return a 500 internal server error., Expected Results:The integration should work without returning an error.Workaround:Retry the request until it succeeds.\\nENG-38849, N/A, Knowledge Base, When parsing logs associated with Syslog Linux Host, the Mediator returns the following error message:“Regex rule match timed out.”, Expected Results:The regex rule should parse successfully without timing out.Workaround:There is currently no workaround for this issue.\\nENG-38594, 7.11, SmartResponse Plugins, When SmartResponse Plugin scripts are modified but not triggered for 7 days, the custom changes are deleted and the SRP reverts to default settings., Expected Results:When SRP scripts are modified, the changes should be retained.Workaround:There is currently no workaround for this issue.\\nENG-41651, 7.127.13, Web Console, After upgrading to 7.12 or 7.13, the CAC authorization used to log in to the Web Console stops working., Expected Results:The CAC authorization should work when logging in to the Web Console.Workaround:There is currently no workaround for this issue.\\nBug #\\nFound In Version\\nComponents\\nDescription\\nRelease Notes\\nENG-43218\\nN/A\\nAlarm API\\nWhen using the XSOAR integration with Alarm API, requests periodically return a 500 internal server error.\\nExpected Results:\\nThe integration should work without returning an error.\\nWorkaround:\\nRetry the request until it succeeds.\\nENG-38849\\nN/A\\nKnowledge Base\\nWhen parsing logs associated with Syslog Linux Host, the Mediator returns the following error message:\\n“Regex rule match timed out.”\\nExpected Results:\\nThe regex rule should parse successfully without timing out.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nENG-38594\\n7.11\\nSmartResponse Plugins\\nWhen SmartResponse Plugin scripts are modified but not triggered for 7 days, the custom changes are deleted and the SRP reverts to default settings.\\nExpected Results:\\nWhen SRP scripts are modified, the changes should be retained.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nENG-41651\\n7.12\\n7.13\\nWeb Console\\nAfter upgrading to 7.12 or 7.13, the CAC authorization used to log in to the Web Console stops working.\\nExpected Results:\\nThe CAC authorization should work when logging in to the Web Console.\\nWorkaround:\\nThere is currently no workaround for this issue.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.15.0.64 Release Notes - 5 February 2024': 'This guide describes one issue that was fixed in LogRhythm 7.15, as well as the upgrade procedure from 7.15.x to 7.15.0.64.\\nThe updated components provided in 7.15.0.64 were added to the 7.15.0 GA release downloads on February 5, 2024.\\xa0If you upgraded using 7.15.0 GA software downloaded after February 5, you do not need to apply this patch.\\n', 'Resolved Issues': 'Bug #, Component, Description\\nENG-53447, Web Console, LR Cloud, When the TrueIdentity Sync Client is enabled, users no longer receive error messages associated with TopX widgets on their Web Console dashboards.\\nBug #\\nComponent\\nDescription\\nENG-53447\\nWeb Console, LR Cloud\\nWhen the TrueIdentity Sync Client is enabled, users no longer receive error messages associated with TopX widgets on their Web Console dashboards.\\n', 'Download the Upgrade Components': 'The 7.15.0.64 release includes an updated installer. The new installer can be downloaded from the LogRhythm Community.\\nLog in to the\\nCommunity\\n.\\nLog in to the\\nCommunity\\n.\\nOn the main menu bar, click\\nDocumentation & Downloads\\n, and then click\\nSIEM\\n.\\nOn the main menu bar, click\\nDocumentation & Downloads\\n, and then click\\nSIEM\\n.\\nClick\\nNextGen SIEM\\n, and then click\\n7.15.0 GA Downloads\\n.\\nClick\\nNextGen SIEM\\n, and then click\\n7.15.0 GA Downloads\\n.\\nUnder 7.15.0 GA Downloads, download the\\nLogRhythm Install Wizard\\n.\\nUnder 7.15.0 GA Downloads, download the\\nLogRhythm Install Wizard\\n.\\n', 'Upgrade the 7.15.0 Deployment': 'Run the LogRhythm Install Wizard just as you would to upgrade a deployment.\\nOpen the Install Wizard directory, and right-click the\\nLogRhythmInstallWizard.exe\\nyou downloaded in the steps above.\\nOpen the Install Wizard directory, and right-click the\\nLogRhythmInstallWizard.exe\\nyou downloaded in the steps above.\\nClick\\nRun as administrator\\n.\\nThe LogRhythm Install Wizard 7.15.0 appears.\\nClick\\nRun as administrator\\n.\\nThe LogRhythm Install Wizard 7.15.0 appears.\\nClick\\nNext\\n.\\nThe LogRhythm Install Wizard Confirmation dialog box appears.\\nClick\\nNext\\n.\\nThe LogRhythm Install Wizard Confirmation dialog box appears.\\nClick\\nYes\\n.\\nThe License Agreement appears.\\nClick\\nYes\\n.\\nThe License Agreement appears.\\nSelect the check box to accept the terms in the license agreement, and then click\\nNext\\n.\\nSelect the check box to accept the terms in the license agreement, and then click\\nNext\\n.\\nOn the configuration page, select the\\nData Processor\\nconfiguration.\\nOn the configuration page, select the\\nData Processor\\nconfiguration.\\nUnder Optional Applications, deselect\\nLRD Agent\\n,\\xa0and then click\\nInstall\\n.\\nUnder Optional Applications, deselect\\nLRD Agent\\n,\\xa0and then click\\nInstall\\n.\\nWhen the installer is finished, verify that the Web services are running.\\nWhen the installer is finished, verify that the Web services are running.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.7.0 GA Release Notes': '', 'New Features': 'Functional Group, Feature, Description\\nPlatform Administration, Alarm API, Explanation:A newly developed RESTful Alarm API enables users to add alarm functionality to their LogRhythm deployment at parity with the capabilities of the existing SOAP API.Benefit:The Alarm API can be used in third-party integration, allowing customers to extend the LogRhythm solution or integrate it with other systems. It also brings LogRhythm closer to full deprecation of the complex SOAP API for Alarm Service. For more information, see Deprecated Features.\\nPlatform Administration, Configure Cloud Log Source in Web Console, Explanation:Cloud log collection enables users to create, configure, and manage Beat Log Sources and Sysmon Log Sources through a user interface in the Web Console.Benefit:Instead of having to configure log sources through the Console or command line interface, users can now configure log sources through a GUI using a list of available log sources.\\nSecurity Analytics, Timeline View, Explanation:From the Inspector, users can now launch a search on a single user or host and land on a details page that displays the search results in the new Timeline widget.Benefit:The timeline widget is a chronological way to \"tell a story\" about the user or host activity, including a contextualized sentence helping explain the log activity in plain English.\\nExplanation:\\nA newly developed RESTful Alarm API enables users to add alarm functionality to their LogRhythm deployment at parity with the capabilities of the existing SOAP API.\\nBenefit:\\nThe Alarm API can be used in third-party integration, allowing customers to extend the LogRhythm solution or integrate it with other systems. It also brings LogRhythm closer to full deprecation of the complex SOAP API for Alarm Service. For more information, see Deprecated Features.\\nExplanation:\\nCloud log collection enables users to create, configure, and manage Beat Log Sources and Sysmon Log Sources through a user interface in the Web Console.\\nBenefit:\\nInstead of having to configure log sources through the Console or command line interface, users can now configure log sources through a GUI using a list of available log sources.\\nExplanation:\\nFrom the Inspector, users can now launch a search on a single user or host and land on a details page that displays the search results in the new Timeline widget.\\nBenefit:\\nThe timeline widget is a chronological way to \"tell a story\" about the user or host activity, including a contextualized sentence helping explain the log activity in plain English.\\n', 'Improvements': 'Numerous third-party libraries have been updated to mitigate\\nthe risk of security vulnerabilities manifesting in LogRhythm 7.7.0. For more information, see\\xa0Open Source License Acknowledgements.\\nUpdates to the Admin API provide\\naccess to Notification Groups at the user profile level. New Users and Notification endpoints are now available in the Admin API.\\nIf a SysMon Agent is licensed as a Collection Agent, then EDR features are now disabled.\\xa0This gives users control over use of the EDR feature for a license user.\\nIf a SysMon Agent is licensed as a Collection Agent, then EDR features are now disabled.\\xa0This gives users control over use of the EDR feature for a license user.\\nThe DB upgrade process now includes a measure to\\nvalidate that a user trying to upgrade LogRhythm has a valid license file for the target version, and provides a warning/error that a new license is required before proceeding.\\n', 'Deprecated Features': 'LogRhythm is deprecating the SOAP API in favor of more usable and sustainable integration through RESTful APIs. Starting with the release of LogRhythm SIEM version 7.7.0, development work will cease on the SOAP API. We will still publish the SOAP API installer, and existing integrations will continue to function. LogRhythm 7.8.0 (expected Q2 2021) will be the last published version of the SOAP API. We encourage customers and partners using the SOAP API to migrate their integrations to REST APIs. For more information on REST integration, see our REST API documentation.\\n', 'Resolved Issues': \"Bug #, Ticket #, Component, Description\\nDE1975, 322187, 370669, 00403498, Mediator, Special characters such as(')are no longer allowed in the LicensedTo field during license generation, allowing Mediator service to start without error.\\nDE10612, 3680676, Mediator, Missing Messaging Performance Counters or corruption to counters no longer prevents Mediator from starting up.\\nDE10883, 382311, Databases, Sub-rule field mapping tags have been removed from the MPERule table.\\nDE11024, 381875, 396764,\\xa0397660, Job Manager, Active Directory sync now validates when using secure LDAP.\\nDE11029, N/A, Job Manager, Log source virtualization templates are now imported by automatic KB sync.\\nDE11106, 390438, API Gateway, LogRhythm API Gateway now uses strong ciphers.\\nDE11134, 392559, Data Indexer, The Carpenter service can now connect to SQL in non-FIPS mode.\\nDE11159, 391799, Job Manager, Having two user accounts with same first and last namein an AD group nowlogs a descriptive error and does not prevent AD sync from completing.\\nDE11227, 00393721, Mediator, LDS no longer stops forwarding when Log Source lists are updated.\\nDE11299, 00406368,\\xa0409590,\\xa000411655, Windows Agent, SNMP Trap Receiver configuration encryption in scsm.ini has been fixed.\\nDE11425, 00398689, Mediator, The Admin API Get Identity Identifiers now supports pagination in API responses.\\nDE11516, 00399571, 00400795, Mediator, The LDS secure TCP option in the Network Protocol dropdown of the Syslog Receiver Properties is now working properly.\\nDE11688, 401385,\\xa0403686, User Profile Manager, Restricted Analysts/Admins can now see TrueIdentity data.\\nDE11713, N/A, Documentation, Data Indexer upgrade guidance with regard to preinstall.sh has been updated and clarified.\\nDE11722, 00403700,\\xa000404093,\\xa000403994,\\xa000405766,\\xa000412702, Web Console, The Host Details page was improperly displaying in 7.6.0, and is now displaying properly.\\nDE11732, 00403549,\\xa000405700,\\xa000405755,\\xa000403914,\\xa000404814,\\xa000405027, Data Indexer, Elasticsearch upgrades for Data Indexer can now continue even when an environment variable is deleted.\\nDE11748, 00404491,\\xa000403989, Data Indexer, Data Indexer upgrade no longer throws a LRDXNode Installer Warm Node Insufficient Resources error.\\nDE11777, 404694, Documentation, 7.6.0 XM DR installation documentation no longer lists duplicate cluster names.\\nDE11786, 404217, 400347, 404360,\\xa0409515, Job Manager, The Job Manager now retries three times if there is an error during AD group member lookup. After three failures, Job Manager skips that group.\\nDE11850, 403762, 405412,\\xa0404759,\\xa0409733, Job Manager, Renaming an Active Directory group being used in AD Group-based authorization is now caught and logged as a warning during the group-based authorization sync.\\nDE11873, 405774, 406288, Mediator, An error in TrueIdentity sync on large data sets no longer causes MPE to stop processing.\\nDE11895, 00406862, CloudAI, CloudAI data is now accessible in Web Console with SSO login.\\nDE11925, 00406944, Web Console, SSO timeout no longer occurs when multifactor authentication is enabled and the user authenticates with SSO.\\nDE11995, 408293, Data Indexer, Elasticsearch startup has been modified to prevent Elasticsearch from starting when Windows Service Registry is not available.\\nDE12067, 00408347, Data Indexer, Transporter now fully starts after automatic restart at five minutes past midnight UTC.\\nDE12068, 405081, Log Sources, Client Console no longer freezes filtering log sources on the Log Source tab.\\nDE12105, 409558, Data Indexer, The migrate-consul-keyspace.ps1 script has been signed.\\nDE12123, 406612, Admin API, Admin API GET /identities/ no longer returns duplicate identities.\\nDE12124, N/A, Data Indexer, Elasticsearch startup has been modified to prevent Elasticsearch from starting when Service Registry is not available.\\nDE12183, 00407818, Web Console, JRE (java) files have been excluded from the hashed files list to allow users to apply security patches.\\nDE12191, 00410813, Admin API, Admin API's Create Agent Record action now works properly.\\nSpecial characters such as\\n(')\\nare no longer allowed in the LicensedTo field during license generation, allowing Mediator service to start without error.\\nMissing Messaging Performance Counters or corruption to counters no longer prevents Mediator from starting up.\\nSub-rule field mapping tags have been removed from the MPERule table.\\nActive Directory sync now validates when using secure LDAP.\\nLog source virtualization templates are now imported by automatic KB sync.\\nLogRhythm API Gateway now uses strong ciphers.\\nThe Carpenter service can now connect to SQL in non-FIPS mode.\\nHaving two user accounts with same first and last name\\nin an AD group now\\nlogs a descriptive error and does not prevent AD sync from completing.\\nLDS no longer stops forwarding when Log Source lists are updated.\\nSNMP Trap Receiver configuration encryption in scsm.ini has been fixed.\\nThe Admin API Get Identity Identifiers now supports pagination in API responses.\\nThe LDS secure TCP option in the Network Protocol dropdown of the Syslog Receiver Properties is now working properly.\\nRestricted Analysts/Admins can now see TrueIdentity data.\\nData Indexer upgrade guidance with regard to preinstall.sh has been updated and clarified.\\nThe Host Details page was improperly displaying in 7.6.0, and is now displaying properly.\\nElasticsearch upgrades for Data Indexer can now continue even when an environment variable is deleted.\\nData Indexer upgrade no longer throws a LRDXNode Installer Warm Node Insufficient Resources error.\\n7.6.0 XM DR installation documentation no longer lists duplicate cluster names.\\nThe Job Manager now retries three times if there is an error during AD group member lookup. After three failures, Job Manager skips that group.\\nRenaming an Active Directory group being used in AD Group-based authorization is now caught and logged as a warning during the group-based authorization sync.\\nAn error in TrueIdentity sync on large data sets no longer causes MPE to stop processing.\\n\\nCloudAI data is now accessible in Web Console with SSO login.\\nSSO timeout no longer occurs when multifactor authentication is enabled and the user authenticates with SSO.\\nElasticsearch startup has been modified to prevent Elasticsearch from starting when Windows Service Registry is not available.\\nTransporter now fully starts after automatic restart at five minutes past midnight UTC.\\nClient Console no longer freezes filtering log sources on the Log Source tab.\\nThe migrate-consul-keyspace.ps1 script has been signed.\\nAdmin API GET /identities/ no longer returns duplicate identities.\\n\\nElasticsearch startup has been modified to prevent Elasticsearch from starting when Service Registry is not available.\\nJRE (java) files have been excluded from the hashed files list to allow users to apply security patches.\\nAdmin API's Create Agent Record action now works properly.\\n\", 'Known Issues': 'The following issues have each been found and reported by multiple users.\\nBug #, Found in Version, Component, Description, Release Notes\\nDE1288, 7.4.6, AI Engine, When an AIE Rule uses the Host (Impacted) or Host (Origin) in the Group By block, the rule misfires., Expected Results:AIE Rules should not fire if the rule block relationship is not met.Workaround:Change the Host (origin) or Host (impacted) fields to IP Address, and the AIE Rule works as expected.\\nDE1336, 7.4.6, AI Engine, In certain circumstances, the AIE Summary Fields are not populating in the AIE Notification emails., Expected Results:AIE Summary Fields should be displayed on all AIE Notification emails.Workaround:View the AIE Summary Fields in the Alarm instead of the Notification email.\\nDE1606, 7.3.5, AI Engine, When an AIE Rule with two rule blocks has an evaluation period of 0 seconds, the rule does not trigger\\xa0as expected., Expected Results:AIE Rule Blocks should fire when they are triggered at the same time.Workaround:As the behavior of simultaneous events is unpredictable\\xa0and the use case for a 0-time interval is rare, LogRhythm does not plan to change this behavior at this time. To avoid the issue, set the evaluation period to 1 second.\\nDE1759, 7.3.4, AI Engine, Errors\\xa0are\\xa0being\\xa0reported\\xa0numerous\\xa0times\\xa0in\\xa0the\\xa0AIE\\xa0Engine\\xa0log when the AIE service starts up., Expected Results:These errors should not be reported in the AIE Engine log, but AIE\\xa0is\\xa0working\\xa0and\\xa0alarms\\xa0are\\xa0firing.Workaround:There is currently no workaround for this issue.\\nDE1871, 7.3.3, AI Engine, Under conditions of load, AI Engine Rules that are written incorrectly can cause significant issues throughout the entire AIE\\xa0server., Expected Results:Poorly written AIE Rules should be suspended until they are altered and re-enabled.Workaround:Rewrite the AIE Rule for\\xa0better performance.\\xa0Often, this involves adding filters, reducing log sources, and\\xa0modifying the logic. Tuning an AIE Rule requires expertise, so contact LogRhythm Training, Professional Services, or a Sales Engineer to assist if necessary. Additional solutions to identify and monitor poorly performing rules are being developed for a\\xa0future release.\\nDE10313, 7.4.9, AI Engine, In rare circumstances, AIE Unique Value Rules\\xa0misfire., Expected Results:AIE Rules fire as expected.Workaround:There is no workaround at this time. LogRhythm is actively investigating the issue for a future release.\\nDE10397, 7.4.8, AI Engine, In certain circumstances, when an AIE Rule is evaluating an Observed block followed by a Not Observed block, alarms\\xa0fire even if there are logs that indicate the second block was Observed., Expected Results:Alarms do\\xa0not fire if a log is received for a Not Observed block.Workaround:There is no workaround at this time. LogRhythm is investigating this issue for a future release.\\nDE10501, 7.4.7, AI Engine: Host Interference, The HostInferenceLogs are not being maintained/purged out after 7 days as defined., Expected Results:These logs should be automatically purged after 7 days as defined.Workaround:Sort by log date and delete all older logs.\\nDE10946, 7.4.9, AI Engine, SmartResponse Plugin, When an AIE Alarm has an action including a SmartResponse Plugin, the execution is slow., Expected Results:Alarms should execute quickly as expected with other AIE Alarms.Workaround:There is currently no workaround for this issue.\\nDE11098, 7.4.9,7.4.10, ARM: Notifications, When using a SMTP server with SSL authentication, the Alarming and Response Manager fails to send alarm notifications., Expected Results:The Alarming and Response Manager should able to send alarm notifications using any SMTP server and SSL authentication.Workaround:There is currently no workaround for this issue.\\nDE6072, 7.3.4, APIs, When using a 512-bit RSA-signed certificate, Case API and Admin API do not start due to an incomplete\\xa0implementation of TLS 1.2.\\xa0This typically happens when a GPO pushes the certificate to the server., Expected Results:Case API and Admin API should start when using any size certificate.Workaround:Remove\\xa0the\\xa0server\\xa0from\\xa0the\\xa0domain and reboot it.\\xa0Verify that the\\xa0512-bit\\xa0certificate has\\xa0been\\xa0removed, re-run the installers, and reboot. To\\xa0avoid\\xa0this issue, do not join the domain\\xa0again\\xa0or\\xa0the\\xa0certificate will\\xa0be\\xa0pushed\\xa0out\\xa0again.\\xa0In addition, create a new certificate that\\xa0uses a 384-bit (or less) hash or exclude the impacted system from the GPO that pushes\\xa0the\\xa0certificate.\\nDE10200, 7.4.9, APIs, PowerShell scripts utilizing the Case and Admin APIs may stop working upon upgrade to 7.4.9 or later.\\xa0This is due to an additional semicolon at the end of the valid content-type value., Expected Results:The extra semicolon, which is an optional valid separator in a content-type header, should not prevent scripts from working upon upgrade.Workaround:There is no workaround for this issue at this time. A solution is being investigated for a future release.\\nDE1829, 7.3.3, Client Console, There may be inconsistencies in the way a log parses through MPE processing and within the MPE Rule Builder. A log that parses without issue in the Rule Builder may not parse when run through MPE processing.\\xa0This could be caused by rule match timeouts., Expected Results:The processing of a log should be the same whether it is parsed in Rule Builder or MPE.Workaround:Change the sub-rule to use a different tag, such as <Tag1>.\\xa0If you are experiencing this issue, ensure that you are not using a custom Log Processing Policy and that there are no MPE timeouts.\\xa0If issues persist, contact Technical Support and reference this bug number\\xa0(DE1829) or its sister defect\\xa0(DE1651).\\nDE3195, 7.3.4, Client Console, When running a search in either the Client or Web Console, users see an error: \"\"Error fetching data - Gateway timeout.\"\", Expected Results:When a search times out, a message should inform users and instruct them\\xa0to re-run the search with a longer timeout.Workaround:Increase the timeout on the query and re-run it.\\nDE3932, 7.4.7, Client Console, After disabling Log Source Virtualization for a log source, users are unable to perform certain tasks on the System Monitor from which the log source is collected., Expected Results:Disabling Log Source Virtualization should not change the behavior of the System Monitor.Workaround:This issue is caused by the scsm.ini file not being updated immediately.\\xa0To work around it, refresh the Log Sources tab in the Client Console to\\xa0force the .ini file to refresh.\\nDE4049, 7.4.6, Client Console, When running a report that contains User Origin Identity or User Impacted Identity fields, the report runs and provides data, but the Identity fields are\\xa0not\\xa0populated., Expected Results:Identity data appears\\xa0in reports that contain those fields.Workaround:Run an investigation to provide the same information.\\nDE5185, 7.3.4, Client Console, The Network (Impacted) field does not display on reports where it is included as a column, even though data appears in that field., Expected Results:All chosen fields should appear\\xa0on the report if they contain data.Workaround:Running the report as an investigation yields the expected results in the Network (Impacted) column. LogRhythm is\\xa0actively working on a solution to this issue in\\xa0a future release.\\nDE7612, 7.1.7, Client Console, Reports exported to .csv format are not formatted correctly. The headers are duplicated in each row as name/value pairs., Expected Results:When exporting reports in .csv format, the column headers should not be repeated on each row.Workaround:The report needs to be formatted to remove columns that show the column headers. In addition, LogRhythm data can be exported using Log Distribution Services (LDS).\\nDE7632, 7.1.3, Client Console, Entities cannot be deleted from within the Client Console., Expected Results:Entities\\xa0should be retireable\\xa0and able to be hidden from view.Workaround:Contact Technical Support to assist you in removing entities that are no longer needed.\\nDE10621, 7.4.9, Client Console, When an existing report template that includes the Normal Date field is edited, the Normal Date field disappears from the template until\\xa0it is added again., Expected Results:When editing a report template, existing fields should remain unless they are explicitly removed.Workaround:When editing a report template that contains the Normal Date field, add that field back to the template prior to saving it.\\nDE10678, 7.4.8, Client Console: Report Center, The Configuration Manager may display an error \"Cannot connect to LogRhythm API Gateway\" when it first loads. In addition, it may show all services are down when they appear to be healthy otherwise., Expected Results:The Configuration Manager should load immediately and show the services in the correct state.Workaround:The Configuration Manager will eventually load if given a little time.\\xa0 When the services show down, a refresh of the Configuration Manager should show them correctly.\\xa0 We are working on a resolution to this issue.\\nDE3385, 7.3.2, Data Indexer, The DX Diagnostic logs are firing too often., Expected Results:The Diagnostic logs should be tuned to alarm less frequently.Workaround:There is no workaround for this issue at this time.\\nDE1737, 7.4.9, Installation Components, In rare circumstances, Alarms may not be available in the Web Console or will stop triggering. Typically, this occurs\\xa0directly after a configuration change to the ARM service., Expected Results:Alarms should continue to trigger and be displayed in the Web Console.Workaround:Contact Technical Support for assistance, as there could be many reasons for this behavior beyond this defect.\\xa0Support will help determine the root cause.\\nDE10569, 7.4.10, Installation Components, In certain circumstances, when the Platform Manager reboots, the Data Processor and Data Indexer are not able to connect to consul\\xa0and logs may not be indexed., Expected Results:The Data Processor and Data Indexer connect to Service Registry after a reboot of the Platform Manager.Workaround:Manually restart the API Gateway and Service Registry services on the Data Indexer and Data Processor after a reboot of\\xa0the Platform Manager.\\nDE10768, 7.4.9, Installation Components, In certain circumstances, the Data Processor runs slowly and the \"\"non-paged pool\"\" uses significant system memory.\\xa0This can cause a large unprocessed logs queue or other backlog in the system., Expected Results:The \"non-paged pool\" should not increase and cause system performance issues.Workaround:Restart the LogRhythm API Gateway service.\\nDE11015, 7.4.10, Installation Components, SQL Database autogrowth settings are too small, causing fragmentation and performance issues., Expected Results:\\xa0Autogrowth increases in larger increments so it does not cause fragmentation.Workaround:Set the autogrowth settings to the following:EMDB: 256 MBEvents: 1 GBAlarms: 256 MBLogMart: 256 MBCMDB: 256 MB\\nDE260, 7.4.7, Installation Components, Job Manager, In certain circumstances, customers may receive an alarm for a missed heartbeat on the AI Engine.\\xa0This can stem from a deadlock on resources in SQL., Expected Results:SQL deadlock issues should not cause a missed heartbeat.Workaround:While there is no\\xa0known workaround, this issue is being actively investigated for a solution.\\nDE9367, 7.4.7, Installation Components, Job Manager, SQL Server deadlocks causing missed heartbeats on AI Engine., Expected Results: Deadlocks should not cause a missed heartbeat alarm.Workaround:While there is no workaround for this issue, LogRhythm is investigating a solution.\\nDE1750, 7.4.6, Installation Components, Web Console, In certain circumstances, the Web Console may show a 500 Error page.\\xa0Typically, this occurs overnight when new service tokens are created for authentication., Expected Results:Authentication services for Web Console should not be interrupted by\\xa0the change to the new tokens.Workaround:Restarting the LogRhythm Authentication API on the Platform Manager mitigates this issue until the next time it occurs.\\nDE1013, 7.4.7, Job Manager, Reports are not completing when a large set of data is required.\\xa0This is due to a limitation within Crystal Reports., Expected Results:The Client Console should provide an alternate way to retrieve the data if Crystal Reports is not able to render it.Workaround:Decrease the amount of data the report is trying to retrieve or export the data instead.\\nDE9995, 7.4.6, Job Manager: Scheduled Reporting, Scheduled reports are sent to a disabled account if an email is attached to the disabled account., Expected Results:Scheduled reports should not be sent to disabled accounts.Workaround:There is currently no workaround for this issue.\\nDE11097, 7.4.9,7.4.10, Job Manager: Scheduled Reporting, When using Gmail SMTP with SSL authentication, the Job Manager fails to send scheduled reports., Expected Results:The Job Manager should able to send scheduled reports using any SMTP server and SSL authentication.Workaround:There is currently no workaround for this issue.\\nDE1879, 2.4, LogRhythm Diagnostics, The LogRhythm Diagnostics Report shows the last backup information incorrectly., Expected Results:The report should show the accurate last backup time for each database.Workaround:Review the backup information in SQL Server Management Studio.\\nDE1113, 7.2.5, Mediator, When the Mediator does agent license enumeration and cache refresh it stops sending heartbeats for few minutes., Expected Results:Cache refresh and License enumeration does not interfere with the heartbeat. We should send heartbeat packets at the required interval.Workaround:There is currently no workaround for this issue.\\nDE1640, 7.3.5, Mediator, The AIE Data Provider service does not start up correctly unless the Mediator service is also stopped and restarted.\\xa0Because logging is inconsistent, users\\xa0may not know that the service has failed to start properly., Expected Results:The AIE Data Provider service should start consistently and as expected. Failures should be consistently logged to alert when the service\\xa0did not start correctly.Workaround:Restart the Mediator service to allow the AIE Data Provider service to start. A more permanent solution to this issue is being evaluated for\\xa0a future release.\\nDE1968, 7.2.5, Mediator, Processing of Archive .bin files is sometimes delayed during heavy load and can back up at the Mediator, filling the hard drive., Expected Results:Archives should process, seal, and move out of the Unprocessed Archives folder as long as the processing rate is at or below the system specification.Workaround:Evaluate system sizing and consider an expansion to meet active load demands. In some systems, increasing the ArchiveSize setting in the Data Processor Advanced Properties to 51200 (from the default value of 10240) can help process archive files faster.\\xa0If necessary, move large files out of the Unprocessed Archives folder to another drive and slowly feed them back in when the system is successfully processing the live data. A more permanent solution to this issue will be provided\\xa0in a future release.\\nDE39, 7.4.5, TrueIdentity Sync Client, The TrueIdentity Sync may fail if attempting to run\\xa0with a large number of users (greater than approximately 10,000)., Expected Results:The TrueIdentity Sync Client should work for any number of users.Workaround:While there is no workaround for this issue, the next release of the Sync Client will be able to support\\xa0larger AD environments.\\nDE5312, 7.4.3, TrueIdentity Sync Client, The OU/DC filter in the TrueIdentity Sync Client does not allow white space., Expected Results:White space should be allowed in the OU/DC filter.Workaround:While there is no workaround for this issue, LogRhythm is\\xa0investigating a resolution for a future release.\\nDE514, 7.4.3, Web Console, When viewing TrueIdentity records in the Web Console, 1,000 records are shown at once. Scrolling past that initial 1,000 records produces the error\\xa0message: \"\"Failed to fetch Identities: Bad Request.\"\", Expected Results:Users should be able to scroll through all TrueIdentity records in the Web Console.Workaround:Using filters to find specific data in the TrueIdentity page prevents the error message from showing and helps find data more quickly. LogRhythm is\\xa0working on a resolution for a future release.\\nDE1198, 7.4.6, Web Console, When downloading large NetMon PCAPs from the Web Console, there may be\\xa0delays\\xa0to the initial\\xa0download,\\xa0increased\\xa0memory usage, or\\xa0timeouts., Expected Results:The Web Console\\xa0should not time out when downloading large PCAP files.Workaround:Change the time out setting in the Configuration Manager.\\nDE1238, 7.4.2, Web Console, When copying a Top X widget to another dashboard, all configuration is lost after saving and refreshing the target dashboard., Expected Results:When copying widgets, all settings should remain.Workaround:Users can add a new widget to the dashboard and configure it manually to work around this issue. This issue is still being actively investigated and will be resolved in a future release.\\nDE1334, 7.3.3, Web Console, Customers who have integrated NetMon into the Web Console\\xa0may encounter a condition where the PCAP has aged out, but the user interface\\xa0indicates that it is still available. Attempting to download the PCAP results in an \"\"unclassified failure\"\" message., Expected Results:When users try to download a PCAP that is no longer available on disk, the error message should provide that detail instead of an unclassified failure.Workaround:The error message will be changed in a future release. There are two simple troubleshooting steps to identify if the PCAP exists or if other issues are occurring in the integration: Log in to NetMon\\xa0directly and verify if the selected PCAP has already aged out or should be available on disk. Recreate the API key for the selected NetMon\\xa0and update the NetMon configuration in the Deployment Manager.\\nDE7263, 7.4.2, Web Console, When exporting the results of an Investigation to .csv\\xa0from the Web Console Analyzer Grid, the date values in the first and last rows are exported as UNIX-formatted large integers rather than simple dates., Expected Results:All data contained in the .csv export should be valid and match the data displayed in the Web Console.Workaround:Export the same investigation from the Client Console or manually adjust the first and last date post export. LogRhythm is investigating a solution to this issue.\\nDE10403, 7.4.9, Web Console, The Web Console Current Processing Rate widget does\\xa0not showing the correct rate.\\xa0It does\\xa0not include messages older than 3 minutes in the rate determined., Expected Results:The Current Processing Rate widget\\xa0shows all logs\\xa0being processed.Workaround:Resolve any log source issues that are causing old logs to be ingested, or use Grafana or Performance Counters to check the current processing rate.\\nDE10442, 7.4.9, Web Console, When viewing NetMon logs in the Web Console using Internet Explorer, the Download PCAP button does not appear., Expected Results:The Download PCAP button appears\\xa0when reviewing NetMon logs.Workaround:Reload the frame with the Download PCAP button to activate it.\\nDE11101, 7.4.10, SmartResponse Plugin, In certain circumstances, a SmartResponse action may fail to execute with an error: \"No System Monitor Associated with execution target.\", Expected Results:The SmartResponse Plugin should execute after selecting the System Monitor Agent.Workaround:There is currently no workaround for this issue.\\nDE11398, 7.5.1, Web Console: Other, When running a Vulnerability Scanner, you may see an issue stating \"HSTS is missing from the HTTPS Server.\", Expected Results:The remote web server should be enforcing HSTS.Workaround:Configure the remote web server to use HSTS.\\nDE11463, 7.6.0, Web Console, When the browser window is zoomed out, the Node-Link Graph on the Web Console dashboards may display an error: \"Failed to establish logs subscription with the Web Console API.\" This is not related to the zoom functionality within the Node-Link Graph itself., Expected Results:The Node-Link Graph should function regardless of the browser zoom level.Workaround:Return the browser to 100% zoom and refresh the Web Console.\\nDE11123, 7.4.9, Web Console, Occasionally in multiple Web Console environments, AIE Drilldown does\\xa0not export results or show data in the filters., Expected Results:Drilldowns should always allow export of results and filters should always have data.Workaround:Use the Client Console to drill down and export results.\\nDE11124, 7.4.9, 7.5.0, Web Console, When\\xa0SSL Port In Redirects is set to Exclude\\xa0in the Web Console configuration, links in Alarm and Case notification emails do not work., Expected Results:The links sent in Case and Alarm notification emails should redirect to port 443 instead of 8443, as they are coming from an external location.Workaround:Open the Web Console and manually find the Alarm or Case to review.\\nDE11316, 7.4.10, Job Manager, Scheduled reports that do not complete within an hour return only partial results without indication of additional results available., Expected Results:The Job Manager should generate a message stating that the results were not complete and the report should indicate partial results.Workaround:There is currently no workaround for this issue.\\nDE11663, 7.6.0, Web Console, When clicking Case Evidence logs from the Case page, the Analyze window shows a Custom Filter that prevents the logs from displaying., Expected Results:Clicking Case Evidence logs should open an Analyze page showing the logs selected.Workaround:To show the logs, click theXnext to the Custom Filter.\\nDE11710, 7.4.8, Admin API, If FIPS and Integrated Security are enabled in a Disaster Recovery (DR) environment, the Admin API errors during startup because of\\xa0a failure to connect to SQL during failover., Expected Results:The Admin API should connect to SQL during failover.Workaround:Manually change the Global IP to the Management IP.\\xa0This may need to be done after each upgrade.\\nDE11733, 7.6.0, Installation Components, When running the LogRhythm Infrastructure Installer (LRII), you may receive the\\xa0error: \"No plan file found in LogRhythm Service Registry KV store.\"\\xa0This is caused by the plan file not fully updating into the Consul KV store, and only happens in certain environments., Expected Results:LRII\\xa0should be able to run multiple times without affecting the plan file.Workaround:For assistance with this issue, contact LogRhythm Technical Support.\\nDE11765, 7.5.1, Data Indexer, In certain circumstances, Elasticsearch uses more memory than the set limit, causing performance issues on the server., Expected Results:Elasticsearch should abide by the memory limit that is set.Workaround:For a workaround, contact LogRhythm Technical Support.\\nDE11775, 7.6.0, Data Indexer, Searches and drilldowns using Location lists do not return results., Expected Results:Search results should return if using a Location list.Workaround:Clone the original rule and replace the Location list with manual entries for the countries in Location (Origin).\\nDE11792, 7.5.0, Job Manager, After the Active Directory Sync, some Active Directory users may be disabled., Expected Results:Only users who are disabled in Active Directory should be disabled within LogRhythm.Workaround:Manually re-enable users by logging in to the Console as a Global Administrator or LogRhythm Admin user.\\nDE11929, 7.6.0, Web Console, When using a Direction filter in the Web Console dashboard and\\xa0drilling into any of the TopX widgets, the data shown in the Analyzer Grid contains logs that do not match the dashboard filter., Expected Results:Drilling into data on a dashboard should not change the dashboard filter criteria.Workaround:Reapply the dashboard filter.\\nDE11934, 7.6.0, Data Indexer, In certain circumstances, customers with warm node indices may experience failed searches against those\\xa0indices.\\xa0This is due to Columbo being unable to close certain warm indices., Expected Results:Columbo should handle the warm node indices correctly and allow searches.Workaround:For assistance with this workaround, contact LogRhythm Technical Support.\\nDE12188, 7.6.0, LR Metrics, When viewing the Metrics dashboard in Grafana, the Memory Used Percentage widget in the LR Metrics - Deployment View dashboard shows incorrect results for timeframes greater than three hours., Expected Results:The aggregator in the widget query should use an average calculation instead of a sum calculation.Workaround:For assistance with this workaround, seethis knowledge article on the LogRhythm Community.\\nDE6244, 7.4.5, Alarms, In certain circumstances, an Alarm does not associate\\xa0with a\\xa0SmartResponse Plugin\\xa0and does\\xa0not run\\xa0the SmartResponse Plugin., Expected Results:The SmartResponse Plugin should be triggered by any Alarm meeting the criteria.Workaround:There is currently no workaround for this issue.\\nExpected Results:\\nAIE Rules should not fire if the rule block relationship is not met.\\nWorkaround:\\nChange the Host (origin) or Host (impacted) fields to IP Address, and the AIE Rule works as expected.\\nExpected Results:\\nAIE Summary Fields should be displayed on all AIE Notification emails.\\nWorkaround:\\nView the AIE Summary Fields in the Alarm instead of the Notification email.\\nExpected Results:\\nAIE Rule Blocks should fire when they are triggered at the same time.\\nWorkaround:\\nAs the behavior of simultaneous events is unpredictable\\xa0and the use case for a 0-time interval is rare, LogRhythm does not plan to change this behavior at this time. To avoid the issue, set the evaluation period to 1 second.\\nExpected Results:\\nThese errors should not be reported in the AIE Engine log, but AIE\\xa0is\\xa0working\\xa0and\\xa0alarms\\xa0are\\xa0firing.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nExpected Results:\\nPoorly written AIE Rules should be suspended until they are altered and re-enabled.\\nWorkaround:\\nRewrite the AIE Rule for\\xa0better performance.\\xa0Often, this involves adding filters, reducing log sources, and\\xa0modifying the logic. Tuning an AIE Rule requires expertise, so contact LogRhythm Training, Professional Services, or a Sales Engineer to assist if necessary. Additional solutions to identify and monitor poorly performing rules are being developed for a\\xa0future release.\\nExpected Results:\\nAIE Rules fire as expected.\\nWorkaround:\\nThere is no workaround at this time. LogRhythm is actively investigating the issue for a future release.\\nExpected Results:\\nAlarms do\\xa0not fire if a log is received for a Not Observed block.\\nWorkaround:\\nThere is no workaround at this time. LogRhythm is investigating this issue for a future release.\\nExpected Results:\\nThese logs should be automatically purged after 7 days as defined.\\nWorkaround:\\nSort by log date and delete all older logs.\\nExpected Results:\\nAlarms should execute quickly as expected with other AIE Alarms.\\nWorkaround:\\nThere is currently no workaround for this issue.\\n7.4.9,\\n7.4.10\\nExpected Results:\\nThe Alarming and Response Manager should able to send alarm notifications using any SMTP server and SSL authentication.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nExpected Results:\\nCase API and Admin API should start when using any size certificate.\\nWorkaround:\\nRemove\\xa0the\\xa0server\\xa0from\\xa0the\\xa0domain and reboot it.\\xa0Verify that the\\xa0512-bit\\xa0certificate has\\xa0been\\xa0removed, re-run the installers, and reboot. To\\xa0avoid\\xa0this issue, do not join the domain\\xa0again\\xa0or\\xa0the\\xa0certificate will\\xa0be\\xa0pushed\\xa0out\\xa0again.\\xa0In addition, create a new certificate that\\xa0uses a 384-bit (or less) hash or exclude the impacted system from the GPO that pushes\\xa0the\\xa0certificate.\\nExpected Results:\\nThe extra semicolon, which is an optional valid separator in a content-type header, should not prevent scripts from working upon upgrade.\\nWorkaround:\\nThere is no workaround for this issue at this time. A solution is being investigated for a future release.\\nExpected Results:\\nThe processing of a log should be the same whether it is parsed in Rule Builder or MPE.\\nWorkaround:\\nChange the sub-rule to use a different tag, such as <Tag1>.\\xa0If you are experiencing this issue, ensure that you are not using a custom Log Processing Policy and that there are no MPE timeouts.\\xa0If issues persist, contact Technical Support and reference this bug number\\xa0(DE1829) or its sister defect\\xa0(DE1651).\\nExpected Results:\\nWhen a search times out, a message should inform users and instruct them\\xa0to re-run the search with a longer timeout.\\nWorkaround:\\nIncrease the timeout on the query and re-run it.\\nExpected Results:\\nDisabling Log Source Virtualization should not change the behavior of the System Monitor.\\nWorkaround:\\nThis issue is caused by the scsm.ini file not being updated immediately.\\xa0To work around it, refresh the Log Sources tab in the Client Console to\\xa0force the .ini file to refresh.\\nExpected Results:\\nIdentity data appears\\xa0in reports that contain those fields.\\nWorkaround:\\nRun an investigation to provide the same information.\\nExpected Results:\\nAll chosen fields should appear\\xa0on the report if they contain data.\\nWorkaround:\\nRunning the report as an investigation yields the expected results in the Network (Impacted) column. LogRhythm is\\xa0actively working on a solution to this issue in\\xa0a future release.\\nExpected Results:\\nWhen exporting reports in .csv format, the column headers should not be repeated on each row.\\nWorkaround:\\nThe report needs to be formatted to remove columns that show the column headers. In addition, LogRhythm data can be exported using Log Distribution Services (LDS).\\nExpected Results:\\nEntities\\xa0should be retireable\\xa0and able to be hidden from view.\\nWorkaround:\\nContact Technical Support to assist you in removing entities that are no longer needed.\\nExpected Results:\\nWhen editing a report template, existing fields should remain unless they are explicitly removed.\\nWorkaround:\\nWhen editing a report template that contains the Normal Date field, add that field back to the template prior to saving it.\\nExpected Results:\\nThe Configuration Manager should load immediately and show the services in the correct state.\\nWorkaround:\\nThe Configuration Manager will eventually load if given a little time.\\xa0 When the services show down, a refresh of the Configuration Manager should show them correctly.\\xa0 We are working on a resolution to this issue.\\nExpected Results:\\nThe Diagnostic logs should be tuned to alarm less frequently.\\nWorkaround:\\nThere is no workaround for this issue at this time.\\nExpected Results:\\nAlarms should continue to trigger and be displayed in the Web Console.\\nWorkaround:\\nContact Technical Support for assistance, as there could be many reasons for this behavior beyond this defect.\\xa0Support will help determine the root cause.\\nExpected Results:\\nThe Data Processor and Data Indexer connect to Service Registry after a reboot of the Platform Manager.\\nWorkaround:\\nManually restart the API Gateway and Service Registry services on the Data Indexer and Data Processor after a reboot of\\xa0the Platform Manager.\\nExpected Results:\\nThe \"non-paged pool\" should not increase and cause system performance issues.\\nWorkaround:\\nRestart the LogRhythm API Gateway service.\\nExpected Results:\\xa0Autogrowth increases in larger increments so it does not cause fragmentation.\\nWorkaround:\\nSet the autogrowth settings to the following:\\nEMDB: 256 MB\\nEvents: 1 GB\\nAlarms: 256 MB\\nLogMart: 256 MB\\nCMDB: 256 MB\\nExpected Results:\\nSQL deadlock issues should not cause a missed heartbeat.\\nWorkaround:\\nWhile there is no\\xa0known workaround, this issue is being actively investigated for a solution.\\nExpected Results: Deadlocks should not cause a missed heartbeat alarm.\\nWorkaround:\\nWhile there is no workaround for this issue, LogRhythm is investigating a solution.\\nExpected Results:\\nAuthentication services for Web Console should not be interrupted by\\xa0the change to the new tokens.\\nWorkaround:\\nRestarting the LogRhythm Authentication API on the Platform Manager mitigates this issue until the next time it occurs.\\nExpected Results:\\nThe Client Console should provide an alternate way to retrieve the data if Crystal Reports is not able to render it.\\nWorkaround:\\nDecrease the amount of data the report is trying to retrieve or export the data instead.\\nExpected Results:\\nScheduled reports should not be sent to disabled accounts.\\nWorkaround:\\nThere is currently no workaround for this issue.\\n7.4.9,\\n7.4.10\\nExpected Results:\\nThe Job Manager should able to send scheduled reports using any SMTP server and SSL authentication.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nExpected Results:\\nThe report should show the accurate last backup time for each database.\\nWorkaround:\\nReview the backup information in SQL Server Management Studio.\\nExpected Results:\\nCache refresh and License enumeration does not interfere with the heartbeat. We should send heartbeat packets at the required interval.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nExpected Results:\\nThe AIE Data Provider service should start consistently and as expected. Failures should be consistently logged to alert when the service\\xa0did not start correctly.\\nWorkaround:\\nRestart the Mediator service to allow the AIE Data Provider service to start. A more permanent solution to this issue is being evaluated for\\xa0a future release.\\nExpected Results:\\nArchives should process, seal, and move out of the Unprocessed Archives folder as long as the processing rate is at or below the system specification.\\nWorkaround:\\nEvaluate system sizing and consider an expansion to meet active load demands. In some systems, increasing the ArchiveSize setting in the Data Processor Advanced Properties to 51200 (from the default value of 10240) can help process archive files faster.\\xa0If necessary, move large files out of the Unprocessed Archives folder to another drive and slowly feed them back in when the system is successfully processing the live data. A more permanent solution to this issue will be provided\\xa0in a future release.\\nExpected Results:\\nThe TrueIdentity Sync Client should work for any number of users.\\nWorkaround:\\nWhile there is no workaround for this issue, the next release of the Sync Client will be able to support\\xa0larger AD environments.\\nExpected Results:\\nWhite space should be allowed in the OU/DC filter.\\nWorkaround:\\nWhile there is no workaround for this issue, LogRhythm is\\xa0investigating a resolution for a future release.\\nExpected Results:\\nUsers should be able to scroll through all TrueIdentity records in the Web Console.\\nWorkaround:\\nUsing filters to find specific data in the TrueIdentity page prevents the error message from showing and helps find data more quickly. LogRhythm is\\xa0working on a resolution for a future release.\\nExpected Results:\\nThe Web Console\\xa0should not time out when downloading large PCAP files.\\nWorkaround:\\nChange the time out setting in the Configuration Manager.\\nExpected Results:\\nWhen copying widgets, all settings should remain.\\nWorkaround:\\nUsers can add a new widget to the dashboard and configure it manually to work around this issue. This issue is still being actively investigated and will be resolved in a future release.\\nExpected Results:\\nWhen users try to download a PCAP that is no longer available on disk, the error message should provide that detail instead of an unclassified failure.\\nWorkaround:\\nThe error message will be changed in a future release. There are two simple troubleshooting steps to identify if the PCAP exists or if other issues are occurring in the integration: Log in to NetMon\\xa0directly and verify if the selected PCAP has already aged out or should be available on disk. Recreate the API key for the selected NetMon\\xa0and update the NetMon configuration in the Deployment Manager.\\nExpected Results:\\nAll data contained in the .csv export should be valid and match the data displayed in the Web Console.\\nWorkaround:\\nExport the same investigation from the Client Console or manually adjust the first and last date post export. LogRhythm is investigating a solution to this issue.\\nExpected Results:\\nThe Current Processing Rate widget\\xa0shows all logs\\xa0being processed.\\nWorkaround:\\nResolve any log source issues that are causing old logs to be ingested, or use Grafana or Performance Counters to check the current processing rate.\\nExpected Results:\\nThe Download PCAP button appears\\xa0when reviewing NetMon logs.\\nWorkaround:\\nReload the frame with the Download PCAP button to activate it.\\nIn certain circumstances, a SmartResponse action may fail to execute with an error: \"No System Monitor Associated with execution target.\"\\nExpected Results:\\nThe SmartResponse Plugin should execute after selecting the System Monitor Agent.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nExpected Results:\\nThe remote web server should be enforcing HSTS.\\nWorkaround:\\nConfigure the remote web server to use HSTS.\\nWhen the browser window is zoomed out, the Node-Link Graph on the Web Console dashboards may display an error: \"Failed to establish logs subscription with the Web Console API.\" This is not related to the zoom functionality within the Node-Link Graph itself.\\nExpected Results:\\nThe Node-Link Graph should function regardless of the browser zoom level.\\nWorkaround:\\nReturn the browser to 100% zoom and refresh the Web Console.\\nOccasionally in multiple Web Console environments, AIE Drilldown does\\xa0not export results or show data in the filters.\\nExpected Results:\\nDrilldowns should always allow export of results and filters should always have data.\\nWorkaround:\\nUse the Client Console to drill down and export results.\\nWhen\\xa0SSL Port In Redirects is set to Exclude\\xa0in the Web Console configuration, links in Alarm and Case notification emails do not work.\\nExpected Results:\\nThe links sent in Case and Alarm notification emails should redirect to port 443 instead of 8443, as they are coming from an external location.\\nWorkaround:\\nOpen the Web Console and manually find the Alarm or Case to review.\\nScheduled reports that do not complete within an hour return only partial results without indication of additional results available.\\nExpected Results:\\nThe Job Manager should generate a message stating that the results were not complete and the report should indicate partial results.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nWhen clicking Case Evidence logs from the Case page, the Analyze window shows a Custom Filter that prevents the logs from displaying.\\nExpected Results:\\nClicking Case Evidence logs should open an Analyze page showing the logs selected.\\nWorkaround:\\nTo show the logs, click the\\nX\\nnext to the Custom Filter.\\nIf FIPS and Integrated Security are enabled in a Disaster Recovery (DR) environment, the Admin API errors during startup because of\\xa0a failure to connect to SQL during failover.\\nExpected Results:\\nThe Admin API should connect to SQL during failover.\\nWorkaround:\\nManually change the Global IP to the Management IP.\\xa0This may need to be done after each upgrade.\\nWhen running the LogRhythm Infrastructure Installer (LRII), you may receive the\\xa0error: \"No plan file found in LogRhythm Service Registry KV store.\"\\xa0This is caused by the plan file not fully updating into the Consul KV store, and only happens in certain environments.\\nExpected Results:\\nLRII\\xa0should be able to run multiple times without affecting the plan file.\\nWorkaround:\\nFor assistance with this issue, contact LogRhythm Technical Support.\\nIn certain circumstances, Elasticsearch uses more memory than the set limit, causing performance issues on the server.\\nExpected Results:\\nElasticsearch should abide by the memory limit that is set.\\nWorkaround:\\nFor a workaround, contact LogRhythm Technical Support.\\nSearches and drilldowns using Location lists do not return results.\\nExpected Results:\\nSearch results should return if using a Location list.\\nWorkaround:\\nClone the original rule and replace the Location list with manual entries for the countries in Location (Origin).\\nAfter the Active Directory Sync, some Active Directory users may be disabled.\\nExpected Results:\\nOnly users who are disabled in Active Directory should be disabled within LogRhythm.\\nWorkaround:\\nManually re-enable users by logging in to the Console as a Global Administrator or LogRhythm Admin user.\\nWhen using a Direction filter in the Web Console dashboard and\\xa0drilling into any of the TopX widgets, the data shown in the Analyzer Grid contains logs that do not match the dashboard filter.\\nExpected Results:\\nDrilling into data on a dashboard should not change the dashboard filter criteria.\\nWorkaround:\\nReapply the dashboard filter.\\nIn certain circumstances, customers with warm node indices may experience failed searches against those\\xa0indices.\\xa0This is due to Columbo being unable to close certain warm indices.\\nExpected Results:\\nColumbo should handle the warm node indices correctly and allow searches.\\nWorkaround:\\nFor assistance with this workaround, contact LogRhythm Technical Support.\\nWhen viewing the Metrics dashboard in Grafana, the Memory Used Percentage widget in the LR Metrics - Deployment View dashboard shows incorrect results for timeframes greater than three hours.\\nExpected Results:\\nThe aggregator in the widget query should use an average calculation instead of a sum calculation.\\nWorkaround:\\nFor assistance with this workaround, see\\nthis knowledge article on the LogRhythm Community\\n.\\nIn certain circumstances, an Alarm does not associate\\xa0with a\\xa0SmartResponse Plugin\\xa0and does\\xa0not run\\xa0the SmartResponse Plugin.\\nExpected Results:\\nThe SmartResponse Plugin should be triggered by any Alarm meeting the criteria.\\nWorkaround:\\nThere is currently no workaround for this issue.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.8.0 GA Release Notes': 'System Monitor v7.7.0.8001 (Windows) is incompatible with SIEM v7.8.0x.\\nIf any of your Windows System Monitors are running v7.7.0.8001, you must upgrade them to v7.7.0.8002 (Windows) before upgrading to SIEM v7.8.0x.\\nNo action is required for *NIX System Monitors.\\n', 'New Features': 'No new features in this release.\\n', 'Improvements': 'The Lucene Filters in the Web Console Dashboards have been updated to be more intuitive, allowing the filtering experience to flow better.\\nThere are two Data Indexer updates to the Core SIEM for 7.8.0: added the Cluster Name field to the Configuration Manager and upgraded to Elasticsearch 6.8.15.\\nThe DB upgrade Version Check was updated for 7.8.0 to include\\xa0newly supported upgrade paths and license check. We are still allowing upgrades to 7.8.0 from anything 7.4.0 and above.\\nThe LogRhythm Diagnostics Tool was added directly\\nto the Install Wizard for 7.8.0\\n.\\n', 'Deprecated Features': 'LogRhythm 7.8 is the last published version of the SOAP API. LogRhythm is deprecating the SOAP API in favor of more usable and sustainable integration through RESTful APIs. We encourage customers and partners using the SOAP API to migrate their integrations to REST APIs. For more information on REST integration, see our\\nREST API\\ndocumentation.\\nRemoved DPX configuration option from Install Wizard.\\nRemoved DPX configuration option from Install Wizard.\\n', 'Resolved Issues': 'Bug #, Ticket #, Component, Description\\nDE11524, 402744, 406709, 409024, 410746, 408863, 418912, Admin API, In LRCloud deployments, the Admin API service no longer generates multiple errors, requiring users to restart the service.\\nDE12339, 419586, Alarm API, When queried for alarm status, the Alarm API returns alarm information without a permissions error.\\nDE12421, 417343, Alarm API, When queried for alarm status, the Alarm API returns alarm information without a permissions error.\\nDE10734, 373469, Client Console, Windows 2019 now displays as an operating system option in drop-down lists in the Windows Host Wizard.\\nDE10950, 390999, Client Console, When a user selects Threat ID as the Alarm Field value in an SRP action, it no longer changes from Threat ID to Status after saving and reopening the AIE Rule.\\nDE11642, 401747, Client Console, The LR Console Deployment Manager no longer generates an error when users edit multiple host records at once.\\nDE11716, 400715, 415258, Client Console, When bad entries exist in a list, a message appears to inform users of the issue and prompts them on actions to take.\\nDE12401, 409328, 409475, 420050, Client Console, Drop Raw Log now works with Log Source Virtualization.\\nDE12000, 404861, 418775, Client Console, Mediator, Syslog log sources now have identifiers that match those selected in their Virtualization Settings.\\nDE12220, 407156,408428, 411257, 411368, 414907, Client Console, When data is present, searches and alarm drill downs that use a list with a single Active Directory group now return results.Some customers experienced this issue after upgrading to 7.6.0.\\nDE10377, 379943, Data Indexer, The Carpenter service can now connect to SQL in non-FIPS mode.\\nDE11721, 403754, 403646, 412909, Data Indexer, The upgrade checker now correctly sets DX_ES_PATH_DATA when the DXCONFIGPATH environment variable was not set to Default.\\nDE11775, 403785,408263,409286, 412636,415355,416202,417551,418019,421415,421849, 422382, 422858, Data Indexer, Searches and drill downs that use Location lists now return results.\\nDE12067, 407950, 407950, 408347, 409530, 409657, 410081, 419332, Data Indexer, Transporter now fully starts after automatic restart at five minutes past midnight UTC.\\nDE12139, 405286,408265,411827, 418019, 422222, Data Indexer, AIE Drill Downs now work when rules contain lists.\\nDE12335, 410639, Data Indexer, During service startup on XM8xxx appliances, the SetValuesForES.bat now sets the Elasticsearch heap to 30GB.\\nDE12960, 413300, 418019, Data Indexer, Host list searches now return results.\\nDE12692, 416829, HA Upgrade, The HA PostUpgrade.ps1 script no longer fails to start services.\\nDE12026, 405685, Infrastructure: Data Management, When running investigations on the Data Processor, the Parent Process Id field now displays values up to 38 characters long.\\nDE11896, 411653, 415039, Infrastructure: Database Scripts and Upgrade Scripts, The SQL backup job now backs up the database transaction log.\\nDE11708, 403114, Infrastructure: Database Upgrade Tool, An upgrade no longer fails after an SA user is renamed or deleted.\\nDE12560, 408878, Linux Agent, Linux Agent now collects logs from log source type Syslog - Palo Alto Firewall.\\nDE12800, 408245, 408878, 416933, 417576, Linux Agent, When using Log Source Virtualization, the Linux Agent now splits the logs to a child log source and its parent log source.\\nDE12508, 412243, Mediator, When a log decompression error occurs in the Mediator, scmedsvr logs now include references to Agent ID and Agent Type (Windows or Linux) to facilitate troubleshooting.\\nDE12557, 414739, Mediator, MPE startup is no longer delayed when loading a large number of identities.\\nDE12298, 409381, Search API, Pagination in the LogRhythm Search API now functions as expected.\\nDE12689, 417343, Search API, The Search API redoc now includes the QueryLogSources,QueryEventManager and LogSourceIds fields.\\nDE12200, 405409, Web Console, When a restricted analyst performs a search or investigation in the Web Console, host and entity data are now masked.\\n402744, 406709, 409024, 410746, 408863, 418912\\nWhen data is present, searches and alarm drill downs that use a list with a single Active Directory group now return results.\\nSome customers experienced this issue after upgrading to 7.6.0.\\n407950, 407950, 408347, 409530, 409657, 410081, 419332\\n', 'Known Issues': \"The following issues have each been found and reported by multiple users.\\nBug #, Found In Version, Components, Description, Release Notes\\nDE1879, 2.4, LogRhythm Diagnostics Tool, The LogRhythm Diagnostics Report shows the last backup information incorrectly., Expected Results:\\xa0The report should show the accurate last backup time for each database.Workaround:\\xa0Review the backup information in SQL Server Management Studio.\\nDE10867, 1.2.0.10, TrueIdentity Sync Client, The TrueIdentity Sync Client will not connect to the Microsoft Active Directory LDAP server on port 636 using LDAP., Expected Results: The TrueIdentity Sync Client should be able to connect using LDAP via port 636.Workaround: Use port 389 instead and ensure the proper certificates are in place for security.\\nDE7632, 7.1.3, Client Console, Entities cannot be deleted from within the Client Console., Expected Results: Entities\\xa0should be retireable\\xa0and able to be hidden from view.Workaround: Contact Technical Support to assist you in removing entities that are no longer needed.\\nDE7612, 7.1.7, Client Console, Reports exported to .csv format are not formatted correctly. The headers are duplicated in each row as name/value pairs., Expected Results:\\xa0When exporting reports in .csv format, the column headers should not be repeated on each row.Workaround:\\xa0The report needs to be formatted to remove columns that show the column headers. In addition, LogRhythm data can be exported using Log Distribution Services (LDS).\\nDE1968, 7.2.5, Mediator, Processing of Archive .bin files is sometimes delayed during heavy load and can back up at the Mediator, filling the hard drive., Expected Results:\\xa0Archives should process, seal, and move out of the Unprocessed Archives folder as long as the processing rate is at or below the system specification.Workaround:\\xa0Evaluate system sizing and consider an expansion to meet active load demands. In some systems, increasing the ArchiveSize setting in the Data Processor Advanced Properties to 51200 (from the default value of 10240) can help process archive files faster.\\xa0If necessary, move large files out of the Unprocessed Archives folder to another drive and slowly feed them back in when the system is successfully processing the live data. A more permanent solution to this issue will be provided\\xa0in a future release.\\nDE1113, 7.2.5, Mediator, When the Mediator service is busy enumerating the\\xa0agent licenses, the Data Processor heartbeat may be delayed., Expected Results:\\xa0 When the Mediator is handling agent licenses, the heartbeat packet should still be sent so the system shows it is healthy.Workaround:There is currently no workaround for this issue.\\nDE3385, 7.3.2, Data Indexer, The DX Diagnostic logs are firing too often., Expected Results:The Diagnostic logs should be tuned to alarm less frequently.Workaround:There is currently no workaround for this issue.\\nDE1871, 7.3.3, AI Engine, Under conditions of load, AI Engine Rules that are written incorrectly can cause significant issues throughout the entire AIE\\xa0server., Expected Results:\\xa0Poorly written AIE Rules should be suspended until they are altered and re-enabled.Workaround:\\xa0Rewrite the AIE Rule for\\xa0better performance.\\xa0Often, this involves adding filters, reducing log sources, and\\xa0modifying the logic. Tuning an AIE Rule requires expertise, so contact LogRhythm Training, Professional Services, or a Sales Engineer to assist if necessary. Additional solutions to identify and monitor poorly performing rules are being developed for a\\xa0future release.\\nDE1829, 7.3.3, Client Console, There may be inconsistencies in the way a log parses through MPE processing and within the MPE Rule Builder. A log that parses without issue in the Rule Builder may not parse when run through MPE processing.\\xa0This could be caused by rule match timeouts., Expected Results: The processing of a log should be the same whether it is parsed in Rule Builder or MPE.Workaround: Change the sub-rule to use a different tag, such as <Tag1>.\\xa0If you are experiencing this issue, ensure that you are not using a custom Log Processing Policy and that there are no MPE timeouts.\\xa0If issues persist, contact Technical Support and reference this bug number\\xa0(DE1829) or its sister defect\\xa0(DE1651).\\nDE1334, 7.3.3, Web Console, Customers who have integrated NetMon into the Web Console\\xa0may encounter a condition where the PCAP has aged out, but the user interface\\xa0indicates that it is still available. Attempting to download the PCAP results in an unclassified failure message., Expected Results:\\xa0When users try to download a PCAP that is no longer available on disk, the error message should provide that detail instead of an unclassified failure.Workaround:\\xa0The error message will be changed in a future release. There are two simple troubleshooting steps to identify if the PCAP exists or if other issues are occurring in the integration: Log in to NetMon\\xa0directly and verify if the selected PCAP has already aged out or should be available on disk. Recreate the API key for the selected NetMon\\xa0and update the NetMon configuration in the Deployment Manager.\\nDE6072, 7.3.4, APIs, When using a 512-bit RSA-signed certificate, Case API and Admin API do not start due to an incomplete\\xa0implementation of TLS 1.2.\\xa0This typically happens when a GPO pushes the certificate to the server., Expected Results: Case API and Admin API should start when using any size certificate.Workaround:\\xa0Remove\\xa0the\\xa0server\\xa0from\\xa0the\\xa0domain and reboot it.\\xa0Verify that the\\xa0512-bit\\xa0certificate has\\xa0been\\xa0removed, re-run the installers, and reboot. To\\xa0avoid\\xa0this issue, do not join the domain\\xa0again\\xa0or\\xa0the\\xa0certificate will\\xa0be\\xa0pushed\\xa0out\\xa0again.\\xa0In addition, create a new certificate that\\xa0uses a 384-bit (or less) hash or exclude the impacted system from the GPO that pushes\\xa0the\\xa0certificate.\\nDE1759, 7.3.4, AI Engine, When the AIE service starts up, errors\\xa0are\\xa0generated multiple\\xa0times\\xa0in\\xa0the\\xa0AIE\\xa0Engine\\xa0log., Expected Results:\\xa0These errors should not be generated in the AIE Engine log, but AIE\\xa0is\\xa0working\\xa0and\\xa0alarms\\xa0are\\xa0firing.Workaround:\\xa0There is currently no workaround for this issue.\\nDE3195, 7.3.4, Client Console, When running a search in either the Client or Web Console, users see an error: Error fetching data - Gateway timeout., Expected Results:\\xa0When a search times out, a message should inform users and instruct them\\xa0to re-run the search with a longer timeout.Workaround:\\xa0Increase the timeout on the query and re-run it.\\nDE5185, 7.3.4, Client Console, The Network (Impacted) field does not display on reports where it is included as a column, even though data appears in that field., Expected Results:\\xa0All chosen fields should appear\\xa0on the report if they contain data.Workaround:\\xa0Running the report as an investigation yields the expected results in the Network (Impacted) column. LogRhythm is\\xa0actively working on a solution to this issue in\\xa0a future release.\\nDE1606, 7.3.5, AI Engine, When an AIE Rule with two rule blocks has an evaluation period of 0 seconds, the rule does not trigger\\xa0as expected., Expected Results:\\xa0AIE Rule Blocks should fire when they are triggered at the same time.Workaround:\\xa0As the behavior of simultaneous events is unpredictable\\xa0and the use case for a 0-time interval is rare, LogRhythm does not plan to change this behavior at this time. To avoid the issue, set the evaluation period to 1 second.\\nDE1640, 7.3.5, Mediator, The AIE Data Provider service does not start up correctly unless the Mediator service is also stopped and restarted.\\xa0Because logging is inconsistent, users\\xa0may not know that the service has failed to start properly., Expected Results:\\xa0The AIE Data Provider service should start consistently and as expected. Failures should be consistently logged to alert when the service\\xa0did not start correctly.Workaround:\\xa0Restart the Mediator service to allow the AIE Data Provider service to start. A more permanent solution to this issue is being evaluated for\\xa0a future release.\\nDE10937, 7.4.10, Alarming, If an SRP is retired, the Alarming and Response Manager (ARM) does not recognize this and could cause the C: drive to fill\\xa0with errors trying to execute the SRP if the logging level on the ARM is set high., Expected Results: The Alarming and Response Manager should be aware of a change of status of the SRPs and should not continue to attempt to execute them.Workaround: Lower the logging level on the ARM to help mitigate this, but contact LogRhythm Technical Support if assistance is needed to retire the SRP.\\nDE10569, 7.4.10, Common Components, In certain circumstances, when the Platform Manager reboots, the Data Processor and Data Indexer are not able to connect to consul\\xa0and logs may not be indexed., Expected Results: The Data Processor and Data Indexer should connect to Service Registry after a reboot of the Platform Manager.Workaround: Manually restart the API Gateway and Service Registry services on the Data Indexer and Data Processor after a reboot of\\xa0the Platform Manager.\\nDE11798, 7.4.10, Client Console, When exporting a large number of logs using the Send all Logs option from the Log Viewer in Client Console, the Console freezes., Expected Results: The Console should not freeze when exporting logs.Workaround: Export selected logs instead of all logs to allow the export to complete.\\nDE11015, 7.4.10, Installation Components, SQL Database autogrowth settings are too small, causing fragmentation and performance issues., Expected Results:\\xa0Autogrowth should increase in larger increments so it does not cause fragmentation.Workaround:\\xa0Set the autogrowth settings to the following:EMDB: 256 MBEvents: 1 GBAlarms: 256 MBLogMart: 256 MBCMDB: 256 MB\\nDE11316, 7.4.10, Job Manager, Scheduled reports that do not complete within an hour return only partial results without indication of additional results available., Expected Results: The Job Manager should generate a message stating that the results were not complete and the report should indicate partial results.Workaround: There is currently no workaround for this issue.\\nDE11701, 7.4.10, Job Manager, When exporting reports as .csv files, there are duplications of headers and footers that cause the report to be much larger in size than when run in the Console., Expected Results: Exported reports should not duplicate header and footer lines.Workaround: Export the report in another format or remove the extra lines from the .csv.\\nDE11101, 7.4.10, Smart Response Plugin, In certain circumstances, a SmartResponse action may fail to execute with an error: No System Monitor Associated with execution target., Expected Results:\\xa0 The SmartResponse Plugin should execute after selecting the System Monitor Agent.Workaround:There is currently no workaround for this issue.\\nDE13301, 7.4.10, Mediator, In certain circumstances when\\xa0Entity Archive settings are turned on, customers may receive the following error:**ERROR** Failed to locate or create inactive subdirectory: The given key was not present in the dictionary.. Inactive archive files will be temporarily stored at the root of the system drive (C:\\\\ in most cases). This error must be corrected in order for inactive archives to be stored at the specified location., Expected Results: Entity archiving should function without errors.Workaround: There is currently no workaround for this issue.\\nDE7263, 7.4.2, Web Console, When exporting the results of an Investigation to .csv\\xa0from the Web Console Analyzer Grid, the date values in the first and last rows are exported as UNIX-formatted large integers rather than simple dates., Expected Results:\\xa0All data contained in the .csv export should be valid and match the data displayed in the Web Console.Workaround:\\xa0Export the same investigation from the Client Console or manually adjust the first and last date post export. LogRhythm is investigating a solution to this issue.\\nDE1238, 7.4.2, Web Console, When copying a Top X widget to another dashboard, all configuration is lost after saving and refreshing the target dashboard., Expected Results:\\xa0When copying widgets, all settings should remain.Workaround:\\xa0Users can add a new widget to the dashboard and configure it manually to work around this issue. This issue is still being actively investigated and will be resolved in a future release.\\nDE1324, 7.4.3, AI Engine, In certain circumstances, there may be a discrepancy between the AIE event date/time and\\xa0the date/time of the message(s) triggering the AIE rule, causing the AIE event to show a future date/time., Expected Results: The date and time of the AIE Event should not have a future time.Workaround: There is no workaround for this issue.\\nDE5312, 7.4.3, TrueIdentity Sync Client, The OU/DC filter in the TrueIdentity Sync Client does not allow white space., Expected Results: White space should be allowed in the OU/DC filter.Workaround: While there is no workaround for this issue, LogRhythm is\\xa0investigating a resolution for a future release.\\nDE514, 7.4.3, Web Console, When viewing TrueIdentity records in the Web Console, 1,000 records are shown at once. Scrolling past that initial 1,000 records produces the error\\xa0message: Failed to fetch Identities: Bad Request., Expected Results:\\xa0Users should be able to scroll through all TrueIdentity records in the Web Console.Workaround:\\xa0Using filters to find specific data in the TrueIdentity page prevents the error message from showing and helps find data more quickly. LogRhythm is\\xa0working on a resolution for a future release.\\nDE2689, 7.4.4, Data Indexer, When the Data Indexer cluster health changes from green to yellow during EMDB list maintenance, alarms for Indexer\\xa0Cluster\\xa0Health\\xa0Excessive Warnings are generated.\\xa0This can cause concern when there is no\\xa0actual\\xa0issue on the system., Expected Results: An alarm should only generate when the cluster health changes to red.Workaround:\\xa0Edit\\xa0the\\xa0impacted\\xa0alarm\\xa0to\\xa0suppress\\xa0for\\xa024\\xa0hours\\xa0or\\xa0disable\\xa0that\\xa0alarm.\\nDE6244, 7.4.5, Alarming, In certain circumstances, an Alarm does not associate\\xa0with a\\xa0SmartResponse Plugin\\xa0and does\\xa0not run\\xa0the SmartResponse Plugin., Expected Results:\\xa0The SmartResponse Plugin should be triggered by any Alarm meeting the criteria.Workaround: There is currently no workaround for this issue.\\nDE39, 7.4.5, TrueIdentity Sync Client, The TrueIdentity Sync may fail if attempting to run\\xa0with a large number of users (greater than approximately 10,000)., Expected Results:\\xa0The TrueIdentity Sync Client should work for any number of users.Workaround:\\xa0While there is no workaround for this issue, the next release of the Sync Client will be able to support\\xa0larger AD environments.\\nDE1336, 7.4.6, AI Engine, In certain circumstances, the AIE Summary Fields are not populating in the AIE Notification emails., Expected Results:\\xa0AIE Summary Fields should be displayed on all AIE Notification emails.Workaround:\\xa0View the AIE Summary Fields in the Alarm instead of the Notification email.\\nDE1288, 7.4.6, AI Engine, When an AIE Rule uses the Host (Impacted) or Host (Origin) in the Group By block, the rule misfires., Expected Results:\\xa0AIE Rules should not fire if the rule block relationship is not met.Workaround:\\xa0Change the Host (origin) or Host (impacted) fields to IP Address, and the AIE Rule works as expected.\\nDE4049, 7.4.6, Client Console, When running a report that contains User Origin Identity or User Impacted Identity fields, the report runs and provides data, but the Identity fields are\\xa0not\\xa0populated., Expected Results: Identity data should appear\\xa0in reports that contain those fields.Workaround: Run an investigation to provide the same information.\\nDE9995, 7.4.6, Job Manager, Scheduled reports are sent to a disabled account if an email is attached to the disabled account., Expected Results: Scheduled reports should not be sent to disabled accounts.Workaround: There is currently no workaround for this issue.\\nDE1750DE147, 7.4.6, Web Console, In certain circumstances, the Web Console may show a 500 Error page.\\xa0Typically, this occurs overnight when new service tokens are created for authentication., Expected Results:Authentication services for Web Console should handle the change to the new tokens without errors.Workaround:\\xa0Restarting the LogRhythm Authentication API on the Platform Manager mitigates this issue until the next time it occurs.\\nDE1198, 7.4.6, Web Console, When downloading large NetMon PCAPs from the Web Console, there may be\\xa0delays\\xa0to the initial\\xa0download,\\xa0increased\\xa0memory usage, or\\xa0timeouts., Expected Results: The Web Console\\xa0should not time out when downloading large PCAP files.Workaround: Change the time out setting in the Configuration Manager.\\nDE1869, 7.4.7, APIs, In certain circumstances the Admin API log generates multiple invalid argument errors without providing context., Expected Results: When the Admin API log generates errors, it should provide some context within the error message.Workaround: There is currently no workaround for this issue.\\nDE10501, 7.4.7, AI Engine, The Retire\\xa0logs in the C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm AI Engine\\\\HostInferenceLogs directory are not being removed after the defined number of expiration days., Expected Results: Logs in this directory should be purged after the number of days defined for expiration has passed, defaulted to 7 days.Workaround:\\xa0 Manually remove these files to prevent the C drive from filling up.\\nDE3932, 7.4.7, Client Console, After disabling Log Source Virtualization for a log source, users are unable to perform certain tasks on the System Monitor from which the log source is collected., Expected Results:\\xa0Disabling Log Source Virtualization should not change the behavior of the System Monitor.Workaround: This issue is caused by the scsm.ini file not being updated immediately.\\xa0To work around it, refresh the Log Sources tab in the Client Console to\\xa0force the .ini file to refresh.\\nDE260DE9367, 7.4.7, Installation Components, In certain circumstances, customers may receive an alarm for a missed heartbeat on the AI Engine.\\xa0This can stem from a deadlock on resources in SQL., Expected Results: SQL deadlock issues should not cause a missed heartbeat.Workaround: While there is no\\xa0known workaround, LogRhythm is actively investigating this issue for a solution.\\nDE1013, 7.4.7, Job Manager, Reports are not completing when a large set of data is required.\\xa0This is due to a limitation within Crystal Reports., Expected Results: The Client Console should provide an alternate way to retrieve the data if Crystal Reports is not able to render it.Workaround: Decrease the amount of data the report is trying to retrieve or export the data instead.\\nDE11710, 7.4.8, APIs, If FIPS and Integrated Security are enabled in a Disaster Recovery (DR) environment, the Admin API errors during startup because of\\xa0a failure to connect to SQL during failover., Expected Results:\\xa0The Admin API should connect to SQL during failover.Workaround: Manually change the Global IP to the Management IP.\\xa0This may need to be done after each upgrade.\\nDE10397, 7.4.8, AI Engine, In certain circumstances, when an AIE Rule is evaluating an Observed block followed by a Not Observed block, alarms\\xa0fire even if there are logs that indicate the second block was Observed., Expected Results:\\xa0Alarms should\\xa0not fire if a log is received for a Not Observed block.Workaround:\\xa0While there is currently no workaround, LogRhythm is investigating this issue for a future release.\\nDE10678, 7.4.8, Client Console, The Log Management Usage Auditing Event Detail, Event List, and Logon & Logoff Events reports are rendering in UTC date/time format instead of the local time., Expected Results:Reports should all display in the local time zone or that specified in the\\xa0report configuration.Workaround:\\xa0 There is currently no workaround for this issue.\\nDE3839, 7.4.8, Client Console, In certain circumstances after running a Second Look restore, an error appears stating there is an issue with the Min and Max Ticks., Expected Results:\\xa0 Second Look restore should run without issues.Workaround:\\xa0 There is currently no workaround for this issue.\\nDE10514, 7.4.8, Web Console, In certain circumstances when running an alarm\\xa0drill down in the Web Console, the the type-ahead filters do not display the correct values., Expected Results: The type-ahead filters should display correct values.Workaround: Turning off Web Services on fail-over temporarily fixes the issue.\\nDE10200, 7.4.9, APIs, PowerShell scripts utilizing the Case and Admin APIs may stop working upon upgrade to 7.4.9 or later.\\xa0This is due to an additional semicolon at the end of the valid content-type value., Expected Results: The extra semicolon, which is an optional valid separator in a content-type header, should not prevent scripts from working upon upgrade.Workaround:While there is currently no workaround, LogRhythm is investigating this issue for a future release.\\nDE10313, 7.4.9, AI Engine, In rare circumstances, AIE Unique Value Rules\\xa0misfire., Expected Results:\\xa0AIE Rules should fire as expected.Workaround:While there is currently no workaround, LogRhythm is investigating this issue for a future release.\\nDE10946, 7.4.9, AI Engine, When an AIE Alarm has an action including a SmartResponse Plugin, the execution is slow., Expected Results:\\xa0Alarms should execute quickly as expected with other AIE Alarms.Workaround:\\xa0There is currently no workaround for this issue.\\nDE11098, 7.4.9, Alarming, When using a SMTP server with SSL authentication, the Alarming and Response Manager fails to send alarm notifications., Expected Results:\\xa0The Alarming and Response Manager should able to send alarm notifications using any SMTP server and SSL authentication.Workaround:\\xa0There is currently no workaround for this issue.\\nDE11124, 7.4.9, Web Console, When\\xa0SSL Port In Redirects is set to Exclude\\xa0in the Web Console configuration, links in Alarm and Case notification emails do not work., Expected Results:\\xa0The links sent in Case and Alarm notification emails should redirect to port 443 instead of 8443, as they are coming from an external location.Workaround:\\xa0Open the Web Console and manually find the Alarm or Case to review.\\nDE10768, 7.4.9, Common Components, In certain circumstances, the Data Processor runs slowly and the non-paged pool uses significant system memory.\\xa0This can cause a large unprocessed logs queue or other backlog in the system., Expected Results: The non-paged pool should not increase and cause system performance issues.Workaround:\\xa0Restart the LogRhythm API Gateway service.\\nDE1737DE12489, 7.4.9, Common Components, In rare circumstances, Alarms may not be available in the Web Console or will stop triggering. Typically, this occurs\\xa0directly after a configuration change to the ARM service., Expected Results: Alarms should continue to trigger and be displayed in the Web Console.Workaround: Contact Technical Support for assistance, as there could be many reasons for this behavior beyond this defect.\\xa0Support will help determine the root cause.\\nDE10621, 7.4.9, Client Console, When an existing report template that includes the Normal Date field is edited, the Normal Date field disappears from the template until\\xa0it is added again., Expected Results:\\xa0When editing a report template, existing fields should remain unless they are explicitly removed.Workaround:\\xa0When editing a report template that contains the Normal Date field, add that field back to the template prior to saving it.\\nDE11342, 7.4.9, Data Indexer, Having entity lists with Entity (Impacted) or Entity (Origin) as filter criteria in an AIE Rule causes the alarm drill down to fail., Expected Results: Drill downs on AIE rules should work regardless of the filter criteria.Workaround: There is no workaround for this issue.\\nDE10403, 7.4.9, Web Console, The Web Console Current Processing Rate widget does\\xa0not show the correct processing rate.\\xa0It does\\xa0not include messages older than 3 minutes in the rate determined., Expected Results: The Current Processing Rate widget\\xa0should show all logs\\xa0being processed.Workaround: Resolve any log source issues that are causing old logs to be ingested, or use Grafana or Performance Counters to check the current processing rate.\\nDE10442, 7.4.9, Web Console, When viewing NetMon logs in the Web Console using Internet Explorer, the Download PCAP button does not appear., Expected Results:\\xa0The Download PCAP button should appear\\xa0when reviewing NetMon logs.Workaround:\\xa0Reload the frame with the Download PCAP button to activate it.\\nDE11123, 7.4.9, Web Console, Occasionally in multiple Web Console environments, AIE Drilldown does\\xa0not export results or show data in the filters., Expected Results:\\xa0Drill downs should always allow export of results and filters should always have data.Workaround: Use the Client Console to drill down and export results.\\nDE11051, 7.4.9, AI Engine, In certain circumstances, the AIE Engine does not consistently trigger alarms for Log Not Observed., Expected Results: The AIE Engine should trigger alarms for Log Not Observed.Workaround: There is currently no workaround for this issue.\\nDE11822, 7.5.0, Data Indexer, The C:\\\\Windows\\\\Temp directory may become full with jtds.tmp files if the Carpenter service continually recycles.\\xa0 This can happen if using an SRP with List Management., Expected Results: Temporary files should not be left on disk.Workaround: Contact Technical Support for assistance with the workaround for this issue.\\nDE11792, 7.5.0, Job Manager, After the Active Directory Sync, some Active Directory users may be disabled., Expected Results: Only users who are disabled in Active Directory should be disabled within LogRhythm.Workaround: Manually re-enable users by logging in to the Console as a Global Administrator or LogRhythm Admin user.\\nDE12597, 7.5.0, Smart Response Plugin, When grouping two values in a SmartResponse Plugin, users receive an error that they do not have access to the Config file., Expected Results: Grouping values in SmartResponse Plugins should be allowed.Workaround: There is no workaround for this issue.\\nDE12514, 7.5.1, APIs, If a high volume of list updates occur in a short amount of time, incorrect data will be input and the lists will not be useable., Expected Results: List updates should occur without inputting incorrect data.Workaround: There is currently no workaround for this issue.\\xa0Contact LogRhythm Technical Support for assistance if you have a list that is not currently useable.\\nDE11499, 7.5.1, Client Console, When DNStoIP is enabled on the Data Processor and the DNS name doesn't have a host record, the host field shows only the IP address without the host name.\\xa0 This impacts only the Client Console and is displayed correctly in the Web Console., Expected Results: The hostname should be displayed the same for both Web and Client Consoles.Workaround: View the record in the Web Console.\\nDE11765, 7.5.1, Data Indexer, In certain circumstances, Elasticsearch uses more memory than the set limit, causing performance issues on the server., Expected Results:\\xa0Elasticsearch should abide by the memory limit that is set.Workaround: For a workaround, contact LogRhythm Technical Support.\\nDE11496, 7.5.1, Mediator, In certain circumstances, the Mediator will attempt to seal the same archive file twice.\\xa0 This causes errors in the scmedsvr.log file., Expected results: The Mediator should only attempt to seal the archive file once.Workaround: There is no workaround for this issue.\\nDE11932, 7.6.0, Common Components, In some instances, when a service is restarted, the API Gateway does not recognize that the service has started and will not allow normal functionality\\xa0to resume., Expected Results: API Gateway should always recognize a service restart and adjust accordingly.Workaround: Reboot the API Gateway service to resume normal operations.\\nDE11663, 7.6.0, Web Console, When clicking Case Evidence logs from the Case page, the Analyze window shows a Custom Filter that prevents the logs from displaying., Expected Results: Clicking Case Evidence logs should open an Analyze page showing the logs selected.Workaround: To show the logs, click the X next to the Custom Filter.\\nDE11733, 7.6.0, Common Components, When running the LogRhythm Infrastructure Installer (LRII), you may receive the\\xa0error: No plan file found in LogRhythm Service Registry KV store.\\xa0This is caused by the plan file not fully updating into the Consul KV store, and only happens in certain environments., Expected Results:\\xa0LRII\\xa0should be able to run multiple times without affecting the plan file.Workaround: For assistance with this issue, contact LogRhythm Technical Support.\\nDE12153, 7.6.0, Common Components, In some cases after a Data Indexer install, the Service Registry may not be able to communicate with the Platform Manager, causing alarms and errors in the Service Registry log., Expected Results: Communication to the Platform Manager should be maintained after an install.Workaround: Restart Service Registry on each node in the cluster after the installation is complete.\\nDE12893, 7.6.0, Client Console, Active Directory users that are linked to User Profiles may not be updated after moving the user to a different Active Directory group., Expected Results: Users that are moved between Active Directory groups should update upon the move.Workaround: There is no workaround for this issue other than manually updating the profiles.\\nDE12106, 7.6.0, Data Indexer, Fields of a log that are larger than 32766 bytes cause errors in the Transporter log, even though the default Transporter Max Log Size (bytes) is set to 1,000,000 bytes., Expected Results: Transporter should allow the size indicated in the Configuration Manager.Workaround: Changing the Transporter Max Log Size (bytes) to 32766 will prevent the error, but may also prevent these large messages from being indexed.\\nDE11934, 7.6.0, Data Indexer, In certain circumstances, customers with warm node indices may experience failed searches against those\\xa0indices.\\xa0This is due to Columbo being unable to close certain warm indices., Expected Results: Columbo should handle the warm node indices correctly and allow searches.Workaround: For assistance with this workaround, contact LogRhythm Technical Support.\\nDE13234, 7.6.0, Job Manager, In certain circumstances, after user accounts\\xa0have been disabled in the LogRhythm Console, the users may continue to have read and write privileges., Expected Results: When user accounts are disabled in the LogRhythm Console, their read and write privileges should be revoked.Workaround: There is currently no workaround for this issue.\\nDE12188, 7.6.0, Common Components, When viewing the Metrics dashboard in Grafana, the Memory Used Percentage widget in the LR Metrics - Deployment View dashboard shows incorrect results for timeframes greater than three hours., Expected Results: The aggregator in the widget query should use an average calculation instead of a sum calculation.Workaround: For assistance with this workaround, see\\xa0this knowledge article on the LogRhythm Community:https://community.logrhythm.com/t5/Knowledge/Metrics-dashboard-widget-for-memory-utilization-shows-incorrect/ta-p/461213\\nDE12187, 7.6.0, Mediator, When re-licensing the Data Processor, the AIE Data Provider settings are not preserved., Expected Results: The AIE Data Provider settings in the Data Processor should persist during a re-license.Workaround: Re-enable the AIE Data Provider in the AI Engine tab within the Data Processor Properties.\\nDE12292, 7.6.0, Mediator, Entity Network Resolution processing performance is slow if there is a large number of entity networks., Expected Results: Performance on Entity Network Resolution should be quicker.Workaround: Contact LogRhythm Technical Support for assistance applying a workaround for this issue.\\nDE11820, 7.6.0, Smart Response Plugin, When utilizing multiple SmartResponse Plugins as part of the actions for an AIE Rule, inconsistent results may occur., Expected Results: SmartResponse Plugins should fire each time the AIE Rule is triggered.Workaround: There is no workaround for this issue.\\nDE13108, 7.6.0, Threat Intelligence Service, TIS STIX feed files do not parse correctly., Expected Results: TIS STIX feed files should parse without issues.Workaround: There is currently no workaround for this issue.\\nDE11929, 7.6.0, Web Console, When using a Direction filter in the Web Console dashboard and\\xa0drilling into any of the TopX widgets, the data shown in the Analyzer Grid contains logs that do not match the dashboard filter., Expected Results: Drilling into data on a dashboard should not change the dashboard filter criteria.Workaround:\\xa0Reapply the dashboard filter.\\nDE12714, 7.6.0, Web Console, In the Web Console, if the last selected Analyzer page dashboard has a filter, drill down results are hidden., Expected Results:\\xa0drill down results should not be hidden.Workaround:\\xa0Select Default Analyze Dashboard\\nDE12521, 7.6.0, Web Console, When pausing live data in the Web Console, the Analyzer grid continues to update with new events., Expected Results: The Analyzer grid should not\\xa0update with new events when paused.Workaround: There is currently no workaround for this issue.\\nDE12908, 7.6.0, Web Console, Event logs are not appearing in the Web Console dashboard., Expected Results: Event data should appear in the dashboard.Workaround: There is currently no workaround for this issue.\\nDE11863, 7.6.0, Web Console, When running AIE Events drill down from an AIE events dashboard, the Analyze Dashboard filter does not reset properly., Expected Results: The Analyze Dashboard filter should reset.Workaround: In User Settings set the Drilldown setting to Open in Page.\\nDE11463, 7.6.0, Web Console, When the browser window is zoomed out, the Node-Link Graph on the Web Console dashboards may display an error Failed to establish logs subscription with the Web Console API.\\xa0 This is not related to the zoom functionality within the Node-Link Graph itself., Expected Results:\\xa0The Node-Link Graph should function regardless of the browser zoom level.Workaround:\\xa0 Return the browser to 100% zoom and refresh the Web Console.\\nDE13079, 7.6.0, Web Console, When running a search or drill down in the Web Console, the operation does not return results or terminate as intended., Expected Results: The search and drill down operations should return results upon completion or terminate.Workaround: Reload the page.\\nDE11924, 7.6.0, Web Console, When a hostname\\xa0IP address is showing in brackets, drill downs do not work., Expected Results: Brackets should not affect the ability to drill down into a hostname.Workaround: There is no workaround for this issue.\\nDE12836, 7.6.0, Web Console, When running a search or drill down in the Web Console, the operation does not return results or terminate as intended., Expected Results: The search and drill down operations should return results upon completion or terminate.Workaround: Reload the page.\\nDE12207, 7.6.0.HF2, Data Indexer, In some circumstances, installing the 7.6.0 Hotfix 2 upgrade will install a second instance of the Data Indexer., Expected Results: The Data Indexer should be removed and re-added instead of adding a second instance.Workaround: Uninstall both versions of the Data Indexer, ensure there or no hung .msi processes in the Task Manager, then re-install the 7.6.0 Hotfix 2 version.\\nDE12608, 7.7.0, Agents, When searching System Monitor Agent Properties log sources, all log sources from all agents are displayed., Expected Results: Searching System Monitor Agent Properties log sources should return all log sources from the current agent.Workaround: There is currently no workaround for this issue.\\nDE12581, 7.7.0, Client Console, The Log Source Type filter in the Client Console does not work unless the Include Retired log sources box is selected., Expected Results: Users should be able to filter out the retired log sources when filtering by Log Source Type.Workaround:\\xa0 Use the Include Retired box or use another method of filtering.\\nDE13150, 7.7.0, Data Indexer, In certain circumstances after upgrading to 7.7.0, the Carpenter service causes port exhaustion and the service must be restarted., Expected Results: The Carpenter service should not cause port exhaustion.Workaround: Create a scheduled task to restart the Carpenter service each day.\\nDE13128, 7.7.0, Web Console, When running a search or drill down in the Web Console, the operation does not return results or terminate as intended., Expected Results: The search and drill down operations should return results upon completion or terminate.Workaround: Reload the page.\\nDE12624, 7.7.0, Web Console, When using the Check Visible option in Alarms after upgrading to 7.7.0, the checked count does not reset properly., Expected Results: The checked count should reset.Workaround: After performing an action, select the Uncheck All option to reset the checked count.\\nDE12819, 7.8.0, Infrastructure:DatabaseUpgrade Tool, In certain circumstances when upgrading to 7.8.0, customers may experience\\xa0a database upgrade\\xa0error and receive the following message:Violation of UNIQUE KEY constraint 'UniqueKey'. Cannot insert duplicate key in object 'dbo.SCMaint'., Expected Results: Customers should not experience errors during database upgrade.Workaround:For assistance with this workaround, see\\xa0this knowledge article on the LogRhythm Community:https://community.logrhythm.com/t5/Solution-Articles/Known-Issue-Violation-of-Unique-Key-Constraint-for-dbo-SCMaint/ta-p/483175\\nExpected Results\\n:\\xa0The report should show the accurate last backup time for each database.\\nWorkaround\\n:\\xa0Review the backup information in SQL Server Management Studio.\\nExpected Results\\n: The TrueIdentity Sync Client should be able to connect using LDAP via port 636.\\nWorkaround\\n: Use port 389 instead and ensure the proper certificates are in place for security.\\nExpected Results\\n: Entities\\xa0should be retireable\\xa0and able to be hidden from view.\\nWorkaround\\n: Contact Technical Support to assist you in removing entities that are no longer needed.\\nExpected Results\\n:\\xa0When exporting reports in .csv format, the column headers should not be repeated on each row.\\nWorkaround\\n:\\xa0The report needs to be formatted to remove columns that show the column headers. In addition, LogRhythm data can be exported using Log Distribution Services (LDS).\\nExpected Results\\n:\\xa0Archives should process, seal, and move out of the Unprocessed Archives folder as long as the processing rate is at or below the system specification.\\nWorkaround\\n:\\xa0Evaluate system sizing and consider an expansion to meet active load demands. In some systems, increasing the ArchiveSize setting in the Data Processor Advanced Properties to 51200 (from the default value of 10240) can help process archive files faster.\\xa0If necessary, move large files out of the Unprocessed Archives folder to another drive and slowly feed them back in when the system is successfully processing the live data. A more permanent solution to this issue will be provided\\xa0in a future release.\\nExpected Results\\n:\\xa0 When the Mediator is handling agent licenses, the heartbeat packet should still be sent so the system shows it is healthy.\\nWorkaround\\n:\\nThere is currently no workaround for this issue\\n.\\nExpected Results:\\nThe Diagnostic logs should be tuned to alarm less frequently.\\nWorkaround\\n:\\nThere is currently no workaround for this issue\\n.\\nExpected Results\\n:\\xa0Poorly written AIE Rules should be suspended until they are altered and re-enabled.\\nWorkaround\\n:\\xa0Rewrite the AIE Rule for\\xa0better performance.\\xa0Often, this involves adding filters, reducing log sources, and\\xa0modifying the logic. Tuning an AIE Rule requires expertise, so contact LogRhythm Training, Professional Services, or a Sales Engineer to assist if necessary. Additional solutions to identify and monitor poorly performing rules are being developed for a\\xa0future release.\\nExpected Results\\n: The processing of a log should be the same whether it is parsed in Rule Builder or MPE.\\nWorkaround\\n: Change the sub-rule to use a different tag, such as <Tag1>.\\xa0If you are experiencing this issue, ensure that you are not using a custom Log Processing Policy and that there are no MPE timeouts.\\xa0If issues persist, contact Technical Support and reference this bug number\\xa0(DE1829) or its sister defect\\xa0(DE1651).\\nExpected Results\\n:\\xa0When users try to download a PCAP that is no longer available on disk, the error message should provide that detail instead of an unclassified failure.\\nWorkaround\\n:\\xa0The error message will be changed in a future release. There are two simple troubleshooting steps to identify if the PCAP exists or if other issues are occurring in the integration: Log in to NetMon\\xa0directly and verify if the selected PCAP has already aged out or should be available on disk. Recreate the API key for the selected NetMon\\xa0and update the NetMon configuration in the Deployment Manager.\\nExpected Results\\n: Case API and Admin API should start when using any size certificate.\\nWorkaround\\n:\\xa0Remove\\xa0the\\xa0server\\xa0from\\xa0the\\xa0domain and reboot it.\\xa0Verify that the\\xa0512-bit\\xa0certificate has\\xa0been\\xa0removed, re-run the installers, and reboot. To\\xa0avoid\\xa0this issue, do not join the domain\\xa0again\\xa0or\\xa0the\\xa0certificate will\\xa0be\\xa0pushed\\xa0out\\xa0again.\\xa0In addition, create a new certificate that\\xa0uses a 384-bit (or less) hash or exclude the impacted system from the GPO that pushes\\xa0the\\xa0certificate.\\nExpected Results\\n:\\xa0These errors should not be generated in the AIE Engine log, but AIE\\xa0is\\xa0working\\xa0and\\xa0alarms\\xa0are\\xa0firing.\\nWorkaround\\n:\\xa0There is currently no workaround for this issue.\\nExpected Results\\n:\\xa0When a search times out, a message should inform users and instruct them\\xa0to re-run the search with a longer timeout.\\nWorkaround\\n:\\xa0Increase the timeout on the query and re-run it.\\nExpected Results\\n:\\xa0All chosen fields should appear\\xa0on the report if they contain data.\\nWorkaround\\n:\\xa0Running the report as an investigation yields the expected results in the Network (Impacted) column. LogRhythm is\\xa0actively working on a solution to this issue in\\xa0a future release.\\nExpected Results\\n:\\xa0AIE Rule Blocks should fire when they are triggered at the same time.\\nWorkaround\\n:\\xa0As the behavior of simultaneous events is unpredictable\\xa0and the use case for a 0-time interval is rare, LogRhythm does not plan to change this behavior at this time. To avoid the issue, set the evaluation period to 1 second.\\nExpected Results\\n:\\xa0The AIE Data Provider service should start consistently and as expected. Failures should be consistently logged to alert when the service\\xa0did not start correctly.\\nWorkaround\\n:\\xa0Restart the Mediator service to allow the AIE Data Provider service to start. A more permanent solution to this issue is being evaluated for\\xa0a future release.\\nExpected Results\\n: The Alarming and Response Manager should be aware of a change of status of the SRPs and should not continue to attempt to execute them.\\nWorkaround\\n: Lower the logging level on the ARM to help mitigate this, but contact LogRhythm Technical Support if assistance is needed to retire the SRP.\\nExpected Results\\n: The Data Processor and Data Indexer should connect to Service Registry after a reboot of the Platform Manager.\\nWorkaround\\n: Manually restart the API Gateway and Service Registry services on the Data Indexer and Data Processor after a reboot of\\xa0the Platform Manager.\\nExpected Results\\n: The Console should not freeze when exporting logs.\\nWorkaround\\n: Export selected logs instead of all logs to allow the export to complete.\\nExpected Results\\n:\\xa0Autogrowth should increase in larger increments so it does not cause fragmentation.\\nWorkaround\\n:\\xa0Set the autogrowth settings to the following:EMDB: 256 MBEvents: 1 GBAlarms: 256 MBLogMart: 256 MBCMDB: 256 MB\\nExpected Results\\n: The Job Manager should generate a message stating that the results were not complete and the report should indicate partial results.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: Exported reports should not duplicate header and footer lines.\\nWorkaround\\n: Export the report in another format or remove the extra lines from the .csv.\\nExpected Results\\n:\\xa0 The SmartResponse Plugin should execute after selecting the System Monitor Agent.\\nWorkaround\\n:\\nThere is currently no workaround for this issue\\n.\\nIn certain circumstances when\\xa0Entity Archive settings are turned on, customers may receive the following error:\\n**ERROR** Failed to locate or create inactive subdirectory: The given key was not present in the dictionary.. Inactive archive files will be temporarily stored at the root of the system drive (C:\\\\ in most cases). This error must be corrected in order for inactive archives to be stored at the specified location.\\nExpected Results\\n: Entity archiving should function without errors.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n:\\xa0All data contained in the .csv export should be valid and match the data displayed in the Web Console.\\nWorkaround\\n:\\xa0Export the same investigation from the Client Console or manually adjust the first and last date post export. LogRhythm is investigating a solution to this issue.\\nExpected Results\\n:\\xa0When copying widgets, all settings should remain.\\nWorkaround\\n:\\xa0Users can add a new widget to the dashboard and configure it manually to work around this issue. This issue is still being actively investigated and will be resolved in a future release.\\nExpected Results\\n: The date and time of the AIE Event should not have a future time.\\nWorkaround\\n: There is no workaround for this issue.\\nExpected Results\\n: White space should be allowed in the OU/DC filter.\\nWorkaround\\n: While there is no workaround for this issue, LogRhythm is\\xa0investigating a resolution for a future release.\\nExpected Results\\n:\\xa0Users should be able to scroll through all TrueIdentity records in the Web Console.\\nWorkaround\\n:\\xa0Using filters to find specific data in the TrueIdentity page prevents the error message from showing and helps find data more quickly. LogRhythm is\\xa0working on a resolution for a future release.\\nExpected Results\\n: An alarm should only generate when the cluster health changes to red.\\nWorkaround\\n:\\xa0Edit\\xa0the\\xa0impacted\\xa0alarm\\xa0to\\xa0suppress\\xa0for\\xa024\\xa0hours\\xa0or\\xa0disable\\xa0that\\xa0alarm.\\nExpected Results\\n:\\xa0The SmartResponse Plugin should be triggered by any Alarm meeting the criteria.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n:\\xa0The TrueIdentity Sync Client should work for any number of users.\\nWorkaround\\n:\\xa0While there is no workaround for this issue, the next release of the Sync Client will be able to support\\xa0larger AD environments.\\nExpected Results\\n:\\xa0AIE Summary Fields should be displayed on all AIE Notification emails.\\nWorkaround\\n:\\xa0View the AIE Summary Fields in the Alarm instead of the Notification email.\\nExpected Results\\n:\\xa0AIE Rules should not fire if the rule block relationship is not met.\\nWorkaround\\n:\\xa0Change the Host (origin) or Host (impacted) fields to IP Address, and the AIE Rule works as expected.\\nExpected Results\\n: Identity data should appear\\xa0in reports that contain those fields.\\nWorkaround\\n: Run an investigation to provide the same information.\\nExpected Results\\n: Scheduled reports should not be sent to disabled accounts.\\nWorkaround\\n: There is currently no workaround for this issue.\\nDE1750\\nDE147\\nExpected Results\\n:\\nAuthentication services for Web Console should handle the change to the new tokens without errors\\n.\\nWorkaround\\n:\\xa0Restarting the LogRhythm Authentication API on the Platform Manager mitigates this issue until the next time it occurs.\\nExpected Results\\n: The Web Console\\xa0should not time out when downloading large PCAP files.\\nWorkaround\\n: Change the time out setting in the Configuration Manager.\\nExpected Results\\n: When the Admin API log generates errors, it should provide some context within the error message.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: Logs in this directory should be purged after the number of days defined for expiration has passed, defaulted to 7 days.\\nWorkaround\\n:\\xa0 Manually remove these files to prevent the C drive from filling up.\\nExpected Results\\n:\\xa0Disabling Log Source Virtualization should not change the behavior of the System Monitor.\\nWorkaround\\n: This issue is caused by the scsm.ini file not being updated immediately.\\xa0To work around it, refresh the Log Sources tab in the Client Console to\\xa0force the .ini file to refresh.\\nDE260\\nDE9367\\nExpected Results\\n: SQL deadlock issues should not cause a missed heartbeat.\\nWorkaround\\n: While there is no\\xa0known workaround, LogRhythm is actively investigating this issue for a solution.\\nExpected Results\\n: The Client Console should provide an alternate way to retrieve the data if Crystal Reports is not able to render it.\\nWorkaround\\n: Decrease the amount of data the report is trying to retrieve or export the data instead.\\nExpected Results\\n:\\xa0The Admin API should connect to SQL during failover.\\nWorkaround\\n: Manually change the Global IP to the Management IP.\\xa0This may need to be done after each upgrade.\\nExpected Results\\n:\\xa0Alarms should\\xa0not fire if a log is received for a Not Observed block.\\nWorkaround\\n:\\xa0While there is currently no workaround, LogRhythm is investigating this issue for a future release.\\nExpected Results:\\nReports should all display in the local time zone or that specified in the\\xa0report configuration.\\nWorkaround\\n:\\xa0 There is currently no workaround for this issue.\\nExpected Results\\n:\\xa0 Second Look restore should run without issues.\\nWorkaround\\n:\\xa0 There is currently no workaround for this issue.\\nExpected Results\\n: The type-ahead filters should display correct values.\\nWorkaround\\n: Turning off Web Services on fail-over temporarily fixes the issue.\\nExpected Results\\n: The extra semicolon, which is an optional valid separator in a content-type header, should not prevent scripts from working upon upgrade.\\nWorkaround\\n:\\nWhile there is currently no workaround, LogRhythm is investigating this issue for a future release\\n.\\nExpected Results\\n:\\xa0AIE Rules should fire as expected.\\nWorkaround\\n:\\nWhile there is currently no workaround, LogRhythm is investigating this issue for a future release\\n.\\nExpected Results\\n:\\xa0Alarms should execute quickly as expected with other AIE Alarms.\\nWorkaround\\n:\\xa0There is currently no workaround for this issue.\\nExpected Results\\n:\\xa0The Alarming and Response Manager should able to send alarm notifications using any SMTP server and SSL authentication.\\nWorkaround\\n:\\xa0There is currently no workaround for this issue.\\nExpected Results\\n:\\xa0The links sent in Case and Alarm notification emails should redirect to port 443 instead of 8443, as they are coming from an external location.\\nWorkaround\\n:\\xa0Open the Web Console and manually find the Alarm or Case to review.\\nExpected Results\\n: The non-paged pool should not increase and cause system performance issues.\\nWorkaround\\n:\\xa0Restart the LogRhythm API Gateway service.\\nDE1737\\nDE12489\\nExpected Results\\n: Alarms should continue to trigger and be displayed in the Web Console.\\nWorkaround\\n: Contact Technical Support for assistance, as there could be many reasons for this behavior beyond this defect.\\xa0Support will help determine the root cause.\\nExpected Results\\n:\\xa0When editing a report template, existing fields should remain unless they are explicitly removed.\\nWorkaround\\n:\\xa0When editing a report template that contains the Normal Date field, add that field back to the template prior to saving it.\\nExpected Results\\n: Drill downs on AIE rules should work regardless of the filter criteria.\\nWorkaround\\n: There is no workaround for this issue.\\nExpected Results\\n: The Current Processing Rate widget\\xa0should show all logs\\xa0being processed.\\nWorkaround\\n: Resolve any log source issues that are causing old logs to be ingested, or use Grafana or Performance Counters to check the current processing rate.\\nExpected Results\\n:\\xa0The Download PCAP button should appear\\xa0when reviewing NetMon logs.\\nWorkaround\\n:\\xa0Reload the frame with the Download PCAP button to activate it.\\nExpected Results\\n:\\xa0Drill downs should always allow export of results and filters should always have data.\\nWorkaround\\n: Use the Client Console to drill down and export results.\\nExpected Results\\n: The AIE Engine should trigger alarms for Log Not Observed.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: Temporary files should not be left on disk.\\nWorkaround\\n: Contact Technical Support for assistance with the workaround for this issue.\\nExpected Results\\n: Only users who are disabled in Active Directory should be disabled within LogRhythm.\\nWorkaround\\n: Manually re-enable users by logging in to the Console as a Global Administrator or LogRhythm Admin user.\\nExpected Results\\n: Grouping values in SmartResponse Plugins should be allowed.\\nWorkaround\\n: There is no workaround for this issue.\\nExpected Results\\n: List updates should occur without inputting incorrect data.\\nWorkaround\\n: There is currently no workaround for this issue.\\xa0Contact LogRhythm Technical Support for assistance if you have a list that is not currently useable.\\nExpected Results\\n: The hostname should be displayed the same for both Web and Client Consoles.\\nWorkaround\\n: View the record in the Web Console.\\nExpected Results\\n:\\xa0Elasticsearch should abide by the memory limit that is set.\\nWorkaround\\n: For a workaround, contact LogRhythm Technical Support.\\nExpected results\\n: The Mediator should only attempt to seal the archive file once.\\nWorkaround\\n: There is no workaround for this issue.\\nExpected Results\\n: API Gateway should always recognize a service restart and adjust accordingly.\\nWorkaround\\n: Reboot the API Gateway service to resume normal operations.\\nExpected Results\\n: Clicking Case Evidence logs should open an Analyze page showing the logs selected.\\nWorkaround\\n: To show the logs, click the X next to the Custom Filter.\\nExpected Results\\n:\\xa0LRII\\xa0should be able to run multiple times without affecting the plan file.\\nWorkaround\\n: For assistance with this issue, contact LogRhythm Technical Support.\\nExpected Results\\n: Communication to the Platform Manager should be maintained after an install.\\nWorkaround\\n: Restart Service Registry on each node in the cluster after the installation is complete.\\nExpected Results\\n: Users that are moved between Active Directory groups should update upon the move.\\nWorkaround\\n: There is no workaround for this issue other than manually updating the profiles.\\nExpected Results\\n: Transporter should allow the size indicated in the Configuration Manager.\\nWorkaround\\n: Changing the Transporter Max Log Size (bytes) to 32766 will prevent the error, but may also prevent these large messages from being indexed.\\nExpected Results\\n: Columbo should handle the warm node indices correctly and allow searches.\\nWorkaround\\n: For assistance with this workaround, contact LogRhythm Technical Support.\\nExpected Results\\n: When user accounts are disabled in the LogRhythm Console, their read and write privileges should be revoked.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: The aggregator in the widget query should use an average calculation instead of a sum calculation.\\nWorkaround\\n: For assistance with this workaround, see\\xa0this knowledge article on the LogRhythm Community:\\nhttps://community.logrhythm.com/t5/Knowledge/Metrics-dashboard-widget-for-memory-utilization-shows-incorrect/ta-p/461213\\nExpected Results\\n: The AIE Data Provider settings in the Data Processor should persist during a re-license.\\nWorkaround\\n: Re-enable the AIE Data Provider in the AI Engine tab within the Data Processor Properties.\\nExpected Results\\n: Performance on Entity Network Resolution should be quicker.\\nWorkaround\\n: Contact LogRhythm Technical Support for assistance applying a workaround for this issue.\\nExpected Results\\n: SmartResponse Plugins should fire each time the AIE Rule is triggered.\\nWorkaround\\n: There is no workaround for this issue.\\nExpected Results\\n: TIS STIX feed files should parse without issues.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: Drilling into data on a dashboard should not change the dashboard filter criteria.\\nWorkaround\\n:\\xa0Reapply the dashboard filter.\\nExpected Results\\n:\\xa0drill down results should not be hidden.\\nWorkaround\\n:\\xa0Select Default Analyze Dashboard\\nExpected Results\\n: The Analyzer grid should not\\xa0update with new events when paused.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: Event data should appear in the dashboard.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: The Analyze Dashboard filter should reset.\\nWorkaround\\n: In User Settings set the Drilldown setting to Open in Page.\\nExpected Results\\n:\\xa0The Node-Link Graph should function regardless of the browser zoom level.\\nWorkaround\\n:\\xa0 Return the browser to 100% zoom and refresh the Web Console.\\nExpected Results\\n: The search and drill down operations should return results upon completion or terminate.\\nWorkaround\\n: Reload the page.\\nExpected Results\\n: Brackets should not affect the ability to drill down into a hostname.\\nWorkaround\\n: There is no workaround for this issue.\\nExpected Results\\n: The search and drill down operations should return results upon completion or terminate.\\nWorkaround\\n: Reload the page.\\nExpected Results\\n: The Data Indexer should be removed and re-added instead of adding a second instance.\\nWorkaround\\n: Uninstall both versions of the Data Indexer, ensure there or no hung .msi processes in the Task Manager, then re-install the 7.6.0 Hotfix 2 version.\\nExpected Results\\n: Searching System Monitor Agent Properties log sources should return all log sources from the current agent.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: Users should be able to filter out the retired log sources when filtering by Log Source Type.\\nWorkaround\\n:\\xa0 Use the Include Retired box or use another method of filtering.\\nExpected Results\\n: The Carpenter service should not cause port exhaustion.\\nWorkaround\\n: Create a scheduled task to restart the Carpenter service each day.\\nExpected Results\\n: The search and drill down operations should return results upon completion or terminate.\\nWorkaround\\n: Reload the page.\\nExpected Results\\n: The checked count should reset.\\nWorkaround\\n: After performing an action, select the Uncheck All option to reset the checked count.\\nIn certain circumstances when upgrading to 7.8.0, customers may experience\\xa0a database upgrade\\xa0error and receive the following message:\\nViolation of UNIQUE KEY constraint 'UniqueKey'. Cannot insert duplicate key in object 'dbo.SCMaint'.\\nExpected Results\\n: Customers should not experience errors during database upgrade.\\nWorkaround\\n:\\nFor assistance with this workaround, see\\xa0this knowledge article on the LogRhythm Community:\\nhttps://community.logrhythm.com/t5/Solution-Articles/Known-Issue-Violation-of-Unique-Key-Constraint-for-dbo-SCMaint/ta-p/483175\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Release Notes\\n', '7.9.0 GA Release Notes - 23 June 2022': '', 'Upgrade Considerations': 'LogRhythm 7.9.0 introduces support for Microsoft\\xa0SQL Server 2019 and Windows Server 2019 on standard deployments.\\nIf your deployment is running SQL Server 2016 Standard or Windows Server 2016, there is no need to upgrade to\\n2019\\n.\\nFor more information on the optional upgrades, see:\\nUpgrade SQL Server 2016 to SQL Server 2019\\nUpgrade Windows Server 2016 to Windows Server 2019\\nL\\nogRhythm 7.9.0 does not support upgrades to\\nMicrosoft SQL Server 2019 and Windows Server 2019 on existing High Availability (HA) and Disaster Recovery (DR) environments.\\nSQL Server 2019 Licensing\\nIf you\\npurchased hardware through LogRhythm and wish to upgrade SQL, you must provide your own SQL 2019 installer and license.\\nSoftware-only purchases allow customers to either bring their own SQL license or purchase one through LogRhythm. See the table below to determine whether your software purchase includes a SQL 2019 license.\\nSQL Purchase Date, LogRhythm SKU, SQL 2019 License, Customer Action\\nOn or after February 1, 2022, LR-ACC-MSSQL-P, Included, If you wish to upgrade SQL, you can request SQL 2019 license and installer through a support case.\\nPrior to February 1, 2022, LR-ACC-MSSQL-P, Not included, If you wish to upgrade SQL, you must provide your own SQL 2019 license and installer.\\nWindows Server 2019 Licensing\\nIf you\\npurchased hardware from\\nLogRhythm\\non or after Nov\\n.\\n1, 2020\\n, you\\npurchased a Server 2019 from\\nLogRhythm\\n. This license can be used to upgrade the operating system.\\nYou\\ncan use and validate\\nyour\\nlicense by looking at the license sticker on top of the server. If\\nyou are\\nunable to locate the license,\\nyou\\ncan\\nopen a support case\\n.\\nIf you purchased\\nhardware prior to Nov\\n.\\n1, 2020\\n, you\\nmust\\nprovide\\nyour\\nown Server 2019 license\\nto upgrade\\n.\\n', 'New Features': \"Functional Group, Feature, Description\\nCustomer Enhancements, License Information Report, Explanation:The License Information Report now shows the 24-hour average MPS for each Data Processor. The License Metering Report was added to the bottom of the License Information Report. This shows the 24-hour moving average over the last 30 days, making licensing overages more visible and easier to understand.Benefit:These two updates improve the accuracy and readability of MPS rates and improve users' ability to manage their license usage and lower expenses.Relevant Documentation Updates:Assign LogRhythm Licenses(See View LogRhythm License Report section at the bottom of the page.)\\nEnterprise Log Management, Windows Event Log Filtering, Explanation:Event log filtering allows users to select specific types of Windows Event logs during System Monitor Agent queries. Users can also split collection from a single log source across multiple Agents.Benefit:Event log filtering reduces the Agent's workload and decreases log clutter.Relevant Documentation Updates:Add a Single Log Source(See Additional Info Tab table in step 10.)This feature requiresLogRhythm System Monitorto be updated to version 7.9.\\nPlatform Administration, Admin API, Explanation:The Admin API library now includes System Monitoring Management endpoints. This enables SIEM administrators to manage pending or modify existing System Monitor Agents through the API.Benefit:The Admin API reduces administrative overhead and expedites workflow by automating routine tasks.Relevant Documentation Updates:Administration API Endpoints\\nPlatform Administration, Search API, Explanation:Simplified the the process for creating Search API queries.Benefit:Search API queries are easier to use.Relevant Documentation Updates:Search API Endpoints\\nPlatform Administration, Windows Server 2019 and SQL Server 2019, Explanation:LogRhythm 7.9 introduces support for Windows Server 2019 and SQL 2019 on standard deployments. (Licensing entitlements vary. For more information, see Relevant Documentation Updates.)Benefit:Enables customers to run the latest versions of Windows Server and SQL Server.Relevant Documentation Updates:Review the Upgrade Requirements and Considerations,Upgrade Windows Server 2016 to Windows Server 2019, andUpgrade SQL Server 2016 to SQL Server 2019.LogRhythm 7.9.0 does not support upgrades toMicrosoft SQL Server 2019 and Windows Server 2019 on existing High Availability (HA) and Disaster Recovery (DR) environments.\\nSecurity Analytics, New Use Contexts for General List, Explanation:Use Contexts added as options when creating a General List in the Client Console and Web Console: Command, Object Name, MAC Address.Benefit:Allows SIEM administrators to create lists for LogRhythm metadata fields to leverage MITRE ATT&CK and more sophisticated log sources that generate these data fields.Relevant Documentation Updates:Lists in the Client Console,Create a List in the Web Console,Use Lists with Filters\\nSecurity and Reliability, Log4j Patches, Explanation:LogRhythm made security patches to libraries, including Log4j, to resolve recently discovered vulnerabilities. This includes an Elasticsearch upgrade to version 6.8.23.Benefit:Reduces customer vulnerability to exploits.Relevant Documentation Updates:N/A\\nUser and Entity Behavior Analytics (UEBA), CloudAI, Explanation:UEBA models in LogRhythm CloudAI now map to the MITRE D3FEND matrix.Benefit:The updated models reduce alert fatigue and ensure today's complex attacks are still detected.Relevant Documentation Updates:CloudAI Lab\\nUser and Entity Behavior Analytics (UEBA), TrueIdentity Performance Increase, Explanation:Reduced the time needed to fetch and process identity data when the Mediator service starts.Benefit:Customers with large data sets ofidentities will notice a significant increase in performance.Relevant Documentation Updates:N/A\\nExplanation:\\nThe License Information Report now shows the 24-hour average MPS for each Data Processor. The License Metering Report was added to the bottom of the License Information Report. This shows the 24-hour moving average over the last 30 days, making licensing overages more visible and easier to understand.\\nBenefit:\\nThese two updates improve the accuracy and readability of MPS rates and improve users' ability to manage their license usage and lower expenses.\\nRelevant Documentation Updates:\\nAssign LogRhythm Licenses\\n(See View LogRhythm License Report section at the bottom of the page.)\\nExplanation:\\nEvent log filtering allows users to select specific types of Windows Event logs during System Monitor Agent queries. Users can also split collection from a single log source across multiple Agents.\\nBenefit:\\nEvent log filtering reduces the Agent's workload and decreases log clutter.\\nRelevant Documentation Updates:\\nAdd a Single Log Source\\n(See Additional Info Tab table in step 10.)\\nThis feature requires\\nLogRhythm System Monitor\\nto be updated to version 7.9.\\nExplanation:\\nThe Admin API library now includes System Monitoring Management endpoints. This enables SIEM administrators to manage pending or modify existing System Monitor Agents through the API.\\nBenefit:\\nThe Admin API reduces administrative overhead and expedites workflow by automating routine tasks.\\nRelevant Documentation Updates:\\nAdministration API Endpoints\\nExplanation:\\nSimplified the the process for creating Search API queries.\\nBenefit:\\nSearch API queries are easier to use.\\nRelevant Documentation Updates:\\nSearch API Endpoints\\nExplanation:\\nLogRhythm 7.9 introduces support for Windows Server 2019 and SQL 2019 on standard deployments. (Licensing entitlements vary. For more information, see Relevant Documentation Updates.)\\nBenefit:\\nEnables customers to run the latest versions of Windows Server and SQL Server.\\nRelevant Documentation Updates:\\nReview the Upgrade Requirements and Considerations\\n,\\nUpgrade Windows Server 2016 to Windows Server 2019\\n, and\\nUpgrade SQL Server 2016 to SQL Server 2019\\n.\\nL\\nogRhythm 7.9.0 does not support upgrades to\\nMicrosoft SQL Server 2019 and Windows Server 2019 on existing High Availability (HA) and Disaster Recovery (DR) environments.\\nExplanation:\\nUse Contexts added as options when creating a General List in the Client Console and Web Console: Command, Object Name, MAC Address.\\nBenefit:\\nAllows SIEM administrators to create lists for LogRhythm metadata fields to leverage MITRE ATT&CK and more sophisticated log sources that generate these data fields.\\nRelevant Documentation Updates:\\nLists in the Client Console\\n,\\nCreate a List in the Web Console\\n,\\nUse Lists with Filters\\nExplanation:\\nLogRhythm made security patches to libraries, including Log4j, to resolve recently discovered vulnerabilities. This includes an Elasticsearch upgrade to version 6.8.23.\\nBenefit:\\nReduces customer vulnerability to exploits.\\nRelevant Documentation Updates:\\nN/A\\nExplanation:\\nUEBA models in LogRhythm CloudAI now map to the MITRE D3FEND matrix.\\nBenefit:\\nThe updated models reduce alert fatigue and ensure today's complex attacks are still detected.\\nRelevant Documentation Updates:\\nCloudAI Lab\\nExplanation:\\nReduced the time needed to fetch and process identity data when the Mediator service starts.\\nBenefit:\\nCustomers with large data sets of\\nidentities will notice a significant increase in performance.\\nRelevant Documentation Updates:\\nN/A\\n\", 'Improvements': 'Users can now enable MPE Timeout when configuring SecondLook. For more information, see Data Masking in\\nCreate a SecondLook Restore\\n.\\nUsers can now filter out System Log Sources. For more information, see General tab in\\nManage Your Preferences\\n.\\nUpdated third party components to the lates compatible versions: Angular 1.8.2, jQuery 3.6.0, Go and Bazel-Gazelle.\\nUpgraded the Service Registry consul to version 1.9.4.\\n', 'Deprecated Features': 'LogRhythm 7.8 was the last published version of the SOAP API. LogRhythm is deprecating the SOAP API in favor of more effective and sustainable integration through RESTful APIs. While the SOAP API is still usable in 7.9, we encourage customers and partners using the SOAP API to migrate their integrations to REST APIs. For more information on REST integration, see our\\nREST API\\ndocumentation\\n.\\nRemoved the Content Delivery Network (CDN) setting from the Configuration Manager. This was a beta feature that is no longer in use.\\n', 'Resolved Issues': 'Bug #, Ticket #, Component, Description\\nDE1579, 350227, 354060, 351088, 358746, 360510, 4107691, AI Engine: Communication Manager, The AIE service now stops and restarts without error at reboot.\\nDE11162, 393282, AI Engine: Drilldown Cache, The AI Engine Cache Drilldown service now generates service logs as expected.\\nDE13400, 421288, AI Engine: Drilldown Cache, When reconnecting to the Web Service Host, the number of times the AIE Cache Drilldown service tries to reconnect now matches the RetryCount value set in the Configuration Manager.\\nDE6244, 353979, 395642, ARM: Alarms, When the service restarts, unprocessed alarms now persist in memory and trigger SmartResponse Plugins as expected.\\nDE11932, 406880, 419417, APIs, After a configuration change in the Console causes a service to restart, the API Gateway now recognizes that the service has restarted and allows normal functionality to resume.\\nDE11710, 375582, 400069, 414910, 418452, 418676, Admin API, When FIPS is enabled in a Disaster Recovery (DR) environment, the\\xa0Admin API now connects to SQL during failover.\\nDE12514, 402747, 413130, 420239, 422164, 422378, 426766, 427266, Admin API, The Admin API no longer inserts corrupt entries into IP Address List Items during list updates.\\nDE13736, 427551, 433515, Admin API, The Get Events by Alarm ID Admin API function no longer generates a timeout error in environments with high alarm volume (> 500 alarms/day).\\nDE13683, 418118, 427061, 425135, 428423, Client Console: AIE Event Drill Down, The Client Console AIE Drill Down now returns results consistently or provides an error message when data is not available.\\nDE1626, 345857, 423244, Client Console: AIE Rule Block Wizard, When the AIE Event Forwarding option is unchecked, the AI Engine no longer forwards events to the Events database.\\nDE13184, 420241, Client Console: Component Licensing, After uploading a new LogRhythm License, the System Monitor License no longer gets reset to Unlicensed.\\nDE10145, 418496, 420550, Client Console: Log Sources, When adding log sources from a file, the system no longer crashes.\\nDE12616, 414079, Client Console: Log Sources, When a single log source is manually added, the host name is now pre-pended to the log source name.\\nDE12151, 398662, Client Console: Rule Builder, When a Restricted Admin clicks the Custom Sort Above option in the MPE Rule Editor, the Client Console no longer crashes.\\nDE10652, 387520, Client Console: SmartResponse, When adding or modifying a\\xa0SmartResponse Plugin in an Alarm Rule, the Console no longer crashes and the Alarm Rule is saved as expected.\\nDE12721, 417589, 429854, Client Console: User, Restricted Admins can see only the log sources within the permissible entity. Log Sources on non-permissible entities are no longer visible to Restricted Admins.\\nDE13922DE13923, 427939, Client Console: User Profile ManagerSmartResponse Plugin, After drilling down on an alarm, Restricted Admins can no longer see installed SmartResponse Plugins they do not have access to.\\nDE12258, 418298, Client Console: User Profile ManagerWeb Console, Restricted Admins and Restricted Analysts who log in using SSO can now see log sources they have access to, and their Web Console search results are now accurate.\\nDE14122, 427640, Client Console: Windows Host Wizard, After a domain is successfully validated, the Windows Host Wizard no longer returns a bad username or password when attempting to scan with Secure LDAP.\\nDE12664, 416099, CloudAI: DeploymentDocumentation: Deployment, Updated specifications in the documentation for\\xa0LogRhythm deployments in AWS to ensure customers are on well-architected instances.\\nDE1737, 379934, 380707, 381030, 382490, 382962, 383576, 384654, 386466, 387765, 388771, 388894, 390540, 390649, 390651, 391117, 391911, 392708, 392736, 392968, 393716, 394580, 395961, 396018, 396112, 397309, 397905, 397970, 398903, 399006, 400187, 400388, 401868, 401976, 401994, 402528, 403427, 403583, 403688, 404059, 404864, 405260, 405714, 407070, 408033, 408292, 408377, 408608, 409560, 409760, 410088, 411135, 411906, 412162, 412835, Common Components, After a configuration change in the ARM service, procman no longer interrupts services, and Alarms continue to trigger and appear in the Web Console as expected.\\nDE12188, 409694, 408704, Common Components, When viewing the Metrics dashboard in Grafana, the Memory Used Percentage widget in the LR Metrics - Deployment View dashboard now shows correct results for timeframes greater than three hours.\\nDE11129, 393043, Data Indexer, GoMaintain no longer closes\\xa0the current active index.\\nDE12106, 407057, 411738, 413260, Data Indexer, When the Command field, Action field, or LogMessage field is larger than 32767 bytes, the Mediator now truncates the field before sending the log message in Transporter.\\nDE12350, 409401, Data Indexer, The Upgrade Checker now checks for LogRhythm versions between 7.2.0 and 7.5.1\\xa0and prompts the user with an appropriate warning message.\\nDE12799, 416374, 428902, Data Indexer, Carpenter no longer deletes\\xa0EMDB list indices without creating new ones when they are in use by a search.\\nDE13590 (Windows)DE13591 (Linux), N/A, Data Indexer, Elasticsearch no longer starts if it is unable to communicate with Service Registry and the check data path.\\nDE13805, 429257, 434551, DR, The Cluster IP setting in the Configuration Manager Global Database no longer reverts to default when the primary DR server is rebooted.\\nDE11015, 382674, 390442, 390671, 391011, 391496, 392225, Infrastructure: Database Scripts and Upgrade Scripts, The SQL Database autogrowth settings are now set to increase\\xa0in 256-MB increments and no longer cause\\xa0fragmentation.\\nDE13182, N/A, Infrastructure: Database Scripts and Upgrade Scripts, Modifications were made to improve SQL performance.\\nDE13324DE13439, 415889, 422685, Infrastructure: Database Scripts and Upgrade Scripts, Modifications were made to prevent SQL deadlocks from occurring.\\nDE14136, 431620, Infrastructure: Database Scripts and Upgrade Scripts, Updated the System Monitor Configuration Manager to allow the use of higher max values for FlushBatch, MaxServiceMemory, and MaxLogQueueMemory.\\nDE13234, 418072, 413680, Job Manager: Active Directory Synchronization, When user accounts are disabled in the LogRhythm Console, their read and write privileges are now revoked.\\nDE11792, 404360, 404501, 404217, 405620, 408614, 429047, 427107, 429996, 419659, 416145, 419620, 421265, 423159, 424244, 421282, 421918, 429829, 431459, 432862, 432073, 440508, 434347, 442110, Job Manager: Active Directory Synchronization, Active Directory users are no longer disabled in certain situations after an Active Directory Sync.\\nDE12167, 408873, Job Manager: Scheduled Reporting, When a scheduled report is successfully sent to a recipient, the Job Manager now generates the correct log message.\\nDE1113, 363911, 384172, Mediator, Cache refresh and license enumeration no longer interfere with sending heartbeat packets at the required interval.\\nDE12187, 409528, Mediator, When the license status is modified in the Client Console\\'s\\xa0Data Processor Properties configuration, the user now receives a pop-up message instructing them to re-enable the AI Engine servers assigned to the Data Processor.\\nDE12292, 415902, 409104, 413327, 414161, Mediator, The MPE Entity Network Resolution processing performance is no longer slow if there is a large number of entity networks.\\nDE12967, 415692, Mediator, The Mediator no longer sends archive files to the quarantine folder when there are issues connecting to the SQL server.\\nDE13212, 415902, 429193, Mediator, The thread lock timeout setting was increased to prevent the MPE from suspending log processing.\\nDE13626, 414739, Mediator, Reduced the time needed to fetch and process identity data when the Mediator service starts.\\nDE13848, 428101, Mediator, Changed the frequency of the Location sync in the MPE from once per minute to once per day to ensure MPE processing is not needlessly disrupted.\\nDE14646, 436667, Mediator, Resolved software crashes caused by unhandled .NET exceptions that could be encountered in the Data Processor.\\nDE11776, 404940, Notification Service, After the LogRhythm Windows Authentication Service is restarted, the Notification Service now connects to it and restarts successfully.\\nDE13108, 418782, 419135, Threat Intelligence Service, TIS STIX feed files now parse correctly.\\nDE11123DE11624, 390479, 400777, 401288, 406939, 404015, 405321, 409641, 390479, 400777, 409339, 411398, 412574, 412738, \\xa0421703, 430048, Web Console, When performing AIE Drilldowns in the Web Console, filters and exported results now show data as expected.\\nDE147, 360986, 360776, Web Console, Authentication services for Web Console now handle the change to the new tokens without errors.\\nDE10514, 381030, 420857, Web Console: Analyzer Grid, The type-ahead filters now show correct values when filtering data in the Analyzer grid.\\nDE13603, 425006, 430228, Web Console: Case API, The Case Inspector pane no longer generates an error when the user adds a large number of logs to the case and attempts to view the evidence.\\nDE13700, 416924, Web Console: Case Management, The Web Console no longer generates a 400 error when the user attaches logs to a case.\\nDE1041, 368599, Web Console UI, The Web Console now displays the same Group By and Relationship fields shown in the\\xa0AIE\\xa0rule configuration.\\nDE13605, 426338, 428752, Windows Agent: Auto-update, After updating an Agent through the System Monitor Package Manager, the\\xa0StartScmedsvrAfterReboot job no longer appears in the Task Scheduler.\\nDE12600, 413909, Windows Agent: Flat File Log Collection, The Agent no longer generates \"Failed to parse log data\" errors in the scsm.log file when processing multi-line XML flat files.\\nWhen the service restarts, unprocessed alarms now persist in memory and trigger SmartResponse Plugins as expected.\\nAfter a configuration change in the Console causes a service to restart, the API Gateway now recognizes that the service has restarted and allows normal functionality to resume.\\nWhen FIPS is enabled in a Disaster Recovery (DR) environment, the\\xa0Admin API now connects to SQL during failover.\\nThe Admin API no longer inserts corrupt entries into IP Address List Items during list updates.\\nThe Get Events by Alarm ID Admin API function no longer generates a timeout error in environments with high alarm volume (> 500 alarms/day).\\nWhen a single log source is manually added, the host name is now pre-pended to the log source name.\\nWhen a Restricted Admin clicks the Custom Sort Above option in the MPE Rule Editor, the Client Console no longer crashes.\\nDE13922\\nDE13923\\nClient Console: User Profile Manager\\nSmartResponse Plugin\\nClient Console: User Profile Manager\\nWeb Console\\nCloudAI: Deployment\\nDocumentation: Deployment\\n379934, 380707, 381030, 382490, 382962, 383576, 384654, 386466, 387765, 388771, 388894, 390540, 390649, 390651, 391117, 391911, 392708, 392736, 392968, 393716, 394580, 395961, 396018, 396112, 397309, 397905, 397970, 398903, 399006, 400187, 400388, 401868, 401976, 401994, 402528, 403427, 403583, 403688, 404059, 404864, 405260, 405714, 407070, 408033, 408292, 408377, 408608, 409560, 409760, 410088, 411135, 411906, 412162, 412835\\nAfter a configuration change in the ARM service, procman no longer interrupts services, and Alarms continue to trigger and appear in the Web Console as expected.\\nWhen viewing the Metrics dashboard in Grafana, the Memory Used Percentage widget in the LR Metrics - Deployment View dashboard now shows correct results for timeframes greater than three hours.\\nGoMaintain no longer closes\\xa0the current active index.\\nWhen the Command field, Action field, or LogMessage field is larger than 32767 bytes, the Mediator now truncates the field before sending the log message in Transporter.\\nDE13590 (Windows)\\nDE13591 (Linux)\\nThe Cluster IP setting in the Configuration Manager Global Database no longer reverts to default when the primary DR server is rebooted.\\nThe SQL Database autogrowth settings are now set to increase\\xa0in 256-MB increments and no longer cause\\xa0fragmentation.\\nDE13324\\nDE13439\\nWhen a scheduled report is successfully sent to a recipient, the Job Manager now generates the correct log message.\\nCache refresh and license enumeration no longer interfere with sending heartbeat packets at the required interval.\\nWhen the license status is modified in the Client Console\\'s\\xa0Data Processor Properties configuration, the user now receives a pop-up message instructing them to re-enable the AI Engine servers assigned to the Data Processor.\\nThe MPE Entity Network Resolution processing performance is no longer slow if there is a large number of entity networks.\\nThe thread lock timeout setting was increased to prevent the MPE from suspending log processing.\\nReduced the time needed to fetch and process identity data when the Mediator service starts.\\nChanged the frequency of the Location sync in the MPE from once per minute to once per day to ensure MPE processing is not needlessly disrupted.\\nTIS STIX feed files now parse correctly.\\nDE11123\\nDE11624\\nThe Web Console no longer generates a 400 error when the user attaches logs to a case.\\nAfter updating an Agent through the System Monitor Package Manager, the\\xa0StartScmedsvrAfterReboot job no longer appears in the Task Scheduler.\\n', 'Resolved Issues - Security': 'Security-related issues resolved with this release are available for customers to view on the\\nCommunity\\n.\\n', 'Known Issues': \"The following issues have each been found and reported by multiple users.\\nBug #, Found In Version, Components, Description, Release Notes\\nDE12608, 7.7.0, Agents, When searching System Monitor Agent Properties log sources, all log sources from all agents are displayed., Expected Results: Searching System Monitor Agent Properties log sources should return all log sources from the current agent.Workaround: There is currently no workaround for this issue.\\nDE1871, 7.3.3, AI Engine, Under conditions of load, AI Engine Rules that are written incorrectly can cause significant issues throughout the entire AIE\\xa0server., Expected Results:\\xa0Poorly written AIE Rules should be suspended until they are altered and re-enabled.Workaround:\\xa0Rewrite the AIE Rule for\\xa0better performance.\\xa0Often, this involves adding filters, reducing log sources, and\\xa0modifying the logic. Tuning an AIE Rule requires expertise, so contact LogRhythm Training, Professional Services, or a Sales Engineer to assist if necessary. Additional solutions to identify and monitor poorly performing rules are being developed for a\\xa0future release.\\nDE1759, 7.3.4, AI Engine, When the AIE service starts up, errors\\xa0are\\xa0generated multiple\\xa0times\\xa0in\\xa0the\\xa0AIE\\xa0Engine\\xa0log., Expected Results:\\xa0These errors should not be generated in the AIE Engine log, but AIE\\xa0is\\xa0working\\xa0and\\xa0alarms\\xa0are\\xa0firing.Workaround:\\xa0There is currently no workaround for this issue.\\nDE1606, 7.3.5, AI Engine, When an AIE Rule with two rule blocks has an evaluation period of 0 seconds, the rule does not trigger\\xa0as expected., Expected Results:\\xa0AIE Rule Blocks should fire when they are triggered at the same time.Workaround:\\xa0As the behavior of simultaneous events is unpredictable\\xa0and the use case for a 0-time interval is rare, LogRhythm does not plan to change this behavior at this time. To avoid the issue, set the evaluation period to 1 second.\\nDE1324, 7.4.3, AI Engine, In certain circumstances, there may be a discrepancy between the AIE event date/time and\\xa0the date/time of the message(s) triggering the AIE rule, causing the AIE event to show a future date/time., Expected Results: The date and time of the AIE Event should not have a future time.Workaround: There is no workaround for this issue.\\nDE1288, 7.4.6, AI Engine, When an AIE Rule uses the Host (Impacted) or Host (Origin) in the Group By block, the rule misfires., Expected Results:\\xa0AIE Rules should not fire if the rule block relationship is not met.Workaround:\\xa0Change the Host (origin) or Host (impacted) fields to IP Address, and the AIE Rule works as expected.\\nDE1336, 7.4.6, AI Engine, In certain circumstances, the AIE Summary Fields are not populating in the AIE Notification emails., Expected Results:\\xa0AIE Summary Fields should be displayed on all AIE Notification emails.Workaround:\\xa0View the AIE Summary Fields in the Alarm instead of the Notification email.\\nDE10501, 7.4.7, AI Engine, The Retire\\xa0logs in the C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm AI Engine\\\\HostInferenceLogs directory are not being removed after the defined number of expiration days., Expected Results: Logs in this directory should be purged after the number of days defined for expiration has passed, defaulted to 7 days.Workaround:\\xa0 Manually remove these files to prevent the C drive from filling up.\\nDE10397, 7.4.8, AI Engine, In certain circumstances, when an AIE Rule is evaluating an Observed block followed by a Not Observed block, alarms\\xa0fire even if there are logs that indicate the second block was Observed., Expected Results:\\xa0Alarms should\\xa0not fire if a log is received for a Not Observed block.Workaround:\\xa0While there is currently no workaround, LogRhythm is investigating this issue for a future release.\\nDE10313, 7.4.9, AI Engine, In rare circumstances, AIE Unique Value Rules\\xa0misfire., Expected Results:\\xa0AIE Rules should fire as expected.Workaround:While there is currently no workaround, LogRhythm is investigating this issue for a future release.\\nDE10946, 7.4.9, AI Engine, When an AIE Alarm has an action including a SmartResponse Plugin, the execution is slow., Expected Results:\\xa0Alarms should execute quickly as expected with other AIE Alarms.Workaround:\\xa0There is currently no workaround for this issue.\\nDE11051, 7.4.9, AI Engine, In certain circumstances, the AIE Engine does not consistently trigger alarms for Log Not Observed., Expected Results: The AIE Engine should trigger alarms for Log Not Observed.Workaround: There is currently no workaround for this issue.\\nDE14530DE14531, 7.9.0, AI Engine, There is no input validation for the MAC Address field in the SIEM, which means that a MAC Address could be in multiple different formats., Expected Results:Input normalization for MAC Addresses, requiring them to be entered in the accepted format.Workaround:Use data masking rules to transform the MAC addresses to the colon delimited format.\\nDE1087, 7.3.5, AI Engine, AI Engine rule group changes are not reflected in the Web Console until Web Services is restarted., Expected Results: Web Services does not need to be restarted to have a rule group change show up.Workaround: Restart Web Services.\\nDE11098, 7.4.9, Alarming, When using a SMTP server with SSL authentication, the Alarming and Response Manager fails to send alarm notifications., Expected Results:\\xa0The Alarming and Response Manager should able to send alarm notifications using any SMTP server and SSL authentication.Workaround:\\xa0There is currently no workaround for this issue.\\nDE10937, 7.4.10, Alarming, If an SRP is retired, the Alarming and Response Manager (ARM) does not recognize this and could cause the C: drive to fill\\xa0with errors trying to execute the SRP if the logging level on the ARM is set high., Expected Results: The Alarming and Response Manager should be aware of a change of status of the SRPs and should not continue to attempt to execute them.Workaround: Lower the logging level on the ARM to help mitigate this, but contact LogRhythm Technical Support if assistance is needed to retire the SRP.\\nDE6072, 7.3.4, APIs, When using a 512-bit RSA-signed certificate, Case API and Admin API do not start due to an incomplete\\xa0implementation of TLS 1.2.\\xa0This typically happens when a GPO pushes the certificate to the server., Expected Results: Case API and Admin API should start when using any size certificate.Workaround:\\xa0Remove\\xa0the\\xa0server\\xa0from\\xa0the\\xa0domain and reboot it.\\xa0Verify that the\\xa0512-bit\\xa0certificate has\\xa0been\\xa0removed, re-run the installers, and reboot. To\\xa0avoid\\xa0this issue, do not join the domain\\xa0again\\xa0or\\xa0the\\xa0certificate will\\xa0be\\xa0pushed\\xa0out\\xa0again.\\xa0In addition, create a new certificate that\\xa0uses a 384-bit (or less) hash or exclude the impacted system from the GPO that pushes\\xa0the\\xa0certificate.\\nDE1869, 7.4.7, APIs, In certain circumstances the Admin API log generates multiple invalid argument errors without providing context., Expected Results: When the Admin API log generates errors, it should provide some context within the error message.Workaround: There is currently no workaround for this issue.\\nDE10200, 7.4.9, APIs, PowerShell scripts utilizing the Case and Admin APIs may stop working upon upgrade to 7.4.9 or later.\\xa0This is due to an additional semicolon at the end of the valid content-type value., Expected Results: The extra semicolon, which is an optional valid separator in a content-type header, should not prevent scripts from working upon upgrade.Workaround:While there is currently no workaround, LogRhythm is investigating this issue for a future release.\\nDE7632, 7.1.3, Client Console, Entities cannot be deleted from within the Client Console., Expected Results: Entities\\xa0should be retireable\\xa0and able to be hidden from view.Workaround: Contact Technical Support to assist you in removing entities that are no longer needed.\\nDE7612, 7.1.7, Client Console, Reports exported to .csv format are not formatted correctly. The headers are duplicated in each row as name/value pairs., Expected Results:\\xa0When exporting reports in .csv format, the column headers should not be repeated on each row.Workaround:\\xa0The report needs to be formatted to remove columns that show the column headers. In addition, LogRhythm data can be exported using Log Distribution Services (LDS).\\nDE1829, 7.3.3, Client Console, There may be inconsistencies in the way a log parses through MPE processing and within the MPE Rule Builder. A log that parses without issue in the Rule Builder may not parse when run through MPE processing.\\xa0This could be caused by rule match timeouts., Expected Results: The processing of a log should be the same whether it is parsed in Rule Builder or MPE.Workaround: Change the sub-rule to use a different tag, such as <Tag1>.\\xa0If you are experiencing this issue, ensure that you are not using a custom Log Processing Policy and that there are no MPE timeouts.\\xa0If issues persist, contact Technical Support and reference this bug number\\xa0(DE1829) or its sister defect\\xa0(DE1651).\\nDE3195, 7.3.4, Client Console, When running a search in either the Client or Web Console, users see an error: Error fetching data - Gateway timeout., Expected Results:\\xa0When a search times out, a message should inform users and instruct them\\xa0to re-run the search with a longer timeout.Workaround:\\xa0Increase the timeout on the query and re-run it.\\nDE5185, 7.3.4, Client Console, The Network (Impacted) field does not display on reports where it is included as a column, even though data appears in that field., Expected Results:\\xa0All chosen fields should appear\\xa0on the report if they contain data.Workaround:\\xa0Running the report as an investigation yields the expected results in the Network (Impacted) column. LogRhythm is\\xa0actively working on a solution to this issue in\\xa0a future release.\\nDE4049, 7.4.6, Client Console, When running a report that contains User Origin Identity or User Impacted Identity fields, the report runs and provides data, but the Identity fields are\\xa0not\\xa0populated., Expected Results: Identity data should appear\\xa0in reports that contain those fields.Workaround: Run an investigation to provide the same information.\\nDE3932, 7.4.7, Client Console, After disabling Log Source Virtualization for a log source, users are unable to perform certain tasks on the System Monitor from which the log source is collected., Expected Results:\\xa0Disabling Log Source Virtualization should not change the behavior of the System Monitor.Workaround: This issue is caused by the scsm.ini file not being updated immediately.\\xa0To work around it, refresh the Log Sources tab in the Client Console to\\xa0force the .ini file to refresh.\\nDE3839, 7.4.8, Client Console, In certain circumstances after running a Second Look restore, an error appears stating there is an issue with the Min and Max Ticks., Expected Results:\\xa0 Second Look restore should run without issues.Workaround:\\xa0 There is currently no workaround for this issue.\\nDE10678, 7.4.8, Client Console, The Log Management Usage Auditing Event Detail, Event List, and Logon & Logoff Events reports are rendering in UTC date/time format instead of the local time., Expected Results:Reports should all display in the local time zone or that specified in the\\xa0report configuration.Workaround:\\xa0 There is currently no workaround for this issue.\\nDE10621, 7.4.9, Client Console, When an existing report template that includes the Normal Date field is edited, the Normal Date field disappears from the template until\\xa0it is added again., Expected Results:\\xa0When editing a report template, existing fields should remain unless they are explicitly removed.Workaround:\\xa0When editing a report template that contains the Normal Date field, add that field back to the template prior to saving it.\\nDE11798, 7.4.10, Client Console, When exporting a large number of logs using the Send all Logs option from the Log Viewer in Client Console, the Console freezes., Expected Results: The Console should not freeze when exporting logs.Workaround: Export selected logs instead of all logs to allow the export to complete.\\nDE11499, 7.5.1, Client Console, When DNStoIP is enabled on the Data Processor and the DNS name doesn't have a host record, the host field shows only the IP address without the host name.\\xa0 This impacts only the Client Console and is displayed correctly in the Web Console., Expected Results: The hostname should be displayed the same for both Web and Client Consoles.Workaround: View the record in the Web Console.\\nDE12893, 7.6.0, Client Console, Active Directory users that are linked to User Profiles may not be updated after moving the user to a different Active Directory group., Expected Results: Users that are moved between Active Directory groups should update upon the move.Workaround: There is no workaround for this issue other than manually updating the profiles.\\nDE12581, 7.7.0, Client Console, The Log Source Type filter in the Client Console does not work unless the Include Retired log sources box is selected., Expected Results: Users should be able to filter out the retired log sources when filtering by Log Source Type.Workaround:\\xa0 Use the Include Retired box or use another method of filtering.\\nDE12510, 7.7.0, Client Console, When importing a new SmartResponse Plugin to the Client Console, permissions have to be explicitly granted to the user account that imported the plugin., Expected Results: The user importing the SmartResponse Plugin should have permissions granted automatically.Workaround: Go into the User Profile Manager and grant access to the newly imported SmartResponse Plugin.\\nDE11717, 7.4.0, Client Console, When the Knowledge Base is synced, customized Log Source Type settings in the Windows Host Wizard revert to default., Expected Results: When custom settings are selected, they should persist through a Knowledge Base update.Workaround: Reselect the Log Source Type settings prior to doing a Windows Host Wizard scan.\\nDE10628, 7.4.8, Client Console, Duplicate Active Directory groups and users are being created because OU filters are not being used when scanning domains., Expected Results: No duplicate entries should be created.Workaround: There is currently no workaround for this issue.\\nDE12489, 7.4.9, Common Components, In rare circumstances, Alarms may not be available in the Web Console or will stop triggering. Typically, this occurs\\xa0directly after a configuration change to the ARM service., Expected Results: Alarms should continue to trigger and be displayed in the Web Console.Workaround: Contact Technical Support for assistance, as there could be many reasons for this behavior beyond this defect.\\xa0Support will help determine the root cause.\\nDE10768, 7.4.9, Common Components, In certain circumstances, the Data Processor runs slowly and the non-paged pool uses significant system memory.\\xa0This can cause a large unprocessed logs queue or other backlog in the system., Expected Results: The non-paged pool should not increase and cause system performance issues.Workaround:\\xa0Restart the LogRhythm API Gateway service.\\nDE10569, 7.4.10, Common Components, In certain circumstances, when the Platform Manager reboots, the Data Processor and Data Indexer are not able to connect to consul\\xa0and logs may not be indexed., Expected Results: The Data Processor and Data Indexer should connect to Service Registry after a reboot of the Platform Manager.Workaround: Manually restart the API Gateway and Service Registry services on the Data Indexer and Data Processor after a reboot of\\xa0the Platform Manager.\\nDE11733, 7.6.0, Common Components, When running the LogRhythm Infrastructure Installer (LRII), you may receive the\\xa0error: No plan file found in LogRhythm Service Registry KV store.\\xa0This is caused by the plan file not fully updating into the Consul KV store, and only happens in certain environments., Expected Results:\\xa0LRII\\xa0should be able to run multiple times without affecting the plan file.Workaround: For assistance with this issue, contact LogRhythm Technical Support.\\nDE12153, 7.6.0, Common Components, In some cases after a Data Indexer install, the Service Registry may not be able to communicate with the Platform Manager, causing alarms and errors in the Service Registry log., Expected Results: Communication to the Platform Manager should be maintained after an install.Workaround: Restart Service Registry on each node in the cluster after the installation is complete.\\nDE14729, 7.6.0, Common Components, Grafana does not categorize Mediators per cluster Log Indexing since moving to 7.6., Expected Results: Filter should show data processor stats for only the selected cluster.Workaround: Contact LogRhythm support for a new Mediator.json file.\\nDE3385, 7.3.2, Data Indexer, The DX Diagnostic logs are firing too often., Expected Results:The Diagnostic logs should be tuned to alarm less frequently.Workaround:There is currently no workaround for this issue.\\nDE2689, 7.4.4, Data Indexer, When the Data Indexer cluster health changes from green to yellow during EMDB list maintenance, alarms for Indexer\\xa0Cluster\\xa0Health\\xa0Excessive Warnings are generated.\\xa0This can cause concern when there is no\\xa0actual\\xa0issue on the system., Expected Results: An alarm should only generate when the cluster health changes to red.Workaround:\\xa0Edit\\xa0the\\xa0impacted\\xa0alarm\\xa0to\\xa0suppress\\xa0for\\xa024\\xa0hours\\xa0or\\xa0disable\\xa0that\\xa0alarm.\\nDE11342, 7.4.9, Data Indexer, Having entity lists with Entity (Impacted) or Entity (Origin) as filter criteria in an AIE Rule causes the alarm drill down to fail., Expected Results: Drill downs on AIE rules should work regardless of the filter criteria.Workaround: There is no workaround for this issue.\\nDE11822, 7.5.0, Data Indexer, The C:\\\\Windows\\\\Temp directory may become full with jtds.tmp files if the Carpenter service continually recycles.\\xa0 This can happen if using an SRP with List Management., Expected Results: Temporary files should not be left on disk.Workaround: Contact Technical Support for assistance with the workaround for this issue.\\nDE11765, 7.5.1, Data Indexer, In certain circumstances, Elasticsearch uses more memory than the set limit, causing performance issues on the server., Expected Results:\\xa0Elasticsearch should abide by the memory limit that is set.Workaround: For a workaround, contact LogRhythm Technical Support.\\nDE11934, 7.6.0, Data Indexer, In certain circumstances, customers with warm node indices may experience failed searches against those\\xa0indices.\\xa0This is due to Columbo being unable to close certain warm indices., Expected Results: Columbo should handle the warm node indices correctly and allow searches.Workaround: For assistance with this workaround, contact LogRhythm Technical Support.\\nDE12207, 7.6.0.HF2, Data Indexer, In some circumstances, installing the 7.6.0 Hotfix 2 upgrade will install a second instance of the Data Indexer., Expected Results: The Data Indexer should be removed and re-added instead of adding a second instance.Workaround: Uninstall both versions of the Data Indexer, ensure there or no hung .msi processes in the Task Manager, then re-install the 7.6.0 Hotfix 2 version.\\nDE13150, 7.7.0, Data Indexer, In certain circumstances after upgrading to 7.7.0, the Carpenter service causes port exhaustion and the service must be restarted., Expected Results: The Carpenter service should not cause port exhaustion.Workaround: Create a scheduled task to restart the Carpenter service each day.\\nDE12218, 7.6.0, Data Indexer, The Transporter can fail to fully start after restart at UTC midnight, causing indexing and performance issues. (This issue only impacts Linux clusters.), Expected Results: The Transporter should continue to run after a restart signal is sent.Workaround: Restart the Transporter service.\\nDE12201, 7.6.0, Data Indexer, Data is being indexed in lower case, ignoring the case of the original logs., Expected Results: Data should be stored in the format in which it was sent.Workaround: There is currently no workaround for this issue.\\nDE260DE9367, 7.4.7, Installation Components, In certain circumstances, customers may receive an alarm for a missed heartbeat on the AI Engine.\\xa0This can stem from a deadlock on resources in SQL., Expected Results: SQL deadlock issues should not cause a missed heartbeat.Workaround: While there is no\\xa0known workaround, LogRhythm is actively investigating this issue for a solution.\\nDE9995, 7.4.6, Job Manager, Scheduled reports are sent to a disabled account if an email is attached to the disabled account., Expected Results: Scheduled reports should not be sent to disabled accounts.Workaround: There is currently no workaround for this issue.\\nDE1013, 7.4.7, Job Manager, Reports are not completing when a large set of data is required.\\xa0This is due to a limitation within Crystal Reports., Expected Results: The Client Console should provide an alternate way to retrieve the data if Crystal Reports is not able to render it.Workaround: Decrease the amount of data the report is trying to retrieve or export the data instead.\\nDE11316, 7.4.10, Job Manager, Scheduled reports that do not complete within an hour return only partial results without indication of additional results available., Expected Results: The Job Manager should generate a message stating that the results were not complete and the report should indicate partial results.Workaround: There is currently no workaround for this issue.\\nDE11701, 7.4.10, Job Manager, When exporting reports as .csv files, there are duplications of headers and footers that cause the report to be much larger in size than when run in the Console., Expected Results: Exported reports should not duplicate header and footer lines.Workaround: Export the report in another format or remove the extra lines from the .csv.\\nDE11892, 7.6.0, Job Manager, When re-enabling a disabled Active Directory user, the user's LogRhythm login is not re-enabled., Expected Results: When a disabled user is re-enabled, the user's login should also be enabled during the next AD Synchronization.Workaround: Manually enable the user's login after the AD sync.\\nDE1879, 2.4, LogRhythm Diagnostics Tool, The LogRhythm Diagnostics Report shows the last backup information incorrectly., Expected Results:\\xa0The report should show the accurate last backup time for each database.Workaround:\\xa0Review the backup information in SQL Server Management Studio.\\nDE1968, 7.2.5, Mediator, Processing of Archive .bin files is sometimes delayed during heavy load and can back up at the Mediator, filling the hard drive., Expected Results:\\xa0Archives should process, seal, and move out of the Unprocessed Archives folder as long as the processing rate is at or below the system specification.Workaround:\\xa0Evaluate system sizing and consider an expansion to meet active load demands. In some systems, increasing the ArchiveSize setting in the Data Processor Advanced Properties to 51200 (from the default value of 10240) can help process archive files faster.\\xa0If necessary, move large files out of the Unprocessed Archives folder to another drive and slowly feed them back in when the system is successfully processing the live data. A more permanent solution to this issue will be provided\\xa0in a future release.\\nDE1640, 7.3.5, Mediator, The AIE Data Provider service does not start up correctly unless the Mediator service is also stopped and restarted.\\xa0Because logging is inconsistent, users\\xa0may not know that the service has failed to start properly., Expected Results:\\xa0The AIE Data Provider service should start consistently and as expected. Failures should be consistently logged to alert when the service\\xa0did not start correctly.Workaround:\\xa0Restart the Mediator service to allow the AIE Data Provider service to start. A more permanent solution to this issue is being evaluated for\\xa0a future release.\\nDE13301, 7.4.10, Mediator, In certain circumstances when\\xa0Entity Archive settings are turned on, customers may receive the following error:**ERROR** Failed to locate or create inactive subdirectory: The given key was not present in the dictionary.. Inactive archive files will be temporarily stored at the root of the system drive (C:\\\\ in most cases). This error must be corrected in order for inactive archives to be stored at the specified location., Expected Results: Entity archiving should function without errors.Workaround: There is currently no workaround for this issue.\\nDE11496, 7.5.1, Mediator, In certain circumstances, the Mediator will attempt to seal the same archive file twice.\\xa0 This causes errors in the scmedsvr.log file., Expected results: The Mediator should only attempt to seal the archive file once.Workaround: There is no workaround for this issue.\\nDE11101, 7.4.10, Smart Response Plugin, In certain circumstances, a SmartResponse action may fail to execute with an error: No System Monitor Associated with execution target., Expected Results:\\xa0 The SmartResponse Plugin should execute after selecting the System Monitor Agent.Workaround:There is currently no workaround for this issue.\\nDE12597, 7.5.0, Smart Response Plugin, When grouping two values in a SmartResponse Plugin, users receive an error that they do not have access to the Config file., Expected Results: Grouping values in SmartResponse Plugins should be allowed.Workaround: There is no workaround for this issue.\\nDE11820, 7.6.0, Smart Response Plugin, When utilizing multiple SmartResponse Plugins as part of the actions for an AIE Rule, inconsistent results may occur., Expected Results: SmartResponse Plugins should fire each time the AIE Rule is triggered.Workaround: There is no workaround for this issue.\\nDE10867, 1.2.0.10, TrueIdentity Sync Client, The TrueIdentity Sync Client will not connect to the Microsoft Active Directory LDAP server on port 636 using LDAP., Expected Results: The TrueIdentity Sync Client should be able to connect using LDAP via port 636.Workaround: Use port 389 instead and ensure the proper certificates are in place for security.\\nDE5312, 7.4.3, TrueIdentity Sync Client, The OU/DC filter in the TrueIdentity Sync Client does not allow white space., Expected Results: White space should be allowed in the OU/DC filter.Workaround: While there is no workaround for this issue, LogRhythm is\\xa0investigating a resolution for a future release.\\nDE39, 7.4.5, TrueIdentity Sync Client, The TrueIdentity Sync may fail if attempting to run\\xa0with a large number of users (greater than approximately 10,000)., Expected Results:\\xa0The TrueIdentity Sync Client should work for any number of users.Workaround:\\xa0While there is no workaround for this issue, the next release of the Sync Client will be able to support\\xa0larger AD environments.\\nDE1334, 7.3.3, Web Console, Customers who have integrated NetMon into the Web Console\\xa0may encounter a condition where the PCAP has aged out, but the user interface\\xa0indicates that it is still available. Attempting to download the PCAP results in an unclassified failure message., Expected Results:\\xa0When users try to download a PCAP that is no longer available on disk, the error message should provide that detail instead of an unclassified failure.Workaround:\\xa0The error message will be changed in a future release. There are two simple troubleshooting steps to identify if the PCAP exists or if other issues are occurring in the integration: Log in to NetMon\\xa0directly and verify if the selected PCAP has already aged out or should be available on disk. Recreate the API key for the selected NetMon\\xa0and update the NetMon configuration in the Deployment Manager.\\nDE1238, 7.4.2, Web Console, When copying a Top X widget to another dashboard, all configuration is lost after saving and refreshing the target dashboard., Expected Results:\\xa0When copying widgets, all settings should remain.Workaround:\\xa0Users can add a new widget to the dashboard and configure it manually to work around this issue. This issue is still being actively investigated and will be resolved in a future release.\\nDE7263, 7.4.2, Web Console, When exporting the results of an Investigation to .csv\\xa0from the Web Console Analyzer Grid, the date values in the first and last rows are exported as UNIX-formatted large integers rather than simple dates., Expected Results:\\xa0All data contained in the .csv export should be valid and match the data displayed in the Web Console.Workaround:\\xa0Export the same investigation from the Client Console or manually adjust the first and last date post export. LogRhythm is investigating a solution to this issue.\\nDE514, 7.4.3, Web Console, When viewing TrueIdentity records in the Web Console, 1,000 records are shown at once. Scrolling past that initial 1,000 records produces the error\\xa0message: Failed to fetch Identities: Bad Request., Expected Results:\\xa0Users should be able to scroll through all TrueIdentity records in the Web Console.Workaround:\\xa0Using filters to find specific data in the TrueIdentity page prevents the error message from showing and helps find data more quickly. LogRhythm is\\xa0working on a resolution for a future release.\\nDE1750, 7.4.6, Web Console, In certain circumstances, the Web Console may show a 500 Error page.\\xa0Typically, this occurs overnight when new service tokens are created for authentication., Expected Results: Authentication services for Web Console should handle the change to the new tokens without errors.Workaround:\\xa0Restarting the LogRhythm Authentication API on the Platform Manager mitigates this issue until the next time it occurs.\\nDE1198, 7.4.6, Web Console, When downloading large NetMon PCAPs from the Web Console, there may be\\xa0delays\\xa0to the initial\\xa0download,\\xa0increased\\xa0memory usage, or\\xa0timeouts., Expected Results: The Web Console\\xa0should not time out when downloading large PCAP files.Workaround: Change the time out setting in the Configuration Manager.\\nDE10403, 7.4.9, Web Console, The Web Console Current Processing Rate widget does\\xa0not show the correct processing rate.\\xa0It does\\xa0not include messages older than 3 minutes in the rate determined., Expected Results: The Current Processing Rate widget\\xa0should show all logs\\xa0being processed.Workaround: Resolve any log source issues that are causing old logs to be ingested, or use Grafana or Performance Counters to check the current processing rate.\\nDE10442, 7.4.9, Web Console, When viewing NetMon logs in the Web Console using Internet Explorer, the Download PCAP button does not appear., Expected Results:\\xa0The Download PCAP button should appear\\xa0when reviewing NetMon logs.Workaround:\\xa0Reload the frame with the Download PCAP button to activate it.\\nDE11124, 7.4.9, Web Console, When\\xa0SSL Port In Redirects is set to Exclude\\xa0in the Web Console configuration, links in Alarm and Case notification emails do not work., Expected Results:\\xa0The links sent in Case and Alarm notification emails should redirect to port 443 instead of 8443, as they are coming from an external location.Workaround:\\xa0Open the Web Console and manually find the Alarm or Case to review.\\nDE11463, 7.6.0, Web Console, When the browser window is zoomed out, the Node-Link Graph on the Web Console dashboards may display an error Failed to establish logs subscription with the Web Console API.\\xa0 This is not related to the zoom functionality within the Node-Link Graph itself., Expected Results:\\xa0The Node-Link Graph should function regardless of the browser zoom level.Workaround:\\xa0 Return the browser to 100% zoom and refresh the Web Console.\\nDE11663, 7.6.0, Web Console, When clicking Case Evidence logs from the Case page, the Analyze window shows a Custom Filter that prevents the logs from displaying., Expected Results: Clicking Case Evidence logs should open an Analyze page showing the logs selected.Workaround: To show the logs, click the X next to the Custom Filter.\\nDE11863, 7.6.0, Web Console, When running AIE Events drill down from an AIE events dashboard, the Analyze Dashboard filter does not reset properly., Expected Results: The Analyze Dashboard filter should reset.Workaround: In User Settings set the Drilldown setting to Open in Page.\\nDE11924, 7.6.0, Web Console, When a hostname\\xa0IP address is showing in brackets, drill downs do not work., Expected Results:Brackets should not affect the ability to drill down into a hostname.Workaround: There is no workaround for this issue.\\nDE11929, 7.6.0, Web Console, When using a Direction filter in the Web Console dashboard and\\xa0drilling into any of the TopX widgets, the data shown in the Analyzer Grid contains logs that do not match the dashboard filter., Expected Results: Drilling into data on a dashboard should not change the dashboard filter criteria.Workaround:\\xa0Reapply the dashboard filter.\\nDE12521, 7.6.0, Web Console, When pausing live data in the Web Console, the Analyzer grid continues to update with new events., Expected Results: The Analyzer grid should not\\xa0update with new events when paused.Workaround: There is currently no workaround for this issue.\\nDE12714, 7.6.0, Web Console, In the Web Console, if the last selected Analyzer page dashboard has a filter, drill down results are hidden., Expected Results:\\xa0drill down results should not be hidden.Workaround:\\xa0Select Default Analyze Dashboard\\nDE12836, 7.6.0, Web Console, When running a search or drill down in the Web Console, the operation does not return results or terminate as intended., Expected Results: The search and drill down operations should return results upon completion or terminate.Workaround: Reload the page.\\nDE12908, 7.6.0, Web Console, Event logs are not appearing in the Web Console dashboard., Expected Results: Event data should appear in the dashboard.Workaround: There is currently no workaround for this issue.\\nDE13079, 7.6.0, Web Console, When running a search or drill down in the Web Console, the operation does not return results or terminate as intended., Expected Results: The search and drill down operations should return results upon completion or terminate.Workaround: Reload the page.\\nDE12624, 7.7.0, Web Console, When using the Check Visible option in Alarms after upgrading to 7.7.0, the checked count does not reset properly., Expected Results: The checked count should reset.Workaround: After performing an action, select the Uncheck All option to reset the checked count.\\nDE13128, 7.7.0, Web Console, When running a search or drill down in the Web Console, the operation does not return results or terminate as intended., Expected Results: The search and drill down operations should return results upon completion or terminate.Workaround: Reload the page.\\nDE12852, 7.5.0, Web Console, Searching the Log Message field for a term containing a hyphen breaks the search into parts rather than searching for the full term as an exact match., Expected Results: Searching for terms should yield results for exact matches and not 'AND' the words separated by hyphens.Workaround: There is currently no workaround for this issue.\\nDE12185, 7.5.0, Web Console, Lucene widget filtering is applied globally to the entire opened dashboard when a drilldown or time slice is initiated., Expected Results: \\xa0Lucene filtering should only apply to the widget from which it originated, Other widgets on the page will still lack the drilldown or time slice,Workaround: There is currently no workaround for this issue.\\nDE15596, 7.9.0, Web Console, Data does not populate in the AI Engine Rule Tab when switching from one AIE alarm to another., Expected Results: Data should populate successfully when switching from one AIE alarm to another in the AI Engine Rule Tab.Workaround: Switching from the Data, Comments and Details tab to AI Engine Rule tab will populate the data.\\nDE15617, 7.9.0, Web Console, The Lucene Filter is not working on mouse click in widget and is also inconsistent on dashboard., Expected Results: The autosuggest value should get selected by clicking as well in the Lucene Filter.Workaround: Use the Enter key to select the value from the autosuggest popup from the Lucene Filter.\\nExpected Results\\n: Searching System Monitor Agent Properties log sources should return all log sources from the current agent.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n:\\xa0Poorly written AIE Rules should be suspended until they are altered and re-enabled.\\nWorkaround\\n:\\xa0Rewrite the AIE Rule for\\xa0better performance.\\xa0Often, this involves adding filters, reducing log sources, and\\xa0modifying the logic. Tuning an AIE Rule requires expertise, so contact LogRhythm Training, Professional Services, or a Sales Engineer to assist if necessary. Additional solutions to identify and monitor poorly performing rules are being developed for a\\xa0future release.\\nExpected Results\\n:\\xa0These errors should not be generated in the AIE Engine log, but AIE\\xa0is\\xa0working\\xa0and\\xa0alarms\\xa0are\\xa0firing.\\nWorkaround\\n:\\xa0There is currently no workaround for this issue.\\nExpected Results\\n:\\xa0AIE Rule Blocks should fire when they are triggered at the same time.\\nWorkaround\\n:\\xa0As the behavior of simultaneous events is unpredictable\\xa0and the use case for a 0-time interval is rare, LogRhythm does not plan to change this behavior at this time. To avoid the issue, set the evaluation period to 1 second.\\nExpected Results\\n: The date and time of the AIE Event should not have a future time.\\nWorkaround\\n: There is no workaround for this issue.\\nExpected Results\\n:\\xa0AIE Rules should not fire if the rule block relationship is not met.\\nWorkaround\\n:\\xa0Change the Host (origin) or Host (impacted) fields to IP Address, and the AIE Rule works as expected.\\nExpected Results\\n:\\xa0AIE Summary Fields should be displayed on all AIE Notification emails.\\nWorkaround\\n:\\xa0View the AIE Summary Fields in the Alarm instead of the Notification email.\\nExpected Results\\n: Logs in this directory should be purged after the number of days defined for expiration has passed, defaulted to 7 days.\\nWorkaround\\n:\\xa0 Manually remove these files to prevent the C drive from filling up.\\nExpected Results\\n:\\xa0Alarms should\\xa0not fire if a log is received for a Not Observed block.\\nWorkaround\\n:\\xa0While there is currently no workaround, LogRhythm is investigating this issue for a future release.\\nExpected Results\\n:\\xa0AIE Rules should fire as expected.\\nWorkaround\\n:\\nWhile there is currently no workaround, LogRhythm is investigating this issue for a future release\\n.\\nExpected Results\\n:\\xa0Alarms should execute quickly as expected with other AIE Alarms.\\nWorkaround\\n:\\xa0There is currently no workaround for this issue.\\nExpected Results\\n: The AIE Engine should trigger alarms for Log Not Observed.\\nWorkaround\\n: There is currently no workaround for this issue.\\nDE14530\\nDE14531\\nExpected Results:\\nInput normalization for MAC Addresses, requiring them to be entered in the accepted format.\\nWorkaround:\\nUse data masking rules to transform the MAC addresses to the colon delimited format.\\nExpected Results\\n: Web Services does not need to be restarted to have a rule group change show up.\\nWorkaround\\n: Restart Web Services.\\nExpected Results\\n:\\xa0The Alarming and Response Manager should able to send alarm notifications using any SMTP server and SSL authentication.\\nWorkaround\\n:\\xa0There is currently no workaround for this issue.\\nExpected Results\\n: The Alarming and Response Manager should be aware of a change of status of the SRPs and should not continue to attempt to execute them.\\nWorkaround\\n: Lower the logging level on the ARM to help mitigate this, but contact LogRhythm Technical Support if assistance is needed to retire the SRP.\\nExpected Results\\n: Case API and Admin API should start when using any size certificate.\\nWorkaround\\n:\\xa0Remove\\xa0the\\xa0server\\xa0from\\xa0the\\xa0domain and reboot it.\\xa0Verify that the\\xa0512-bit\\xa0certificate has\\xa0been\\xa0removed, re-run the installers, and reboot. To\\xa0avoid\\xa0this issue, do not join the domain\\xa0again\\xa0or\\xa0the\\xa0certificate will\\xa0be\\xa0pushed\\xa0out\\xa0again.\\xa0In addition, create a new certificate that\\xa0uses a 384-bit (or less) hash or exclude the impacted system from the GPO that pushes\\xa0the\\xa0certificate.\\nExpected Results\\n: When the Admin API log generates errors, it should provide some context within the error message.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: The extra semicolon, which is an optional valid separator in a content-type header, should not prevent scripts from working upon upgrade.\\nWorkaround\\n:\\nWhile there is currently no workaround, LogRhythm is investigating this issue for a future release\\n.\\nExpected Results\\n: Entities\\xa0should be retireable\\xa0and able to be hidden from view.\\nWorkaround\\n: Contact Technical Support to assist you in removing entities that are no longer needed.\\nExpected Results\\n:\\xa0When exporting reports in .csv format, the column headers should not be repeated on each row.\\nWorkaround\\n:\\xa0The report needs to be formatted to remove columns that show the column headers. In addition, LogRhythm data can be exported using Log Distribution Services (LDS).\\nExpected Results\\n: The processing of a log should be the same whether it is parsed in Rule Builder or MPE.\\nWorkaround\\n: Change the sub-rule to use a different tag, such as <Tag1>.\\xa0If you are experiencing this issue, ensure that you are not using a custom Log Processing Policy and that there are no MPE timeouts.\\xa0If issues persist, contact Technical Support and reference this bug number\\xa0(DE1829) or its sister defect\\xa0(DE1651).\\nExpected Results\\n:\\xa0When a search times out, a message should inform users and instruct them\\xa0to re-run the search with a longer timeout.\\nWorkaround\\n:\\xa0Increase the timeout on the query and re-run it.\\nExpected Results\\n:\\xa0All chosen fields should appear\\xa0on the report if they contain data.\\nWorkaround\\n:\\xa0Running the report as an investigation yields the expected results in the Network (Impacted) column. LogRhythm is\\xa0actively working on a solution to this issue in\\xa0a future release.\\nExpected Results\\n: Identity data should appear\\xa0in reports that contain those fields.\\nWorkaround\\n: Run an investigation to provide the same information.\\nExpected Results\\n:\\xa0Disabling Log Source Virtualization should not change the behavior of the System Monitor.\\nWorkaround\\n: This issue is caused by the scsm.ini file not being updated immediately.\\xa0To work around it, refresh the Log Sources tab in the Client Console to\\xa0force the .ini file to refresh.\\nExpected Results\\n:\\xa0 Second Look restore should run without issues.\\nWorkaround\\n:\\xa0 There is currently no workaround for this issue.\\nExpected Results:\\nReports should all display in the local time zone or that specified in the\\xa0report configuration.\\nWorkaround\\n:\\xa0 There is currently no workaround for this issue.\\nExpected Results\\n:\\xa0When editing a report template, existing fields should remain unless they are explicitly removed.\\nWorkaround\\n:\\xa0When editing a report template that contains the Normal Date field, add that field back to the template prior to saving it.\\nExpected Results\\n: The Console should not freeze when exporting logs.\\nWorkaround\\n: Export selected logs instead of all logs to allow the export to complete.\\nExpected Results\\n: The hostname should be displayed the same for both Web and Client Consoles.\\nWorkaround\\n: View the record in the Web Console.\\nExpected Results\\n: Users that are moved between Active Directory groups should update upon the move.\\nWorkaround\\n: There is no workaround for this issue other than manually updating the profiles.\\nExpected Results\\n: Users should be able to filter out the retired log sources when filtering by Log Source Type.\\nWorkaround\\n:\\xa0 Use the Include Retired box or use another method of filtering.\\nExpected Results\\n: The user importing the SmartResponse Plugin should have permissions granted automatically.\\nWorkaround\\n: Go into the User Profile Manager and grant access to the newly imported SmartResponse Plugin.\\nExpected Results\\n: When custom settings are selected, they should persist through a Knowledge Base update.\\nWorkaround\\n: Reselect the Log Source Type settings prior to doing a Windows Host Wizard scan.\\nDuplicate Active Directory groups and users are being created because OU filters are not being used when scanning domains.\\nExpected Results\\n: No duplicate entries should be created.\\nWorkaround\\n: There is currently no workaround for this issue.\\nDE12489\\nExpected Results\\n: Alarms should continue to trigger and be displayed in the Web Console.\\nWorkaround\\n: Contact Technical Support for assistance, as there could be many reasons for this behavior beyond this defect.\\xa0Support will help determine the root cause.\\nExpected Results\\n: The non-paged pool should not increase and cause system performance issues.\\nWorkaround\\n:\\xa0Restart the LogRhythm API Gateway service.\\nExpected Results\\n: The Data Processor and Data Indexer should connect to Service Registry after a reboot of the Platform Manager.\\nWorkaround\\n: Manually restart the API Gateway and Service Registry services on the Data Indexer and Data Processor after a reboot of\\xa0the Platform Manager.\\nExpected Results\\n:\\xa0LRII\\xa0should be able to run multiple times without affecting the plan file.\\nWorkaround\\n: For assistance with this issue, contact LogRhythm Technical Support.\\nExpected Results\\n: Communication to the Platform Manager should be maintained after an install.\\nWorkaround\\n: Restart Service Registry on each node in the cluster after the installation is complete.\\nExpected Results\\n: Filter should show data processor stats for only the selected cluster.\\nWorkaround\\n: Contact LogRhythm support for a new Mediator.json file.\\nExpected Results:\\nThe Diagnostic logs should be tuned to alarm less frequently.\\nWorkaround\\n:\\nThere is currently no workaround for this issue\\n.\\nExpected Results\\n: An alarm should only generate when the cluster health changes to red.\\nWorkaround\\n:\\xa0Edit\\xa0the\\xa0impacted\\xa0alarm\\xa0to\\xa0suppress\\xa0for\\xa024\\xa0hours\\xa0or\\xa0disable\\xa0that\\xa0alarm.\\nExpected Results\\n: Drill downs on AIE rules should work regardless of the filter criteria.\\nWorkaround\\n: There is no workaround for this issue.\\nExpected Results\\n: Temporary files should not be left on disk.\\nWorkaround\\n: Contact Technical Support for assistance with the workaround for this issue.\\nExpected Results\\n:\\xa0Elasticsearch should abide by the memory limit that is set.\\nWorkaround\\n: For a workaround, contact LogRhythm Technical Support.\\nExpected Results\\n: Columbo should handle the warm node indices correctly and allow searches.\\nWorkaround\\n: For assistance with this workaround, contact LogRhythm Technical Support.\\nExpected Results\\n: The Data Indexer should be removed and re-added instead of adding a second instance.\\nWorkaround\\n: Uninstall both versions of the Data Indexer, ensure there or no hung .msi processes in the Task Manager, then re-install the 7.6.0 Hotfix 2 version.\\nExpected Results\\n: The Carpenter service should not cause port exhaustion.\\nWorkaround\\n: Create a scheduled task to restart the Carpenter service each day.\\nExpected Results\\n: The Transporter should continue to run after a restart signal is sent.\\nWorkaround\\n: Restart the Transporter service.\\nExpected Results\\n: Data should be stored in the format in which it was sent.\\nWorkaround\\n: There is currently no workaround for this issue.\\nDE260\\nDE9367\\nExpected Results\\n: SQL deadlock issues should not cause a missed heartbeat.\\nWorkaround\\n: While there is no\\xa0known workaround, LogRhythm is actively investigating this issue for a solution.\\nExpected Results\\n: Scheduled reports should not be sent to disabled accounts.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: The Client Console should provide an alternate way to retrieve the data if Crystal Reports is not able to render it.\\nWorkaround\\n: Decrease the amount of data the report is trying to retrieve or export the data instead.\\nExpected Results\\n: The Job Manager should generate a message stating that the results were not complete and the report should indicate partial results.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: Exported reports should not duplicate header and footer lines.\\nWorkaround\\n: Export the report in another format or remove the extra lines from the .csv.\\nExpected Results\\n: When a disabled user is re-enabled, the user's login should also be enabled during the next AD Synchronization.\\nWorkaround\\n: Manually enable the user's login after the AD sync.\\nExpected Results\\n:\\xa0The report should show the accurate last backup time for each database.\\nWorkaround\\n:\\xa0Review the backup information in SQL Server Management Studio.\\nExpected Results\\n:\\xa0Archives should process, seal, and move out of the Unprocessed Archives folder as long as the processing rate is at or below the system specification.\\nWorkaround\\n:\\xa0Evaluate system sizing and consider an expansion to meet active load demands. In some systems, increasing the ArchiveSize setting in the Data Processor Advanced Properties to 51200 (from the default value of 10240) can help process archive files faster.\\xa0If necessary, move large files out of the Unprocessed Archives folder to another drive and slowly feed them back in when the system is successfully processing the live data. A more permanent solution to this issue will be provided\\xa0in a future release.\\nExpected Results\\n:\\xa0The AIE Data Provider service should start consistently and as expected. Failures should be consistently logged to alert when the service\\xa0did not start correctly.\\nWorkaround\\n:\\xa0Restart the Mediator service to allow the AIE Data Provider service to start. A more permanent solution to this issue is being evaluated for\\xa0a future release.\\nIn certain circumstances when\\xa0Entity Archive settings are turned on, customers may receive the following error:\\n**ERROR** Failed to locate or create inactive subdirectory: The given key was not present in the dictionary.. Inactive archive files will be temporarily stored at the root of the system drive (C:\\\\ in most cases). This error must be corrected in order for inactive archives to be stored at the specified location.\\nExpected Results\\n: Entity archiving should function without errors.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected results\\n: The Mediator should only attempt to seal the archive file once.\\nWorkaround\\n: There is no workaround for this issue.\\nExpected Results\\n:\\xa0 The SmartResponse Plugin should execute after selecting the System Monitor Agent.\\nWorkaround\\n:\\nThere is currently no workaround for this issue\\n.\\nExpected Results\\n: Grouping values in SmartResponse Plugins should be allowed.\\nWorkaround\\n: There is no workaround for this issue.\\nExpected Results\\n: SmartResponse Plugins should fire each time the AIE Rule is triggered.\\nWorkaround\\n: There is no workaround for this issue.\\nExpected Results\\n: The TrueIdentity Sync Client should be able to connect using LDAP via port 636.\\nWorkaround\\n: Use port 389 instead and ensure the proper certificates are in place for security.\\nExpected Results\\n: White space should be allowed in the OU/DC filter.\\nWorkaround\\n: While there is no workaround for this issue, LogRhythm is\\xa0investigating a resolution for a future release.\\nExpected Results\\n:\\xa0The TrueIdentity Sync Client should work for any number of users.\\nWorkaround\\n:\\xa0While there is no workaround for this issue, the next release of the Sync Client will be able to support\\xa0larger AD environments.\\nExpected Results\\n:\\xa0When users try to download a PCAP that is no longer available on disk, the error message should provide that detail instead of an unclassified failure.\\nWorkaround\\n:\\xa0The error message will be changed in a future release. There are two simple troubleshooting steps to identify if the PCAP exists or if other issues are occurring in the integration: Log in to NetMon\\xa0directly and verify if the selected PCAP has already aged out or should be available on disk. Recreate the API key for the selected NetMon\\xa0and update the NetMon configuration in the Deployment Manager.\\nExpected Results\\n:\\xa0When copying widgets, all settings should remain.\\nWorkaround\\n:\\xa0Users can add a new widget to the dashboard and configure it manually to work around this issue. This issue is still being actively investigated and will be resolved in a future release.\\nExpected Results\\n:\\xa0All data contained in the .csv export should be valid and match the data displayed in the Web Console.\\nWorkaround\\n:\\xa0Export the same investigation from the Client Console or manually adjust the first and last date post export. LogRhythm is investigating a solution to this issue.\\nExpected Results\\n:\\xa0Users should be able to scroll through all TrueIdentity records in the Web Console.\\nWorkaround\\n:\\xa0Using filters to find specific data in the TrueIdentity page prevents the error message from showing and helps find data more quickly. LogRhythm is\\xa0working on a resolution for a future release.\\nDE1750\\nExpected Results\\n: Authentication services for Web Console should handle the change to the new tokens without errors.\\nWorkaround\\n:\\xa0Restarting the LogRhythm Authentication API on the Platform Manager mitigates this issue until the next time it occurs.\\nExpected Results\\n: The Web Console\\xa0should not time out when downloading large PCAP files.\\nWorkaround\\n: Change the time out setting in the Configuration Manager.\\nExpected Results\\n: The Current Processing Rate widget\\xa0should show all logs\\xa0being processed.\\nWorkaround\\n: Resolve any log source issues that are causing old logs to be ingested, or use Grafana or Performance Counters to check the current processing rate.\\nExpected Results\\n:\\xa0The Download PCAP button should appear\\xa0when reviewing NetMon logs.\\nWorkaround\\n:\\xa0Reload the frame with the Download PCAP button to activate it.\\nExpected Results\\n:\\xa0The links sent in Case and Alarm notification emails should redirect to port 443 instead of 8443, as they are coming from an external location.\\nWorkaround\\n:\\xa0Open the Web Console and manually find the Alarm or Case to review.\\nExpected Results\\n:\\xa0The Node-Link Graph should function regardless of the browser zoom level.\\nWorkaround\\n:\\xa0 Return the browser to 100% zoom and refresh the Web Console.\\nExpected Results\\n: Clicking Case Evidence logs should open an Analyze page showing the logs selected.\\nWorkaround\\n: To show the logs, click the X next to the Custom Filter.\\nExpected Results\\n: The Analyze Dashboard filter should reset.\\nWorkaround\\n: In User Settings set the Drilldown setting to Open in Page.\\nExpected Results:\\nBrackets should not affect the ability to drill down into a hostname.\\nWorkaround\\n: There is no workaround for this issue.\\nExpected Results\\n: Drilling into data on a dashboard should not change the dashboard filter criteria.\\nWorkaround\\n:\\xa0Reapply the dashboard filter.\\nExpected Results\\n: The Analyzer grid should not\\xa0update with new events when paused.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n:\\xa0drill down results should not be hidden.\\nWorkaround\\n:\\xa0Select Default Analyze Dashboard\\nExpected Results\\n: The search and drill down operations should return results upon completion or terminate.\\nWorkaround\\n: Reload the page.\\nExpected Results\\n: Event data should appear in the dashboard.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: The search and drill down operations should return results upon completion or terminate.\\nWorkaround\\n: Reload the page.\\nExpected Results\\n: The checked count should reset.\\nWorkaround\\n: After performing an action, select the Uncheck All option to reset the checked count.\\nExpected Results\\n: The search and drill down operations should return results upon completion or terminate.\\nWorkaround\\n: Reload the page.\\nExpected Results\\n: Searching for terms should yield results for exact matches and not 'AND' the words separated by hyphens.\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: \\xa0Lucene filtering should only apply to the widget from which it originated, Other widgets on the page will still lack the drilldown or time slice,\\nWorkaround\\n: There is currently no workaround for this issue.\\nExpected Results\\n: Data should populate successfully when switching from one AIE alarm to another in the AI Engine Rule Tab.\\nWorkaround\\n: Switching from the Data, Comments and Details tab to AI Engine Rule tab will populate the data.\\nExpected Results\\n: The autosuggest value should get selected by clicking as well in the Lucene Filter.\\nWorkaround\\n: Use the Enter key to select the value from the autosuggest popup from the Lucene Filter.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n', 'Application Tab': 'The fields in the Application tab describe the\\nImpacted Object\\nreferenced by the log. The Application tab contains the most fields.\\nThe following fields are on the Application tab:\\nAction [7.2]\\nAmount\\nCommand\\nHash [7.2]\\nIANA Protocol Name\\nIANA Protocol Number\\nObject\\nObject Name\\nObject Type [7.2]\\nParent Process ID [7.2]\\nParent Process Name [7.2]\\nParent Process Path [7.2]\\nPolicy [7.2]\\nProcess ID\\nProcess Name\\nQuantity\\nRate\\nReason [7.2]\\nResponse Code [7.2]\\nResult [7.2]\\nSession\\nSession Type [7.2]\\nSize\\nStatus [7.2]\\nSubject\\nURL\\nUser Agent [7.2]\\nVersion\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n', 'Classification Tab': 'This section contains the fields displayed in the Classification tab. These fields relate to metadata around the log, focusing on adding context to the information in other tabs that are more descriptive of the object.\\nThe following fields are on the Classification tab:\\nCVE [7.2]\\nSeverity\\nThreat ID [7.2]\\nThreat Name [7.2]\\nVendor Info [7.2]\\nVendor Message ID\\nThere are several polyfields and injected/configuration data in this section, including:\\nClassification\\nCommon Event\\nPriority\\nDirection\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n', 'Derived Data': 'Derived data is not parsed in the schema, but is instead inferred and built from other metadata fields.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n', 'Host Tab': 'The Host Tab contains fields that help identify the impacted or origin host, such as IP, hostname, MAC address, and so on.\\nThe following fields are on the Host tab:\\nDIP/DestinationIP/Impacted IP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted Interface\\nImpacted MAC Address\\nImpacted NAT IP\\nIP Address (Origin)\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin Interface\\nOrigin MAC Address\\nOrigin NAT IP\\nSerial Number [7.2]\\nSIPv4\\nSIPv6\\nSIPv6E\\nMany fields in this tab are polyfields including:\\nHost (Origin)\\nHost (Impacted)\\nIP Address (Origin)\\nIP Address (Impacted)\\nHostname (Origin)\\nHostname (Impacted)\\nKnown Host (Origin)\\nKnown Host (Impacted)\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n', 'Identity Tab': 'The identity tab contains metadata fields related to the user associated with the action or object in the log.\\nThe following fields are on the Identity tab:\\nAccount > User (Impacted)\\nGroup\\nLogin > User (Origin)\\nRecipient\\nSender\\nThis tab contains one polyfield: User (Impacted).\\nThis tab contains four Identity Analytics fields: User Identity (Origin), User Identity (Impacted), Sender Identity, and Recipient Identity.\\nIdentity Analytics fields aggregate multiple identifiers for a user/email into a single unique ID. Each Identity Field is mapped to the corresponding MPE metadata field described in this section. These fields are not available for parsing. For more information about Identity Analytics fields, see\\nIdentity-Derived Data\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n', 'Kbytes/Packets Tab': 'Schema fields that are displayed in the Kybtes/Packets tab of the Web Console. All fields in this section are polyfields:\\nHost (Impacted) Kbytes Rcvd\\nHost (Impacted) Kbytes Sent\\nHost (Impacted) Kbytes Total\\nHost (Impacted) Packets Rcvd\\nHost (Impacted) Packets Sent\\nHost (Impacted) Packets Total\\nThese fields are calculated from source data that is parsed in fields with different names, different units, or both.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n', 'Location Tab': 'The Location tab contains fields that attempt to identify a physical or logical location for the object referenced in a log.\\nThe Location fields are either polyfields or enrichment fields added after parsing:\\nEntity (Origin)\\nEntity (Impacted)\\nZone (Origin)\\nZone (Impacted)\\nLocation (Origin)\\nLocation (Impacted)\\nCountry (Origin)\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n', 'Log Tab': '\\nThe Log tab contains metadata that describe the log source rather than the log itself.\\nMost of these fields are generated by the log source type or agent configuration. They are not parsed into the schema from the raw log:\\nLog count\\nLog source entity\\nLog source type\\nLog source host\\nLog source\\nLog sequence number (from Agent)\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n', 'Network Tab': 'The Network tab contains fields that relate to the networks associated with the origin and impacted host.\\nThe following fields are on the Network tab:\\nDomain [7.2] (Domain (Impacted))\\nImpacted NAT Port\\nImpacted Port\\nOrigin NAT Port\\nOrigin Port\\nSeveral of the network fields are polyfields or are auto-calculated based on the entity structure:\\nNetwork (Origin)\\nNetwork (Impacted)\\nProtocol\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n', 'Other MPE Fields': 'These fields do not immediately map to a tab in the Web Console:\\nItems In\\nItems Out\\n[Tag1-Tag5]\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Action [7.2]': 'Action is a broad field for what was done as described in the log. Action is usually a secondary function of a command or process.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Action\\nClient Console Short Name, Action\\nWeb Console Tab/Name, Action\\nElasticsearch Field Name, action\\nRule Builder Column Name, Action\\nRegex Pattern, <action>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nAction\\nClient Console Short Name\\nAction\\nWeb Console Tab/Name\\nAction\\nElasticsearch Field Name\\naction\\nRule Builder Column Name\\nAction\\nRegex Pattern\\n<action>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Command\\nStatus\\nResult\\nResponse Code\\nProcess\\n', 'Common Applications': 'Firewall\\nProxy\\nAntivirus\\nIDS/IPS\\nVulnerability scanner\\nRIM/FIM\\n', 'Use Case': 'Recording network traffic accepts, drops, or blocks.\\nSecondary function of a command—for example, PowerShell (process), might issue \"AD commandlet\" (command), which might have an action of lock out user.\\nAction describes a mechanism. The result describes a state outcome. A firewall action can \"pass\" traffic. The result might be \"success.”\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Capture more simplistic actions than command might.\\nAn Action is what you are trying to initiate via a command.\\nAction, Process, and Command separation:\\nA process is something \"running.\"\\nA command is an operating system command (for example, batch) or a user originated command to a system.\\nThe Action is often the \"result\" of a process or command. The A/V process (Symantec) might have a command of \"Run Scan\", which could have an Action of Quarantine.\\nA process is something \"running.\"\\nA command is an operating system command (for example, batch) or a user originated command to a system.\\nThe Action is often the \"result\" of a process or command. The A/V process (Symantec) might have a command of \"Run Scan\", which could have an Action of Quarantine.\\nIn RIM/FIM, the Action would be \"read, write, add, delete\" or any other common action verb applied to the file or registry key.\\n', 'Examples': 'FortiGate\\n02 18 2015 16:13:49 1.1.1.1 <LOC7:INFO> date=2015-02-18 time=16:13:51 devname=FG22222222222217 devid=FGdfsdfds1111111 logid=1059028704 type=utm subtype=app-ctrl eventtype=app-ctrl-all level=information vd=\"root\" appid=16637 user=\"pete.store\" srcip=1.1.1.1 srcport=57227 dstip=1.1.1.1 dstport=53 proto=17 service=\"DNS\" sessionid=391322221 applist=\"APPC Monitor All\" appcat=\"Update\" app=\"Sophos.Update\"\\naction=pass\\nmsg=\"Update: Sophos.Update,\" apprisk=low\\nIn this case, the firewall action is to \"pass\" the traffic because it is on an approved list.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Amount': 'The qualitative description of quantity (percentage or relative numbers).\\n', 'Data Type': 'Double\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Amount\\nClient Console Short Name, Amount\\nWeb Console Tab/Name, Amount\\nElasticsearch Field Name, amount\\nRule Builder Column Name, Amount\\nRegex Pattern, <amount>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nAmount\\nClient Console Short Name\\nAmount\\nWeb Console Tab/Name\\nAmount\\nElasticsearch Field Name\\namount\\nRule Builder Column Name\\nAmount\\nRegex Pattern\\n<amount>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Quantity\\nRate\\nSize\\n', 'Common Applications': 'Point of Sale\\nHardware Monitoring\\n', 'Use Case': 'Capturing price into amount and quantity of items purchased to quantity for fraud analytics.\\nMonitoring disk or CPU use and thresholds.\\nCapturing the\\nCVSSv3BASE standard from Qualys logs.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Currency amounts can be captured here.\\nPercentages can be captured here.\\n', 'Examples': 'Huawei Access Router\\n04 07 2014 15:43:50 1.1.1.1 <LOC7:WARN> Apr\\xa0 7 2014 13:43:49 USABLDRRECFLOW01 %%01CPUP/4/CPU_USAGE_HIGH(l)[1237]:The CPU is overloaded, and the tasks with top three CPU occupancy are HardIrq(80.8%), TICK(6.8%), ROUT(2.2%) . (\\nCpuUsage=83%\\n, Threshold=80%)\\nIndicates the percent amount of CPU usage on router.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Command': 'The specific command executed that has been recorded in the log message.\\nData Type\\nString\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Command\\nClient Console Short Name, Command\\nWeb Console Tab/Name, Command\\nElasticsearch Field Name, command\\nRule Builder Column Name, Command\\nRegex Pattern, <command>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nCommand\\nClient Console Short Name\\nCommand\\nWeb Console Tab/Name\\nCommand\\nElasticsearch Field Name\\ncommand\\nRule Builder Column Name\\nCommand\\nRegex Pattern\\n<command>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Result\\nStatus\\nProcess\\nAction\\n', 'Common Applications': 'PowerShell\\nWindows Command Shell\\nSSH\\nTelnet\\nBash\\n', 'Use Case': 'Cron\\nSudo\\nAuditing\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Vendor Message ID is a unique event type identifier.\\nCommand identifies an executable or script with arguments.\\nMay contain an executable, but is distinct from Process.\\nCan describe the execution of a process.\\nCommand within a process.\\nOften specifically called out as CMD or Command.\\nNot Action (for example, Firewall Block/Allow).\\nNot Result (Command can have a Result).\\nCommand may describe Action.\\n', 'Examples': '', 'Correct Examples': 'CrowdStrike FalconHost\\n12 14 2016 18:53:39 1.1.1.1 <USER:NOTE> CEF:0|CrowdStrike|FalconHost|1.0|ScanResults|AV Scan Results In A Detection Summary Event|4| externalID=2222222222222222eee799 cn2Label=ProcessId cn2=148181079514282 shost=WIN-HPBKBMLLSST suser=pete.store fname=GoogleUpdate.exe filePath=\\\\\\\\Device\\\\\\\\HarddiskVolume1\\\\\\\\Users\\\\\\\\pete.store\\\\\\\\AppData\\\\\\\\Local fileHash=e361a8c5da2e3d1a0ed3be85ed906dad cs1Label=CommandLine cs1=\"\\nC:\\\\\\\\Users\\\\\\\\pete.store\\\\\\\\AppData\\\\\\\\Local\\\\\\\\GoogleUpdate.exe\\n\" sntdom=safaware cs2Label=ScanResultEngine cs2=AVware cs3Label=ScanResultName cs3=Trojan-Downloader.Win32.Fraudload cn4Label=ScanResultVersion cs4=1.1.1.1 cs6Label=FalconHostLink cs6=\\nhttps://falcon.crowdstrike.com/activity/detections/detail/ec3f4ca727a04f025f2ea97647a61799/222222222\\ncn3Label=Offset cn3=1066242\\nSpecifically called out Command Line, even though it is an executable.\\nCrowdStrike FalconHost\\n12 15 2016 00:19:05 1.1.1.1 <USER:NOTE> CEF:0|CrowdStrike|FalconHost|1.0|ScanResults|AV Scan Results In A Detection Summary Event|3| externalID=022222222222222222ea584f3783f5b1eee9 cn2Label=ProcessId cn2=1482087830222222 shost= USABLDRRECFLOW01suser=Pete.Store fname=upnp.exe filePath=\\\\\\\\Device\\\\\\\\HarddiskVolume1\\\\\\\\Users\\\\\\\\pete.store\\\\\\\\AppData\\\\\\\\Local\\\\\\\\Temp fileHash=13804f8dc4e72ba103d5e34de895c9db cs1Label=CommandLine cs1=\"\\nC:\\\\\\\\Users\\\\\\\\ALVINF~1\\\\\\\\AppData\\\\\\\\Local\\\\\\\\Temp\\\\\\\\upnp.exe\" -a 1.1.1.1 1604 1604 TCP\\nsntdom=safaware cs2Label=ScanResultEngine cs2=TrendMicro cs3Label=ScanResultName cs3=TROJ_GEN.R0FBC0CI116 cn4Label=ScanResultVersion cs4=1.1.1.12 cs6Label=FalconHostLink cs6=\\nhttps://falcon.crowdstrike.com/activity/detections/detail/02c60e7a579b4fea584f3783f5b1eee9/222222222\\ncn3Label=Offset cn3=1066392\\nExecutable with arguments.\\nAIX\\n02 20 2013 09:16:33 1.1.1.1 <SAU1:NOTE> Feb 20 09:16:33 Message forwarded from USABLDRRECFLOW01: sudo:\\xa0 dt14437 : TTY=pts/0 ; PWD=/dst/home/omg37 ; USER=root ; COMMAND=\\n/usr/bin/crontab -l\\nCommand called out explicitly.\\nProofpoint Spam Firewall\\n12 07 2011 14:19:10 1.1.1.1 <USER:NOTE> Dec\\xa0 7 14:19:10 filter_instance1 rprt s=11huq2222 m=1 x=pB7JJAlE02222 mod=access cmd=\\nrun\\nrule=spamsafe duration=0.000\\nRun is the Command, not the Process.\\n', 'Incorrect Examples': 'Check Point Firewall\\n26Feb2013 14:59:21 Product=VPN-1 & FireWall-1 OriginIP=1.1.1.1 Origin= USABLDRRECFLOW01Action=\\nencrypt\\nSIP=1.1.1.1 Source= USABLDRRECFLOW01SPort=0 DIP=1.1.1.1 Destination= USABLDRRECFLOW01DPort=0 Protocol=icmp ICMPType=8 ICMPCode=0 IFName=eth1 IFDirection=inbound Reason=- Rule=32 Info=- XlateSIP=1.1.1.1 XlateSPort=- XlateDIP=- XlateDPort=-\\nEncrypt is not a command. Encrypt is better parsed into Action.\\nJuniper Firewall\\n04 22 2012 17:28:13 1.1.1.1 <USER:INFO> 1 2012-04-23T08:27:25.564\\xa0 RT_FLOW -\\nRT_FLOW_SESSION_CLOSE\\n[junos@21.1.1.1.2.41 reason=\"unset\" source-address=\"1.1.1.1\" source-port=\"138\" destination-address=\"1.1.1.1\" destination-port=\"138\" service-name=\"junos-nbds\" nat-source-address=\"1.1.1.1\" nat-source-port=\"138\" nat-destination-address=\"1.1.1.1\" nat-destination-port=\"138\" src-nat-rule-name=\"None\" dst-nat-rule-name=\"None\" protocol-id=\"17\" policy-name=\"allowAll\" source-zone-name=\"trust\" destination-zone-name=\"trust\" session-id-32=\"21434\" packets-from-client=\"1\" bytes-from-client=\"229\" packets-from-server=\"0\" bytes-from-server=\"0\" elapsed-time=\"59\" application=\"UNKNOWN\" nested-application=\"UNKNOWN\" username=\"N/A\" roles=\"N/A\" packet-incoming-interface=\"fe-0/0/7.0\"]\\nRT_FLOW_SESSION_CLOSE is not a command. RT_FLOW_SESSION_CLOSE is VMID.\\nPalo Alto Firewall\\n02 24 2015 15:21:01 1.1.1.1 <USER:INFO> Feb 24 15:21:01 1,2015/02/24 15:21:01,0011C100222,TRAFFIC,\\ndrop\\n,0,2015/02/24 15:21:01,1.1.1.1,1.1.1.1,1.1.1.1,1.1.1.1,\\ndenyall\\n,,,not-applicable,vsys1,dmz,inet,ethernet1/9,,LogRhythm-Receiver,2015/02/24 15:21:00,0,1,64812,443,0,0,0x0,tcp,deny,66,66,0,1,2015/02/24 15:21:02,0,any,0,27629666933,0x0,United States,United States,0,1,0\\nDrop is not the Command. Drop is the Action. Denyall is not Command either. Denyall is closer to Result (could also be the name of a Policy).\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Hash [7.2]': 'The hash value (for example, MD5 or SHA256) of a file, process, or object. The value is independent of the algorithm. Only the resulting hash is stored in this field.\\nOnly three hash types are in common usage: MD5, SHA1, and SHA256.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'Alphanumeric string (0-512 characters, 64 average characters)\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Hash\\nClient Console Short Name, Hash\\nWeb Console Tab/Name, Hash\\nElasticsearch Field Name, hash\\nRule Builder Column Name, Hash\\nRegex Pattern, <hash>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nHash\\nClient Console Short Name\\nHash\\nWeb Console Tab/Name\\nHash\\nElasticsearch Field Name\\nhash\\nRule Builder Column Name\\nHash\\nRegex Pattern\\n<hash>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Object, Process, and Object Name fields. This is the hash for the process identified in process.\\n', 'Common Applications': 'IDS/IPS\\nVulnerability scanners\\nEndpoint monitoring (for example, Cbresponse)\\nThreat Intelligence feeds\\nAntivirus\\n', 'Use Case': 'Mapping hash value to threat feeds and known Indictators of Compromise (IOCs).\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Priority if there are multiple hashes is MD5 > SHA1 > SHA256, until strongly typed fields available.\\nMake it as easy as possible to match to most common threat feeds.\\nDo not include the hash type in the field (for example, remove MD5:).\\n', 'Examples': 'Cylance log sample\\nSample - 05 09 2016 21:40:29 1.1.1.1 <SLOG:WARN> 1 2016-05-10T02:40:19.2905167Z sysloghost CylancePROTECT - - - Event Type: AppControl, Event Name: pechange, Device Name: US-JNTJKV1, IP Address: (1.1.1.1, 1.1.1.1,), Action: Deny, Action Type: PE File Change, File Path: C:\\\\Users\\\\Public\\\\TechTools\\\\Host65,\\nSHA256:\\n8050FE3DCA43D594611492AA149AF09FC9669149602BB2945AFEA4148A24B175\\nParse the hash removing the algorithm header SHA256.\\nCb Response log sample\\nSample - 05 13 2016 20:56:15 1.1.1.1 <USER:NOTE> LEEF:1.0|CB|CB|5.1|watchlist.hit.binary|cb_server=cbserver\\xa0\\xa0\\xa0 cb_version=511\\xa0\\xa0\\xa0 company_name=Microsoft Corporation\\xa0\\xa0\\xa0 copied_mod_len=11616\\xa0\\xa0\\xa0 digsig_issuer=Microsoft Windows Production PCA 2011\\xa0\\xa0\\xa0 digsig_prog_name=Microsoft Windows\\xa0\\xa0\\xa0 digsig_publisher=Microsoft Corporation\\xa0\\xa0\\xa0 digsig_result=Signed\\xa0 \\xa0\\xa0digsig_result_code=0\\xa0\\xa0\\xa0 digsig_sign_time=2015-10-30T12:32:00Z\\xa0\\xa0\\xa0 digsig_subject=Microsoft Windows\\xa0\\xa0\\xa0 endpoint=[\" USABLDRRECFLOW01\"]\\xa0\\xa0\\xa0 file_desc=recordflow console\\xa0\\xa0\\xa0 file_version=10.0.10.0 (th2_release.151029-1700)\\xa0\\xa0\\xa0 group=[\"Testing\"]\\xa0\\xa0\\xa0 host_count=1\\xa0 \\xa0\\xa0internal_name=recflowcon\\xa0\\xa0\\xa0 is_64bit=true\\xa0\\xa0\\xa0 is_executable_image=false\\xa0\\xa0\\xa0 last_seen=2016-05-14T03:42:10.709Z\\xa0\\xa0\\xa0 legal_copyright=© Record Flow LLC. All rights reserved.\\nmd5=\\n59E0D058686BD35B0D5C02A4FD8BD0E0observed_filename=[\"c:\\\\\\\\windows\\\\\\\\system32\\\\\\\\downlevel\\\\\\\\api-ms-win-core-stringansi-l1-1-0.dll\"]\\xa0\\xa0\\xa0 orig_mod_len=11616\\xa0\\xa0\\xa0 original_filename=apisetstub\\xa0\\xa0\\xa0 os_type=Windows\\xa0\\xa0\\xa0 product_name=Microsoft® Windows® Operating System\\xa0\\xa0\\xa0 product_version=10.0.10586.0\\xa0\\xa0\\xa0 server_added_timestamp=2016-05-14T03:42:10.709Z \\xa0\\xa0\\xa0server_name=USABLDRRECFLOW01 signed=Signed\\xa0\\xa0\\xa0 timestamp=2016-05-14T03:42:10.709Z\\xa0\\xa0\\xa0 type=watchlist.hit.binary\\xa0\\xa0\\xa0 watchlist_id=4\\xa0\\xa0\\xa0 watchlist_name=Newly Loaded Modules\\nParse the hash removing the type md5=.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'IANA Protocol Name': 'The IANA Protocol Name representing the official registered name for well-known network protocols. For more information, see\\nRFC 5237\\nand\\nRFC 7045\\n.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Known Application\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Application\\nElasticsearch Field Name, application/protocolName/serviceName\\nRule Builder Column Name, <protname>\\nRegex Pattern, <protname>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nKnown Application\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nApplication\\nElasticsearch Field Name\\napplication/protocolName/serviceName\\nRule Builder Column Name\\n<protname>\\nRegex Pattern\\n<protname>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\n', 'Common Applications': 'Firewalls\\nIDS/IPS\\nNetMon\\n', 'Use Case': 'Classifying network traffic.\\n', 'MPE/Data Masking Manipulations': 'Compares to list of IANA Protocol Names and is shown in Known Application in the Client Console or Application in the Web Console.\\n', 'Usage Standards': 'Only parse IANA Protocol Names in this field.\\nIf both Protocol Number and Protocol Name are present in a log, parse Protocol Number.\\nFor Protocol Names and Numbers, see\\nhttps://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml\\n', 'Examples': 'FortiGate\\n12 12 2016 12:18:55 1.1.1.1 <LOC7:ALRT> date=2016-12-12 time=12:18:55 devname=ABC-DEF-FORTIGATE-02 devid=FG80050000000 logid=0419016385 type=utm subtype=ips eventtype=signature level=alert vd=root severity=low srcip=1.1.1.1 srccountry=\"Reserved\" dstip=1.1.1.1 srcintf=\"WIFI_NETWORK\" dstintf=\"VLAN\" policyid=380 sessionid=24634444 action=dropped proto=1\\nservice=\"PING\"\\nattack=\"Traceroute\" icmpid=0x6425 icmptype=0x08 icmpcode=0x00 attackid=12466 profile=\"IPS_WEB_OUT\" ref=\"http://Host1/ids/VID12345\" incidentserialno=123456789 msg=\"icmp: Traceroute,\" crscore=5 crlevel=low\\nService corresponds with proto=1 which is ICMP (Ping). Service can sometimes indicate an IANA Protocol Name instead of a process. For more information, see\\nhttp://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml\\n.\\nJuniper Firewall\\n11 06 2009 12:09:51 1.1.1.1 <SAU1:CRIT> dc-dp-1: NetScreen device_id=dc-dp-1 [Root]system-critical-00033: Src IP session limit! From 1.1.1.1:11698 to 1.1.1.1:49156,\\nproto UDP\\n(zone DAVE-PK1 int\\xa0 ethernet0/0.3). Occurred 16 times. (2010-11-06 12:09:50)\\nProto shows the Protocol Name UDP instead of a number. Corresponds to protocol number 17. For more information, see\\nhttp://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'IANA Protocol Number': '\\nThe Internet Assigned Numbers Authority (IANA) Protocol Number represents the official registered ID for well-known network protocols. For more information, see\\nRFC 5237\\nand\\nRFC 7045\\n.\\n', 'Data Type': 'Integer (0 to 255)\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Known Application\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Application\\nElasticsearch Field Name, application/protocolId/serviceName\\nRule Builder Column Name, Protnum\\nRegex Pattern, <protnum>\\nNetMon Name, Application (remapped by syslog parser)\\nClient Console Full Name\\nKnown Application\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nApplication\\nElasticsearch Field Name\\napplication/protocolId/serviceName\\nRule Builder Column Name\\nProtnum\\nRegex Pattern\\n<protnum>\\nNetMon Name\\nApplication (remapped by syslog parser)\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Name\\n', 'Common Applications': 'Firewalls\\nIDS/IPS\\n', 'Use Case': 'Classifying network traffic.\\n', 'MPE/Data Masking Manipulations': 'Compares to a list of IANA Protocol Numbers and is shown in Known Application in the Client Console or Application in the Web Console.\\n', 'Usage Standards': 'Do not overload this field. It maps to a table in the SIEM (protocol).\\nOnly parse IANA Protocol Numbers in this field.\\nIf both the Protocol Number and Protocol Name are present in a log, parse the Protocol Number.\\nFor Protocol Names and Numbers, see\\nhttps://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml\\n.\\n', 'Examples': 'FortiGate\\n12 12 2016 12:18:55 1.1.1.1 <LOC7:ALRT> date=2016-12-12 time=12:18:55 devname=ABC-DEF-FORTIGATE-02 devid=FG000000000000 logid=042006385 type=utm subtype=ips eventtype=signature level=alert vd=root severity=low srcip=1.1.1.1 srccountry=\"Reserved\" dstip=1.1.1.1 srcintf=\"WIFI_NETWORK\" dstintf=\"VLAN\" policyid=4 sessionid=5156446 action=dropped\\nproto=1\\nservice=\"PING\" attack=\"Traceroute\" icmpid=0x6425 icmptype=0x08 icmpcode=0x00 attackid=12466 profile=\"IPS_WEB_OUT\" ref=\"http://Host1/ids/VID5555\" incidentserialno=5000000000 msg=\"icmp: Traceroute,\" crscore=5 crlevel=low\\nProto (short for protocol) typically indicates IANA Protocol Numbers or Protocol Names. In this case, proto represents a number. Proto=1 corresponds to ICMP (Ping). For more information, see\\nhttp://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml\\n.\\nCisco Netflow\\n02 19 2014 06:41:03 NetFlow V9 CONN_ID=- Src=1.1.1.1 SPort=57534 InIfc=4 Dst=1.1.1.1 DPort=8612 OutIfc=9\\nProt=17\\nICMP_IPV4_TYPE=- ICMP_IPV4_CODE=- XLATE_SRC_ADDR_IPV4=- XLATE_DST_ADDR_IPV4=- XLATE_SRC_PORT=- XLATE_DST_PORT=- FW_EVENT=- FW_EXT_EVENT=- EVENT_TIME_MSEC=- IN_PERMANENT_BYTES=- DETAILS=CONN_ID=1632425523 ICMP_IPV4_TYPE=0 ICMP_IPV4_CODE=0 XLATE_SRC_ADDR_IPV4=1.1.1.1 XLATE_DST_ADDR_IPV4=1.1.1.1 XLATE_SRC_PORT=57534 XLATE_DST_PORT=8612 FW_EVENT=2 FW_EXT_EVENT=2013 EVENT_TIME_MSEC=1392835263526 IN_PERMANENT_BYTES=16 DefaultDevice TemplateID=263\\nProt indicates an IANA Protocol Number, corresponding to UDP. For more information, see\\nhttp://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml\\n.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Object': 'The resource (file) referenced or impacted by activity reported in the log, except when another schema field is more precisely relevant.\\nThe following fields should be used if they are more relevant:\\nProcess\\n. For anything clearly executable or running as a process.\\nAction\\n. Data explicitly classified as an action (for example, block traffic).\\nResult\\n. Result of a process (for example, HTTP result codes).\\nStatus\\n. Explicit status as presented by log source.\\nReason\\n. Explicit reason as presented by log source.\\nPolicy\\n. Explicit policy.\\nCommand\\n. Command executed by log source.\\nThreat Name\\n. Explicit threat name (for example, APT1).\\nCVE\\n. Explicit CVE in standard CVE format.\\nHash\\n. Explicitly generated Hash field. For more information, see\\nHash\\n.\\nHash\\n. Explicitly generated Hash field. For more information, see\\nHash\\n.\\nVendor Information\\n. Additional information from vendor (beyond the Vendor Message ID or VMID).\\nUserAgent\\n. User agent string for web traffic.\\nAnything that can be inferred into the LogRhythm Entity, Location or Network.\\n', 'Data Type': 'String (1000 characters maximum)\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Object\\nClient Console Short Name, Object\\nWeb Console Tab/Name, Object\\nElasticsearch Field Name, object\\nRule Builder Column Name, Object\\nRegex Pattern, <object>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nObject\\nClient Console Short Name\\nObject\\nWeb Console Tab/Name\\nObject\\nElasticsearch Field Name\\nobject\\nRule Builder Column Name\\nObject\\nRegex Pattern\\n<object>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Object Name\\nObject Type\\nHash\\n', 'Common Applications': 'Stores a resource being mentioned in the log message.\\nCan be used in almost every log source type.\\n', 'Use Case': 'Finding a specific known resource for log source type (for example, searching for a specific database name).\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': \"Do not use in the following cases:\\nWhen another schema field is more appropriate to describe the resource (Process, Dname, Hash, Sender, Command, Recipient, Subject, etc.).\\nWhen describing a LogRhythm-defined entity.\\nTo describe an event. Object describes an event's target.\\n\", 'Examples': '', 'Correct Examples': 'Windows System Log\\n<Event xmlns=\\'http://dum.dummy.com/win/2004/08/events/event\\'><System><Provider Name=\\'Microsoft-Windows-DHCP-Server\\' Guid=\\'{6d44402c-a145-4dac-9a01-f0555b41ca84}\\' EventSourceName=\\'DhcpServer\\'/><EventID Qualifiers=\\'0\\'>1020</EventID><Version>0</Version><Level>Warning</Level><Task>None</Task><Opcode>Info</Opcode><Keywords>Classic</Keywords><TimeCreated SystemTime=\\'2016-08-02T13:14:16.000000000Z\\'/><EventRecordID>1340877</EventRecordID><Correlation/><Execution ProcessID=\\'0\\' ThreadID=\\'0\\'/><Channel>System</Channel><Computer>IVNMKDP.DKVM.IVAN.log.cz.ru.biz</Computer><Security/></System><EventData><Data>\\n1.1.1.1\\n</Data><Data>100</Data><Data>0</Data></EventData></Event>\\nThe IP represents the IP Scope of this DHCP log, so it is the referenced object in this context. It is not appropriate to use SIP/DIP/SNATIP/DNATIP because the data field does not represent a host.\\nWindows System Log\\n<Event xmlns=\\'http://dum.dummy.com/win/2004/08/events/event\\'><System><Provider Name=\\'Microsoft-Windows-Kernel-PnP\\' Guid=\\'{9c343432439-12340-48324d-abhh7-e831c6sdf4539}\\'/><EventID>219</EventID><Version>0</Version><Level>Warning</Level><Task></Task><Opcode>Info</Opcode><Keywords></Keywords><TimeCreated SystemTime=\\'2016-08-03T01:44:55.547851500Z\\'/><EventRecordID>5823877</EventRecordID><Correlation/><Execution ProcessID=\\'4\\' ThreadID=\\'88\\'/><Channel>System</Channel><Computer>IVNMKDP.DKVM.IVAN.log.cz.ru.biz</Computer><Security UserID=\\'NT AUTHORITY\\\\SYSTEM\\'/></System><EventData><Data Name=\\'DriverNameLength\\'>60</Data><Data Name=\\'DriverName\\'>\\nPCI\\\\VEN_8086&DEV_7020&SUBSYS_110434AF4&REV_01\\\\3&13c0b0c5&0&0A\\n</Data><Data Name=\\'Status\\'>3221226382</Data><Data Name=\\'FailureNameLength\\'>15</Data><Data Name=\\'FailureName\\'>\\n\\\\Driver\\\\usbuhci\\n</Data><Data Name=\\'Version\\'>0</Data></EventData></Event>\\nObject is the specific driver component that failed to load (\\\\driver\\\\usbuhci). ObjectName is the DriverName. Both are correct as the referenced object is the driver component, and ObjectName expands on this with the full driver name.\\nOffice 365 Exchange Logs\\nTS=2016-03-03T01:17:28 SESSID=50e4435a-45e6-42de-7ae3-08d13419636 COMMAND=Set-TransportConfig USERTYPE=DcAdmin USERKEY=NT AUTHORITY\\\\SYSTEM (Microsoft.Exchange.ServiceHost) WORKLOAD=Exchange RESULTCODE=True OBJECT=\\nivantesto365.onmicrosoft.com\\n\\\\Transport Settings\\nUSER=NT AUTHORITY\\\\SYSTEM (Microsoft.Exchange.ServiceHost) SIP= OBJECTNAME= PARAMETERS=[{\"Name\":\"DomainController\",\"Value\":\"\"},{\"Name\":\"Identity\",\"Value\":\"\\nlrtesto365.onmicrosoft.com\\n\"},{\"Name\":\"HygieneSuite\",\"Value\":\"Premium\"}] MODIFIEDPROPERTIES= EXTERNALACCESS=True ORIGINATINGSERVER=ivandave0298 (15.31.05654.011) ORGANIZATIONNAME=\\nivantesto365.onmicrosoft.com\\nLOGONTYPE= MAILBOXOWNER= MAILBOXMASTER= LOGONUSERSID= LOGONUSERDISPLAYNAME= USERAGENT= CLIENTIPADDRESS= CLIENTPROCESSNAME= CLIENTVERSION= FOLDER= CROSSMAILBOXOPERATIONS= DESTMAILBOX= DESTMAILBOXOWNER= DESTMAILBOXMASTER= DESTFOLDER= FOLDERS= AFFECTEDITEMS= ITEM= SENDASUSER= SENDONBEHALFOFUSER=\\nivantesto365.onmicrosoft.com\\n\\\\Transport Settings parses into Object because this setting is recorded as modified in the log.\\n', 'Incorrect Examples': 'Sensitive Data\\n04/10-07:08:54.002765\\xa0 [**] [139:1:1]\\nSDF_COMBO_ALERT\\n[**] [Classification: Sensitive Data was Transmitted Across the Network] [Priority: 2] {PROTO:254} 1.1.1.1 -> 1.1.1.1\\nSDF_COMBO_ALERT parses into Object. This is incorrect because SDF_COMBO_ALERT indicates the type of log message, rather than what object is impacted or referenced in the log. In this example, the Object field should not be used.\\nCisco ACS\\n06 07 2013 09:13:19 1.1.1.1 <LOC6:NOTE> Jun\\xa0 7 09:13:19 mrk-prd-acs CSCOacs_TACACS_Accounting 0000819174 2 1\\xa0 NetworkDeviceGroups=Location:All Locations:DPDC, AuditSessionId=davemon:1.1.1.1:tty1:1.1.1.1, Response={Type=Accounting; AcctReply-Status=\\nSuccess\\n; }\\nThe Success value is parsed incorrectly from the key status into Object. It should parse into Status instead. In this example, the Object field should not be used.\\nSymantec Endpoint Server\\n01 28 2015 16:15:37 1.1.1.1 <LPTR:INFO> Jan 28 16:01:42 SymantecServer MVK-GDF-01: hostname,Local: 1.1.1.1,Local: 0,Local: 010000000001,Remote: 1.1.1.1,Remote: ,Remote: 0,Remote: 5156165156RS,7,Inbound,Begin: 2015-01-28 15:54:39,End: 2015-01-28 15:54:39,Occurrences: 1,Application: ,Rule: Block all other traffic,Location:\\nCorporate Network\\n,User: Dave_Store,Domain: DP,Action: Blocked\\nThe\\nLocation value should not parse into Object, as this can be inferred, and entities can be used to gather this type of data. Location should be tied to the entity structure. In this case, the Object field should not be used. Application in a log could be Process or Object, depending on the analysis of additional samples.\\nSnare 2008 Event Log\\n08 28 2016 23:03:14 1.1.1.1 <USER:NOTE> Aug 28 23:03:14\\nDAVEWINDOW.loc.gregsports.com\\nMSWinEventLog\\xa0\\xa0\\xa0\\xa0 1\\xa0\\xa0\\xa0\\xa0 Application 15450631\\xa0\\xa0\\xa0 Sun Aug 28 23:03:14 2016\\xa0\\xa0\\xa0 1026\\xa0 .NET Runtime\\xa0\\xa0\\xa0\\xa0\\xa0 N/A\\xa0\\xa0 N/A\\xa0\\xa0 Error\\nDAVEWINDOW.loc.gregsports.com\\nNone\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Application:\\npptviewerbackendwatchdog.exe\\nFramework Version: v4.0.30319 Description: The process was terminated due to an unhandled exception. Exception Info: System.TypeInitializationException…\\nApplication should be parsed into Process because it is an executable. In this example, the Object field should not be used.\\n', 'Ambiguous Examples': \"Riverbed\\n01 24 2014 02:57:25 1.1.1.1 <LOC0:NOTE> Jan 24 02:57:25 IVNDPMVK01 rbmd[10763]: [rbmd.NOTICE]: Connecting to appliance IVAN48564546TV\\nThe log notice may be a hostname or a device name (such as an AP). It is ambiguous whether this strictly meets the definition of object impacted, object referenced, or something else. In this case, the field could be a device, serial number, or other identifier. Object is not incorrect, but this log source should be researched further.\\nMicrosoft Application Log\\n<Event xmlns='\\nhttp://schemas.microsoft.com/win/2004/08/events/event'><System><Provider\\nName='MsiInstaller'/><EventID Qualifiers='0'>1022</EventID><Level>Information</Level><Task>None</Task><Keywords>Classic</Keywords><TimeCreated SystemTime='2014-11-05T08:50:01.000000000Z'/><EventRecordID>9442</EventRecordID><Channel>Application</Channel><Computer>\\nIVNMKDP.DKVM.IVAN.log.cz.ru.biz\\n</Computer><Security UserID='NT AUTHORITY\\\\SYSTEM'/></System><EventData>Product:\\nMicrosoft .NET Framework 4.5\\n- Update 'KB2979578v2' installed successfully.</EventData></Event>\\nProduct could parse into Process instead of Object. Object is not incorrect, but may be confusing. In this case, the product does not define a runnable process on the system, so Object is a better choice than Process.\\nWindows Application Log\\n<Event xmlns='\\nhttp://Host1/win/2004/08/events/event'><System><Provider\\nName='SQLSERVERAGENT'/><EventID Qualifiers='16384'>208</EventID><Level>Warning</Level><Task>Job Engine</Task><Keywords>Classic</Keywords><TimeCreated SystemTime='2015-07-23T18:20:39.000000000Z'/><EventRecordID>2042567</EventRecordID><Channel>Application</Channel><Computer>\\nIVNMKDP.DKVM.IVAN.log.cz.ru.biz\\n</Computer><Security/></System><EventData>SQL Server Scheduled Job\\n'LogRhythm Sunday Maintenance'\\n(0x7BN5C000E7A34C90000000D2F3) - Status: Failed - Invoked on: 2015-07-23 12:20:38 - Message: The job failed.\\xa0 The Job was invoked by User sa.\\xa0 The last step to run was step 29 (LogRhythm Job Step Validation).\\xa0 The job was requested to start at step 29 (LogRhythm Job Step Validation).</EventData></Event>\\nJob name parses into Object. However, it is ambiguous whether job is an object, an action, or a process.\\nWindows Security Log\\n<Event xmlns='\\nhttp://schemas.microsoft.com/win/2004/08/events/event'><System><Provider\\nName='Microsoft-Windows-Security-Auditing' Guid='{54849625-5478-4994-a5ba-3e3b0328c30d}'/><EventID>4907</EventID><Version>0</Version><Level>Information</Level><Task>Audit Policy Change</Task><Opcode>Info</Opcode><Keywords>Audit Success</Keywords><TimeCreated SystemTime='2016-02-26T06:56:10.852896900Z'/><EventRecordID>228903233</EventRecordID><Correlation/><Execution ProcessID='752' ThreadID='768'/><Channel>Security</Channel><Computer>\\nIVNMKDP.DKVM.IVAN.log.cz.ru.biz\\n</Computer><Security/></System><EventData><Data Name='SubjectUserSid'>IVN\\\\dave.crowley</Data><Data Name='SubjectUserName'>dave.crowley</Data><Data Name='SubjectDomainName'>IVN</Data><Data Name='SubjectLogonId'>0x10be65</Data><Data Name='ObjectServer'>Security</Data><Data Name='ObjectType'>\\nFile\\n</Data><Data Name='ObjectName'>\\nC:\\\\Windows\\\\System32\\\\autochk.exe\\n</Data><Data Name='HandleId'>0xb0</Data><Data Name='OldSd'>S:AI</Data><Data Name='NewSd'>S:(AU;SAFA;DCLCSDSDWDWO;;;WD)</Data><Data Name='ProcessId'>0x3298</Data><Data Name='ProcessName'>C:\\\\Program Files (x86)\\\\Google\\\\Chrome\\\\Application\\\\chrome.exe</Data></EventData></Event>\\nFile parses into Object, and the XML field is ObjectType, so it is a good candidate for ObjectType. Autochk and path parses into ObjectName, and XML calls this ObjectName as well.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Object Name': 'The resource name (filename) referenced or impacted by activity reported in the log, specifically related to what is parsed into Object.\\nObject Name is a friendly name or expanded information about the Object. Do not use Object Name if Object is not also parsed.\\nObject Name is normalized into the star schema of the Events database (LogRhythm_Events.dbo.Object).\\n', 'Data Type': 'String (1000 characters maximum)\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Object Name\\nClient Console Short Name, Object Name\\nWeb Console Tab/Name, Object Name\\nElasticsearch Fieldname, objectName\\nRule Builder Column Name, ObjectName\\nRegex Pattern, <objectname>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nObject Name\\nClient Console Short Name\\nObject Name\\nWeb Console Tab/Name\\nObject Name\\nElasticsearch Fieldname\\nobjectName\\nRule Builder Column Name\\nObjectName\\nRegex Pattern\\n<objectname>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Object is described by Object Name\\nObject Type\\n', 'Common Applications': 'Everywhere that Object is used and a friendly name exists.\\n', 'Use Case': 'Getting context about an Object.\\nNot likely to be a primary search field.\\nNot likely to be a major field in AIE rules.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Object and Object Name are context-sensitive to the log itself. They must be defined for each device and device family across multiple samples.\\nObject is primary and required to be filled first. Object Name is secondary and optional.\\nObject Name is an expanded or friendly name of the object, not necessarily the file or process name (Object).\\nObject is primary and required to be filled first. Object Name is secondary and optional.\\nObject Name is an expanded or friendly name of the object, not necessarily the file or process name (Object).\\nFor any database log:\\nObject is the name of the database.\\nObject Name should only be used if there is a human readable name in addition.\\nObject is the name of the database.\\nObject Name should only be used if there is a human readable name in addition.\\nDo not use Object Name with any other speciality field, such as session, process, URL, and so on.\\n', 'Examples': '', 'Correct Examples': 'Windows Security Event Log\\n<Event xmlns=\\'\\nhttp://schemas.microsoft.com/win/2004/08/events/event\\'><System><Provider\\nName=\\'Microsoft-Windows-Security-Auditing\\' Guid=\\'{54559625-5478-4994-a5ba-3e3b0328c30d}\\'/><EventID>4907</EventID><Version>0</Version><Level>Information</Level><Task>Audit Policy Change</Task><Opcode>Info</Opcode><Keywords>Audit Success</Keywords><TimeCreated SystemTime=\\'2016-02-26T06:56:10.852896900Z\\'/><EventRecordID>228903233</EventRecordID><Correlation/><Execution ProcessID=\\'752\\' ThreadID=\\'768\\'/><Channel>Security</Channel><Computer>log.log.log</Computer><Security/></System><EventData><Data Name=\\'SubjectUserSid\\'>log\\\\dave.crowley</Data><Data Name=\\'SubjectUserName\\'>dave.crowley</Data><Data Name=\\'SubjectDomainName\\'>log</Data><Data Name=\\'SubjectLogonId\\'>0x10be65</Data><Data Name=\\'ObjectServer\\'>Security</Data><Data Name=\\'ObjectType\\'>\\nFile\\n</Data><Data Name=\\'ObjectName\\'>C:\\\\Windows\\\\System32\\\\\\nautochk.exe\\n</Data><Data Name=\\'HandleId\\'>0xb0</Data><Data Name=\\'OldSd\\'>S:AI</Data><Data Name=\\'NewSd\\'>S:(AU;SAFA;DCL545RSDWDWO;;;WD)</Data><Data Name=\\'ProcessId\\'>0x3298</Data><Data Name=\\'ProcessName\\'>C:\\\\Program Files (x86)\\\\Google\\\\Chrome\\\\Application\\\\chrome.exe</Data></EventData></Event>\\nFile parses into Object—though Object Type would be better. Autochk.exe parses into Object Name appropriately.\\nWindows Security Event Log\\n<Event xmlns=\\'\\nhttp://Host3/win/2004/08/events/event\\'><System><Provider\\nName=\\'Microsoft-Windows-Security-Auditing\\' Guid=\\'{548465416845-5478-4994-a5ba-3e3b0328c30d}\\'/><EventID>6144</EventID><Version>0</Version><Level>Informationen</Level><Task>Andere Richtlinienänderungsereignisse</Task><Opcode>Info</Opcode><Keywords>Überwachung erfolgreich</Keywords><TimeCreated SystemTime=\\'2016-03-15T17:52:23.176154700Z\\'/><EventRecordID>57042720</EventRecordID><Correlation/><Execution ProcessID=\\'524\\' ThreadID=\\'2808\\'/><Channel>Security</Channel><Computer>Host2l</Computer><Security/></System><EventData><Data Name=\\'ErrorCode\\'>0</Data><Data Name=\\'GPOList\\'>{\\n31b2f340-016d-11d2-945f-00c04fb984f9}\\xa0\\xa0\\xa0\\xa0 Default Domain Policy\\n</Data></EventData></Event>\\nThe string for GPOList parses into Object. The Default Domain Policy parses into Object Name.\\nCisco Unified Communication Mgr\\n11 09 2009 00:22:45 1.1.1.1 <LOC7:ERRR> 157: : : 125: Nov 09 05:22:03.34 UTC :\\xa0 %CCM_CALLMANAGER-CALLMANAGER-3-DeviceTypeMismatch: Device type mismatch. Name of device.:DAV002454654BA Device type.:436 Database device type:435 App ID:Cisco CallManager Cluster ID:\\nCORP-DP001\\nNode ID:\\nCORP0004-D31005\\nCluster ID parses into Object. Node ID parses into Object Name.\\nVoltage Securemail\\n01 29 2015 01:02:20 1.1.1.1 <USER:DBUG> voltage: LogMsgID=\"3\", ServerNode=\"MVBK1\", TenantID=\"LOG.BIZ.RU\", SubTenant=\"<default>\", Created=\"2015-01-29 01:02:20.673\", Status=\"0\", Summary=\"Authentication being handled for\\npete.store@recordflow.biz\\n\", EventLevel=\"Verbose\", SessionID=\"1odz45646546dfdf3gscuijtpiv8\", RequestID=\"1191\", SourceName=\"IDAdapterEvents\", EventName=\"Auth\", Service=\"VSIBE\", ClusterName=\"GH Data Center\", ClusterUID=\"1\", IPAddress=\"1.1.1.1\", TenantUID=\"36\", UserAgentType=\"2\", Identity=\"\\npete.store@recordflow.bizrecordflow.biz\\n\", AdapterType=\"\\nvs.enrollment\\n\", AdapterID=\"\\n24358855551109029088\\n\", Result=\"4\", Duration=\"9\", Details=\"null\"\\nVs.enrollment parses into Object. The numeric string for AdapterID parses into Object Name.\\n', 'Ambiguous Examples': 'NAC System – FortiGate\\n07 23 2016 20:00:12 1.1.1.1 <LOC7:NOTE> date=2016-07-23 time=23:00:11 devname=logfw devid=FG5555555RecFlw1600315 logid=0100043777 type=event subtype=system level=notice vd=\"Transparent\" logdesc=\"NAC anomaly quarantine\" srcip=1.1.1.1 dstip=2.2.22 src_int=\"port1\" dst_int=\"N/A\" srcport=0 dstport=0 proto=0 service=\"ip\" action=ban-ip user=\"N/A\" group=\"N/A\" policyid=0 banned_src=\\ndos\\nbanned_rule=\"\\ntcp_dst_session\\n\" sensor=\"DoS-policy1\"\\nBanned_src and banned_rule parse into Object and Object Name, respectively. These are ambiguous because the source and rule are related to one another, but source refers to a denial of service attack, which is more of an action than a resource.\\nIn this case, banned_rule could be parsed into Policy and banned_src could parse into Object (because the rule acted on the \"dos\" src).\\nPostgres\\n07 15 2015 14:59:42 1.1.1.1 <LOC4:INFO> Jul 15 14:59:43 src@Host70lt0 postgres[26940]: [708937-1] user=hasselhoff,db=\\nrecordflow_dev\\nLOG:\\nduration: 929.018 ms\\xa0 execute <unnamed>: UPDATE jobs.TRIGGERS SET TRIGGER_STATE = $1 WHERE SCHED_NAME = \\'schedulerFactoryBean\\' AND JOB_NAME = $2 AND JOB_GROUP = $3 AND TRIGGER_STATE = $4\\nDatabase and Log parse into Object Name and Object, respectively. A database meets the criteria of a resource referenced or impacted in this log. However, the log seems closer to a command, action, or result (log parses into Command).\\nThe database value should parse into Object, and the log should parse into Command. Object Name should not be used.\\nTwo logs from FortiGate with URLs\\n08 21 2016 02:16:52 1.1.1.1 <LOC1:ALRT> date=2016-08-21,time=02:17:46,devname=FG123456456,devid=FG5445645641,logid=0419016384,type=utm,subtype=ips,eventtype=signature,level=alert,vd=\"root\",severity=low,srcip=1.1.1.1,dstip=1.1.1.1,srcintf=\"port16\",dstintf=\"port16\",policyid=1,sessionid=22078931,action=detected,proto=6,service=tcp/20480,attack=\"MS.IIS.Web.Server.Folder.Traversal.Evasion\",srcport=53355,dstport=80,hostname=\"1.1.1.1\",direction=outgoing,attackid=15152,profile=\"all_default\",ref=\"\\nhttp://www.fortinet.com\\n/ids/VID5555\",incidentserialno=1981412111,msg=\"web_server\\n:\\n\\nMS.IIS.Web.Server.Folder.Traversal.Evasion,\",crscore=10,crlevel=medium\\n07 23 2016 20:00:12 1.1.1.1 <LOC7:ALRT> date=2016-07-23 time=23:00:11 devname=zackasdsd3343434 devid=FG5555121321 logid=0720018432 type=anomaly subtype=\\nanomaly\\nlevel=alert vd=\"Transparent\" severity=critical srcip=1.1.1.1 dstip=1.1.1.1 srcintf=\"port1\" sessionid=0 action=detected proto=6 service=SNMP count=802 attack=\"tcp_src_session\" srcport=36078 dstport=162 attackid=4544654 policyid=1 ref=\"\\nhttp://www.fortinet.com\\n/ids/VID1511112\\n\" msg=\"anomaly: tcp_src_session, 1251 > threshold 1250, repeats 802 times\" crscore=50 crlevel=critical\\nThe domain of the URL parses into Object Name in the referrer field in both logs. Strictly speaking, this is a referenced object, but Object is not used in the first log, so there is no relation. In the second log, Subtype parses into Object and the domain of the URL parses into Object Name. There is no relation between these fields in the second instance, as subtype describes the event rather than a resource.\\nIn these logs, the ref field defines an outside URL to additional information. It is not the object of the log or the name of the object. The ref field should parse into the Vendor Information field. There is no need to have an Object or Object Name for this log source.\\nEntrust entillgence messaging server - User Credentials\\n06 07 2013 09:29:36 1.1.1.1 <LOC3:WARN> ECD[12901]: b7fd WARN ECD: (31516556428) Warning of credential expiry.\\xa0 Details [[friendlyName=\\nOnboard SSL credential\\nfor\\nwww.recordflow.\\nbiz][days since expiry:161]]\\nFriendly name parses into Object Name and the subsequent hostname parses into Object. Object should parse into impacted host (dname) in this log. Object Name is strictly correct with the usage of object for the hostname, but would probably be better for Object after that is changed to dname.\\nIf onboard SSL Credential parses into Object, then Object Name is empty. Also, the rule name and common event probably captures it already \"credential expiry.\" Look at other samples to see if there are other types of credential besides the one shown here.\\nMicrosoft Antimalware\\n4/24/2013 4:03 PM TYPE=Warning USER= COMP=Host1 SORC=Microsoft Antimalware CATG=(0) EVID=1116 MESG=Microsoft Antimalware has detected malware or other potentially unwanted software.\\xa0 For more information please see the following:\\nhttp://Host3/fwlink/?linkid=37020&name=Worm:Win32/Vobfus.PQ&threatid=2147680921\\nName:\\nWorm:Win32/Vobfus.PQ\\nID: 214764421\\xa0 \\xa0\\xa0 Severity: Severe\\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0 Category: Worm\\xa0 \\xa0 Path:\\nfile:_C:\\\\Documents and Settings\\\\All Users\\\\Application Data\\\\Symantec\\\\SRTSP\\\\Quarantine\\\\APQ7.tmp\\nDetection Origin: Local machine\\xa0 \\xa0\\xa0 Detection Type: Concrete\\xa0 \\xa0\\xa0\\xa0 Detection Source: Real-Time Protection\\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0 User: NT AUTHORITY\\\\SYSTEM\\xa0 \\xa0\\xa0 Process Name: C:\\\\Program Files (x86)\\\\Symantec AntiVirus\\\\RHost2\\xa0 \\xa0\\xa0 Signature Version: AV: 1.1.1.1, AS: 1.1.1.1, NIS: 1.1.1.1\\xa0 \\xa0\\xa0\\xa0 Engine Version: AM: 1.1.9402.0, NIS: 1.1.1.1\\nThe object is the target file (apq7.tmp), as it is being acted on. The name is a friendly descriptor and thus is the Object Name.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Object Type [7.2]': 'The resource type (file type) referenced or impacted by activity reported in the log, specifically related to what is parsed into Object. Object Type is a categorization field in comparison to Object Name, which is a specific description of the value in Object.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String (0-512 characters, 64 average characters)\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Object Type\\nClient Console Short Name, Object Type\\nWeb Console Tab/Name, Application/Object Type\\nElasticsearch Field Name, objectType\\nRule Builder Column Name, ObjectType\\nRegex Pattern, <objecttype>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nObject Type\\nClient Console Short Name\\nObject Type\\nWeb Console Tab/Name\\nApplication/Object Type\\nElasticsearch Field Name\\nobjectType\\nRule Builder Column Name\\nObjectType\\nRegex Pattern\\n<objecttype>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Object Type is a categorization of the resource described in Object.\\nObject Type is a broader classification whereas Object Name is a specific name or description.\\n', 'Common Applications': 'AV software\\nHTTP access logs\\n', 'Use Case': 'Sub-classification when the event type is not enough.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Object Type does not require an Object. For example, a file scanner might create a log looking for .gif and not find any. The Object Type would be GIF, but there is no Object because no files were found.\\nDo not use Object Type with any other specialty field, such as Hash, Process, Subject, and so on. Object Type only applies to Object.\\n', 'Examples': \"HTTP access log. Object Type could contain the MIME type of file(s)\\nWindows Security Event Log\\n<Event xmlns='\\nhttp://schemas.microsoft.com/win/2004/08/events/event'><System><Provider\\nName='Microsoft-Windows-Security-Auditing' Guid='{54849625-5478-4994-a5ba-3e3b0328c30d}'/><EventID>4907</EventID><Version>0</Version><Level>Information</Level><Task>Audit Policy Change</Task><Opcode>Info</Opcode><Keywords>Audit Success</Keywords><TimeCreated SystemTime='2016-02-26T06:56:10.852896900Z'/><EventRecordID>228903233</EventRecordID><Correlation/><Execution ProcessID='752' ThreadID='768'/><Channel>Security</Channel><Computer>\\nUSLT0775JCROW.schq.safaware.com\\n</Computer><Security/></System><EventData><Data Name='SubjectUserSid'>SAFAWARErecordflow\\\\julian.crowley</Data><Data Name='SubjectUserName'>julian.crowley</Data><Data Name='SubjectDomainName'>SAFAWARE</Data><Data Name='SubjectLogonId'>0x10be75</Data><Data Name='ObjectServer'>Security</Data><Data Name='ObjectType'>\\nFile\\n</Data><Data Name='ObjectName'>C:\\\\Windows\\\\System32\\\\\\nautochk.exe\\n</Data><Data Name='HandleId'>0xb0</Data><Data Name='OldSd'>S:AI</Data><Data Name='NewSd'>S:(AU;SAFA;DCLCRPCRSDWDWO;;;WD)</Data><Data Name='ProcessId'>0x3298</Data><Data Name='ProcessName'>C:\\\\Program Files (x86)\\\\Google\\\\Chrome\\\\Application\\\\chrome.exe</Data></EventData></Event>\\nIn this case, Object is authchk.exe. Object Name is blank even though the source log explicitly calls it out. If the log had a field that called Auto check process or some other expanded description or friendly name of the object, then that value would parse into Object Name. Object Type would parse into File.\\nMS Forefront TMG Web Proxy\\n1.1.1.1 anonymous Windows-Update-Agent Y 2014-12-22 17:45:02 w3proxy APPGATEDR - - 1.1.1.1 80 31 221 359 http TCP HEAD\\nhttp://ds.download.windowsupdate.com/v11/2/microsoftupdate/redir/\\nv6-muauth.cab?14546421745\\napplication/octet-stream\\nInet 200 0x40800000 [System] Allow all HTTP traffic from Forefront TMG to all networks (for CRL downloads) Req ID: 11c05fb1; Compression: client=No, server=No, compress rate=0% decompress rate=0% Local Host External 0x180 Allowed 2014-12-22 17:45:02 - - - - Allowed Malware Inspection Disabled for the Matching Policy Rule Unknown - - 0 - 0 - - - - - - 0 0 - 0 - - Feature disabled None\\nds.download.windowsupdate.com\\n50937 -\\nApplication/octet-stream parses into Object Type, and v6-muauth.cab parses into Object (if possible). No Object Name is parsed.\\nTrend Micro Deep Discovery Inspector\\n06 05 2016 01:04:09 1.1.1.1 <LOC3:INFO> CEF:0|Trend Micro|Deep Discovery Inspector|3.82.1133|200127|Notable Characteristics of the analyzed sample|6|rt=Jun 05 2016 03:03:49 GMT+04:00 dvc=1.1.1.1 dvchost=uascdiscover.merto.uasc.corp dvcmac=00:00:00:00:00:00 deviceExternalId=4449875B3A-46561482-3301-FCA4-11156\\nfname=recordflow.exe\\nfileHash=\\n9B822B964971D32EC4C97920CDD0D4620F767BC8107D2F\\nfileType=WIN32 EXE\\nfsize=905216 cs1Label=PolicyCategory cs1=Autostart or other system reconfiguration msg=Key: HKEY_CURRENT_USER\\\\\\\\Software\\\\\\\\Microsoft\\\\\\\\Windows NT\\\\\\\\CurrentVersion\\\\\\\\Windows Messaging Subsystem\\\\\\\\Profiles\\\\\\\\Outlook\\\\\\\\ve9375CFF0413d11d3B88A00104B2A6676\\\\\\\\\\\\nValue: \\\\nType: REG_NONE cs3Label=SandboxImageType cs3=UASC2 cs2Label=PolicyName cs2=Modifies important registry entries to perform rogue functions\\nWin32 EXE parses into Object Type, recordflow.exe parses into Object, and the registry name parses into Object Name.\\nCylance Protect\\n08 23 2016 08:39:29 1.1.1.1 <SLOG:WARN> 1 2016-08-23T13:39:12.2911991Z sysloghost CylancePROTECT - - - Event Type: Threat, Event Name: threat_changed, Device Name: USABLDRRECFLOW01, IP Address: (1.1.1.1),\\nFile Name: creative Host77\\n, Path: c:\\\\program files (x86)\\\\adobe\\\\adobe creative cloud\\\\acc\\\\, Drive Type: Internal Hard Drive, SHA256: 8050FE3DCA43D594611492AA149AF09FC9669149602BB2945AFEA4148A24B175, MD5: 59E0D058686BD35B0D5C02A4FD8BD0E0, Status: Abnormal, Cylance Score: 100, Found Date: 8/3/2016 4:22:21 PM, File Type:\\nExecutable\\n, Is Running: True, Auto Run: False, Detected By: FileWatcher\\nExecutable parses into Object Type, and creative Host77 parses into Object.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Parent Process ID [7.2]': 'The Parent Process ID of a system or application process that is of interest.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String (16 characters)\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Parent Process ID\\nClient Console Short Name, Parent Process ID\\nWeb Console Tab/Name, Application/Parent Process ID\\nElasticsearch Field Name, parentProcessId\\nRule Builder Column Name, ParentProcessID\\nRegex Pattern, <parentprocessid>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nParent Process ID\\nClient Console Short Name\\nParent Process ID\\nWeb Console Tab/Name\\nApplication/Parent Process ID\\nElasticsearch Field Name\\nparentProcessId\\nRule Builder Column Name\\nParentProcessID\\nRegex Pattern\\n<parentprocessid>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Parent Process Name\\nParent Process Path\\nProcess Name\\nProcess ID\\nObject\\nObject Name\\nObject Type\\nSession\\nSession Type\\n', 'Common Applications': 'Endpoint devices (for example, Carbon Black)\\nWindows logs\\n', 'Use Case': 'Identifying that Office is the source for a PowerShell process that is malicious.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Parse the most obvious meaningful parent ID, which is typically a top-level root.\\n', 'Examples': \"Windows Event Log - Sysmon\\n<Event xmlns=\\n'\\nhttp://Host3/win/2004/08/events/event\\n'\\n><System><Provider Name='Microsoft-Windows-Sysmon' Guid='{22222222-C22A-43E0-BF4C-06F5698FFBD9}'/><EventID>1</EventID><Version>5</Version><Level>Information</Level><Task>Process Create (rule: ProcessCreate)</Task><Opcode>Info</Opcode><Keywords></Keywords><TimeCreated SystemTime='2016-09-19T17:50:20.719863700Z'/><EventRecordID>230097</EventRecordID><Correlation/><Execution ProcessID='3716' ThreadID='3740'/><Channel>Microsoft-Windows-Sysmon/Operational</Channel><Computer> USABLDRRECFLOW01</Computer><Security UserID='NT AUTHORITY\\\\SYSTEM'/></System><EventData>Process Create:\\nUtcTime: 2016-09-19 17:50:20.718\\nProcessGuid: {FCC7BD93-255C-57E0-0000-00109BAC260D}\\nProcessId: 127228\\nImage: C:\\\\Windows\\\\System32\\\\Host2\\nCommandLine: Host2 /c echo ffsuli > \\\\\\\\.\\\\pipe\\\\ffsuli\\nCurrentDirectory: C:\\\\Windows\\\\system32\\\\\\nUser: NT AUTHORITY\\\\SYSTEM\\nLogonGuid: {FCC7BD93-8F2C-57DC-0000-22222222222}\\nLogonId: 0x3E7\\nTerminalSessionId: 0\\nIntegrityLevel: System\\nHashes: SHA1=\\n811627E612944FE5DADF2A14763A08111143C27E\\nParentProcessGuid: {FCC7BD93-8F2B-57DC-0000-222222222222}\\nParentProcessId:\\n504\\nParentImage: C:\\\\Windows\\\\System32\\\\Host1\\nParentCommandLine: C:\\\\Windows\\\\system32\\\\Host1</EventData></Event>\\nParent Process ID is specifically called out in this log.\\nCb Response\\n08 30 2016 02:20:42 1.1.1.1 <USER:NOTE> LEEF:1.0|CB|CB|1.1.1.1623.1033|watchlist.storage.hit.process|cb_server=cbserver\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 cb_version=1.1.1.1623.1033 childproc_count=1\\xa0\\xa0 cmdline=C:\\\\\\\\Windows\\\\\\\\system32\\\\\\\\cmd.exe /c ping provisionserver >nul 2>nul\\xa0\\xa0\\xa0\\xa0\\xa0 crossproc_count=1\\xa0\\xa0 filemod_count=0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 host_type=workstation\\xa0\\xa0\\xa0\\xa0\\xa0 last_update=2016-08-30T08:02:01.670Z\\xa0\\xa0\\xa0 modload_count=11\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 netconn_count=0\\xa0\\xa0\\xa0\\xa0 os_type=windows\\xa0\\xa0\\xa0\\xa0 parent_guid=222222222-0000-2010-01d2-0294ad4c889c parent_id=2222222222\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 parent_name=scsdiscovery.exe\\xa0\\xa0\\xa0\\xa0 parent_pid=\\n8208\\nparent_unique_id=222222-0000-2010-01d2-0294ad4c889c-2222222222\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 path=c:\\\\\\\\windows\\\\\\\\syswow64\\\\\\\\cmd.exe\\xa0\\xa0\\xa0\\xa0 process_guid=000001c3-0000-097c-01d2-222222222\\xa0\\xa0\\xa0 process_id=000001c3-0000-097c-01d2-22222222222 process_name=cmd.exe\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 process_pid=2428\\xa0\\xa0\\xa0 regmod_count=0\\xa0\\xa0\\xa0\\xa0\\xa0 server_name=localhost.localdomain start=2016-08-30T08:01:24.874Z timestamp=1472548449.903\\xa0\\xa0 type=watchlist.storage.hit.process\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 unique_id=000001c3-0000-097c-01d2-22222222222-00000001\\xa0\\xa0\\xa0\\xa0\\xa0 username=SYSTEM\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 watchlist_155=2016-08-30T09:10:02.525745Z\\xa0\\xa0\\xa0\\xa0\\xa0 watchlist_id=155\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 watchlist_name=Command Line\\nParent_pid (Process ID) called out specifically.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Parent Process Name [7.2]': 'The parent process name of a system or application process.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String (255 characters maximum)\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Parent Process Name\\nClient Console Short Name, Parent Process Name\\nWeb Console Tab/Name, Parent Process Name\\nElasticsearch Field Name, parentProcessName\\nRule Builder Column Name, ParentProcessName\\nRegex Pattern, <parentprocessname>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nParent Process Name\\nClient Console Short Name\\nParent Process Name\\nWeb Console Tab/Name\\nParent Process Name\\nElasticsearch Field Name\\nparentProcessName\\nRule Builder Column Name\\nParentProcessName\\nRegex Pattern\\n<parentprocessname>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Parent Process ID\\nParent Process Path\\nProcess Name\\nProcess ID\\nObject\\nObject Name\\nObject Type\\nSession\\nSession Type\\n', 'Common Applications': 'Endpoint devices (for example, Carbon Black)\\nWindows logs\\n', 'Use Case': 'Identifying that Office is the source for a PowerShell process that is malicious.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Parse the most obvious meaningful parent process (typically top-level root).\\nParent Process Name must match the Parent Process ID.\\nDo not capture the process path in the name. That goes in Parent Process Path.\\n', 'Examples': \"Cb Response\\n08 30 2016 02:20:42 1.1.1.1 <USER:NOTE> LEEF:1.0|CB|CB|1.1.1.1623.1033|watchlist.storage.hit.process|cb_server=cbserver\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 cb_version=1.1.1.1623.1033 childproc_count=1\\xa0\\xa0 cmdline=C:\\\\\\\\Windows\\\\\\\\system32\\\\\\\\cmd.exe /c ping provisionserver >nul 2>nul\\xa0\\xa0\\xa0\\xa0\\xa0 crossproc_count=1\\xa0\\xa0 filemod_count=0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 host_type=workstation\\xa0\\xa0\\xa0\\xa0\\xa0 last_update=2016-08-30T08:02:01.670Z\\xa0\\xa0\\xa0 modload_count=11\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 netconn_count=0\\xa0\\xa0\\xa0\\xa0 os_type=windows\\xa0\\xa0\\xa0\\xa0 parent_guid=000001c3-0000-2010-01d2-0294ad4c889c parent_id=7575139489275778785\\xa0\\xa0\\xa0 parent_name=\\nscsdiscovery.exe\\nparent_pid=8208\\xa0\\xa0\\xa0\\xa0 parent_unique_id=000001c3-0000-2010-01d2-0294ad4c889c-22222222222\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 path=c:\\\\\\\\windows\\\\\\\\syswow64\\\\\\\\cmd.exe\\xa0\\xa0\\xa0\\xa0 process_guid=000001c3-0000-097c-01d2-2222222222\\xa0\\xa0 process_id=000001c3-0000-097c-01d2-22222222222 process_name=cmd.exe\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 process_pid=2428\\xa0\\xa0\\xa0 regmod_count=0\\xa0\\xa0\\xa0\\xa0\\xa0 server_name=localhost.localdomain start=2016-08-30T08:01:24.874Z timestamp=1472548449.903\\xa0\\xa0 type=watchlist.storage.hit.process\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 unique_id=000001c3-0000-097c-01d2-222222222222-00000001\\xa0\\xa0\\xa0\\xa0 username=SYSTEM\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 watchlist_155=2016-08-30T09:10:02.525745Z\\xa0\\xa0\\xa0\\xa0\\xa0 watchlist_id=155\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 watchlist_name=Command Line\\nParent_Name is the parent process name in this instance.\\nWindows Event Log - Sysmon\\n<Event xmlns=\\n'\\nhttp://Host3/win/2004/08/events/event\\n'\\n><System><Provider Name='Microsoft-Windows-Sysmon' Guid='{5770385F-C22A-43E0-BF4C-06F5698FFBD9}'/><EventID>1</EventID><Version>5</Version><Level>Information</Level><Task>Process Create (rule: ProcessCreate)</Task><Opcode>Info</Opcode><Keywords></Keywords><TimeCreated SystemTime='2016-09-19T17:50:20.719863700Z'/><EventRecordID>230097</EventRecordID><Correlation/><Execution ProcessID='3716' ThreadID='3740'/><Channel>Microsoft-Windows-Sysmon/Operational</Channel><Computer>LRXM</Computer><Security UserID='NT AUTHORITY\\\\SYSTEM'/></System><EventData>Process Create:\\nUtcTime: 2016-09-19 17:50:20.718\\nProcessGuid: {FCC7BD93-255C-57E0-0000-222222222222}\\nProcessId: 127228\\nImage: C:\\\\Windows\\\\System32\\\\Host2\\nCommandLine: Host2 /c echo ffsuli > \\\\\\\\.\\\\pipe\\\\ffsuli\\nCurrentDirectory: C:\\\\Windows\\\\system32\\\\\\nUser: NT AUTHORITY\\\\SYSTEM\\nLogonGuid: {FCC7BD93-8F2C-57DC-0000-2222222222}\\nLogonId: 0x3E7\\nTerminalSessionId: 0\\nIntegrityLevel: System\\nHashes: SHA1=\\n811627E612944FE5DADF2A14763A08111143C27E\\nParentProcessGuid: {FCC7BD93-8F2B-57DC-0000-22222222222}\\nParentProcessId: 504\\nParentImage: C:\\\\Windows\\\\System32\\\\\\nHost1\\nParentCommandLine: C:\\\\Windows\\\\system32\\\\Host1</EventData></Event>\\nObfuscated process name, but this would be appropriate for Parent Process Name.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Parent Process Path [7.2]': 'The full path of a parent process of a system or application process.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String (892 characters maximum)\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Parent Process Path\\nClient Console Short Name, Parent Process Path\\nWeb Console Tab/Name, Parent Process Path\\nElasticsearch Field Name, parentProcessPath\\nRule Builder Column Name, ParentProcessPath\\nRegex Pattern, <parentprocesspath>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nParent Process Path\\nClient Console Short Name\\nParent Process Path\\nWeb Console Tab/Name\\nParent Process Path\\nElasticsearch Field Name\\nparentProcessPath\\nRule Builder Column Name\\nParentProcessPath\\nRegex Pattern\\n<parentprocesspath>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Parent Process ID\\nParent Process Name\\nProcess Name\\nProcess ID\\nObject\\nObject Name\\nObject Type\\nSession\\nSession Type\\n', 'Common Applications': 'Endpoint devices (for example, Carbon Black)\\nWindows logs\\n', 'Use Case': 'Identifying where parent executing process resides on target device.\\nTracking malware installation locations.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Parent process path must match the parent process ID/name.\\nDo not capture the process path in this field, only the parent process path.\\nParse out the OS-dependent path using whichever separators are native to that OS.\\n', 'Examples': \"Windows Event Log - Sysmon\\n<Event xmlns=\\n'\\nhttp://Host3/win/2004/08/events/event\\n'\\n><System><Provider Name='Microsoft-Windows-Sysmon' Guid='{2222222222-C22A-43E0-BF4C-06F5698FFBD9}'/><EventID>1</EventID><Version>5</Version><Level>Information</Level><Task>Process Create (rule: ProcessCreate)</Task><Opcode>Info</Opcode><Keywords></Keywords><TimeCreated SystemTime='2016-09-19T17:50:20.719863700Z'/><EventRecordID>230097</EventRecordID><Correlation/><Execution ProcessID='3716' ThreadID='3740'/><Channel>Microsoft-Windows-Sysmon/Operational</Channel><Computer>LRXM</Computer><Security UserID='NT AUTHORITY\\\\SYSTEM'/></System><EventData>Process Create:\\nUtcTime: 2016-09-19 17:50:20.718\\nProcessGuid: {FCC7BD93-255C-57E0-0000-22222222222}\\nProcessId: 127228\\nImage: C:\\\\Windows\\\\System32\\\\Host2\\nCommandLine: Host2 /c echo ffsuli > \\\\\\\\.\\\\pipe\\\\ffsuli\\nCurrentDirectory: C:\\\\Windows\\\\system32\\\\\\nUser: NT AUTHORITY\\\\SYSTEM\\nLogonGuid: {2222222222-8F2C-57DC-0000-2222222}\\nLogonId: 0x3E7\\nTerminalSessionId: 0\\nIntegrityLevel: System\\nHashes: SHA1=\\n811627E612944FE5DADF2A14763A08111143C27E\\nParentProcessGuid: {22222222222-8F2B-57DC-0000-2222222222222}\\nParentProcessId: 504\\nParentImage:\\nC:\\\\Windows\\\\System32\\n\\\\Host1\\nParentCommandLine: C:\\\\Windows\\\\system32\\\\Host1</EventData></Event>\\nParentImage contains a path to the parent process.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Policy [7.2]': 'The specific policy referenced (for example, Firewall or Proxy) in a log message.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Policy\\nClient Console Short Name, Policy\\nWeb Console Tab/Name, Policy\\nElasticsearch Field Name, policy\\nRule Builder Column Name, Policy\\nRegex Pattern, <policy>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nPolicy\\nClient Console Short Name\\nPolicy\\nWeb Console Tab/Name\\nPolicy\\nElasticsearch Field Name\\npolicy\\nRule Builder Column Name\\nPolicy\\nRegex Pattern\\n<policy>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Group\\nLogin\\nAccount\\nDomain\\nObject (disambiguation—policy was historically stored as object in some cases)\\n', 'Common Applications': 'Firewall\\nAntivirus\\nIDS/IPS\\nDirectory\\nVulnerability scanners\\nAudit tools\\nProxies\\nIT management\\n', 'Use Case': 'Tracking group policy\\nCorrelating AV and vulnerability scanners\\nCompliance\\nPolicy violations\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Only store explicitly called out Policy values from log.\\nYou can store policy synonyms (for example, Standard).\\nCapture the broadest policy if multiple different policy types are defined in the log.\\n', 'Examples': 'SourceFire IDS\\n10 02 2016 20:30:22 1.1.1.1 <LOC6:WARN> Oct\\xa0 2 23:27:07 mtl-corp-sen-01 CORPvDC: Protocol: TCP, SrcIP: 1.1.1.1, DstIP: 1.1.1.1, SrcPort: 54217, DstPort: 443, TCPFlags: 0x0, IngressInterface: s1p6, EgressInterface: s1p5, IngressZone: Ingress_CORP_recflow_FROM_NX, EgressZone: Egress_CORP_recflow_TO_ASA, DE: Primary Detection Engine (f20ae1fc-2be2-22e3-9bcc-2222222222222),\\nPolicy: RECFLOW_CORP_Sensor\\n, ConnectType: End, AccessControlRuleName: Rules_Inspection_CORP_RF_Log, AccessControlRuleAction: Allow, UserName: No Authentication Required, Client: SSL client, ApplicationProtocol: HTTPS, WebApplication: recflow, InitiatorPackets: 9, ResponderPackets: 9, InitiatorBytes: 1017, ResponderBytes: 4258, NAPPolicy: RF_CORP_PREPROCESSORS, DNSResponseType: No Error, Sinkhole: Unknown, URLCategory: Unknown, URLReputation: Risk unknown, URL:\\nhttps://www.recordflow.bi\\nz\\nPolicy is parsed here as it is explicitly called out. NAPPolicy can go unparsed as there is a broader policy name field.\\nSourcefire IDS\\n05 22 2014 06:12:49 1.1.1.1 <SLOG:ERRR> 2014-05-22 10:12:47.494 recmetric:SOURCE[recflow.Host4]:REC2604E:[ALARM] Policy[\\nForTheRecord-Media\\n] User[recflow\\\\Domain Usersrecflowusers,Medium Mandatory Level@Mandatory Label...\\\\ercflow,Host4] Process[\\\\SystemRoot\\\\System32\\\\Host2] Action[read_dir] Res[M:\\\\Media\\\\QueryBuilder]\\xa0 Effect[DENIED Code (1U,2U,3U,4U,5U,6U,7U,8U,9U,10U,11U,12P,13P,14U,15U,16U,17A,18U,19M)]\\nForTheRecord-Media parses into Policy as it is explicitly called out.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Process ID': 'System or application process ID.\\n', 'Data Type': 'Integer\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Process ID\\nClient Console Short Name, Process ID\\nWeb Console Tab/Name, Process ID\\nElasticsearch Field Name, processId\\nRule Builder Column Name, ProcessID\\nRegex Pattern, <processid>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nProcess ID\\nClient Console Short Name\\nProcess ID\\nWeb Console Tab/Name\\nProcess ID\\nElasticsearch Field Name\\nprocessId\\nRule Builder Column Name\\nProcessID\\nRegex Pattern\\n<processid>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Process Name\\nParent Process ID\\nParent Process Name\\nParent Process Path\\n', 'Common Applications': 'Anything that tracks applications/processes.\\n', 'Use Case': 'Identifying what is running on a system.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': \"Process ID should be the unique identifier (typically a PID).\\nStore HEX representation by preference, but allow decimal if that's what log source provides.\\n\", 'Examples': '*nix\\n03 21 2014 10:13:00 1.1.1.1 <CLK1:INFO> crond[\\n2596\\n]: (root) CMD (/usr/lib64/sa/sa1 1 1)\\nIn *nix logs, the Process and ProcessID frequently follow the syslog facility and severity. In this case, crond is followed by the ProcessID 2596 in square braces.\\nCb Response\\n08 30 2016 02:20:42 1.1.1.1 <USER:NOTE> LEEF:1.0|CB|CB|1.1.1.1623.1033|watchlist.storage.hit.process|cb_server=cbserver\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 cb_version=1.1.1.1623.1033 childproc_count=1\\xa0\\xa0 cmdline=C:\\\\\\\\Windows\\\\\\\\system32\\\\\\\\cmd.exe /c ping provisionserver >nul 2>nul\\xa0\\xa0\\xa0\\xa0\\xa0 crossproc_count=1\\xa0\\xa0 filemod_count=0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 host_type=workstation\\xa0\\xa0\\xa0\\xa0\\xa0 last_update=2016-08-30T08:02:01.670Z\\xa0\\xa0\\xa0 modload_count=11\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 netconn_count=0\\xa0\\xa0\\xa0\\xa0 os_type=windows\\xa0\\xa0\\xa0\\xa0 parent_guid=11111111-0000-2010-01d2-0294ad4c889c parent_id=7575139489111111 parent_name=scsdiscovery.exe\\xa0\\xa0\\xa0\\xa0 parent_pid=8208\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 parent_unique_id=222222222-0000-2010-01d2-0294ad4c889c-00000001\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 path=c:\\\\\\\\windows\\\\\\\\syswow64\\\\\\\\cmd.exe\\xa0\\xa0\\xa0\\xa0 process_guid=222222-0000-097c-01d2-0294b431d3b1 process_id=2222222222222222\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 process_name=cmd.exe\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 process_pid=\\n2428\\nregmod_count=0\\xa0\\xa0\\xa0\\xa0\\xa0 server_name=localhost.localdomain start=2016-08-30T08:01:24.874Z\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 timestamp=1472548449.903\\xa0\\xa0 type=watchlist.storage.hit.process\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 unique_id=000001c3-0000-097c-01d2-0294b431d3b1-00000001\\xa0\\xa0\\xa0\\xa0 username=SYSTEM\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 watchlist_155=2016-08-30T09:10:02.525745Z\\xa0\\xa0\\xa0\\xa0\\xa0 watchlist_id=155\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 watchlist_name=Command Line\\nProcess_pid called out specifically.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Process Name': 'System or application process described by log message.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Process\\nClient Console Short Name, Process\\nWeb Console Tab/Name, Process Name\\nElasticsearch Field Name, process\\nRule Builder Column Name, Process\\nRegex Pattern, <process>\\nNetMon Name, Varies by protocol\\nClient Console Full Name\\nProcess\\nClient Console Short Name\\nProcess\\nWeb Console Tab/Name\\nProcess Name\\nElasticsearch Field Name\\nprocess\\nRule Builder Column Name\\nProcess\\nRegex Pattern\\n<process>\\nNetMon Name\\nVaries by protocol\\n', 'Field Relationships': 'Parent Process ID\\nParent Process Name\\nParent Process Path\\nProcess\\nProcess ID\\nObject\\nObject Name\\nObject Type\\nSession\\nSession Type\\n', 'Common Applications': 'Any application.\\n', 'Use Case': 'Monitoring timer jobs (for example, cron, or Windows scheduler).\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Process Name should contain the identified process (for example, PowerShell.exe).\\n', 'Examples': \"Cb Response\\n08 30 2016 02:20:42 1.1.1.1 <USER:NOTE> LEEF:1.0|CB|CB|1.1.1.1623.1033|watchlist.storage.hit.process|cb_server=cbserver\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 cb_version=1.1.1.1623.1033 childproc_count=1\\xa0\\xa0 cmdline=C:\\\\\\\\Windows\\\\\\\\system32\\\\\\\\cmd.exe /c ping provisionserver >nul 2>nul\\xa0\\xa0\\xa0\\xa0\\xa0 crossproc_count=1\\xa0\\xa0 filemod_count=0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 host_type=workstation\\xa0\\xa0\\xa0\\xa0\\xa0 last_update=2016-08-30T08:02:01.670Z\\xa0\\xa0\\xa0 modload_count=11\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 netconn_count=0\\xa0\\xa0\\xa0\\xa0 os_type=windows\\xa0\\xa0\\xa0\\xa0 parent_guid=22221c3-0000-2010-01d2-0294ad4c889c parent_id=75751394892752222\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 parent_name=scsdiscovery.exe\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 parent_pid=8208\\xa0\\xa0\\xa0\\xa0 parent_unique_id=2222222-0000-2010-01d2-0294ad4c889c-00002222\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 path=c:\\\\\\\\windows\\\\\\\\syswow64\\\\\\\\cmd.exe\\xa0\\xa0\\xa0\\xa0 process_guid=000001c9-2222-097c-01d2-0294b431d3b1 process_id=000001c3-0000-097c-01d2-222222222\\xa0\\xa0 process_name=\\ncmd.exe\\nprocess_pid=2428\\xa0\\xa0\\xa0 regmod_count=0\\xa0\\xa0\\xa0\\xa0\\xa0 server_name=localhost.localdomain start=2016-08-30T08:01:24.874Z timestamp=1472548449.903\\xa0\\xa0 type=watchlist.storage.hit.process\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 unique_id=000001c3-0000-097c-01d2-0294b431d3b1-00000001\\xa0\\xa0\\xa0\\xa0 username=SYSTEM\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 watchlist_155=2016-08-30T09:10:02.525745Z\\xa0\\xa0\\xa0\\xa0\\xa0 watchlist_id=155\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 watchlist_name=Command Line\\nProcess_name called out specifically.\\nWindows Event Log – System\\n<Event xmlns='\\nhttp://schemas.microsoft.com/win/2004/08/events/event'><System><Provider\\nName='Service Control Manager' Guid='{222222-a6d7-4695-8e1e-26931d2012f4}' EventSourceName='Service Control Manager'/><EventID Qualifiers='16384'>7036</EventID><Version>0</Version><Level>Information</Level><Task>None</Task><Opcode></Opcode><Keywords>Classic</Keywords><TimeCreated SystemTime='2016-08-01T08:58:46.675586600Z'/><EventRecordID>823261</EventRecordID><Correlation/><Execution ProcessID='512' ThreadID='8508'/><Channel>System</Channel><Computer> USABLDRRECFLOW01</Computer><Security/></System><EventData><Data Name='param1'>\\nWindows Error Reporting Service\\n</Data><Data Name='param2'>stopped</Data><Binary>57006500720053007622222222031000000</Binary></EventData></Event>\\nParam1 in the 7036 event indicates the service (process) status.\\n*nix\\n03 21 2014 10:13:00 1.1.1.1 <CLK1:INFO>\\ncrond\\n[2596]: (root) CMD (/usr/lib64/sa/sa1 1 1)\\nIn *nix logs, the process frequently follows the syslog facility and severity, in this case Cron Daemon.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Quantity': 'Quantity is a numeric integer count of something.\\n', 'Data Type': 'Integer\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Quantity\\nClient Console Short Name, Quantity\\nWeb Console Tab/Name, Quantity\\nElasticsearch Field Name, quantity\\nRule Builder Column Name, Quantity\\nRegex Pattern, <quantity>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nQuantity\\nClient Console Short Name\\nQuantity\\nWeb Console Tab/Name\\nQuantity\\nElasticsearch Field Name\\nquantity\\nRule Builder Column Name\\nQuantity\\nRegex Pattern\\n<quantity>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Amount\\nRate\\nSize\\n', 'Common Applications': 'Not heavily used.\\n', 'Use Case': 'Aggregated logs and UDLA queries for fraud detection.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Not used for percentages.\\nNot used for currency.\\nUsed to capture specific integer numbers.\\nUse Quantity to represent numbers, and Amount to represent percentages.\\n', 'Examples': \"Unisys Stealth\\n<Event xmlns='\\nhttp://schemas.microsoft.com/win/2004/08/events/event'><System><Provider\\nName='StealthUI'/><EventID Qualifiers='0'>109</EventID><Level>Information</Level><Task></Task><Keywords>Classic</Keywords><TimeCreated SystemTime='2016-12-09T05:26:38.000000000Z'/><EventRecordID>8449</EventRecordID><Channel>Application</Channel><Computer>psb-stl-em.LRPMBD.local</Computer><Security/></System><EventData><Data>User query for logs retrieved\\n19\\nrecords out of 1631 total records </Data></EventData></Event>\\nQuantity indicates the number of logs retrieved.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Rate': 'Defines a number per unit of time. Always expressed as a fraction.\\n', 'Data Type': 'Double\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Rate\\nClient Console Short Name, Rate\\nWeb Console Tab/Name, Rate\\nElasticsearch Field Name, rate\\nRule Builder Column Name, Rate\\nRegex Pattern, <rate>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nRate\\nClient Console Short Name\\nRate\\nWeb Console Tab/Name\\nRate\\nElasticsearch Field Name\\nrate\\nRule Builder Column Name\\nRate\\nRegex Pattern\\n<rate>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Size\\nQuantity\\nAmount\\n', 'Common Applications': 'Flow rate\\n', 'Use Case': 'Determining frequency.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Rarely used except where specifically called out as a rate.\\nThere is no quantifier of what the time is (second, minute, year, fortnight).\\n', 'Examples': 'SFlow Log\\nsFlow v5 AGENTIP=1.1.1.1 OPAQUE=flow_sample ENTERPRISE=0 FORMAT=2202 SAMPLENAME=AppOperation INPUTINTERFACE=21 OUTPUTINTERFACE=2 SAMPLEDATA=96 APPLICATION=_ OPERATION=_4 ATTRIBUTES=_ STATUS_DESC=TS REQ_BYTES=2323 RESP_BYTES=34343 USEC=12 STATUS=1 DETAILS=SubAgentId=0 AgentUpTime=142864 DatagramSequence=47998\\nSampleRate=16384 SamplePool=18939904\\nSampleRate could be a rate. SamplePool could be a size because it refers to the capacity of the pool.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Reason [7.2]': 'The justification for an action or result.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Reason\\nClient Console Short Name, Reason\\nWeb Console Tab/Name, Reason\\nElasticsearch Field Name, reason\\nRule Builder Column Name, Reason\\nRegex Pattern, <reason>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nReason\\nClient Console Short Name\\nReason\\nWeb Console Tab/Name\\nReason\\nElasticsearch Field Name\\nreason\\nRule Builder Column Name\\nReason\\nRegex Pattern\\n<reason>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Action\\nCommand\\nPolicy\\nResult\\nResponseCode\\n', 'Common Applications': 'Understanding why an action or command was executed, or why a result or ResponseCode was generated.\\n', 'Use Case': 'IDS/IPS\\nEmail filtering\\nFirewall blocking\\nAntivirus\\nVulnerability scanning\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'If the log explicitly calls out a policy, use policy instead.\\nReason should be free text. If it is an industry standard code use ResponseCode.\\nResult should be used for what and Reason should be used for why.\\n', 'Examples': \"eSafe Email Security\\n05 01 2012 16:21:21 1.1.1.1 <LOC5:ERRR> eSafeCR: Alert from eSafe\\xa0\\xa0\\xa0 Scan result: SMTP error\\xa0 Protocol: SMTP\\xa0 File Name\\\\Mail Subject:\\xa0 Business Plan & Financials\\xa0 Source: 1.1.1.1\\xa0 Destination: 1.1.1.1\\xa0 Mail Sender:\\nPeter.Store@recordflow.biz\\nMail Recipients:\\npete.store@recordflow.biz\\nDetails: Delivery Msg #911 - Email b0eeb3e8 NOT sent after multiple retries, likely\\nreason: 554 delivery error\\n: dd This user doesn't have a\\nrecordflow.biz\\naccount (pete.store@\\nrecordflow.biz\\n) [0] -\\nrecordflow.biz\\n.\\nThe Reason field (554) parses into ResponseCode because 554 is an SMTP response. The text after could be parsed into Reason. Obtain other samples to determine whether there is a legitimate pattern in the log.\\nAlcatel-Lucent Wireless Controller\\n12 10 2012 09:08:56 1.1.1.1 <LOC1:DBUG> Dec 10 09:09:03 DAVE authmgr[1600]: <124004> <DBUG> <DAVE-03 1.1.1.1>\\xa0 Setting user 00:00:00:00:00:00 aaa profile to default-dot1x,\\nreason: bbq_set_aaa_profile_defaults\\nThis is an assumed Policy, but additional logs and product knowledge is needed to confirm. There would not be a Reason in this log because the reason is that it is policy.\\nNetApp CIFS Security Audit Event Log\\n04/11/2016 16:55 TYPE=FailureAudit USER= COMP=Computer SORC=Security CATG=Logon/Logoff EVID=537 MESG=Logon Failure:\\nReason:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 An unexpected error occurred during logon\\nUser Name:\\xa0 -\\xa0 \\xa0\\xa0 Domain:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0 Logon Type: 3\\xa0 \\xa0\\xa0 Logon Process:\\xa0\\xa0\\xa0 Data ONTAP\\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0 Authentication Package:\\xa0\\xa0\\xa0 Extended Security\\xa0 \\xa0\\xa0\\xa0\\xa0 Workstation Name: -\\xa0 \\xa0\\xa0 Status code:\\xa0\\xa0\\xa0\\xa0\\xa0 -\\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0 Substatus code:\\xa0\\xa0 -\\xa0 \\xa0\\xa0 Caller User Name: -\\xa0 \\xa0\\xa0 Caller Domain:\\xa0\\xa0\\xa0 -\\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0 Caller Logon ID:\\xa0 -\\xa0 \\xa0\\xa0 Caller Process ID:\\xa0\\xa0\\xa0\\xa0\\xa0 3170862\\xa0 \\xa0\\xa0 Transited Services:\\xa0\\xa0 -\\xa0 \\xa0\\xa0 Source Network Address: 1.1.1.1\\xa0 \\xa0\\xa0 Source Port:\\xa0\\xa0\\xa0\\xa0\\xa0 0\\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0 Caller Process Name:\\nLogon failure is the event, and unexpected error parses into Reason.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Response Code [7.2]': 'The explicit and well-defined response code for an action or command in a log. Response Code differs from Result in that response code should be well structured and easily identifiable as a code.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Response Code\\nClient Console Short Name, Response Code\\nWeb Console Tab/Name, Response Code\\nElasticsearch Field Name, responseCode\\nRule Builder Column Name, ResponseCode\\nRegex Pattern, <responsecode>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nResponse Code\\nClient Console Short Name\\nResponse Code\\nWeb Console Tab/Name\\nResponse Code\\nElasticsearch Field Name\\nresponseCode\\nRule Builder Column Name\\nResponseCode\\nRegex Pattern\\n<responsecode>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Status\\nResult\\nAction\\nCommand\\nVMID\\n', 'Common Applications': 'Web server\\nProxy\\nMail server\\n', 'Use Case': 'Anything that captures HTTP or SMTP traffic.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Response Code should be industry standard. If it is a vendor standard, use VMID.\\nIf the value is unstructured text, use Result instead.\\nThis supplants VMID completely for parsing HTTP and SMTP response codes. In other words, VMID should be tied to a vendor while HTTP codes are an independent standard.\\nThis field can be extended to non-IT industry response codes. For example, credit card response codes if ATM or POS logs are parsed, and ICS/SCADA-specific protocols.\\n', 'Examples': 'IBM WebSphere DataPower Integration\\n03 23 2014 13:14:32 1.1.1.1 <USER:INFO> Mar 23 13:14:26USABLDRRECFLOW01 [Service_Router][mpgw][info] mpgw(Routing_Int_MPG): trans(1954389697)[1.1.1.1]: HTTP\\nresponse code 200\\nfor \\'\\nhttps://1.1.1.1:54010/legacy/eg/aggregate\\n\\'\\n200 parsed into Response code.\\nMicrosoft IIS\\n::1, Host1st@Host2, 8/25/2015, 15:25:43, W3SVC2, USABLDRRECFLOW01, ::1, 171, 327, 512,\\n500\\n, 0, GET, /, |88|800a0009|Subscript_out_of_range:_\\'[number:_1]\\',\\nHTTP response code.\\nMicrosoft ActiveSync 2010\\n2012-08-26 00:07:52 1.1.1.1 GET /owa/1.1.1.1/scripts/premium/flogon.js - 443 - 1.1.1.1 Mozilla/5.0+(Windows+NT+6.1;+WOW64)+AppleWebKit/537.1+(KHTML,+like+Gecko)+Chrome/21.0.1180.83+Safari/537.1\\n304\\n0 0 281\\nHTTP response code from ActiveSync.\\nMicrosoft IIS SMTP\\n2012-03-29 07:30:50 1.1.1.1 USABLDRRECFLOW01SMTPSVC1 CDESMTP 1.1.1.1 0 HELO - +CDENETMON\\n250\\n0 55 14 0 SMTP - - - -\\nSMTP response code.\\nBluecoat Proxy\\n06 29 2015 14:26:18 1.1.1.1 <USER:NOTE> date=2015-06-29 time=19:25:57 time-taken=65 c-ip=1.1.1.1 cs-username=- cs-auth-group=- x-exception-id=- sc-filter-result=OBSERVED cs-categories=\"Technology/Internet\" cs(Referer)=\\nhttp://www.amazon.com/Travel-Mattress-Healing-Magnetic-Cover/dp/B0029OMC6A\\ncs-status=500\\ns-action=TCP_NC_MISS cs-method=GET rs(Content-Type)=text/xml cs-uri-scheme=http cs-host=\\nfls-na.amazon.com\\ncs-uri-port=80 cs-uri-path=/1/amazon-clicks/1/OP cs-uri-query=?requestId=1J6GGDGMDB10asdvasehQ2&childRequestId=152CJ96fgnfhjkjTW28Z5AP&widgetName=variant_ads_below_fold&searchResultNumber=1&impressionRankOnAsin=3 cs-uri-extension=- cs(User-Agent)=Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko s-ip=1.1.1.1 cs-bytes=1217 rs-bytes=293\\nDespite Status being the key, the value is an HTTP response code.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Result [7.2]': 'Result is for the outcome of a command operation or action.\\xa0 For example, the result of “quarantine\" might be \"success.\"\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Result\\nClient Console Short Name, Result\\nWeb Console Tab/Name, Result\\nElasticsearch Field Name, result\\nRule Builder Column Name, Result\\nRegex Pattern, <result>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nResult\\nClient Console Short Name\\nResult\\nWeb Console Tab/Name\\nResult\\nElasticsearch Field Name\\nresult\\nRule Builder Column Name\\nResult\\nRegex Pattern\\n<result>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Action\\n. The Action should be what generated the result.\\nCommand\\n. A Command could also be a generator of a result.\\nStatus\\n. Status is similar to Result, but reserved for explicitly defined result values. Result is an outcome, whereas a Status can be independent of the action.\\n', 'Common Applications': 'Endpoint protection such as CarbonBlack or Cylance\\nIDS/IPS\\n', 'Use Case': 'Determining whether an action or command succeeded or failed. Validating normal operational process.\\nMonitoring backup processes to see if they were successful.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Result is the outcome of an occurence and should be tied to a command, action, or policy.\\nResult should not contain industry standard response codes such as HTTP response codes.\\nIf given a choice, use VMID/Vendor Info if the log is just a message and not tied to an action/command. Use Result if the log contains a clear action/command. For example, VMID/Vendor Info might be tied to \"Attempted quarantine\" and the result might be \"success.”\\nDo not take result in the log literally. It could be a result, a VMID, or a status.\\n', 'Examples': 'F5 BIG-IP ASM\\n03 22 2012 14:19:54 a4eg01-1-admi <LOC1:NOTE> Mar 22 14:19:54 USABLDRRECFLOW01 local/ USABLDRRECFLOW01-1 notice apd[4096]: 01490102:5: de71deef:\\nAccess policy result: Network_Access\\nAccess policy result shows Network Access as the result of a policy being applied. Network Access parses into Result.\\nVamsoft ORF\\n01 27 2013 18:54:25 1.1.1.1 <MAIL:INFO> Jan 27 18:52:57 fe80::1111:11e1:31111:dsfsd%13 ORFEE: SRC:SMTPSVC-1,CLASS:Blacklist,ACT:Reject,FP: OnArrival,IP:1.1.1.1,SND:no-reply@Host34,RCPT: pstore@Host2;agent414@Host2,TEXT:Email blacklisted by the SPF test (sender forged per policy of \"Host34\",\\nSPF result: Fail\\n).\\nFail or SPF Fail parses into Result, reject from the ACT field parses into Action, and Blacklist or Sender Forged parses into Policy.\\nWindows Event Log – Trend Micro AV\\n<Event xmlns=\\'\\nhttp://Host3/win/2004/08/events/event\\'><System><Provider\\nName=\\'Trend Micro OfficeScan Server\\'/><EventID Qualifiers=\\'32773\\'>600</EventID><Level>Warning</Level><Task>System</Task><Keywords>Classic</Keywords><TimeCreated SystemTime=\\'2016-07-26T22:37:03.000000000Z\\'/><EventRecordID>152848</EventRecordID><Channel>Application</Channel><Computer>Host2</Computer><Security UserID=\\'NT AUTHORITY\\\\SYSTEM\\'/></System><EventData>Virus/Malware: Unauthorized File Encryption\\nEndpoint: USABLDRRECFLOW01\\nDomain: safaware\\\\\\nFile: \\\\\\\\safaware\\\\thinnerapp\\\\lotusnotes\\\\bin\\\\lotus Host1\\nDate/Time: 7/26/2016 18:35:25\\nResult: Virus successfully detected, cannot perform the Quarantine action\\n</EventData></Event>\\nShowing result of AV scan and attempted remediation action to Quarantine.\\nCisco IDS/IPS\\n<evStatus eventId=\"1332222222222228024371874\" vendor=\"Cisco\" xmlns=\"\\nhttp://www.cisco.com/cids/2006/08/cidee\\n\">\\n> USABLDRRECFLOW01</hostId><appName>mainApp</appName><appInstanceId>1260</appInstanceId></originator><time offset=\"-300\" timeZone=\"GMT-06:00\">1345793398595703000</time><autoUpgradeServerCheck><uri>\\nhttp://breon.moore@1.1.1.1//swc/esd/06/273556262/contract/recordflowconsole.pkg\\n</packageFileName>\\n<result status=\"true\"></result>\\n</autoUpgradeServerCheck></evStatus>\\nThis is a Result instead of a Status because it represents an outcome of a task or operation. Status represents a state independent of an operation being performed. AutoUpgradeServerCheck may parse into Action.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Session': 'Unique user or system session identifier.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Session\\nClient Console Short Name, Session\\nWeb Console Tab/Name, Session\\nElasticsearch Field Name, session\\nRule Builder Column Name, Session\\nRegex Pattern, <session>\\nNetMon Name, SessionID\\nClient Console Full Name\\nSession\\nClient Console Short Name\\nSession\\nWeb Console Tab/Name\\nSession\\nElasticsearch Field Name\\nsession\\nRule Builder Column Name\\nSession\\nRegex Pattern\\n<session>\\nNetMon Name\\nSessionID\\n', 'Field Relationships': 'Account\\nLogin\\nSessionType\\nProtname\\nProtnum\\nIP Address Fields\\nProcess\\nProcessID\\n', 'Common Applications': 'SSH\\nRemote Desktop\\nTelnet\\nFTP\\nWeb Application\\nShell\\nWeb Browser\\n', 'Use Case': 'NetMon session identifier.\\nUser session for a web session or computer session.\\nSession ID for a VoIP call.\\nSession record for a vulnerability scan.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Unique non-permanent identifier for a user/system session.\\nSession Token identifier/number.\\nUsed for tracking activity associated with a session.\\nNot ProcessID.\\n', 'Examples': \"Linux Host\\n10 15 2010 10:50:31 1.1.1.1 <SAU1:INFO> Oct 15 10:50:30 USABLDRRECFLOW01: [ID 702911 Host7] 700 Auth_method_success, Username: pete.store, Auth method: keyboard-interactive, Session-Id:\\n10707\\nSession-ID parses into Session.\\nWindows Event Log\\n<Event xmlns='\\nhttp://schemas.microsoft.com/win/2004/08/events/event'><System><Provider\\nName='Microsoft-Windows-Security-Auditing' Guid='{54849625-5478-4994-a5ba-22222222222}'/><EventID>4742</EventID><Version>0</Version><Level>Information</Level><Task>Computer Account Management</Task><Opcode>Info</Opcode><Keywords>Audit Success</Keywords><TimeCreated SystemTime='2016-02-24T19:46:19.175040100Z'/><EventRecordID>4814831973</EventRecordID><Correlation/><Execution ProcessID='560' ThreadID='8892'/><Channel>Security</Channel><Computer> USABLDRRECFLOW01</Computer><Security/></System><EventData><Data Name='ComputerAccountChange'>-</Data><Data Name='TargetUserName'> USABLDRRECFLOW01$</Data><Data Name='TargetDomainName'>SAFAWARE</Data><Data Name='TargetSid'>SAFAWARE\\\\ USABLDRRECFLOW01$</Data><Data Name='SubjectUserSid'>NT AUTHORITY\\\\ANONYMOUS LOGON</Data><Data Name='SubjectUserName'>ANONYMOUS LOGON</Data><Data Name='SubjectDomainName'>NT AUTHORITY</Data><Data Name='SubjectLogonId'>\\n0x3e6\\n</Data><Data Name='PrivilegeList'>-</Data><Data Name='SamAccountName'>-</Data><Data Name='DisplayName'>-</Data><Data Name='UserPrincipalName'>-</Data><Data Name='HomeDirectory'>-</Data><Data Name='HomePath'>-</Data><Data Name='ScriptPath'>-</Data><Data Name='ProfilePath'>-</Data><Data Name='UserWorkstations'>-</Data><Data Name='PasswordLastSet'>2/24/2016 12:46:19 PM</Data><Data Name='AccountExpires'>-</Data><Data Name='PrimaryGroupId'>-</Data><Data Name='AllowedToDelegateTo'>-</Data><Data Name='OldUacValue'>-</Data><Data Name='NewUacValue'>-</Data><Data Name='UserAccountControl'>-</Data><Data Name='UserParameters'>-</Data><Data Name='SidHistory'>-</Data><Data Name='LogonHours'>-</Data><Data Name='DnsHostName'>-</Data><Data Name='ServicePrincipalNames'>-</Data></EventData></Event>\\nSubjectLogonID parses into Session. Used to track user activity from login to logout.\\nWindows Event Log\\n<Event xmlns='\\nhttp://schemas.microsoft.com/win/2004/08/events/event'><System><Provider\\nName='Microsoft-Windows-Security-Auditing' Guid='{222222-5478-4994-a5ba-3e3b0328c30d}'/><EventID>4624</EventID><Version>0</Version><Level>Information</Level><Task>Logon</Task><Opcode>Info</Opcode><Keywords>Audit Success</Keywords><TimeCreated SystemTime='2016-02-09T00:45:00.703363000Z'/><EventRecordID>2269912024</EventRecordID><Correlation/><Execution ProcessID='520' ThreadID='12080'/><Channel>Security</Channel><Computer> USABLDRRECFLOW01</Computer><Security/></System><EventData><Data Name='SubjectUserSid'>NT AUTHORITY\\\\SYSTEM</Data><Data Name='SubjectUserName'> USABLDRRECFLOW01$</Data><Data Name='SubjectDomainName'>SAFAWARE</Data><Data Name='SubjectLogonId'>0x3e7</Data><Data Name='TargetUserSid'>NT AUTHORITY\\\\SYSTEM</Data><Data Name='TargetUserName'>SYSTEM</Data><Data Name='TargetDomainName'>NT AUTHORITY</Data><Data Name='TargetLogonId'>\\n0x3e7\\n</Data><Data Name='LogonType'>5</Data><Data Name='LogonProcessName'>Advapi\\xa0 </Data><Data Name='AuthenticationPackageName'>Negotiate</Data><Data Name='WorkstationName'></Data><Data Name='LogonGuid'>{00000000-0000-0000-0000-000000000000}</Data><Data Name='TransmittedServices'>-</Data><Data Name='LmPackageName'>-</Data><Data Name='KeyLength'>0</Data><Data Name='ProcessId'>0x200</Data><Data Name='ProcessName'>C:\\\\Windows\\\\System32\\\\services.exe</Data><Data Name='IpAddress'>-</Data><Data Name='IpPort'>-</Data></EventData></Event>\\nTargetLogonID is parsed instead of SubjectLogonID. Using Target because it is the initiation of a new session that can be tracked separate from the initiator session. For example, Process Run As a different user in Windows.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Session Type [7.2]': 'The type of session described in the log (for example, console, CLI, or web). This field is free text.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String (128 characters)\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Session Type\\nClient Console Short Name, Session Type\\nWeb Console Tab/Name, Session Type\\nElasticsearch Field Name, sessionType\\nRule Builder Column Name, SessionType\\nRegex Pattern, <sessiontype>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nSession Type\\nClient Console Short Name\\nSession Type\\nWeb Console Tab/Name\\nSession Type\\nElasticsearch Field Name\\nsessionType\\nRule Builder Column Name\\nSessionType\\nRegex Pattern\\n<sessiontype>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'See\\nIANA Protocol Number\\nand\\nIANA Protocol Name\\nSee\\nIANA Protocol Number\\nand\\nIANA Protocol Name\\nSession\\nLogin\\nAccount\\nDomain\\nProcess\\nProcessID\\nProtname\\nProtnum\\n', 'Common Applications': 'Windows security log lists all types of sessions (logon type)\\nLinux authentication methods\\n', 'Use Case': 'Tracking how users are interacting with a system.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'SessionType can exist without Session.\\nSession can exist without a defined Session Type.\\n', 'Examples': \"Linux Host\\n10 15 2010 10:50:31 1.1.1.1 <SAU1:INFO> Oct 15 10:50:30 USABLDRRECFLOW01: [ID 702911 Host7] 700 Auth_method_success, Username: pete.store, Auth method:\\nkeyboard-interactive\\n, Session-Id: 10707\\nKeyboard-Interactive parses into Session Type.\\nWindows Event Log\\n<Event xmlns='\\nhttp://schemas.microsoft.com/win/2004/08/events/event'><System><Provider\\nName='Microsoft-Windows-Security-Auditing' Guid='{2222222-5478-4994-a5ba-3e3b0328c30d}'/><EventID>4624</EventID><Version>0</Version><Level>Information</Level><Task>Logon</Task><Opcode>Info</Opcode><Keywords>Audit Success</Keywords><TimeCreated SystemTime='2016-02-09T00:45:00.703363000Z'/><EventRecordID>2269912024</EventRecordID><Correlation/><Execution ProcessID='520' ThreadID='12080'/><Channel>Security</Channel><Computer> USABLDRRECFLOW01</Computer><Security/></System><EventData><Data Name='SubjectUserSid'>NT AUTHORITY\\\\SYSTEM</Data><Data Name='SubjectUserName'>USBO1PDC02$</Data><Data Name='SubjectDomainName'>SAFAWARE</Data><Data Name='SubjectLogonId'>0x3e7</Data><Data Name='TargetUserSid'>NT AUTHORITY\\\\SYSTEM</Data><Data Name='TargetUserName'>SYSTEM</Data><Data Name='TargetDomainName'>NT AUTHORITY</Data><Data Name='TargetLogonId'>\\n0x3e7\\n</Data><Data Name='LogonType'>\\n5\\n</Data><Data Name='LogonProcessName'>Advapi\\xa0 </Data><Data Name='AuthenticationPackageName'>Negotiate</Data><Data Name='WorkstationName'></Data><Data Name='LogonGuid'>{00000000-0000-0000-0000-000000000000}</Data><Data Name='TransmittedServices'>-</Data><Data Name='LmPackageName'>-</Data><Data Name='KeyLength'>0</Data><Data Name='ProcessId'>0x200</Data><Data Name='ProcessName'>C:\\\\Windows\\\\System32\\\\services.exe</Data><Data Name='IpAddress'>-</Data><Data Name='IpPort'>-</Data></EventData></Event>\\nLogonType parses into Session Type. Establishes the LogonID as a Service. Service session can be tracked with Session 0x3e7.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Size': 'Numeric description of capacity (for example, disk size). Size is best thought of as a limit rather than a current measurement. Use Amount for non-specific measurements.\\n', 'Data Type': 'Double\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Size\\nClient Console Short Name, Size\\nWeb Console Tab/Name, Size\\nElasticsearch Field Name, size\\nRule Builder Column Name, Size\\nRegex Pattern, <size>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nSize\\nClient Console Short Name\\nSize\\nWeb Console Tab/Name\\nSize\\nElasticsearch Field Name\\nsize\\nRule Builder Column Name\\nSize\\nRegex Pattern\\n<size>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Amount\\nQuantity\\nRate\\n[prefix]Bytes\\n', 'Common Applications': 'IT Operations (drive size)\\nCPU usage (for example, threshold limit on a CPU alert)\\n', 'Use Case': 'Used in conjunction with other numeric tags such as bytes or megabytes, can show a disk capacity (<size>) and the usage in <megabytes>.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Use size for capacity measures, use quantity, amount, or [prefix]bytes for measuring current value.\\nIf there is no label to an explicit size in the log, use <size> when the value is an integer.\\n', 'Examples': 'Threat Defense\\n07 18 2015 23:30:02 1.1.1.1 <LOC6:INFO> Jul 18 23:30:02 ATD-3000 ATD2ESM[26906]: {\"CPU Alert\": {\"\\nCPU Usage\":83.7, \"CPU Threshold\":75.0\\n}}\\nSize could be based on the CPU Threshold. Amount could be used for the CPU Usage.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Status [7.2]': \"The vendor's perspective on the state of a system, process, or entity. Status should not be used as the result of an action.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n\", 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Status\\nClient Console Short Name, Status\\nWeb Console Tab/Name, Status\\nElasticsearch Field Name, status\\nRule Builder Column Name, Status\\nRegex Pattern, <status>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nStatus\\nClient Console Short Name\\nStatus\\nWeb Console Tab/Name\\nStatus\\nElasticsearch Field Name\\nstatus\\nRule Builder Column Name\\nStatus\\nRegex Pattern\\n<status>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'ResponseCode\\nAction\\nCommand\\nProcess\\nResult\\nPolicy\\n', 'Common Applications': 'Inventory trackers\\nSNMP analysis\\nHeartbeat detection\\n', 'Use Case': 'IT operations\\nDeployment monitors\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Status should refer to the state, not the result of an action.\\n', 'Examples': '', 'Correct Examples': 'Elastic search – red/yellow/green\\nRaid array – drive up/down\\nService monitoring – email server up/down\\n', 'Incorrect Examples': 'Cisco Secure ACS\\n06 06 2013 09:12:45 1.1.1.1 <LOC6:NOTE> Jun\\xa0 6 09:12:45 USABLDRRECFLOW01 CSCOacs_TACACS_Accounting 0000817989 2 1\\xa0 AuditSessionId=firemon:1.1.1.1:tty1:1.1.1.1, Response={Type=Accounting;\\nAcctReply-Status=Success\\n; }\\nAccounting Status was Success, but this is a Result, not a Status.\\nTectia SSH Server\\n84479804 | 8/7/2013 4:00:23 AM | None | N/A | USABLDRRECFLOW01 | Information | 0 | SSH Tectia Server | 709 Publickey_auth_warning, Username: MET_INTNET\\\\SSHVRZCOMM, Algorithm: publickey, \"Unknown key type for `d:\\\\transops\\\\crit\\\\sshusers\\\\SSHBBQCOM\\\\.ssh2\\\\id_rsa_pub\\' (\\nstatus: Key type given not recognized\\n).\", Session-Id: 28172\\nKey value pair showing the status of the public key, but this should be a Reason not a Status.\\nWindows Event Log\\n<Event xmlns=\\'\\nhttp://Host1/win/2004/08/events/event\\'><System><Provider\\nName=\\'SQLSERVERAGENT\\'/><EventID Qualifiers=\\'16384\\'>208</EventID><Level>Warning</Level><Task>Job Engine</Task><Keywords>Classic</Keywords><TimeCreated SystemTime=\\'2015-07-23T18:20:39.000000000Z\\'/><EventRecordID>2042567</EventRecordID><Channel>Application</Channel><Computer> USABLDRRECFLOW01</Computer><Security/></System><EventData>SQL Server Scheduled Job \\'LogRhythm Sunday Maintenance\\' (0x7A222222222E72222F538A9DE038D2F3) -\\nStatus: Failed\\n- Invoked on: 2015-07-23 12:20:38 - Message: The job failed.\\xa0 The Job was invoked by User sa.\\xa0 The last step to run was step 29 (LogRhythm Job Step Validation).\\xa0 The job was requested to start at step 29 (LogRhythm Job Step Validation).</EventData></Event>\\nShowing a failed status for maintenance job. That is a Result, not a Status.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Subject': 'Originally meant to be the subject of an email. In 7.2 schema, this field becomes a secondary \"category\" field that can be used in several ways.\\n', 'Data Type': 'String (255 characters maximum)\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Subject\\nClient Console Short Name, Subject\\nWeb Console Tab/Name, Subject\\nElasticsearch Field Name, subject\\nRule Builder Column Name, Subject\\nRegex Pattern, <subject>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nSubject\\nClient Console Short Name\\nSubject\\nWeb Console Tab/Name\\nSubject\\nElasticsearch Field Name\\nsubject\\nRule Builder Column Name\\nSubject\\nRegex Pattern\\n<subject>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Email fields (if email) for context\\nLook at VMID, Vendor Info, and other category fields before using Subject\\n', 'Common Applications': 'Proxies\\nNGFW\\nNetMon\\n', 'Use Case': 'Classifying traffic (for example, secondary family of http traffic destinations).\\nCategorizing data within the log, not the actual log message (use VMID, Vendor Info instead).\\nUEBA—sub category of anomaly type.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Use Subject as a category field only if another field is not more directly named (for example, Vendor Info).\\n', 'Incorrect Examples': 'Microsoft Event Log\\n<Event xmlns=\\'\\nhttp://schemas.microsoft.com/win/2004/08/events/event\\'><System><Provider\\nName=\\'MetaFrameEvents\\'/><EventID Qualifiers=\\'49152\\'>10001</EventID><Level>Error</Level><Task>None</Task><Keywords>Classic</Keywords><TimeCreated SystemTime=\\'2016-07-20T07:13:01.000000000Z\\'/><EventRecordID>5950393</EventRecordID><Channel>Application</Channel><Computer> USABLDRRECFLOW01</Computer><Security/></System><EventData>\\nA usable server cannot be found on which to launch the application.\\nApplication: Citrix AppCenter, Client: USABLDRRECFLOW01 (address: 1.1.1.1;;;), User pete.store. Check your worker group definitions and load balancing policies to verify appropriate servers are assigned for Citrix AppCenter. </EventData></Event>\\nBased on the current standard this is incorrect; the above parses a description of the event into Subject. The Vendor Info tag can supplant this usage. This needs to parse into Vendor Info.\\nAnother Microsoft Event Log\\n<Event xmlns=\\'\\nhttp://schemas.microsoft.com/win/2004/08/events/event\\'><System><Provider\\nName=\\'MOVEit Central\\'/><EventID Qualifiers=\\'32768\\'>3</EventID><Level>Warning</Level><Task>None</Task><Keywords>Classic</Keywords><TimeCreated SystemTime=\\'2016-09-22T01:18:14.000000000Z\\'/><EventRecordID>1325287</EventRecordID><Channel>Application</Channel><Computer> USABLDRRECFLOW01</Computer><Security/></System><EventData>\\nTask \"Symitar Email Notifications\": Could not log task end: [Microsoft][SQL Server Native Client 10.0]Communication link failure\\n</EventData></Event>\\nSubject is parsing the entire event data. This is too broad and makes any kind of normalization impossible. This should be parsed into multiple fields including Object, Action, and Vendor Info.\\nBlue Coat Proxy Log\\n2016-07-21 20:42:18 3148 1.1.1.1\\nhttp://www.amazon.com/Travel-Mattress-Healing-Magnetic-Cover/dp/B0029OMC6A\\nRCF\\\\Internet_users 1.1.1.1 1.1.1.1 Unavailable - Host3_exception DENIED \"\\nSpam;Malicious Outbound Data/Botnets;Scam/Questionable/Illegal\\n\" -\\xa0 200 TCP_DENIED GET text/html;%20charset=UTF-8 http Host2 80 /Host1 - ico \"Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko\" 1.1.1.1 3323 260 - \"none\" \"none\" unavailable\\nSubject parsing out the web content category. This might be OK if Subject definition is broadened to something more akin to category.\\nWindows Application Event Log\\n<Event xmlns=\\'\\nhttp://schemas.microsoft.com/win/2004/08/events/event\\'><System><Provider\\nName=\\'Microsoft-Windows-EventSystem\\' Guid=\\'{899daace-4868-4295-afcd-9eb8fb497561}\\' EventSourceName=\\'EventSystem\\'/><EventID Qualifiers=\\'32768\\'>4609</EventID><Version>0</Version><Level>Warning</Level><Task>Event Service</Task><Opcode></Opcode><Keywords>Classic</Keywords><TimeCreated SystemTime=\\'2016-10-21T14:39:07.000000000Z\\'/><EventRecordID>1919714</EventRecordID><Correlation/><Execution ProcessID=\\'0\\' ThreadID=\\'0\\'/><Channel>Application</Channel><Computer> USABLDRRECFLOW01</Computer><Security/></System><EventData><Data Name=\\'param1\\'>d:\\\\recflow\\\\com \\\\security.cpp</Data><Data Name=\\'param2\\'>75</Data><Data Name=\\'param3\\'>\\n822706e5\\n</Data></EventData></Event>\\nReturn Code parses into Subject for lack of a better field. Response Code should be used for this instead.\\nWindows Application Event Log\\n<Event xmlns=\\'\\nhttp://schemas.microsoft.com/win/2004/08/events/event\\'><System><Provider\\nName=\\'MsiInstaller\\'/><EventID Qualifiers=\\'0\\'>11728</EventID><Level>Information</Level><Task>None</Task><Keywords>Classic</Keywords><TimeCreated SystemTime=\\'2016-11-15T18:44:56.000000000Z\\'/><EventRecordID>38096</EventRecordID><Channel>Application</Channel><Computer> USABLDRRECFLOW01</Computer><Security UserID=\\'SAFAWARE\\\\pete.store/></System><EventData><Data>Product: LogRhythm Console --\\nConfiguration completed successfully\\n.</Data><Data>(NULL)</Data><Data>(NULL)</Data><Data>(NULL)</Data><Data>(NULL)</Data><Data>(NULL)</Data><Data></Data><Binary>7B38354632314132452D364144432D344638312D38454544211111111111130333237357D</Binary></EventData></Event>\\nAnother example of an event description in Subject. This could be parsed into Vendor Information.\\nWindows Security Event Log\\n<Event xmlns=\\'\\nhttp://schemas.microsoft.com/win/2004/08/events/event\\'><System><Provider\\nName=\\'Microsoft-Windows-Security-Auditing\\' Guid=\\'{54849625-5478-4994-a5ba-3e3b0328c30d}\\'/><EventID>4656</EventID><Version>1</Version><Level>Information</Level><Task>\\nRemovable Storage\\n</Task><Opcode>Info</Opcode><Keywords>Audit Success</Keywords><TimeCreated SystemTime=\\'2016-02-23T00:34:58.244632600Z\\'/><EventRecordID>7148428</EventRecordID><Correlation/><Execution ProcessID=\\'504\\' ThreadID=\\'512\\'/><Channel>Security</Channel><Computer> USABLDRRECFLOW01</Computer><Security/></System><EventData><Data Name=\\'SubjectUserSid\\'>NT AUTHORITY\\\\SYSTEM</Data><Data Name=\\'SubjectUserName\\'> USABLDRRECFLOW01$</Data><Data Name=\\'SubjectDomainName\\'>SAFAWARE</Data><Data Name=\\'SubjectLogonId\\'>0x3e7</Data><Data Name=\\'ObjectServer\\'>Security</Data><Data Name=\\'ObjectType\\'>File</Data><Data Name=\\'ObjectName\\'>\\\\Device\\\\Floppy0</Data><Data Name=\\'HandleId\\'>0x328</Data><Data Name=\\'TransactionId\\'>{00000000-0000-0000-0000-000000000000}</Data></EventData></Event>\\nRemoveable Storage parses into Subject. Object and Object Name are in use already. Object Type could be used in this instance, possibly rearranging use of Object and Object Name, as they are File and \\\\Device\\\\Floppy0, respectively.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'URL': 'The URL referenced or impacted by activity reported in the log.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, URL\\nClient Console Short Name, URL\\nWeb Console Tab/Name, URL\\nElasticsearch Field Name, url\\nRule Builder Column Name, URL\\nRegex Pattern, <url>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nURL\\nClient Console Short Name\\nURL\\nWeb Console Tab/Name\\nURL\\nElasticsearch Field Name\\nurl\\nRule Builder Column Name\\nURL\\nRegex Pattern\\n<url>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Domain (Domain Impacted)\\nDomain Origin\\nSession\\nResponse Code\\nProtocol Number\\nProtocol Name\\n', 'Common Applications': 'Proxy\\nIDS/IPS\\nNetwork monitoring\\nFirewall\\nWeb servers/DNS\\n', 'Use Case': 'Tracking user web activity.\\nTracking and comparing hostile domains with lists of known bad web domains.\\n', 'MPE/Data Masking Manipulations': 'Data Masking is used for QNAME format URL (14)DB001560E6EBC5(9)soasdfgtu(3)com(0.\\n', 'Usage Standards': \"Do not use the vendor's link to details, which parses into Vendor Info.\\n\", 'Examples': 'Blue Coat Proxy\\n08 27 2011 19:00:00 1.1.1.1 <USER:NOTE> 2011-08-27 02:05:36 151 3.1.4.2 - - - OBSERVED \"Email\"\\nhttp://Host10.com/neo/launch?.rand=6upoddav8e6\\n204 TCP_NC_MISS POST text/json http Host10 80 /neo/stat - - \"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.2; WOW64; Trident/4.0; .NET CLR 1.1.4322; .NET CLR 2.0.50727; .NET CLR 3.0.04506.30; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; InfoPath.2)\" 1.1.1.1 492 1434 –\\nHighlighted URL from proxy log parses into URL.\\nWindows DNS\\n11/21/2011 10:14:05 AM 0F8C PACKET\\xa0 00000000089853C0 UDP Snd 1.1.1.1\\xa0 fa93 R Q [8385 A DR NXDOMAIN] A (14)HP001560E6EBC5(9)sonalysts(3)com(0)\\n(14)DB001560E6EBC5(9)soasdfgtu(3)com(0(14)DB001560E6EBC5(9)soasdfgtu(3)com(0 with length octets. This is often a use case for data masking to replace the length octet with a period.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'User Agent [7.2]': 'The User Agent string from web server logs (for example, Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36).\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String (255 characters maximum)\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, User Agent\\nClient Console Short Name, User Agent\\nWeb Console Tab/Name, User Agent\\nElasticsearch Field Name, userAgent\\nRule Builder Column Name, UserAgent\\nRegex Pattern, <useragent>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nUser Agent\\nClient Console Short Name\\nUser Agent\\nWeb Console Tab/Name\\nUser Agent\\nElasticsearch Field Name\\nuserAgent\\nRule Builder Column Name\\nUserAgent\\nRegex Pattern\\n<useragent>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Full URL\\n', 'Common Applications': 'Web server logs\\nFirewalls\\n', 'Use Case': 'Detecting malicious or malformed user agents.\\nSearching for user agents as IOCs.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Parse the full user agent string into the field.\\n', 'Examples': 'Juniper SSLVPN\\n07 31 2007 10:24:57 1.1.1.1 <LOC6:INFO> SSLVPN: id=sslvpn sn=0006222222B74 time=\"2007-07-31 10:24:57\" vp_time=\"2007-07-31 15:24:57 UTC\" fw=1.1.1.1 pri=6 m=18 src=1.1.1.1 dst=1.1.1.1 user=\"pete.store\" usr=\"pete.store\" msg=\"NetExtender\" rule=access-policy proto=NetExtender agent=\"\\nMozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1)\\n\"\\nMozilla/4.0… parses into User Agent.\\nMS IIS Web Log\\n10 30 2007 15:41:49 USABLDRRECFLOW01/1.1.1.1 <USER:NOTE> Oct 30 15:41:53 recflow/1.1.1.1 IISWebLog 3 2007-10-30 19:41:47 W3SVC414557987 recflow 1.1.1.1 POST /DataPHost2 - 443 - 1.1.1.1 HTTP/1.1\\nMozilla/4.0+(compatible;+MSIE+6.0;+Windows+5.2.3790.0;+MS+.NET+Remoting;+MS+.NET+CLR+1.1.4322.2407+)\\n- - Host1 200 0 0 2277 1993 0Full UserAgent string capture\\nBluecoat Proxy\\n2010-03-01 20:23:45 1 1.1.1.1 pete.store safaware\\\\Domain%20Users - OBSERVED \"Sports/Recreation\"\\nhttp://espn.go.com/free-online-games/\\n200 TCP_HIT GET image/jpeg http\\na.espncdn.com\\n80 /i/espnarcade/GOM/116x67_gom_touch.jpg - jpg \"\\nMozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; InfoPath.2; .NET CLR 2.0.50727; .NET CLR 3.0.04506.30; .NET CLR 3.0.04506.648; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729)\\n\" 1.1.1.1 4318 443 -\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nApplication Tab\\n', 'Version': 'The software or hardware device version described in either the process, object, or entity.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Version\\nClient Console Short Name, Version\\nWeb Console Tab/Name, Version\\nElasticsearch Field Name, version\\nRule Builder Column Name, Version\\nRegex Pattern, <version>\\nNetMon Name, Varies by protocol (most commonly ProtocolVersion)\\nClient Console Full Name\\nVersion\\nClient Console Short Name\\nVersion\\nWeb Console Tab/Name\\nVersion\\nElasticsearch Field Name\\nversion\\nRule Builder Column Name\\nVersion\\nRegex Pattern\\n<version>\\nNetMon Name\\nVaries by protocol (most commonly ProtocolVersion)\\n', 'Field Relationships': 'Object (version describes object)\\nProcess (version describes process)\\nEntity\\nHost Fields\\nUser Agent (previously version was abused to contain user agent)\\n', 'Common Applications': 'Vulnerability scanners\\nVirus scanners\\nAsset inventory\\n', 'Use Case': 'If multiple versions are contained in log, the priority is to capture the version of the object of the log, not the version of the product creating the log.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Prioritize the version of an end object over the version of a product generating the log.\\n', 'Examples': '', 'Correct Examples': 'Cb Response\\n05 13 2016 19:56:26 1.1.1.1 <USER:NOTE> LEEF:1.0|CB|CB|5.1|watchlist.storage.hit.binary|cb_server=cbserver cb_version=211 company_name=RecordFlow Technology Ltd. copied_mod_len=1022272 digsig_result=Unsigned digsig_result_code=2148204222 endpoint= USABLDRRECFLOW01|2 file_desc=SysAid\\xa0 Agent file_version=\\n1.1.1.1\\ngroup=RecordFlow HQ host_count=1 internal_name=AgentStuffManager.dll is_64bit=true is_executable_image=false last_seen=2016-05-14T02:49:18.142Z legal_copyright=© Copyright 2013 RecordFlow Technologies Ltd. md5=59E0D058686BD35B0D5C02A4FD8BD0E0observed_filename=c:\\\\\\\\program files\\\\\\\\sysaid\\\\\\\\agentstuffsmanager.dll orig_mod_len=1022976 original_filename=AgentstuffManager.dll os_type=Windows product_name=SysAid\\xa0 Agent product_version=1.1.1.1 server_added_timestamp=2016-05-14T02:49:18.142Z server_name=localhost.localdomain timestamp=1463194218.586 type=watchlist.storage.hit.binary watchlist_4=2016-05-14T02:50:03.177584Z watchlist_id=4 watchlist_name=Newly Loaded Modules\\nFile version parses into Version. Cb_version is not parsed because the device sending the log is not very useful.\\nWindows Event Log\\n10/23/2007 10:07 AM TYPE= USER= Safaware\\\\pete.store COMP= USABLDRRECFLOW01 SORC=BPService CATG=Authentication\\\\Interactive EVID=1000 MESG=Biometric authentication was performed.\\xa0\\xa0\\xa0 Username: pete.store Domain: Safaware Workstation: Safaware \\\\ USABLDRRECFLOW01Security score: 75\\xa0 Threshold: 30\\xa0 Enrollment client: BPDave\\xa0 Authentication client: BPDave\\xa0 Client version:\\n3.0\\nAuthTag: 222222-dff3-4a70-b1940157ab9d2d22\\xa0 Effective settings from: pete.store\\xa0 Keyboard:\\nClient Version parses into Version. This could be useful for software auditing.\\nCylanceProtect\\nCylance08 24 2016 07:11:50 1.1.1.1 <SLOG:WARN> 1 2016-08-24T12:11:30.2394853Z sysloghost CylancePROTECT - - - Event Type: Device, Event Name: SystemSecurity, Device Name: USABLDRRECFLOW01, Agent Version:\\n1.2.1370.119\\n, IP Address: (), MAC Address: (), Logged On Users: (Safaware\\\\pete.store), OS: Microsoft Windows 7 Enterprise Service Pack 1 x64 6.1.7601\\nCylance Agent version parses into Version. This could be used for ensuring all agents are up to date.\\n', 'Incorrect Examples': \"Windows Event Log\\n4/3/2007 10:50 AM TYPE=FailureAudit USER=User1 COMP=Host1 SORC=Security CATG=Detailed Tracking EVID=861 MESG=The Windows Firewall has detected an application listening for incoming traffic.\\xa0\\xa0\\xa0 Name: -\\xa0 Path: D:\\\\stuff\\\\jboss-3.2.3\\\\bin\\\\JavaSHost3\\xa0 Process identifier: 5668\\xa0 User account: SYSTEM\\xa0 User domain: NT AUTHORITY\\xa0 Service: Yes\\xa0 RPC server: No\\xa0 IP version:\\nIPv4\\nIP protocol: TCP\\xa0 Port number: 4087\\xa0 Allowed: No\\xa0 User notified: No\\nIP Version is not the kind of version needed.\\nWindows Event Log\\n<Event xmlns=\\n'\\nhttp://Host2/win/2004/08/events/event\\n'\\n><System><Provider Name='Microsoft-Windows-Security-Auditing' Guid='{54849625-5478-4994-a5ba-3e3b0322g22d}'/><EventID>6272</EventID><\\nVersion\\n>1</\\nVersion\\n><Level>Information</Level><Task>Network Policy Server</Task><Opcode>Info</Opcode><Keywords>Audit Success</Keywords><TimeCreated SystemTime='2010-06-01T21:40:38.228246300Z'/><EventRecordID>26101649</EventRecordID><Correlation/><Execution ProcessID='452' ThreadID='1500'/><Channel>Security</Channel><Computer>Host1</Computer><Security/></System><EventData>Network Policy Server granted access to a user.\\xa0\\xa0\\xa0 User:\\xa0\\xa0 Security ID:\\xa0\\xa0 Safaware\\\\pete.store\\xa0\\xa0 Account Name:\\xa0\\xa0 pete.store\\xa0\\xa0 Account Domain:\\xa0\\xa0 UNR\\xa0\\xa0 Fully Qualified Account Name: UNR\\\\rhickok\\xa0\\xa0\\xa0 Client Machine:\\xa0\\xa0 Security ID:\\xa0\\xa0 NULL SID\\xa0\\xa0 Account Name:\\xa0\\xa0 -\\xa0\\xa0 Fully Qualified Account Name: -\\xa0\\xa0 OS-\\nVersion\\n:\\xa0\\xa0 -\\xa0\\xa0 Called Station Identifier:\\xa0 000B8222222\\xa0\\xa0 Calling Station Identifier:\\xa0 00000000000\\xa0\\xa0\\xa0 NAS:\\xa0\\xa0 NAS IPv4 Address:\\xa0 1.1.1.1\\xa0\\xa0 NAS IPv6 Address:\\xa0 -\\xa0\\xa0 NAS Identifier:\\xa0\\xa0 -\\xa0\\xa0 NAS Port-Type:\\xa0\\xa0 Wireless - IEEE 802.11\\xa0\\xa0 NAS Port:\\xa0\\xa0 0\\xa0\\xa0\\xa0 RADIUS Client:\\xa0\\xa0 Client Friendly Name:\\xa0 Aruba Controller 1\\xa0\\xa0 Client IP Address:\\xa0\\xa0 1.1.1.1\\xa0\\xa0\\xa0 Authentication Details:\\xa0\\xa0 Connection Request Policy Name: Use Windows authentication for all users\\xa0\\xa0 Network Policy Name:\\xa0 RCF WPA\\xa0\\xa0 Authentication Provider:\\xa0 Windows\\xa0\\xa0 Authentication Server:\\xa0 Host1\\xa0\\xa0 Authentication Type:\\xa0 MS-CHAPv2\\xa0\\xa0 EAP Type:\\xa0\\xa0 -\\xa0\\xa0 Account Session Identifier:\\xa0 -\\xa0\\xa0 Logging Results:\\xa0\\xa0 Accounting information was written to the local log file.\\xa0\\xa0\\xa0 Quarantine Information:\\xa0\\xa0 Result:\\xa0\\xa0\\xa0 Full Access\\xa0\\xa0 Session Identifier:\\xa0\\xa0 -\\xa0 </EventData></Event>\\nOS-Version, if populated, would be more appropriate to parse.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nClassification Tab\\n', 'CVE [7.2]': 'CVE ID (for example, CVE-1999-0003) from vulnerability scan data.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String (64 characters maximum)\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Not applicable\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Classification/CVE\\nElasticsearch Field Name, cve\\nRule Builder Column Name, CVE\\nRegex Pattern, <cve>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nNot applicable\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nClassification/CVE\\nElasticsearch Field Name\\ncve\\nRule Builder Column Name\\nCVE\\nRegex Pattern\\n<cve>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Object (prior parsing for CVE)\\nVMID (prior parsing for CVE)\\nThreat Name\\nVMID\\n', 'Common Applications': 'Vulnerability scanners\\nF5\\nQualys\\nIDS (Bro, Snort)\\nNGFW (Palo Alto, Check Point)\\n', 'Use Case': 'Cross referencing threat feeds.\\nFinding an entry point for an attack.\\nLocating what is vulnerable to CVE and what is the impact if exposed.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Use most common format standard CVE-YYYY-#######.\\nA malformed CVE can be represented as CVE-MAP-NOMATCH. Parse that as a valid CVE because that is what the log message says.\\n', 'Examples': 'Symantec Endpoint Protection\\n05 23 2014 20:21:58 1.1.1.1 <LPTR:CRIT> May 23 20:07:35 SymantecServer USABLDRRECFLOW01: USABLDRRECFLOW01,[SID: 27517] Attack: OpenSSL Heartbleed CVE-2014-0160 3 attack blocked. Traffic has been blocked for this application: SYSTEM,Local: 1.1.1.1,Local: 000000000000,Remote: ,Remote: 1.1.1.1,Remote: 000000000000,Inbound,TCP,Intrusion ID: 0,Begin: 2014-05-23 19:48:52,End: 2014-05-23 19:48:52,Occurrences: 1,Application: SYSTEM,Location: Coprorate Network,User: pete.store,Domain: safaware,Local Port 443,Remote Port 52901,CIDS Signature ID: 27517,CIDS Signature string: Attack: OpenSSL Heartbleed\\nCVE-2014-0160\\n3,CIDS Signature SubID: 73036,Intrusion URL: ,Intrusion Payload URL:\\nCVE-2014-0160 parsed into CVE.\\nCb Response\\n05 18 2016 09:51:39 1.1.1.1 <USER:NOTE> LEEF:1.0|CB|CB|511|feed.storage.hit.binary|alliance_data_nvd=[\"10473\",\"10472\",\"10475\",\"10470\",\"10435\"]\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 alliance_link_nvd=\\nhttp://web.nvd.nist.gov/view/vuln/detail?vulnId\\\\=\\nCVE-2013-3353\\nalliance_score_nvd=100\\xa0\\xa0\\xa0\\xa0 alliance_updated_nvd=2015-08-03T23:55:33.000Z\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 cb_server=cbserver\\xa0 cb_version=511\\xa0\\xa0\\xa0\\xa0\\xa0 company_name=Adobe Systems Incorporated\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 computer_name= USABLDRRECFLOW01\\xa0 copied_mod_len=7790179\\xa0\\xa0\\xa0\\xa0 digsig_result=Unsigned\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 digsig_result_code=2148204800\\xa0\\xa0\\xa0 endpoint=[\" USABLDRRECFLOW01|26\",\" USABLDRRECFLOW01|13\",\" USABLDRRECFLOW01|39\",\" USABLDRRECFLOW01|35\",\" USABLDRRECFLOW01|14\"]\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 feed_id=13\\xa0\\xa0 feed_name=nvd file_desc=Adobe Acrobat Annot Plug-In\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 file_version=1.1.1.1\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 group=RecordFlow HQ host_count=5 hostname= USABLDRRECFLOW01\\xa0\\xa0\\xa0 ioc_attr={}\\xa0 ioc_type=md5 ioc_value=4c6b53d9f75cb772e43f65960f905919\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 is_64bit=false\\xa0\\xa0\\xa0\\xa0\\xa0 is_executable_image=false\\xa0 last_seen=2016-05-18T00:01:11.682Z\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 legal_copyright=Copyright 1984-2012 Adobe Systems Incorporated and its licensors. All rights reserved.\\xa0\\xa0\\xa0 md5=59E0D058686BD35B0D5C02A4FD8BD0E0\\xa0\\xa0\\xa0 observed_filename=[\"c:\\\\\\\\program files (x86)\\\\\\\\adobe\\\\\\\\reader 11.0\\\\\\\\reader\\\\\\\\plug_ins\\\\\\\\annots.api\"]\\xa0\\xa0\\xa0 orig_mod_len=7790179\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 original_filename=Annot.api\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 os_type=Windows\\xa0\\xa0\\xa0\\xa0 product_name=Adobe Acrobat Annot\\xa0 product_version=1.1.1.1\\xa0\\xa0\\xa0 report_id=10435\\xa0\\xa0\\xa0\\xa0 report_score=100\\xa0\\xa0\\xa0 sensor_id=14\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 server_added_timestamp=2016-05-17T15:26:48.469Z\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 server_name=localhost.localdomain timestamp=1463589930.842\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 type=feed.storage.hit.binary\\xa0\\xa0\\xa0\\xa0 watchlist_4=2016-05-17T15:30:03.182Z\\nCVE parsed into CVE field from URL (may not be sustainable). Not predictable enough to parse.\\nForcePoint\\n10 28 2016 15:22:15 1.1.1.1 <KERN:INFO> CEF:0|FORCEPOINT|Alert|unknown|278069|HTTP_SHS-Microsoft-Windows-MHTML-Information-Disclosure-\\nCVE-\\n2011-0096\\n-3|7|spt=3811 destinationServiceName=HTTP deviceExternalId=Davestown node 2 dst=1.1.1.1 requestMethod=POST cat=Potential Compromise requestURL=Host2 app=tcp_service_5080 rt=Oct 28 2016 15:22:14 deviceFacility=Inspection destinationTranslatedPort=5080 sourceTranslatedPort=3811 destinationTranslatedAddress=1.1.1.1 sourceTranslatedAddress=1.1.1.1 act=Permit deviceOutboundInterface=2 proto=6 dpt=5080 src=1.1.1.1 dvc=1.1.1.1 dvchost=1.1.1.1 cs1Label=RuleId cs1=1073.1\\nCVE showing inline within CEF vendor info. Full header could be VMID or VendorInfo.\\nMcAfee Network Security Manager\\n03 27 2014 08:29:30 1.1.1.1 <SAU1:WARN> Mar 27 08:29:35 SyslogAlertForwarder: 2014-03-27 08:29:32 EDT!N/A!N/A!22222222222!0x4510fa00!Signature!Medium!Medium!Unknown!Exploit!code-execution!Inbound!Inconclusive!1.1.1.1!1.1.1.1!80!24683!http!tcp!BBQ!BBQ!Proxy Traffic (8A-8B)!signature!\\nCVE-2013-3861\\n!Not Forwarded!Unknown!No error!Unknown!HTTP: JSON Parsing Vulnerability\\nCVE within exclamation delimiters.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nClassification Tab\\n', 'Severity': \"The vendor's view of the severity or level of log message.\\n\", 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Severity\\nClient Console Short Name, Severity\\nWeb Console Tab/Name, Severity\\nElasticsearch Field Name, severity\\nRule Builder Column Name, Severity\\nRegex Pattern, <severity>\\nNetMon Name, Severity for alarms only\\nClient Console Full Name\\nSeverity\\nClient Console Short Name\\nSeverity\\nWeb Console Tab/Name\\nSeverity\\nElasticsearch Field Name\\nseverity\\nRule Builder Column Name\\nSeverity\\nRegex Pattern\\n<severity>\\nNetMon Name\\nSeverity for alarms only\\n', 'Field Relationships': 'Status\\nVMID\\nVendor Info\\nThreatId\\nThreatName\\n', 'Common Applications': 'Syslog reports severity in the format <loc0:info>, with info being the severity level.\\nWindows Event Log severity\\n', 'Use Case': 'Anything that generates alarms or analyzes risk.\\nAlmost every log format has a severity.\\n', 'MPE/Data Masking Manipulations': 'Multilingual logs might have severity in native language. Use masking to convert to standard English. (See Windows logs, for example.)\\n', 'Usage Standards': 'Represent the severity the way the vendor/log source does in the clearest text way. Do not attempt to convert 0-5 to low/medium/high or red/yellow/green unless the vendor defines 0 = low.\\nDo not misuse for level of confidence (for example, from an AV log).\\n', 'Examples': 'Windows Event Log\\n<Event xmlns=\\'\\nhttp://schemas.microsoft.com/win/2004/08/events/event\\'><System><Provider\\nName=\\'Microsoft-Windows-Security-Auditing\\' Guid=\\'{2222222-5478-4994-a5ba-3e3b0328c30d}\\'/><EventID>5058</EventID><Version>0</Version>\\n<Level>Information\\n</Level><Task>Other System Events</Task><Opcode>Info</Opcode><Keywords>Audit Success</Keywords><TimeCreated SystemTime=\\'2016-02-02T00:24:23.559228400Z\\'/><EventRecordID>7670651176</EventRecordID><Correlation/><Execution ProcessID=\\'572\\' ThreadID=\\'3136\\'/><Channel>Security</Channel><Computer> USABLDRRECFLOW01</Computer><Security/></System><EventData><Data Name=\\'SubjectUserSid\\'>NT AUTHORITY\\\\NETWORK SERVICE</Data><Data Name=\\'SubjectUserName\\'> USABLDRRECFLOW01$</Data><Data Name=\\'SubjectDomainName\\'>SAFAWARE</Data><Data Name=\\'SubjectLogonId\\'>0x3e4</Data><Data Name=\\'ProviderName\\'>Microsoft Software Key Storage Provider</Data><Data Name=\\'AlgorithmName\\'>%%2432</Data><Data Name=\\'KeyName\\'>le-a1f08494-0ec3-4902-9d6c-caeeda9ce4f6</Data><Data Name=\\'KeyType\\'>%%2499</Data><Data Name=\\'KeyFilePath\\'>C:\\\\ProgramData\\\\Microsoft\\\\Crypto\\\\RSA\\\\MachineKeys\\\\222222222229530509a71f1</Data><Data Name=\\'Operation\\'>%%2458</Data><Data Name=\\'ReturnCode\\'>0x0</Data></EventData></Event>\\n<Level> tags in Windows indicate severity of the log message.\\nSyslog - Apache Access Log\\n11 14 2013 17:19:04 1.1.1.1 <LOC5:\\nINFO\\n> Nov 14 22:19:04 USABLDRRECFLOW01access_http_log: [14/Nov/2013:22:19:04 +0000] 1.1.1.1 1.1.1.1 HTTP/1.1 \"POST /foundation/getStandingsAjax.jsp HTTP/1.1\" 2764\\nhttps://www.recordflow.biz\\nAny Syslog message contains a header that indicates severity level.\\nSyslog – Crowdstrike Falconhost CEF\\n12 14 2016 11:39:44 1.1.1.1 <USER:NOTE> CEF:0|CrowdStrike|FalconHost|1.0|DetectionSummaryEvent|Detection Summary Event|\\n2\\n| externalID=222222222222222222 cn2Label=ProcessId cn2=148191318711589 cn1Label=ParentProcessId cn1=148191316778231 shost=TheNarrowSea suser=IIS1$ msg=An administrative/reconnaissance tool (xcopy.exe, ping.exe, tasklist.exe, ftp.exe, autoruns.exe) was spawned under an IIS worker process. fname=systeminfo.exe filePath=\\\\\\\\Device\\\\\\\\HarddiskVolume1\\\\\\\\Windows\\\\\\\\System32 cs1Label=CommandLine cs1=systeminfo fileHash=59E0D058686BD35B0D5C02A4FD8BD0E0sntdom=TARGETNET cs6Label=FalconHostLink cs6=\\nhttps://falcon.crowdstrike.com/activity/detections/detail/2222222222/2222222222\\ncn3Label=Offset cn3=1066147 deviceCustomDate1Label=ProcessStartTime deviceCustomDate1=2016-12-14 18:39:42\\nIn this Syslog example, the Syslog severity is ignored in favor of the CEF format header which includes its own severity level.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nClassification Tab\\n', 'Threat ID [7.2]': 'The ID number of a threat when available from an IDS/IPS signature, endpoint protection, or firewall log.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Not applicable\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Threat ID\\nElasticsearch Field Name, threatId\\nRule Builder Column Name, ThreatID\\nRegex Pattern, <threatid>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nNot applicable\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nThreat ID\\nElasticsearch Field Name\\nthreatId\\nRule Builder Column Name\\nThreatID\\nRegex Pattern\\n<threatid>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Threat Name\\nVMID\\nVendor Message\\nObject\\nObject Name\\nObject Type\\nProcess\\nProcess ID\\n', 'Common Applications': 'IDS/IPS\\nVulnerability scanners\\nProxy\\n', 'Use Case': 'Correlating threats.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Signatures\\nNumeric or string identifiers for threats under different names\\n', 'Examples': 'Cisco IDS/IPS\\n<sd:evIdsAlert eventId=\"222222222\" vendor=\"Cisco\" severity=\"high\" xmlns:sd=\"\\nhttp://example.org/2003/08/sdee\">bhiips\\nxmlns:cid=\"\\nhttp://www.cisco.com/cids/2006/08/cidee\">sensorApp\\nxmlns:cid=\"\\nhttp://www.cisco.com/cids/2006/08/cidee\">9055\\noffset=\"-300\" timeZone=\"GMT-05:00\">1232562570119108000</sd:time><sd:signature description=\"MSSQL Resolution Service Stack Overflow\"\\nid=\"4703\"\\ncid:version=\"S367\" cid:type=\"other\" cid:created=\"20000101\" xmlns:cid=\"\\nhttp://www.cisco.com/cids/2006/08/cidee\">0\\nsample truncated.\\nSignature ID of a threat detectedeStreamer.\\neStreamer\\nLOGTYPE=INT_EVT_51_IPV4\\nR_ID=24105\\nR_REV=9 S_IP=1.1.1.1 S_PORT=58730 D_IP=1.1.1.1 D_PORT=8080 U_ID=0 U= R_NAME=MALWARE-OTHER HTTP POST request to a GIF file CLASSIFICATION_ID=22 CLASSIFICATION=Detection of a Non-Standard Protocol or Event PROT_NUM=6 PROT= ING_IF=s1p5 EG_IF=s1p1 BLOCKED=NotBlocked MANAGED_DEV_ID=9 EVT_ID=263305 EVT_T=01/15/2015 20:42:56 GEN_ID=1 PRI_ID=2 PRI=medium IMPACT_FLAGS=MonitoredHost, MappedHost, ServerPortOrIp IMPACT=Orange BBQ_LABEL=0 VLAN_ID=0 POL=Intrusion Policy - Corporate AP_PROT=HTTP ACS_CTL_R=File Inspection Rule ACS_CTL_POL=Access Control Policy - CORPORATE nnq_nnq_Z=Corporate EG_bbq_Z=OOB\\nR_ID=24105 is the Threat ID from this IDS signature log.\\nSymantec Endpoint\\n05 22 2014 11:08:02 1.1.1.1 <LPTR:CRIT> May 22 10:55:13 SymantecServer USABLDRRECFLOW01: USABLDRRECFLOW01,[\\nSID: 25238\\n] Fake App Attack: Misleading Application Website attack blocked. Traffic has been blocked for this application: \\\\DEVICE\\\\HARDDISKVOLUME1\\\\PROGRAM FILES\\\\GOOGLE\\\\CHROME\\\\APPLICATION\\\\CHROME.EXE,Local: 1.1.1.1,Local: 000000000000,Remote: ,Remote: 1.1.1.1,Remote: 000000000000,Inbound,TCP,Intrusion ID: 0,Begin: 2014-05-22 10:53:42,End: 2014-05-22 10:53:42,Occurrences: 1,Application: /DEVICE/HARDDISKVOLUME1/PROGRAM FILES/GOOGLE/CHROME/APPLICATION/CHROME.EXE,Location: Coprorate Network,User: Christina_McCloud,Domain: INDY,Local Port 4295,Remote Port 80,CIDS Signature ID: 25238,CIDS Signature string: Fake App Attack: Misleading Application Website,CIDS Signature SubID: 70185,Intrusion URL:\\npcfaster.info/usdown/?sence=asdifas892nsndsafusaljnsxckad,Intrusion\\nPayload URL:\\nSID is the signature ID of the detected threat.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nClassification Tab\\n', 'Threat Name [7.2]': 'The name of a threat described in the log message (for example, malware, exploit name, or signature name). Do not overload with Policy.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Not applicable\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Threat Name\\nElasticsearch Field Name, threatName\\nRule Builder Column Name, ThreatName\\nRegex Pattern, <threatname>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nNot applicable\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nThreat Name\\nElasticsearch Field Name\\nthreatName\\nRule Builder Column Name\\nThreatName\\nRegex Pattern\\n<threatname>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Threat ID\\nVMID\\nVendor Message\\nObject\\nObject Name\\nObject Type\\nProcess\\nProcessID\\nPolicy\\nReason\\n', 'Common Applications': 'IDS/IPS\\nVulnerability scanners\\nProxy\\n', 'Use Case': 'Threat Name frequency for reporting.\\nIdentifying threats.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Signature names\\nMalware names\\nVulnerability names\\nExploit names\\nCan be used independently of Threat ID (for example, AV detections, or identifying malicious processes or objects)\\n', 'Examples': 'Cisco IDS/IPS\\n<sd:evIdsAlert eventId=\"2222222222222\" vendor=\"Cisco\" severity=\"high\" xmlns:sd=\"\\nhttp://example.org/2003/08/sdee\">bhiips\\nxmlns:cid=\"\\nhttp://www.cisco.com/cids/2006/08/cidee\">sensorApp\\nxmlns:cid=\"\\nhttp://www.cisco.com/cids/2006/08/cidee\">9055\\noffset=\"-300\" timeZone=\"GMT-05:00\">1232562570119108000</sd:time><sd:signature\\ndescription=\"MSSQL Resolution Service Stack Overflow\"\\nid=\"4703\" cid:version=\"S367\" cid:type=\"other\" cid:created=\"20000101\" xmlns:cid=\"\\nhttp://www.cisco.com/cids/2006/08/cidee\">0\\n:...log sample truncated.\\nThe description describes the threat indicated by signature ID 4703.\\nQualys Vulnerability Scanner\\nHOSTIP=1.1.1.1 HOSTNAME= USABLDRRECFLOW01HOSTOS=Linux 2.6 PORT= PROTOCOL= QID=115731 DETECTIONTYPE=Potential STATUS=New FIRSTFOUND=2010-10-05 01:20:11Z LASTFOUND=2010-10-05 01:20:11Z\\nVULNERABILITY=Apache 1.3 and 2.0 Web Server Multiple Vulnerabilities\\nVULNERABILITYTYPE=Vulnerability or Potential Vulnerability CATEGORY=Local SEVERITYLEVEL=3 PATCHABLE=1 KBLASTUPDATE=2010-09-13 18:52:19Z CVE=CVE-2006-5752(\\nhttp://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-5752),CVE-2007-3304(http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2007-3304)\\nName of vulnerability.\\neStreamer\\nLOGTYPE=INT_EVT_51_IPV4 R_ID=24105 R_REV=9 S_IP=1.1.1.1 S_PORT=58730 D_IP=1.1.1.1 D_PORT=8080 U_ID=0 U= R_NAME=\\nMALWARE-OTHER HTTP POST request to a GIF file\\nCLASSIFICATION_ID=22 CLASSIFICATION=Detection of a Non-Standard Protocol or Event PROT_NUM=6 PROT= ING_IF=s1p5 EG_IF=s1p1 BLOCKED=NotBlocked MANAGED_DEV_ID=9 EVT_ID=263305 EVT_T=01/15/2015 20:42:56 GEN_ID=1 PRI_ID=2 PRI=medium IMPACT_FLAGS=MonitoredHost, MappedHost, ServerPortOrIp IMPACT=Orange MPLS_LABEL=0 VLAN_ID=0 POL=Intrusion Policy - Corporate AP_PROT=HTTP ACS_CTL_R=File Inspection Rule ACS_CTL_POL=Access Control Policy - CORPORATE ING_SEC_Z=Corporate BBQ_SEC_Z=OOB\\nR_NAME represents the signature ID (R_ID=24105) of the threat.\\nSymantec Endpoint\\n05 22 2014 11:08:02 1.1.1.1 <LPTR:CRIT> May 22 10:55:13 SymantecServer USABLDRRECFLOW01USABLDRRECFLOW01,[SID: 25238]\\nFake App Attack: Misleading Application Website attack blocked.\\nTraffic has been blocked for this application: \\\\DEVICE\\\\HARDDISKVOLUME1\\\\PROGRAM FILES\\\\GOOGLE\\\\CHROME\\\\APPLICATION\\\\CHROME.EXE,Local: 1.1.1.1,Local: 000000000000,Remote: ,Remote: 1.1.1.1,Remote: 000000000000,Inbound,TCP,Intrusion ID: 0,Begin: 2014-05-22 10:53:42,End: 2014-05-22 10:53:42,Occurrences: 1,Application: /DEVICE/HARDDISKVOLUME1/PROGRAM FILES/GOOGLE/CHROME/APPLICATION/CHROME.EXE,Location: Coprorate Network,User: pete.store,Domain: safaware,Local Port 4295,Remote Port 80,CIDS Signature ID: 25238,CIDS Signature string: Fake App Attack: Misleading Application Website,CIDS Signature SubID: 70185,Intrusion URL:\\nrecordflow.biz\\n,Intrusion Payload URL:\\n“Fake App Attack: Misleading Application Website attack” is the name of the possible threat detected of signature ID 25238.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nClassification Tab\\n', 'Vendor Info [7.2]': 'Description of specific vendor log or event identifier for the log. Human readable elaboration that directly correlates to the VMID.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Not applicable\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Vendor Info\\nElasticsearch Field Name, vendorInfo\\nRule Builder Column Name, VendorInfo\\nRegex Pattern, <vendorinfo>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nNot applicable\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nVendor Info\\nElasticsearch Field Name\\nvendorInfo\\nRule Builder Column Name\\nVendorInfo\\nRegex Pattern\\n<vendorinfo>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'VMID\\nSubject\\n', 'Common Applications': 'Any device that generates predetermined message types or categories that are differentiated by a brief description or identification number.\\n', 'Use Case': 'Understanding VMID for correlating events without depending on the rule name, common event/classification.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'To be used when VMID is present.\\nTo be used rarely when VMID is not present.\\nCapturing long event descriptions such as a sentence.\\nCapturing long event descriptions such as a sentence.\\nNot for subrules.\\n', 'Examples': \"Windows Event Log Security\\n<Event xmlns='\\nhttp://Host2/win/2004/08/events/event'><System><Provider\\nName='Microsoft-Windows-Security-Auditing' Guid='{2222222-5478-4994-a5ba-3e3b0328c30d}'/><EventID>4663</EventID><Version>0</Version><Level>Information</Level><Task>Kernel Object</Task><Opcode>Info</Opcode><Keywords>Audit Success</Keywords><TimeCreated SystemTime='2009-07-07T23:24:49.212Z'/><EventRecordID>451107</EventRecordID><Correlation/><Execution ProcessID='4' ThreadID='88'/><Channel>Security</Channel><Computer> USABLDRRECFLOW01</Computer><Security/></System><EventData>\\nAn attempt was made to access an object.\\nSubject:\\nSecurity ID:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 USABLDRRECFLOW01\\\\Administrator\\nAccount Name:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Administrator\\nAccount Domain:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 USABLDRRECFLOW01\\nLogon ID:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 0x2a9fe\\nObject:\\nObject Server:\\xa0\\xa0\\xa0\\xa0\\xa0 Security\\nObject Type: SymbolicLink\\nObject Name: \\\\GLOBAL??\\\\C:\\nHandle ID:\\xa0\\xa0 0x3c0\\nProcess Information:\\nProcess ID:\\xa0 0x8d0\\nProcess Name: C:\\\\Windows\\\\Host10\\nAccess Request Information:\\nAccesses:\\xa0\\xa0\\xa0 Use symbolic link\\nAccess Mask: 0x1</EventData></Event>\\nDescribes in human readable form what the event ID (VMID) translates to.\\nCyberArk Privileged Threat Analytics\\nCEF:0|CyberArk|PTA|3.1|21|\\nSuspected credentials theft\\n|9|duser=pete.store dst= USABLDRRECFLOW01cs2Label=eventID cs2=5b720c983420f5222222d deviceCustomDate1Label=detectionDate deviceCustomDate1=1422836202000 cs3Label=link cs3=\\nhttps://1.1.1.1/incidents/5b722222224979d\\nSuspected Credentials Theft describes VMID 21.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nClassification Tab\\n', 'Vendor Message ID': 'The specific vendor log or event identifier for the log used to describe a type of event.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Vendor Message ID\\nClient Console Short Name, Vendor Message ID\\nWeb Console Tab/Name, Vendor Message ID\\nElasticsearch Field Name, vendorMessageId\\nRule Builder Column Name, VMID\\nRegex Pattern, <vmid>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nVendor Message ID\\nClient Console Short Name\\nVendor Message ID\\nWeb Console Tab/Name\\nVendor Message ID\\nElasticsearch Field Name\\nvendorMessageId\\nRule Builder Column Name\\nVMID\\nRegex Pattern\\n<vmid>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Vendor Information\\nThreat Name\\nThreat ID\\n', 'Common Applications': 'Any device that generates predetermined message types or categories that are differentiated by a brief description or identification number.\\n', 'Use Case': 'Correlating events.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Describes or identifies an event type\\nSometimes human readable\\nUsually numeric\\nCan be used for subrules\\nIndexed field, do not use subrule tags when making subrules off VMID\\nNot for Response Codes\\nNot for Threat IDs (signatures)\\nNot Event Record ID\\n', 'Examples': \"Windows Event Log Security\\n<Event xmlns='\\nhttp://schemas.microsoft.com/win/2004/08/events/event'><System><Provider\\nName='Microsoft-Windows-Security-Auditing' Guid='{222222222-5478-4994-a5ba-3e3b0328c30d}'/>\\n<EventID>4624</EventID>\\n<Version>0</Version><Level>Information</Level><Task>Logon</Task><Opcode>Info</Opcode><Keywords>Audit Success</Keywords><TimeCreated SystemTime='2016-02-09T00:45:00.703363000Z'/><EventRecordID>\\n2269912024\\n</EventRecordID><Correlation/><Execution ProcessID='520' ThreadID='12080'/><Channel>Security</Channel><Computer> USABLDRRECFLOW01</Computer><Security/></System><EventData><Data Name='SubjectUserSid'>NT AUTHORITY\\\\SYSTEM</Data><Data Name='SubjectUserName'> USABLDRRECFLOW01$</Data><Data Name='SubjectDomainName'>SAFAWARE</Data><Data Name='SubjectLogonId'>0x3e7</Data><Data Name='TargetUserSid'>NT AUTHORITY\\\\SYSTEM</Data><Data Name='TargetUserName'>SYSTEM</Data><Data Name='TargetDomainName'>NT AUTHORITY</Data><Data Name='TargetLogonId'>0x3e7</Data><Data Name='LogonType'>5</Data><Data Name='LogonProcessName'>Advapi\\xa0 </Data><Data Name='AuthenticationPackageName'>Negotiate</Data><Data Name='WorkstationName'></Data><Data Name='LogonGuid'>{00000000-0000-0000-0000-000000000000}</Data><Data Name='TransmittedServices'>-</Data><Data Name='LmPackageName'>-</Data><Data Name='KeyLength'>0</Data><Data Name='ProcessId'>0x200</Data><Data Name='ProcessName'>C:\\\\Windows\\\\System32\\\\services.exe</Data><Data Name='IpAddress'>-</Data><Data Name='IpPort'>-</Data></EventData></Event>\\nThe Event ID number is the Vendor Message ID. Event Record ID is not Vendor Message ID. This describes the individual instance of a log.\\nCisco ASA\\n02 03 2015 08:37:17 1.1.1.1 <LOC3:NOTE> :Feb 03 08:37:17 PST: %ASA-session-5-\\n302013\\n: Built outbound TCP connection 1001222224 for outside:1.1.1.1/80 (1.1.1.1/80) to shr-web-prod:1.1.1.1/58291 (1.1.1.1/58291)\\nFor Cisco ASA and Cisco products generally, this is where the identifier for the type of event is kept.\\nFireEye Web MPS\\n02 01 2016 17:13:19 1.1.1.1 <LOC4:WARN> fenotify-609081.warning: CEF:0|FireEye|MPS|1.1.1.1875|IM|\\ninfection-match\\n|1|rt=Feb 01 2016 23:13:10 UTC src=1.1.1.1 cn3Label=cncPort cn3=80 cn2Label=sid cn2=84575103 shost= USABLDRRECFLOW01proto=tcp spt=51997 dst=1.1.1.1 cs5Label=cncHost cs5=1.1.1.1 dvchost= USABLDRRECFLOW01dvc=1.1.1.1 smac=00:00:00:00:00:00 cn1Label=vlan cn1=0 dpt=80 externalId=609081 cs4Label=link cs4=\\nhttps://romaslcmp01.mayo.edu/event_stream/events_for_bot?ev_id\\\\=609081\\nact=blocked cs6Label=channel cs6=GET THINGS dmac=00:00:00:00:00:00 cs1Label=sname cs1=Exploit.Kit.Angler\\nFor FireEye Web MPS, and CEF messages generally, the type of event is described here in a human readable form.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nDerived Data\\n', 'Identity-Derived Data': \"Identity-Derived data is augmented by LogRhythm’s Identity feature. If you have configured known identities and have the feature enabled, then these fields are populated with known identity data.\\nDisplay Field, Description, Associated Data Sources\\nUser Identity (Origin), The identity that has the login in the User (Origin) field associated with it., Only matches login Identifier fields\\nUser Identity (Impacted), The identity that has the User (Impacted) field associated with it., Only matches login Identifier fields\\nRecipient Identity, Identity that has the Recipient's email address associated with it., Only matches email Identifier fields\\nSender Identity, Identity that has the Sender's email address associated with it., Only matches email Identifier fields\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'DIP/DestinationIP/Impacted IP': 'The host IP that was affected by the activity (for example, target or server). Destination IP in IPv4 or IPv6 format.\\n', 'Data Type': 'IP\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Host (Impacted)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Host (Impacted)\\nElasticsearch Field Name, impactedIp\\nRule Builder Column Name, DIP\\nRegex Pattern, <dip>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nHost (Impacted)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nHost (Impacted)\\nElasticsearch Field Name\\nimpactedIp\\nRule Builder Column Name\\nDIP\\nRegex Pattern\\n<dip>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Networked equipment\\n', 'Use Case': 'Host context\\n', 'MPE/Data Masking Manipulations': 'Polyfield – Impacted Host\\n', 'Usage Standards': 'Do not override/overload, use <dip> not (?<dip>.*?).\\nImpacted is server (In Client-Server Model).\\nImpacted is Target (In Attacker-Target Model).\\nUse when you see an Impacted IP address IPv4 or IPv6, unless it is an IPv4 address mapped to IPv6, in which case use <dipv6e>.\\n', 'Examples': 'FireEye Web MPS\\n02 01 2016 17:13:19 1.1.1.1 <LOC4:WARN> fenotify-609081.warning: CEF:0|FireEye|MPS|1.1.1.1875|IM|infection-match|1|rt=Feb 01 2016 23:13:10 UTC\\nsrc=1.1.1.1\\ncn3Label=cncPort cn3=80 cn2Label=sid cn2=84575103 shost= USABLDRRECFLOW01proto=tcp spt=51997 dst=1.1.1.1 cs5Label=cncHost cs5=1.1.1.1 dvchost=romaslcmp01 dvc=1.1.1.1 smac=00:00:00:00:00:00 cn1Label=vlan cn1=0 dpt=80 externalId=609081 cs4Label=link cs4=THINGS dmac=00:00:00:00:00:00 cs1Label=sname cs1=Exploit.Kit.AnglerDIPv4\\nSrc= in this instance is the host IP impacted by the infection match described in the log. (Attacker-Target). Dst= is the command and control server and therefore the closest Origin (attacker) to be inferred from the log.\\nBrocade Switch\\n03 01 2017 02:08:41 1.1.1.1 <LOC6:NOTE> Mar\\xa0 1 02:08:38 USABLDRRECFLOW01dataplane[2287]: fw rule INTERNAL-IN:10000 block udp(17) src= USABLDRRECFLOW01/0:00:00:0a:ea:e8/fe80::e0c0:f0f0:e00c:2029(546) dst=/22:22:2:1:0:2/\\nff22::2:2\\n(547) len=159 hoplimit=1 len=119\\nDst= IPv6 address following the MAC ID. Network context showing direction src->dst.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'DIPv4': 'Constituent element of <dip> for only IPv4 parsing (not generally used).\\n', 'Data Type': 'IP\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Host (Impacted)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Host (Impacted)\\nElasticsearch Field Name, impactedIpV4\\nRule Builder Column Name, DIP\\nRegex Pattern, <dipv4>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nHost (Impacted)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nHost (Impacted)\\nElasticsearch Field Name\\nimpactedIpV4\\nRule Builder Column Name\\nDIP\\nRegex Pattern\\n<dipv4>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Nested element of <dip> default regex\\nCannot be used with <dipv6>\\n', 'Common Applications': 'IPv4 only network equipment\\n', 'Use Case': 'Use when parsing a log that only contains IPv4 addresses where the very small performance gain over the standard DIP parsing field is necessary.\\n', 'MPE/Data Masking Manipulations': 'Polyfield – Impacted Host\\n', 'Usage Standards': 'This field is rarely used.\\nIs redundant to <dip>.\\nIf you are 100% certain an IPv4 address will always appear.\\nOnly use if you need an extremely minute performance improvement.\\n', 'Examples': 'Trend Micro Deep Security\\n11 19 2014 08:21:12 10.100.6.64 <LOC0:INFO> Nov 19 03:25:07 USABLDRRECFLOW01 dsa_mpnp: REASON=IPv4_Packet HOSTID=230078 ACT=Deny IN=0C:0B:05:07:B0:05 OUT= MAC=00:00:00:00:00:00:00:BE:00:00:00:0D:00:0d SRC=2.2.2.2 DST=1.1.1.1 LEN=86 PROTO=ICMP SPT=0 DPT=0 CNT=1\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'DIPv6': 'Constituent element of <sip> for only IPv6 parsing (not generally used).\\n', 'Data Type': 'IP\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Host (Impacted)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Host (Impacted)\\nElasticsearch Field Name, impactedIpV6\\nRule Builder Column Name, DIP\\nRegex Pattern, <dipv6>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nHost (Impacted)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nHost (Impacted)\\nElasticsearch Field Name\\nimpactedIpV6\\nRule Builder Column Name\\nDIP\\nRegex Pattern\\n<dipv6>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': '<dipv6> is a nested element of <dip>\\n', 'Common Applications': 'IPv6 only network equipment\\n', 'Use Case': 'Use when parsing a log that only contains IPv6 addresses where the very small performance gain over the standard DIP parsing field is necessary.\\n', 'MPE/Data Masking Manipulations': 'Polyfield – Impacted Host\\n', 'Usage Standards': 'This is rarely used.\\nIs redundant to <dip>.\\nIf you are 100% certain an IPv4 address will always appear.\\nUse if you need an extremely minute performance improvement.\\n', 'Examples': 'Trend Micro Deep Security\\n11 19 2014 08:21:12 10.100.6.64 <LOC0:INFO> Nov 19 03:25:07 USABLDRRECFLOW01 dsa_mpnp: REASON=IPv6_Packet HOSTID=230078 ACT=Deny IN=0C:0B:05:07:B0:05 OUT= MAC=00:00:00:00:00:00:00:BE:00:00:00:0D:00:0d SRC=fe80:0:0:0:0cd0:000f:bd2f:000b DST=\\nff01:0:0:0:0:0:0:1\\nLEN=86 PROTO=ICMPv6 SPT=0 DPT=0 CNT=1\\nDST= shows impacted IPv6 Address.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'DIPv6E': 'The Impacted IPv4 IP address that was mapped to (for example, target or server).\\n', 'Data Type': 'IP\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Host (Impacted)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Host (Impacted)\\nElasticsearch Field Name, impactedIpV6\\nRule Builder Column Name, DIP\\nRegex Pattern, <dipv6e>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nHost (Impacted)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nHost (Impacted)\\nElasticsearch Field Name\\nimpactedIpV6\\nRule Builder Column Name\\nDIP\\nRegex Pattern\\n<dipv6e>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Networked equipment\\n', 'Use Case': 'Host context\\n', 'MPE/Data Masking Manipulations': 'Polyfield – Origin Host\\n', 'Usage Standards': 'Do not override/overload, use <dipv6e> not (?<dipv6e>.*?).\\nImpacted is Server (In Client-Server Model).\\nImpacted is Target (In Attacker-Target Model).\\nUse when you see an Impacted IPv4 address mapped to IPv6.\\n', 'Examples': \"Windows Event Log\\n<Event xmlns='\\nhttp://schemas.microsoft.com/win/2004/08/events/event'><System><Provider\\nName='Microsoft-Windows-Iphlpsvc' Guid='{66a5c15c-4f8e-4044-bf6e-71d896038977}'/><EventID>4200</EventID><Version>0</Version><Level>Information</Level><Task>None</Task><Opcode>Info</Opcode><Keywords></Keywords><TimeCreated SystemTime='2016-08-02T19:20:14.492842100Z'/><EventRecordID>5823520</EventRecordID><Correlation/><Execution ProcessID='920' ThreadID='3936'/><Channel>System</Channel><Computer> USABLDRRECFLOW01</Computer><Security UserID='NT AUTHORITY\\\\SYSTEM'/></System><EventData><Data Name='ProtocolType'>1</Data><Data Name='Interface'>isatap.{f7eec065-6118-437c-8414-eeeeeeeeeeeee}</Data><Data Name='Address'>\\nfe80::5efe:1.1.1.1\\n</Data></EventData></Event>\\nImpacted Address is IPv4 address mapped to IPV6. Traditional IP parsers do not work with this type of address.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'IP Address (Origin)': 'The IP address of the origin system. Often referred to as Source IP (in NetMon, Rule Builder and other parts of the system).\\n', 'Data Type': 'IP\\nIPv4 in octets\\nIPv6 (no support for CIDR or IPv6e)\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Host (Origin)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, IP Address (Origin)\\nElasticsearch Field Name, originIp\\nRule Builder Column Name, SIP\\nRegex Pattern, <sip>\\nNetMon Name, SrcIP\\nClient Console Full Name\\nHost (Origin)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nIP Address (Origin)\\nElasticsearch Field Name\\noriginIp\\nRule Builder Column Name\\nSIP\\nRegex Pattern\\n<sip>\\nNetMon Name\\nSrcIP\\n', 'Field Relationships': 'SIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Everything that communicates through a network.\\n', 'Use Case': 'Indicating the host relationship to the log message—for example, if it is an origin threat, impacted by a threat, the client, or the server.\\n', 'MPE/Data Masking Manipulations': 'Polyfield – Origin Host\\n', 'Usage Standards': 'Do not override/overload, use <sip> not (?<sip>.*?).\\nOrigin is Client (In Client-Server Model).\\nOrigin is Attacker (In Attacker-Target Model).\\nUse when you see an Origin IP address IPv4 or IPv6, unless it is an IPv4 address mapped to IPv6, in which case use <sipv6e>.\\n', 'Examples': 'Office 365\\nTS=2016-10-20T20:22:23 SESSID=8b157afd-eb80-45e4-926f-222222222 COMMAND=AnonymousLinkUsed USERTYPE=Regular USERKEY=anonymous WORKLOAD=SharePoint RESULTCODE= OBJECT=\\nhttps://www.recordflow.biz\\n/Shared Documents/abuse_ch_copy.txt USER=anonymous\\nSIP=1.1.1.1\\nITEMTYPE=File EVENTSOURCE=SharePoint USERAGENT=Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.59 Safari/537.36 DOMAIN= FILENAME= DESTINATION= DESTINATIONFILENAME= USERSHAREDWITH= SHARINGTYPE= MODIFIEDPROPERTIES=\\nSIP (IPv4) in this case is Origin (source) connecting to O365 Cloud service. Client-Server are Origin-Impacted in this context.\\nLogBinder\\nJun 11 14:53:48 1.1.1.1 25000 LOGbinder EX|2.0|success|2014-06-11T14:53:48.0000000-05:00|Undocumented Exchange mailbox operation|name=\"occurred\" label=\"Occurred\" value=\"6/11/2014 2:53:48 PM\"|name=\"operation\" label=\"Operation\" value=\"\"|name=\"result\" label=\"Result\" value=\"Succeeded\"|name=\"originatingserver\" label=\"Originating Server\" value=\" USABLDRRECFLOW01 (14.02.0341.000)\"|name=\"mailboxguid\" label=\"Mailbox GUID\" value=\"9db94f90-2222-2222-b6c8-48200020026f\"|name=\"mailboxowner\" label=\"Mailbox Owner\" value=\"n/a\"|name=\"mailboxownerupn\" label=\"Mailbox Owner UPN\" value=\"pete.store@\\nrecordflow.biz\\n\"|name=\"mailboxownersid\" label=\"Mailbox Owner SID\" value=\"S-1-5-21-2141518605-3280587107-2299868870-500\"|name=\"folderid\" label=\"Folder ID\" value=\"n/a\"|name=\"foldername\" label=\"Folder Name\" value=\"\\\\\\\\Inbox\"|name=\"performedusername\" label=\"Performed User Name\" value=\"Administrator\"|name=\"performedusersid\" label=\"Performed User SID\" value=\"S-1-5-21-222222222222-3280587107-2299868870-500\"|name=\"performedlogontype\" label=\"Performed Logon Type\" value=\"Owner\"|name=\"clientinfo\" label=\"Client Info\" value=\"Client\\\\=OWA\"|name=\"clientipaddress\" label=\"Client IP Address\"\\nvalue=\"fe80::b000:00c0:e000:f00e%00\"\\n|name=\"clientprocessname\" label=\"Client Process Name\" value=\"n/a\"|name=\"clientversion\" label=\"Client Version\" value=\"n/a\"|name=\"additionalinfo\" label=\"Additional Information\" value=\"Owner\\\\= [Administrator]; LastAccessed\\\\= [2013-03-06T04:41:48.0670508-05:00];\"\\nIPv6 address for client. Client-Server are Origin-Impacted in this context.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'Impacted Hostname': 'The host that was affected by the activity (for example, target or server).\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Host (Impacted)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Host (Impacted)\\nElasticsearch Field Name, impactedName\\nRule Builder Column Name, DName\\nRegex Pattern, <dname>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nHost (Impacted)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nHost (Impacted)\\nElasticsearch Field Name\\nimpactedName\\nRule Builder Column Name\\nDName\\nRegex Pattern\\n<dname>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Networked equipment\\n', 'Use Case': 'Host context\\n', 'MPE/Data Masking Manipulations': 'Polyfield – Impacted Host\\n', 'Usage Standards': 'Impacted is Server (In Client-Server Model).\\nImpacted is Target (In Attacker-Target Model).\\nCan be used for parsing fully qualified domain names for non-world wide web context hostnames.\\n', 'Examples': \"Windows Event Log\\n<Event xmlns='\\nhttp://Host2/win/2004/08/events/event'><System><Provider\\nName='NETLOGON'/><EventID Qualifiers='0'>5805</EventID><Level></Level><Task>None</Task><Keywords></Keywords><TimeCreated SystemTime='2014-02-06T06:03:06.000000000Z'/><EventRecordID>156578</EventRecordID><Channel>System</Channel><Computer>\\nUSABLDRRECFLOW01\\n</Computer><Security/></System><EventData>The session setup from the computer\\nUSABLDRRECFLOW02\\nfailed to authenticate. The following error occurred:\\nAccess is denied.</EventData></Event>\\n<Computer> is the origin of the log message here, but also the domain controller which the origin is trying to authenticate against and is therefore impacted. Client-Server (origin-impacted) relationship applies here. Computer client trying to authenticate is the origin of the request to the server.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'Impacted Hostname or IP': 'The host that was affected by the activity (for example, target or server).\\n', 'Data Type': 'String\\nIP\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Host (Impacted)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Host (Impacted)\\nElasticsearch Field Name, impactedName, impactedIp\\nRule Builder Column Name, Not applicable\\nRegex Pattern, (<dipn>)\\nNetMon Name, Not applicable\\nClient Console Full Name\\nHost (Impacted)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nHost (Impacted)\\nElasticsearch Field Name\\nimpactedName, impactedIp\\nRule Builder Column Name\\nNot applicable\\nRegex Pattern\\n(<dipn>)\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Not applicable\\n', 'Use Case': 'See\\nDIP/DestinationIP/Impacted IP\\nand\\nImpacted Hostname\\n.\\n', 'MPE/Data Masking Manipulations': 'See\\nDIP/DestinationIP/Impacted IP\\nand\\nImpacted Hostname\\n.\\n', 'Usage Standards': 'Use when a log can contain either an IP or a hostname in the same location.\\nMust be wrapped in parenthesis to function (<dipn>).\\nDo not overload/override.\\n', 'Examples': 'Aruba Clear Pass\\n10 22 2015 16:23:22 1.1.1.1 <LOC1:INFO> 2015-10-22 16:23:22,956 [Th 12047 Req 8677508 SessId R0014aec9-06-5628c022] INFO\\xa0 RadiusServer.Radius - rlm_ldap: found user host/ USABLDRRECFLOW01com in AD:\\ndc-del4-1.synapse.com\\n10 22 2015 13:58:51 1.1.1.1 <LOC1:INFO> 2015-10-22 13:58:51,299 [Th 7649 Req 1708827 SessId R00060774-01-5628c16b] INFO\\xa0 RadiusServer.Radius - rlm_ldap: searching for user 000000000 in AD:\\n1.1.1.1\\n10 22 2015 16:23:22 1.1.1.1 <LOC1:INFO> 2015-10-22 16:23:22,956 [Th 12047 Req 8677508 SessId R0014aec9-06-5628c022] INFO\\xa0 RadiusServer.Radius - rlm_ldap: found user host/ USABLDRRECFLOW01com in AD:\\ndc-del4-1.synapse.com\\n10 22 2015 13:58:51 1.1.1.1 <LOC1:INFO> 2015-10-22 13:58:51,299 [Th 7649 Req 1708827 SessId R00060774-01-5628c16b] INFO\\xa0 RadiusServer.Radius - rlm_ldap: searching for user 000000000 in AD:\\n1.1.1.1\\nServer being queried (impacted) in log can be represented by an IP or a Hostname.\\nCisco Router\\n03 02 2009 11:26:27 ATC-CW2K <LOC0:CRIT> Mar\\xa0 2 11:26:54 USABLDRRECFLOW01ITMGSC: %local0-2-EVENT: 09$Partition=0]PartitionName=&)MODE=3;Alert ID=00061D0}Event ID=001KMPZ|Status=Active^Severity=Critical^Managed Object=\\n1.1.1.1\\n^Managed Object Type=Wireless^CUSTID=Security_Group^CUSTREV=*^Description=HighQueueDropRate::Component=IF-1.1.1.1/1 [Do0];Type=IEEE80211;OutputPacketNoErrorRate=0.11666667\\xa0 PPS;DuplexMode=FULLDUPLEX;InputPacketQueueDropRate=0.0125\\xa0 PPS;InputPacketQueueDropPct=48.07692\\xa0 %;MaxSpeed=54000000;OutputPacketQueueDropPct=0.0\\n03 02 2009 11:24:57 ATC-CW2K <LOC0:CRIT> Mar\\xa0 2 11:25:24 USABLDRRECFLOW01 ITMGSC: %local0-2-EVENT: 09$Partition=0]PartitionName=&)MODE=3;Alert ID=0002O5E}Event ID=001KMPT|Status=Active^Severity=Critical^Managed\\nObject=Host2\\n^Managed Object Type=Routers^CUSTID=Security_Group^CUSTREV=*^Description=Unresponsive::Component=1.1.1.1 [Host2];IPStatus=OK;InterfaceName=IF-Host2/19 [Gi0/0.80] [1.1.1.1] [WAAS INTERFACE];InterfaceType=L2VLAN;InterfaceOperStatus=UP;NetworkNumber=1.1.1.1;Inter\\n03 02 2009 11:26:27 ATC-CW2K <LOC0:CRIT> Mar\\xa0 2 11:26:54 USABLDRRECFLOW01ITMGSC: %local0-2-EVENT: 09$Partition=0]PartitionName=&)MODE=3;Alert ID=00061D0}Event ID=001KMPZ|Status=Active^Severity=Critical^Managed Object=\\n1.1.1.1\\n^Managed Object Type=Wireless^CUSTID=Security_Group^CUSTREV=*^Description=HighQueueDropRate::Component=IF-1.1.1.1/1 [Do0];Type=IEEE80211;OutputPacketNoErrorRate=0.11666667\\xa0 PPS;DuplexMode=FULLDUPLEX;InputPacketQueueDropRate=0.0125\\xa0 PPS;InputPacketQueueDropPct=48.07692\\xa0 %;MaxSpeed=54000000;OutputPacketQueueDropPct=0.0\\n03 02 2009 11:24:57 ATC-CW2K <LOC0:CRIT> Mar\\xa0 2 11:25:24 USABLDRRECFLOW01 ITMGSC: %local0-2-EVENT: 09$Partition=0]PartitionName=&)MODE=3;Alert ID=0002O5E}Event ID=001KMPT|Status=Active^Severity=Critical^Managed\\nObject=Host2\\n^Managed Object Type=Routers^CUSTID=Security_Group^CUSTREV=*^Description=Unresponsive::Component=1.1.1.1 [Host2];IPStatus=OK;InterfaceName=IF-Host2/19 [Gi0/0.80] [1.1.1.1] [WAAS INTERFACE];InterfaceType=L2VLAN;InterfaceOperStatus=UP;NetworkNumber=1.1.1.1;Inter\\nIn the above two logs Managed Object= can contain either a hostname or an IP address. In both cases, the host/IP are impacted as the object being managed not the manager.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'Impacted Interface': 'The network port or interface which was affected by the activity (for example, target or server).\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Interface (Impacted)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Interface (Impacted)\\nElasticsearch Field Name, impactedInterface\\nRule Builder Column Name, DInterface\\nRegex Pattern, <dinterface>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nInterface (Impacted)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nInterface (Impacted)\\nElasticsearch Field Name\\nimpactedInterface\\nRule Builder Column Name\\nDInterface\\nRegex Pattern\\n<dinterface>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Switches\\nFirewalls\\nNetwork equipment\\n', 'Use Case': 'Troubleshooting connectivity.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Impacted is Server (In Client-Server Model).\\nImpacted is Target (In Attacker-Target Model).\\nIf you have more than just a port number (for example, a switch ID), capture full interface name including switch ID.\\nA Wireless Access Point can be an interface.\\n', 'Examples': 'Aerohive Access Point\\n05 28 2013 18:38:30 1.1.1.1 <LOC6:INFO> ah_auth: Notify driver to disassoc 2222:cccc:ffff from\\nwifi1.3\\nDisassociation of client from access point where the AP is impacted server. The client-server (origin-impacted) relationship applies.\\nFortiGate\\n02 25 2010 13:56:25 1.1.1.1 <LOC5:ALRT> date=2010-02-25 time=13:56:25 devname=FG3222222222 device_id=FG22222222222 log_id=0419016384 type=ips subtype=signature pri=alert fwver=040003 severity=critical carrier_ep=\"N/A\" profile=\"scan\" src=1.1.1.1 dst=1.1.1.1 src_int=\"port1\"\\ndst_int=\"port2\"\\npolicyid=48 serial=1514122225 status=detected proto=6 service=2612/tcp vd=\"root\" count=1 src_port=80 dst_port=2612 attack_id=107347979 sensor=\"all_default\" ref=\"\\nhttp://Host1/ids/VID107347979\\n\" user=\"N/A\" group=\"N/A\" incident_serialno=128862693 msg=\"http_decoder: HTTP.Request.Smuggling\"\\nFirewall log showing a signature detection with interface destination (impacted). In this case, the destination (impacted) is represented as destination from the Firewall perspective.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'Impacted MAC Address': 'The MAC Address that was affected by the activity.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, MAC Address (Impacted)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, MAC Address (Impacted)\\nElasticsearch Field Name, impactedMac\\nRule Builder Column Name, DMAC\\nRegex Pattern, <dmac>\\nNetMon Name, DestMAC\\nClient Console Full Name\\nMAC Address (Impacted)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nMAC Address (Impacted)\\nElasticsearch Field Name\\nimpactedMac\\nRule Builder Column Name\\nDMAC\\nRegex Pattern\\n<dmac>\\nNetMon Name\\nDestMAC\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Firewall\\nIDS/IPS\\nVulnerability scanners\\n', 'Use Case': 'Differentiating hosts and interfaces.\\nDetecting MAC ID cloning.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Can be in any format of MAC address\\nMM:MM:MM:SS:SS:SS\\nMM-MM-MM-SS-SS-SS\\nMMM.MMM.SSS.SSS\\nMM MM MM SS SS SS\\nMM:MM:MM:SS:SS:SS\\nMM-MM-MM-SS-SS-SS\\nMMM.MMM.SSS.SSS\\nMM MM MM SS SS SS\\nImpacted is Server (In Client-Server Model)\\nImpacted is Target (In Attacker-Target Model)\\n', 'Examples': 'FireEye Web MPS\\n02 01 2016 17:13:19 1.1.1.1 <LOC4:WARN> fenotify-609081.warning: CEF:0|FireEye|MPS|1.1.1.1875|IM|infection-match|1|rt=Feb 01 2016 23:13:10 UTC src=1.1.1.1 cn3Label=cncPort cn3=80 cn2Label=sid cn2=84575103 shost= USABLDRRECFLOW01proto=tcp spt=51997 dst=1.1.1.1 cs5Label=cncHost cs5=1.1.1.1 dvchost= USABLDRRECFLOW01dvc=1.1.1.1\\nsmac=00:00:00:00:00:00\\ncn1Label=vlan cn1=0 dpt=80 externalId=609081 cs4Label=link cs4=THINGS dmac=00:00:00:00:00:00 cs1Label=sname cs1=Exploit.Kit.AnglerDIPv4\\nsmac= in this log is the target MAC Address (impacted).\\nBrocade Switch\\n03 01 2017 02:08:41 1.1.1.1 <LOC6:NOTE> Mar\\xa0 1 02:08:38 ch3p1gw4 dataplane[2287]: fw rule INTERNAL-IN:10000 block udp(17) src=dp0p160p1/0:50:56:9a:ea:e8/fe80::e9c4:f7f6:e72c:2029(546) dst=/\\n33:33:0:1:0:2\\n/ff02::1:2(547) len=159 hoplimit=1 len=119\\ndst= with a possible destination hostname followed by destination (impacted) MAC Address.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'Impacted NAT IP': 'The Impacted Network Address Translated IP address (for example, target or server).\\n', 'Data Type': 'IP\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, NAT IP Address (Impacted)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, NAT IP Address (Impacted)\\nElasticsearch Field Name, impactedNatIp\\nRule Builder Column Name, DNATIP\\nRegex Pattern, <dnatip>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nNAT IP Address (Impacted)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nNAT IP Address (Impacted)\\nElasticsearch Field Name\\nimpactedNatIp\\nRule Builder Column Name\\nDNATIP\\nRegex Pattern\\n<dnatip>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Network equipment\\n', 'Use Case': 'Internal host context\\n', 'MPE/Data Masking Manipulations': 'Polyfield – Impacted Host\\n', 'Usage Standards': 'Do not override/overload, use <dnatip> not (?<dnatip>.*?).\\nNAT Impacted is Server (In Client-Server Model).\\nNAT Impacted is Target (In Attacker-Target Model).\\nUse when you see an Impacted IP address IPv4 or IPv6.\\n', 'Examples': 'Cisco Netflow\\n02 19 2014 06:40:29 NetFlow V9 CONN_ID=- Src=1.1.1.1 SPort=62173 InIfc=4 Dst=1.1.1.1 DPort=8080 OutIfc=3 Prot=6 ICMP_IPV4_TYPE=- ICMP_IPV4_CODE=- XLATE_SRC_ADDR_IPV4=- XLATE_DST_ADDR_IPV4=- XLATE_SRC_PORT=- XLATE_DST_PORT=- FW_EVENT=- FW_EXT_EVENT=- EVENT_TIME_MSEC=- IN_PERMANENT_BYTES=- DETAILS=CONN_ID=1632431052 ICMP_IPV4_TYPE=0 ICMP_IPV4_CODE=0 XLATE_SRC_ADDR_IPV4=\\n1.1.1.1\\nXLATE_DST_ADDR_IPV4=1.1.1.1 XLATE_SRC_PORT=61695 XLATE_DST_PORT=8080 FW_EVENT=2 FW_EXT_EVENT=2015 EVENT_TIME_MSEC=1392835229440 IN_PERMANENT_BYTES=8807 DefaultDevice TemplateID=263\\nXLATE-DST-ADDR (Translated) indicates an impacted IP (destination in a network context) that utilizes Network Address Translation (NAT). SIP and DIP (Origin and Impacted) are indicated here with src= and dst=.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'Origin Hostname': 'The hostname from which activity originated (for example, attacker or client).\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Host (Origin)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Host (Origin)\\nElasticsearch Field Name, originHostName\\nRule Builder Column Name, SName\\nRegex Pattern, <sname>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nHost (Origin)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nHost (Origin)\\nElasticsearch Field Name\\noriginHostName\\nRule Builder Column Name\\nSName\\nRegex Pattern\\n<sname>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Networked equipment.\\n', 'Use Case': 'Host context\\n', 'MPE/Data Masking Manipulations': 'Polyfield – Origin Host\\n', 'Usage Standards': 'Origin is Client (In Client-Server Model).\\nOrigin is Attacker (In Attacker-Target Model).\\nCan be used for parsing fully qualified domain names for non-world wide web context hostnames.\\n', 'Examples': \"Windows Event Log\\n<Event xmlns='\\nhttp://Host2/win/2004/08/events/event'><System><Provider\\nName='NETLOGON'/><EventID Qualifiers='0'>5805</EventID><Level></Level><Task>None</Task><Keywords></Keywords><TimeCreated SystemTime='2014-02-06T06:03:06.000000000Z'/><EventRecordID>156578</EventRecordID><Channel>System</Channel><Computer>\\nUSABLDRRECFLOW01\\n</Computer><Security/></System><EventData>The session setup from the computer\\nUSABLDRRECFLOW02\\nfailed to authenticate. The following error occurred:\\nAccess is denied.</EventData></Event>\\nOrigin Host is the system trying to authenticate. <Computer> is the origin of the log message here, but also the domain controller which the origin is trying to authenticate against. Client-Server (origin-impacted) relationship applies here.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'Origin Hostname or IP': 'The hostname or IP from which activity originated (for example, attacker or client).\\n', 'Data Type': 'String\\nIP\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Host (Origin)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Host (Origin)\\nElasticsearch Field Name, originName, originIp\\nRule Builder Column Name, SIP, SName\\nRegex Pattern, (<sipn>)\\nNetMon Name, Not applicable\\nClient Console Full Name\\nHost (Origin)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nHost (Origin)\\nElasticsearch Field Name\\noriginName, originIp\\nRule Builder Column Name\\nSIP, SName\\nRegex Pattern\\n(<sipn>)\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'See\\nIP Address (Origin)\\nand\\nOrigin Hostname\\n.\\n', 'Use Case': 'See\\nIP Address (Origin)\\nand\\nOrigin Hostname\\n.\\n', 'MPE/Data Masking Manipulations': 'See\\nIP Address (Origin)\\nand\\nOrigin Hostname\\n.\\n', 'Usage Standards': 'Use when a log can contain either an IP or a hostname in the same location.\\nMust be wrapped in parenthesis to function (<sipn>).\\nDo not overload or override.\\n', 'Examples': \"Windows Event Log\\n<Event xmlns='\\nhttp://schemas.microsoft.com/win/2004/08/events/event'><System><Provider\\nName='Microsoft-Windows-Time-Service' Guid='{06edcfeb-0fd0-4e53-acca-a6f8bbf81bcb}'/><EventID>37</EventID><Version>0</Version><Level>Information</Level><Task>None</Task><Opcode>Info</Opcode><Keywords></Keywords><TimeCreated SystemTime='2016-08-02T19:21:10.521541000Z'/><EventRecordID>5823536</EventRecordID><Correlation/><Execution ProcessID='968' ThreadID='6580'/><Channel>System</Channel><Computer> USABLDRRECFLOW01</Computer><Security UserID='NT AUTHORITY\\\\LOCAL SERVICE'/></System><EventData Name='TMP_EVENT_TIME_SOURCE_REACHABLE'><Data Name='TimeSource'>\\nUSABLDRRECFLOW01\\n(ntp.d|1.1.1.1:123->1.1.1.1:123)</Data></EventData></Event>\\n<Event xmlns='\\nhttp://schemas.microsoft.com/win/2004/08/events/event'><System><Provider\\nName='Microsoft-Windows-Time-Service' Guid='{06edcfeb-0fd0-4e53-acca-a6f8bbf81bcb}'/><EventID>37</EventID><Version>0</Version><Level>Information</Level><Task>None</Task><Opcode>Info</Opcode><Keywords></Keywords><TimeCreated SystemTime='2016-09-10T02:47:47.934071900Z'/><EventRecordID>534913</EventRecordID><Correlation/><Execution ProcessID='1008' ThreadID='7908'/><Channel>System</Channel><Computer> USABLDRRECFLOW01</Computer><Security UserID='NT AUTHORITY\\\\LOCAL SERVICE'/></System><EventData Name='TMP_EVENT_TIME_SOURCE_REACHABLE'><Data Name='TimeSource'>\\n1.1.1.1\\n,0x8 (ntp.m|0x8|1.1.1.1:123->1.1.1.1:123)</Data></EventData></Event>\\n<Event xmlns='\\nhttp://schemas.microsoft.com/win/2004/08/events/event'><System><Provider\\nName='Microsoft-Windows-Time-Service' Guid='{06edcfeb-0fd0-4e53-acca-a6f8bbf81bcb}'/><EventID>37</EventID><Version>0</Version><Level>Information</Level><Task>None</Task><Opcode>Info</Opcode><Keywords></Keywords><TimeCreated SystemTime='2016-08-02T19:21:10.521541000Z'/><EventRecordID>5823536</EventRecordID><Correlation/><Execution ProcessID='968' ThreadID='6580'/><Channel>System</Channel><Computer> USABLDRRECFLOW01</Computer><Security UserID='NT AUTHORITY\\\\LOCAL SERVICE'/></System><EventData Name='TMP_EVENT_TIME_SOURCE_REACHABLE'><Data Name='TimeSource'>\\nUSABLDRRECFLOW01\\n(ntp.d|1.1.1.1:123->1.1.1.1:123)</Data></EventData></Event>\\n<Event xmlns='\\nhttp://schemas.microsoft.com/win/2004/08/events/event'><System><Provider\\nName='Microsoft-Windows-Time-Service' Guid='{06edcfeb-0fd0-4e53-acca-a6f8bbf81bcb}'/><EventID>37</EventID><Version>0</Version><Level>Information</Level><Task>None</Task><Opcode>Info</Opcode><Keywords></Keywords><TimeCreated SystemTime='2016-09-10T02:47:47.934071900Z'/><EventRecordID>534913</EventRecordID><Correlation/><Execution ProcessID='1008' ThreadID='7908'/><Channel>System</Channel><Computer> USABLDRRECFLOW01</Computer><Security UserID='NT AUTHORITY\\\\LOCAL SERVICE'/></System><EventData Name='TMP_EVENT_TIME_SOURCE_REACHABLE'><Data Name='TimeSource'>\\n1.1.1.1\\n,0x8 (ntp.m|0x8|1.1.1.1:123->1.1.1.1:123)</Data></EventData></Event>\\nTimeSource can either be an IP or a hostname in these examples.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'Origin Interface': 'The network port or interface from which the activity originated (for example, attacker or client).\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Interface (Origin)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Interface (Origin)\\nElasticsearch Field Name, originInterface\\nRule Builder Column Name, sinterface\\nRegex Pattern, <sinterface>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nInterface (Origin)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nInterface (Origin)\\nElasticsearch Field Name\\noriginInterface\\nRule Builder Column Name\\nsinterface\\nRegex Pattern\\n<sinterface>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Switches\\nFirewalls\\nNetwork equipment\\n', 'Use Case': 'Troubleshooting connectivity.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Origin is Client (In Client-Server Model).\\nOrigin is Attacker (In Attacker-Target Model).\\nIf you have more than just a port number (for example, a switch ID), capture full interface name including switch ID.\\nA Wireless Access Point can be an interface.\\n', 'Examples': 'FortiGate\\n02 25 2010 13:56:25 1.1.1.1 <LOC5:ALRT> date=2010-02-25 time=13:56:25 devname=FG322222222222222 device_id=FG2222222222 log_id=0419016384 type=ips subtype=signature pri=alert fwver=040003 severity=critical carrier_ep=\"N/A\" profile=\"scan\" src=1.1.1.1 dst=1.1.1.1\\nsrc_int=\"port1\"\\ndst_int=\"port2\" policyid=48 serial=23455436 status=detected proto=6 service=2612/tcp vd=\"root\" count=1 src_port=80 dst_port=2612 attack_id=107347979 sensor=\"all_default\" ref=\"\\nhttp://Host1/ids/VID107347979\\n\" user=\"N/A\" group=\"N/A\" incident_serialno=128862663 msg=\"http_decoder: HTTP.Request.Smuggling\"\\nFirewall log showing a signature detection with interface src (origin). In this case, the possible attacker (origin) is represented as source from the Firewall perspective.\\nSquid Proxy\\n2014/05/01 10:45:29| Accepting\\xa0 spoofing HTTP connections at 1.1.1.1:3128,\\nFD 14\\n.\\nConnection origin showing IP and corresponding interface.\\nJuniper Firewall\\n08 23 2016 09:56:43 1.1.1.1 <USER:INFO> 1 2016-08-23T14:56:42.429Z USABLDRRECFLOW01 RT_FLOW - RT_FLOW_SESSION_CREATE [junos@1.1.1.1.2.40 source-address=\"1.1.1.1\" source-port=\"57101\" destination-address=\"1.1.1.1\" destination-port=\"443\" service-name=\"junos-https\" nat-source-address=\"1.1.1.1\" nat-source-port=\"57101\" nat-destination-address=\"1.1.1.1\" nat-destination-port=\"443\" src-nat-rule-type=\"static rule\" src-nat-rule-name=\"ARUBA_RAP_WLC3600_xlate\" dst-nat-rule-type=\"N/A\" dst-nat-rule-name=\"N/A\" protocol-id=\"6\" policy-name=\"EMEA_ARUBA_GUEST_ACCESS\" source-zone-name=\"FRONTEND_DMZ\" destination-zone-name=\"INTERNET\" session-id-32=\"83048\" username=\"N/A\" roles=\"N/A\"\\npacket-incoming-interface=\"reth5.0\"\\napplication=\"UNKNOWN\" nested-application=\"UNKNOWN\" encrypted=\"UNKNOWN\"]\\nShowing inbound interface in flow.\\nCisco Router\\n10 09 2016 01:59:26 1.1.1.1 <LOC7:ERRR> Original Address=1.1.1.1 39296: Oct\\xa0 9 01:59:48: %ILPOWER-3-CONTROLLER_PORT_ERR: Controller port error,\\nInterface Gi4/0/38\\n: Power Controller reports Short detected\\nParse full interface Gi4/0/38.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'Origin MAC Address': 'The MAC Address from which activity originated.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, MAC Address (Origin)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, MAC Address (Origin)\\nElasticsearch Field Name, originMac\\nRule Builder Column Name, SMAC\\nRegex Pattern, <smac>\\nNetMon Name, SrcMAC\\nClient Console Full Name\\nMAC Address (Origin)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nMAC Address (Origin)\\nElasticsearch Field Name\\noriginMac\\nRule Builder Column Name\\nSMAC\\nRegex Pattern\\n<smac>\\nNetMon Name\\nSrcMAC\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Firewall\\nIDS/IPS\\nVulnerability scanners\\n', 'Use Case': 'Differentiating hosts and interfaces.\\nDetecting MAC ID cloning.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Can be in any format of MAC address:\\nMM:MM:MM:SS:SS:SS\\nMM-MM-MM-SS-SS-SS\\nMMM.MMM.SSS.SSS\\nMM MM MM SS SS SS\\nMM:MM:MM:SS:SS:SS\\nMM-MM-MM-SS-SS-SS\\nMMM.MMM.SSS.SSS\\nMM MM MM SS SS SS\\nOrigin is Client (In Client-Server Model)\\nOrigin is Attacker (In Attacker-Target Model)\\n', 'Examples': \"FireEye Web MPS\\n02 01 2016 17:13:19 1.1.1.1 <LOC4:WARN> fenotify-609081.warning: CEF:0|FireEye|MPS|1.1.1.1875|IM|infection-match|1|rt=Feb 01 2016 23:13:10 UTC src=1.1.1.1 cn3Label=cncPort cn3=80 cn2Label=sid cn2=84575103 shost=\\nhttps://www.recordflow.biz\\nproto=tcp spt=51997 dst=1.1.1.1 cs5Label=cncHost cs5=1.1.1.1 dvchost= USABLDRRECFLOW01dvc=1.1.1.1 smac=00:00:00:00:00:00 cn1Label=vlan cn1=0 dpt=80 externalId=609081 cs4Label=link cs4=THING\\ndmac=00:00:00:00:00:00\\ncs1Label=sname cs1=Exploit.Kit.AnglerDIPv4\\nDmac= in this log is the attacker MAC Address (origin).\\nBrocade Switch\\n03 01 2017 02:08:41 1.1.1.1 <LOC6:NOTE> Mar\\xa0 1 02:08:38 USABLDRRECFLOW01dataplane[2287]: fw rule INTERNAL-IN:10000 block udp(17) src= USABLDRRECFLOW01/\\n0:00:00:00:00:00\\n/IPV6Address dst=/00:00:00:00/0000::0:0(547) len=159 hoplimit=1 len=119\\nSrc= with hostname followed by origin MAC Address. Network traffic shown src->dst will be origin->impacted.\\nWindows Event Log – DHCP Ops\\n<Event xmlns='\\nhttp://Host2/win/2004/08/events/event'><System><Provider\\nName='Microsoft-Windows-DHCP-Server' Guid='{6d64f02c-a125-4dac-9a01-f0555b41ca84}'/><EventID>20097</EventID><Version>0</Version><Level>Information</Level><Task>None</Task><Opcode>Info</Opcode><Keywords></Keywords><TimeCreated SystemTime='2014-10-07T00:13:02.116745100Z'/><EventRecordID>445336</EventRecordID><Correlation/><Execution ProcessID='1320' ThreadID='2952'/><Channel>Microsoft-Windows-Dhcp-Server/FilterNotifications</Channel><Computer> USABLDRRECFLOW01</Computer><Security UserID='NT AUTHORITY\\\\NETWORK SERVICE'/></System><EventData>DHCP Services were denied to machine with hardware address\\n00-00-00-00-00-00\\n, hardware type 1 and FQDN/Hostname USABLDRRECFLOW01because it did not match any entry in the Allow List.</EventData></Event>\\nOrigin MAC Address with dashes instead of colons.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'Origin NAT IP': 'The Network Address Translated IP from which activity originated (for example, attacker or client).\\n', 'Data Type': 'IP\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, NAT IP Address (Origin)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, NAT IP Address (Origin)\\nElasticsearch Field Name, originNatIp\\nRule Builder Column Name, SNATIP\\nRegex Pattern, <snatip>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nNAT IP Address (Origin)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nNAT IP Address (Origin)\\nElasticsearch Field Name\\noriginNatIp\\nRule Builder Column Name\\nSNATIP\\nRegex Pattern\\n<snatip>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Network equipment\\n', 'Use Case': 'Internal host context\\n', 'MPE/Data Masking Manipulations': 'Polyfield – Origin Host\\n', 'Usage Standards': 'Do not override/overload, use <snatip> not (?<snatip>.*?).\\nNAT Origin is Client (In Client-Server Model).\\nNAT Origin is Attacker (In Attacker-Target Model).\\nUse when you see an Origin IP address IPv4 or IPv6.\\n', 'Examples': 'Cisco Netflow\\n02 19 2014 06:40:29 NetFlow V9 CONN_ID=- Src=1.1.1.1 SPort=62173 InIfc=4 Dst=1.1.1.1 DPort=8080 OutIfc=3 Prot=6 ICMP_IPV4_TYPE=- ICMP_IPV4_CODE=- XLATE_SRC_ADDR_IPV4=- XLATE_DST_ADDR_IPV4=- XLATE_SRC_PORT=- XLATE_DST_PORT=- FW_EVENT=- FW_EXT_EVENT=- EVENT_TIME_MSEC=- IN_PERMANENT_BYTES=- DETAILS=CONN_ID=1632431052 ICMP_IPV4_TYPE=0 ICMP_IPV4_CODE=0 XLATE_SRC_ADDR_IPV4=1.1.1.1 XLATE_DST_ADDR_IPV4=\\n1.1.1.1\\nXLATE_SRC_PORT=61695 XLATE_DST_PORT=8080 FW_EVENT=2 FW_EXT_EVENT=2015 EVENT_TIME_MSEC=1392835229440 IN_PERMANENT_BYTES=8807 DefaultDevice TemplateID=263\\nXLATE-SRC-ADDR indicates an origin IP (source in a network context) utilizing Network Address Translation (NAT). SIP and DIP (Origin and Impacted) are indicated here with src= and dst=.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'SIPv4': 'Constituent element of <sip> for only IPv4 parsing (not generally used). Completely redundant to SIP.\\n', 'Data Type': 'IP\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Host (Origin)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Host (Origin)\\nElasticsearch Field Name, originIpV4\\nRule Builder Column Name, SIP\\nRegex Pattern, <sipv4>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nHost (Origin)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nHost (Origin)\\nElasticsearch Field Name\\noriginIpV4\\nRule Builder Column Name\\nSIP\\nRegex Pattern\\n<sipv4>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Nested element of <sip> default regex\\nCan not be used with <sipv6>\\n', 'Common Applications': 'IPv4 only network equipment.\\n', 'Use Case': 'For more information, see\\nIP Address (Origin)\\n.\\n', 'MPE/Data Masking Manipulations': 'Polyfield – Origin Host\\n', 'Usage Standards': 'This field is rarely used because it is redundant to <sip>.\\nIf you are 100% certain an IPv4 address will always appear.\\nOnly use if you need an extremely minute performance improvement.\\n', 'Examples': 'Not applicable.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'SIPv6': 'Constituent element of <sip> for only IPv6 parsing (not generally used).\\n', 'Data Type': 'IP\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Host (Origin)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Host (Origin)\\nElasticsearch Field Name, originIpV6\\nRule Builder Column Name, SIP\\nRegex Pattern, <sipv6>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nHost (Origin)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nHost (Origin)\\nElasticsearch Field Name\\noriginIpV6\\nRule Builder Column Name\\nSIP\\nRegex Pattern\\n<sipv6>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Nested element of <sip> default regex\\nCan not be used with <sipv4>\\n', 'Common Applications': 'IPv6 only network equipment.\\n', 'Use Case': 'For more information, see\\nIP Address (Origin)\\n.\\n', 'MPE/Data Masking Manipulations': 'Polyfield – Origin Host\\n', 'Usage Standards': 'This is rarely used.\\nIs redundant to <sip>.\\nIf you are 100% certain an IPv6 address will always appear.\\nUse if you need an extremely minute performance improvement.\\n', 'Examples': 'Trend Micro Deep Security\\n11 19 2014 08:21:12 10.100.6.64 <LOC0:INFO> Nov 19 03:25:07 USABLDRRECFLOW01 dsa_mpnp: REASON=IPv6_Packet HOSTID=230078 ACT=Deny IN=0C:0B:05:07:B0:05 OUT= MAC=00:00:00:00:00:00:00:BE:00:00:00:0D:00:0d SRC=\\nfe80:0:0:0:0cd0:000f:bd2f:000b\\nDST=ff01:0:0:0:0:0:0:1 LEN=86 PROTO=ICMPv6 SPT=0 DPT=0 CNT=1\\nSRC= shows origin IPv6 Address.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'SIPv6E': 'The IPv4 IP address mapped to IPv6e from which activity originated (for example, attacker or client).\\n', 'Data Type': 'IP\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Host (Origin)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Host (Origin)\\nElasticsearch Field Name, originIpV6\\nRule Builder Column Name, SIP\\nRegex Pattern, <sipv6e>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nHost (Origin)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nHost (Origin)\\nElasticsearch Field Name\\noriginIpV6\\nRule Builder Column Name\\nSIP\\nRegex Pattern\\n<sipv6e>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Networked equipment.\\n', 'Use Case': 'Host context\\n', 'MPE/Data Masking Manipulations': 'Polyfield – Origin Host\\n', 'Usage Standards': 'Do not override/overload, use <sipv6e> not (?<sipv6e>.*?).\\nOrigin is Client (In Client-Server Model).\\nOrigin is Attacker (In Attacker-Target Model).\\nUse when you see an Origin IPv4 address mapped to IPv6.\\n', 'Examples': 'Townsend Alliance LogAgent\\n11 02 2015 22:10:02 1.1.1.1 <ALRT:INFO> Nov\\xa0 2 22:09:39 USABLDRRECFLOW01QAUDJRN:[PW@0 event=\"PW-Invalid user or password\" event_type=\"Q-Signon failed profile disabled\" actual_type=\"PW-Q\" user_profile=\"PSTORE\" device=\"\" jrn_seq=\"6849716\" timestamp=\"20151102220939315000\" job_name=\"QZSOSIGN\" user_name=\"QUSER\" job_number=\"535772\" eff_user=\"QUSER\" ip_addr=\"\\n::ffff:1.1.1.1\\n\" port=\"52584\"]\\n::ffff:1.1.1.1 is an IPv4 IP mapped to IPv6. Traditional <sip> and <dip> IP parsers do not work with this type of IP.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nHost Tab\\n', 'Serial Number [7.2]': 'The hardware or software serial number in a log message. Should be a permanent, unique identifier of what it is identifying.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String (128 characters maximum)\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Serial Number\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Serial Number\\nElasticsearch Field Name, serialNumber\\nRule Builder Column Name, SerialNumber\\nRegex Pattern, <serialnumber>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nSerial Number\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nSerial Number\\nElasticsearch Field Name\\nserialNumber\\nRule Builder Column Name\\nSerialNumber\\nRegex Pattern\\n<serialnumber>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'This field was previously an overload of object and subject.\\nSession is often used for what are called serial numbers, but are closer to session identifiers.\\n', 'Common Applications': 'Palo Alto\\nJuniper\\nF5\\nAsset management systems\\n', 'Use Case': 'Uniquely identify systems.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Serial Number is only used for data that uniquely identifies an object, device or application. It is not meant to be used for defining a \"session\" or \"record id.\"\\nOnly overload this field with GUID when S/N not present when the GUID is permanent.\\n', 'Examples': '', 'Correct Examples': \"Avaya Secure Access Link Remote Access Log\\nJun 21 16:29:30 Host2ldomain Host1 xgEnterpriseProxy: Device registered with server\\nhttps://Host4/eMessage\\n: model: SessionMgr, serial number:\\n(000)222-2222\\nSerial Number describes the device being registered to the server.\\nBluecat Adonis\\n03 19 2013 14:34:17 1.1.1.1 <LOC1:INFO> Mar 19 14:34:17 USABLDRRECFLOW01named[4476]: info: zone\\n10.in-addr.arpa/IN/Internal\\n: transferred serial 324442789: TSIG 'view13530'\\nSerial used in DNS transaction.\\n\", 'Ambiguous Examples': 'FortiGate\\n03 27 2016 12:24:47 1.1.1.1 <LOC5:ALRT> date=2016-03-27 time=12:24:47 devname=SLAVE devid=FG222222222222222222 logid=0419016384 type=utm subtype=ips eventtype=signature level=alert vd=\"Front_End\" severity=high srcip=1.1.1.1 dstip=1.1.1.1 srcintf=\"port14\" dstintf=\"port13\" policyid=1897 sessionid=3487142146 action=detected proto=6 service=HTTPS attack=\"OpenSSL.ChangeCipherSpec.Injection\" srcport=50077 dstport=443 hostname=\"\\nrecordflow.biz\\n\" direction=outgoing attackid=38738 profile=\"All-All-All\" ref=\"\\nhttp://www.fortinet.com/ids/VID38738\\n\" incidentserialno=\\n981770026\\nmsg=\"applications3: OpenSSL.ChangeCipherSpec.Injection,\" crscore=30 crlevel=high\\nIncidentserialno correlates logs describing a single incident, and is closer to a session or record ID than a serial number.\\nCisco Telepresence VCS\\n04 26 2016 18:07:35 1.1.1.1 <USER:NOTE> 2016-04-26T18:07:36-04:00 radvcsx tvcs: Event=\"Search Completed\" Reason=\"Not Found\" Service=\"H323\" Src-alias-type=\"H323\" Src-alias=\"pima_373@Host5\" Dst-alias-type=\"E164\" Dst-alias=\"93516#9#935\" Call-serial-number=\"\\ne2c39d22-cd9f-222c-a2ea-7b57a39239fc\\n\" Tag=\"f420cf74-2222-45d6-989a-76e32d94525a\" Detail=\"found:false, searchtype:LRQ\" Level=\"1\" UTCTime=\"2016-04-26 22:07:36,027\"\\nCall-Serial-Number is closer to a session in this context.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nIdentity Tab\\n', 'Account > User (Impacted)': 'The user or system account impacted by activity reported in the log.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, User (Impacted)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, User (Impacted)\\nElasticsearch Field Name, account\\nRule Builder Column Name, Account\\nRegex Pattern, <account>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nUser (Impacted)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nUser (Impacted)\\nElasticsearch Field Name\\naccount\\nRule Builder Column Name\\nAccount\\nRegex Pattern\\n<account>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Any applications, systems or devices that utilize accounts.\\n', 'Use Case': 'Correlating or monitoring user activity.\\n', 'MPE/Data Masking Manipulations': 'Mapped to User Identity (Impacted)\\n', 'Usage Standards': 'Use to indicate the user or account that is being altered or logged off a system by another user or system account.\\nUse for User Accounts and System Accounts.\\n', 'Examples': \"Windows Event Log\\n<Event xmlns='\\nhttp://Host2/win/2004/08/events/event'><System><Provider\\nName='Microsoft-Windows-Security-Auditing' Guid='{54849625-5478-4994-a5ba-3e3b0328c30d}'/><EventID>4738</EventID><Version>0</Version><Level>Information</Level><Task>User Account Management</Task><Opcode>Info</Opcode><Keywords>Audit Success</Keywords><TimeCreated SystemTime='2014-02-26T13:18:11.277015700Z'/><EventRecordID>1635656743</EventRecordID><Correlation/><Execution ProcessID='524' ThreadID='4900'/><Channel>Security</Channel><Computer> USABLDRRECFLOW01Computer><Security/></System><EventData>A user account was changed.\\nSubject:\\nSecurity ID:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 safaware\\\\pete.store\\nAccount Name:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 pete.store\\nAccount Domain:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 safaware\\nLogon ID:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 0x7b1adb067\\nTarget Account:\\nSecurity ID:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 S-1-5-21-2222222-2222222222-2222222222-90119\\nAccount Name:\\nLHR-Reception\\nAccount Domain:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 safaware\\nChanged Attributes:\\nSAM Account Name:\\xa0\\xa0 -\\nDisplay Name:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nUser Principal Name:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nHome Directory:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nHome Drive:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nScript Path:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nProfile Path:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nUser Workstations:\\xa0 -\\nPassword Last Set:\\xa0 -\\nAccount Expires:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nPrimary Group ID:\\xa0\\xa0 -\\nAllowedToDelegateTo:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nOld UAC Value:\\xa0\\xa0\\xa0\\xa0\\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 0x15\\nNew UAC Value:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 0x211\\nUser Account Control:\\n'Password Not Required' - Disabled\\n'Don't Expire Password' - Enabled\\nUser Parameters:\\xa0\\xa0\\xa0 -\\nSID History:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nLogon Hours:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nAdditional Information:\\nPrivileges:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -</EventData></Event>\\nTarget in Windows indicates Impacted. In this log, the Target Account (Impacted) is being modified by Subject Account (Origin).\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nIdentity Tab\\n', 'Group': 'The user group or role impacted by activity reported in the log. Do not use for entity group (zone or domain).\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Group\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Group\\nElasticsearch Field Name, group\\nRule Builder Column Name, Group\\nRegex Pattern, <group>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nGroup\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nGroup\\nElasticsearch Field Name\\ngroup\\nRule Builder Column Name\\nGroup\\nRegex Pattern\\n<group>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Login\\nAccount\\nDomain\\nSession\\nSessionType\\nPolicy\\n', 'Common Applications': 'AD group\\nLinux user group\\nSecurity role\\n', 'Use Case': 'Capturing active directory organizational unit.\\nCapturing certificate organizational units.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Not Zone (internet, network, security).\\nOnly to capture explicitly called out (user) group, organizational units, and roles.\\n', 'Examples': 'Cylance\\n08 16 2016 22:42:18 1.1.1.1 <USER:NOTE> 250 <44>1 2016-08-17T04:42:20.0816805Z sysloghost CylancePROTECT - - - Event Type: AuditLog, Event Name: ZoneAddDevice, Message: Zone:\\nCorporate\\n; Devices: USABLDRRECFLOW01, , User: Dave Foss (pete.store@\\nrecordflow.biz\\n)\\npete.store@recordflow.biz\\n)\\nCorporate Zone is parsed here.\\nAWS\\nTS=2015-07-03T07:15:21Z ACCT=22222222222 RSRC=sg-22222222222 ARN= USABLDRRECFLOW01:security-group/sg- USABLDRRECFLOW01CREATETS= STS=ResourceDiscovered REG=us-west-2 RSRCTYP=AWS::EC2::SecurityGroup DETALS=ownerid=9052222962 groupname=\\nlaunch-wizard-1\\ngroupid=gg22222 description=launch-wizard-1 created 2015-07-03T00:07:57.767-07:00 vpcid=vpc-22222226\\nGroupname= parses into Group. Is explicit as a group.\\nSalesforce\\nEVT_TYP=RestApi TS=2015-07-13T22:37:51Z REQ_ID=3z1tWodgfdgdH5TjAgF- ORG_ID=\\n00D00000000001\\nU_N=pete.store@\\nrecordflow.biz\\n.isvdev01 RUN_T=77 CPU_T=19 CLNT_IP=1.1.1.1 URI=/services/data/v33.0/query\\nOrganization ID parsed (specific to LogRhythm in this example).\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nIdentity Tab\\n', 'Login > User (Origin)': 'The host IP that was affected by the activity (for example, target or server). Destination IP in IPv4 or IPv6 format.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, User (Origin)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, User (Origin)\\nElasticsearch Field Name, login\\nRule Builder Column Name, Login\\nRegex Pattern, <login>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nUser (Origin)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nUser (Origin)\\nElasticsearch Field Name\\nlogin\\nRule Builder Column Name\\nLogin\\nRegex Pattern\\n<login>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Any applications, systems or devices that utilize accounts.\\n', 'Use Case': 'Correlating or monitoring user activity.\\n', 'MPE/Data Masking Manipulations': 'Mapped to User Identity (Origin)\\n', 'Usage Standards': 'Use to indicate the user or system account that is performing altering another account or logging in to a system.\\nUse for User Accounts and System Accounts.\\n', 'Examples': \"Windows Event Log\\n<Event xmlns='\\nhttp://Host2/win/2004/08/events/event'><System><Provider\\nName='Microsoft-Windows-Security-Auditing' Guid='{54849625-5478-4994-a5ba-3e3b0328c30d}'/><EventID>4738</EventID><Version>0</Version><Level>Information</Level><Task>User Account Management</Task><Opcode>Info</Opcode><Keywords>Audit Success</Keywords><TimeCreated SystemTime='2014-02-26T13:18:11.277015700Z'/><EventRecordID>1635656743</EventRecordID><Correlation/><Execution ProcessID='524' ThreadID='4900'/><Channel>Security</Channel><Computer> USABLDRRECFLOW01Computer><Security/></System><EventData>A user account was changed.\\nSubject:\\nSecurity ID:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Safaware\\\\pete.store\\nAccount Name:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 pete.store\\nAccount Domain:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 safaware\\nLogon ID:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 0x7b1adb067\\nTarget Account:\\nSecurity ID:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 S-1-5-21-2222222-22222222-22222-90119\\nAccount Name:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 dave.store\\nAccount Domain:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 safaware\\nChanged Attributes:\\nSAM Account Name:\\xa0\\xa0 -\\nDisplay Name:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nUser Principal Name:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nHome Directory:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nHome Drive:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nScript Path:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nProfile Path:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nUser Workstations:\\xa0 -\\nPassword Last Set:\\xa0 -\\nAccount Expires:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nPrimary Group ID:\\xa0\\xa0 -\\nAllowedToDelegateTo:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nOld UAC Value:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 0x15\\nNew UAC Value:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 0x211\\nUser Account Control:\\n'Password Not Required' - Disabled\\n'Don't Expire Password' - Enabled\\nUser Parameters:\\xa0\\xa0\\xa0 -\\nSID History:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nLogon Hours:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -\\nAdditional Information:\\nPrivileges:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 -</EventData></Event>\\nSubject in Windows indicates Origin. In this log, the Subject Account (Origin) is modifying the Target Account (Impacted).\\nCisco Clean Access Appliance\\n03 28 2010 14:55:50 1.1.1.1 <USER:INFO> Perfigo: Authentication:[00:00:00:00:00:00 ## 1.1.1.1]\\nescribne\\n- Successfully logged in, Provider: conncoll, L2 MAC address: 00:00:00:00:00:00, Role: Students, OS: Macintosh OSX\\nUser logon event. Listed user is the client (origin) connecting to a server (impacted) (client-server).\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nIdentity Tab\\n', 'Recipient': 'The recipient of an email or called to number for a VoIP log.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Recipient\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Recipient\\nElasticsearch Field Name, recipient\\nRule Builder Column Name, Recipient\\nRegex Pattern, <recipient>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nRecipient\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nRecipient\\nElasticsearch Field Name\\nrecipient\\nRule Builder Column Name\\nRecipient\\nRegex Pattern\\n<recipient>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Sender\\nSubject\\nSession\\nSession Type\\n', 'Common Applications': 'Email logs\\nVoIP logs\\nInstant messaging services\\n', 'Use Case': 'Tracking malware infection vector.\\n', 'MPE/Data Masking Manipulations': 'Mapped to Recipient Identity.\\n', 'Usage Standards': 'Recipient shall not be used for identifying the direction of network traffic or network zones.\\nOnly used for destination email, destination caller, chat, instant messaging, or other communication mediums, such as\\nAOL Instant Messenger\\nIRC\\nLync\\nSkype\\nGoogle Hangouts\\nFax\\nAOL Instant Messenger\\nIRC\\nLync\\nSkype\\nGoogle Hangouts\\nFax\\n', 'Examples': 'ColdFusion Mailsent Log\\n\"Information\",\"scheduler-2\",\"12/28/11\",\"09:14:33\",,\"Mail: \\'Web site submission from Pete Store\\' From:\\'NoReply@\\nrecordflow.biz\\n\\' To:\\'\\nmdaveman@recordlow.com\\n\\' was successfully sent using\\nsmtp.recordflow.biz\\n\"\\nTo email parsed appropriately.\\nCisco Telepresence Video Communications Server\\n04 26 2016 16:40:14 1.1.1.1 <USER:NOTE> 2016-04-26T16:40:14-04:00 radvcsx tvcs: Event=\"Call Attempted\" Service=\"SIP\" Src-ip=\"1.1.1.1\" Src-port=\"1196\" Src-alias-type=\"SIP\" Src-alias=\"sip:\\npete.store@Host5\\n\" Dst-alias-type=\"SIP\" Dst-alias=\"sip:dpackl@Host5\" Call-serial-number=\"d415c222-fd22-47fd-8d0a-222b1a351460\" Tag=\"02e3b418-f67b-408b-22b2-adafea222e32\" Protocol=\"TLS\" Auth=\"NO\" Level=\"1\" UTCTime=\"2016-04-26 20:40:14,467\"\\nDst-Alias in this case a VoIP call destination.\\nCisco Unified Comm Mgr (Call Mgr)\\n05 22 2012 15:05:49 1.1.1.1 <LOC7:WARN> 750: May 22 2012 20:05:49.41 UTC :\\xa0 %UC_CALLMANAGER-4-MaliciousCall: %[Called Party Number=2755][Called Device Name= USABLDRRECFLOW01][Called Display Name=\\nJason Riggins\\n][Calling Party Number=2378][Calling Device Name= USABLDRRECFLOW01][Calling Display Name=Dave Store Test][App ID=Cisco CallManager][Cluster ID=StandAloneCluster][Node ID=KaM-CCM2-SubT]: A malicious call has been identified\\nAnother VoIP call destination.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nIdentity Tab\\n', 'Sender': 'The sender of an email or the caller number for a VoIP log. Must relate to a specific user, or unique address in the case of a phone call or email.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Sender\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Sender\\nElasticsearch Field Name, sender\\nRule Builder Column Name, Sender\\nRegex Pattern, <sender>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nSender\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nSender\\nElasticsearch Field Name\\nsender\\nRule Builder Column Name\\nSender\\nRegex Pattern\\n<sender>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Recipient\\nSubject\\nSession\\nSession Type\\n', 'Common Applications': 'Email logs\\nVoIP logs\\n', 'Use Case': 'Identify spam traffic by looking at top senders of email.\\nTrack ransomware back to source/spread pattern.\\n', 'MPE/Data Masking Manipulations': 'Mapped to Sender Identity.\\n', 'Usage Standards': 'Sender shall not be used for identifying the direction of network traffic or network zones.\\nOnly used for origin email, origin caller, chat, instant messaging, or other communication mediums, such as\\nAOL Instant Messenger\\nIRC\\nLync\\nSkype\\nGoogle Hangouts\\nFax\\nAOL Instant Messenger\\nIRC\\nLync\\nSkype\\nGoogle Hangouts\\nFax\\n', 'Examples': 'ColdFusion Mailsent Log\\n\"Information\",\"scheduler-2\",\"12/28/11\",\"09:14:33\",,\"Mail: \\'Web site submission from Donna Hirt\\' From:\\'\\nNoReply@recordflow\\n.biz\\' To:\\'mcoffman@\\nsagepointadvisor.com\\n\\' was successfully sent using mta23.colo.lan\"\\nFrom email parsed appropriately.\\nCisco Telepresence Video Communications Server\\n04 26 2016 16:40:14 1.1.1.1 <USER:NOTE> 2016-04-26T16:40:14-04:00 radvcsx tvcs: Event=\"Call Attempted\" Service=\"SIP\" Src-ip=\"1.1.1.1\" Src-port=\"1196\" Src-alias-type=\"SIP\" Src-alias=\"sip:\\npete_store@Host5\\n\" Dst-alias-type=\"SIP\" Dst-alias=\"sip:dpack@Host5\" Call-serial-number=\"d415c736-fd67-47fd-8d0a-892b1a351460\" Tag=\"02e3b418-f67b-408b-92b2-adafea551e32\" Protocol=\"TLS\" Auth=\"NO\" Level=\"1\" UTCTime=\"2016-04-26 20:40:14,467\"\\nSrc-Alias in this case a VoIP call origin.\\nCisco Unified Comm Mgr (Call Mgr)\\n05 22 2012 15:05:49 1.1.1.1 <LOC7:WARN> 750: May 22 2012 20:05:49.41 UTC :\\xa0 %UC_CALLMANAGER-4-MaliciousCall: %[Called Party Number=2755][Called Device Name=SEP002414B3815B][Called Display Name=Jason Riggins][Calling Party Number=2378][Calling Device Name=recflow00001][Calling Display Name=\\nrecflow Test\\n][App ID=Cisco CallManager][Cluster ID=StandAloneCluster][Node ID=rec-flow-001]: A malicious call has been identified\\nAnother VoIP call origin.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nNetwork Tab\\n', 'Domain [7.2] (Domain (Impacted))': 'The Windows or DNS domain name referenced or impacted by activity reported in the log.\\nThis field is not available in LogRhythm versions earlier than 7.2.1.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Domain (Origin)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Domain (Impacted)\\nElasticsearch Field Name, domain\\nRule Builder Column Name, Domain\\nRegex Pattern, <domain> or <domainimpacted>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nDomain (Origin)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nDomain (Impacted)\\nElasticsearch Field Name\\ndomain\\nRule Builder Column Name\\nDomain\\nRegex Pattern\\n<domain> or <domainimpacted>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'WebpProxy\\nNetwork monitoring\\nActive Directory\\nSSO\\n', 'Use Case': 'Correlating user activity across domains.\\n', 'MPE/Data Masking Manipulations': 'Not applicable.\\n', 'Usage Standards': 'Used for capturing an Active Directory Domain name.\\n', 'Examples': \"Windows Event Log\\n<Event xmlns='\\nhttp://schemas.microsoft.com/win/2004/08/events/event'><System><Provider\\nName='Microsoft-Windows-Security-Auditing' Guid='{54849625-5478-4994-a5ba-3e3b0328c30d}'/><EventID>4742</EventID><Version>0</Version><Level>Information</Level><Task>Computer Account Management</Task><Opcode>Info</Opcode><Keywords>Audit Success</Keywords><TimeCreated SystemTime='2016-02-26T03:09:41.988899400Z'/><EventRecordID>2283625151</EventRecordID><Correlation/><Execution ProcessID='520' ThreadID='1140'/><Channel>Security</Channel><Computer> USABLDRRECFLOW01</Computer><Security/></System><EventData><Data Name='ComputerAccountChange'>-</Data><Data Name='TargetUserName'>USLT0752CROBB$</Data><Data Name=\\n'TargetDomainName'>SAFAWARE\\n</Data><Data Name='TargetSid'>SAFAWARE\\\\ USABLDRRECFLOW01$</Data><Data Name='SubjectUserSid'>SAFAWARE\\\\pete.store</Data><Data Name='SubjectUserName'>pete.store</Data><Data Name='SubjectDomainName'>SAFAWARE</Data><Data Name='SubjectLogonId'>0x14af66a2b</Data><Data Name='PrivilegeList'>-</Data><Data Name='SamAccountName'>-</Data><Data Name='DisplayName'>-</Data><Data Name='UserPrincipalName'>-</Data><Data Name='HomeDirectory'>-</Data><Data Name='HomePath'>-</Data><Data Name='ScriptPath'>-</Data><Data Name='ProfilePath'>-</Data><Data Name='UserWorkstations'>-</Data><Data Name='PasswordLastSet'>-</Data><Data Name='AccountExpires'>-</Data><Data Name='PrimaryGroupId'>-</Data><Data Name='AllowedToDelegateTo'>-</Data><Data Name='OldUacValue'>0x80</Data><Data Name='NewUacValue'>0x81</Data><Data Name='UserAccountControl'>\\n%%2080</Data><Data Name='UserParameters'>-</Data><Data Name='SidHistory'>-</Data><Data Name='LogonHours'>-</Data><Data Name='DnsHostName'>-</Data><Data Name='ServicePrincipalNames'>-</Data></EventData></Event>\\nTargetDomainName is the Domain of the impacted user in this Account Management event. In Windows Event Logging, Subject refers to Origin and Target refers to Impacted.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nNetwork Tab\\n', 'Impacted NAT Port': 'The Network Address Translated (NAT) port to which activity is targeted—for example, server or target port.\\n', 'Data Type': 'Integer\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, TCP/UDP Port (Impacted)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, TCP/UDP Port (Impacted)\\nElasticsearch Field Name, impactedNatPort\\nRule Builder Column Name, DNATPort\\nRegex Pattern, <snatport>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nTCP/UDP Port (Impacted)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nTCP/UDP Port (Impacted)\\nElasticsearch Field Name\\nimpactedNatPort\\nRule Builder Column Name\\nDNATPort\\nRegex Pattern\\n<snatport>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Any network connected application or device.\\n', 'Use Case': 'Host and application contexts.\\n', 'MPE/Data Masking Manipulations': 'Used to help in determining Application.\\n', 'Usage Standards': 'Use to indicate the Network Address Translated (NAT) impacted port number associated with a server or targeted host.\\nOrigin is Server (In Client-Server Model).\\nTarget is Impacted (In Attacker-Target Model).\\n', 'Examples': 'Cisco Netflow\\n02 19 2014 06:40:29 NetFlow V9 CONN_ID=- Src=1.1.1.1 SPort=62173 InIfc=4 Dst=1.1.1.1 DPort=8080 OutIfc=3 Prot=6 ICMP_IPV4_TYPE=- ICMP_IPV4_CODE=- XLATE_SRC_ADDR_IPV4=- XLATE_DST_ADDR_IPV4=- XLATE_SRC_PORT=- XLATE_DST_PORT=- FW_EVENT=- FW_EXT_EVENT=- EVENT_TIME_MSEC=- IN_PERMANENT_BYTES=- DETAILS=CONN_ID=1632431052 ICMP_IPV4_TYPE=0 ICMP_IPV4_CODE=0 XLATE_SRC_ADDR_IPV4=1.1.1.1 XLATE_DST_ADDR_IPV4=1.1.1.1 XLATE_SRC_PORT=61695\\nXLATE_DST_PORT=8080\\nFW_EVENT=2 FW_EXT_EVENT=2015 EVENT_TIME_MSEC=1392835229440 IN_PERMANENT_BYTES=8807 DefaultDevice TemplateID=263\\nXLATE_DST_PORT shows the translation IPs destination (impacted) port. In a network flow context, destination and impacted are synonymous.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nNetwork Tab\\n', 'Impacted Port': 'The port to which activity is targeted (for example, server or target port).\\n', 'Data Type': 'Integer\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, TCP/UDP Port (Impacted)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, TCP/UDP Port (Impacted)\\nElasticsearch Field Name, impactedPort\\nRule Builder Column Name, DPort\\nRegex Pattern, <dport>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nTCP/UDP Port (Impacted)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nTCP/UDP Port (Impacted)\\nElasticsearch Field Name\\nimpactedPort\\nRule Builder Column Name\\nDPort\\nRegex Pattern\\n<dport>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Any network connected application or device.\\n', 'Use Case': 'Host and application contexts.\\n', 'MPE/Data Masking Manipulations': 'Used to help in determining Application.\\n', 'Usage Standards': 'Use to indicate the impacted port number associated with a server or targeted host.\\nOrigin is Server (In Client-Server Model).\\nTarget is Impacted (In Attacker-Target Model).\\n', 'Examples': 'FireEye Web MPS\\n02 01 2016 17:13:19 1.1.1.1 <LOC4:WARN> fenotify-609081.warning: CEF:0|FireEye|MPS|1.1.1.1875|IM|infection-match|1|rt=Feb 01 2016 23:13:10 UTC src=1.1.1.1 cn3Label=cncPort cn3=80 cn2Label=sid cn2=84575103 shost= USABLDRRECFLOW01proto=tcp\\nspt=51997\\ndst=1.1.1.1 cs5Label=cncHost cs5=1.1.1.1 dvchost= USABLDRRECFLOW01dvc=1.1.1.1 smac=00:00:00:00:00:00 cn1Label=vlan cn1=0 dpt=80 externalId=609081 cs4Label=link cs4URL act=blocked cs6Label=channel cs6=GET Stuff dmac=00:00:00:00:00:00 cs1Label=sname cs1=Exploit.Kit.AnglerDIPv4\\nSpt= in this case is the impacted (target) port in the attacker-target paradigm.\\nCisco\\nNext Generation\\nFirewall\\nCISCONGFW EVENT Ev_Id=610 Ev_Severity=6 Ev_TypeId=HTTP_COMPLETE Ev_SrcId=32 Ev_RecvTime=2/24/2013 10:04:34 PM Ev_MetaData=0 Smx_Config_Version=2 Identity_Source=0 Smx_Policy_Id=0 Flow_ConnId=456 Smx_Egress_Interface_Id=0 Smx_Ingress_Interface_Id=0 Avc_App_Id=300003 Ev_GenTime=2/24/2013 10:04:09 PM Flow_Protocol=6 Flow_SrcIp=1.1.1.1 Flow_DstIp=1.1.1.1 Flow_SrcPort=60221\\nFlow_DstPort=80\\nEv_Producer_Id=5 Flow_Transaction_Id=0 Url=\\nrecordflow.biz\\nFlow_DstHostName=\\nrecordflow.biz\\nSmx_Policy_Id=0 Flow_Bytes_Sent=391 Http_Response_Status=302 Flow_Bytes_Received=647\\nImpacted port (destination in a network traffic flow context).\\nCisco ISE\\n02 10 2014 13:54:24 1.1.1.1 <LOC6:NOTE> Feb 10 13:54:43 USABLDRRECFLOW01 CISE_Failed_Attempts 0000217969 2 0 2014-02-10 13:54:43.264 +02:00 0008145644 5413 NOTICE Failed-Attempt: RADIUS Accounting-Request dropped, ConfigVersionId=143, Device IP Address=1.1.1.1, Device Port=1646, DestinationIPAddress=1.1.1.1,\\nDestinationPort=1646\\n, Protocol=Radius, NetworkDeviceName=Switch_ USABLDRRECFLOW01, NAS-IP-Address=1.1.1.1, NAS-Port=50023, Service-Type=Framed, Acct-Status-Type=Start, Acct-Delay-Time=20, Acct-Session-Id=000022222, Acct-Authentic=Local, NAS-Port-Type=Ethernet, NAS-Port-Id=GigabitEthernet0/23, cisco-av-pair=connect-progress=Call Up, AcsSessionID= USABLDRRECFLOW01/151856948/212124, FailureReason=11038 RADIUS Accounting-Request header contains invalid Authenticator field, Step=11004, Step=11017, Step=11038, Step=5413, NetworkDeviceGroups=Device Type#All Device Types#Switch, NetworkDeviceGroups=Location#All Locations#HQ, NetworkDeviceGroups=Unit#All Units#Networking, NetworkDeviceGroups=ACS Group#All ACS Groups, ACS Group=ACS Group#All ACS Groups,\\nDestination Port (Impacted) is the server port being authenticated against (Client-Server relationship).\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nNetwork Tab\\n', 'Origin NAT Port': 'The Network Address Translated (NAT) port from which activity originated (for example, client or attacker port).\\n', 'Data Type': 'Integer\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, TCP/UDP Port (Origin)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, TCP/UDP Port (Origin)\\nElasticsearch Field Name, originNatPort\\nRule Builder Column Name, SNATPort\\nRegex Pattern, <snatport>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nTCP/UDP Port (Origin)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nTCP/UDP Port (Origin)\\nElasticsearch Field Name\\noriginNatPort\\nRule Builder Column Name\\nSNATPort\\nRegex Pattern\\n<snatport>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin Port\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Any network connected application or device.\\n', 'Use Case': 'Host and application contexts.\\n', 'MPE/Data Masking Manipulations': 'Used to help in determining Application.\\n', 'Usage Standards': 'Use to indicate the Network Address Translated (NAT) origin port number associated with a client or attacker host where Origin is Client (In Client-Server Model).\\nOrigin is Attacker (In Attacker-Target Model).\\n', 'Examples': 'Cisco Netflow\\n02 19 2014 06:40:29 NetFlow V9 CONN_ID=- Src=1.1.1.1 SPort=62173 InIfc=4 Dst=1.1.1.1 DPort=8080 OutIfc=3 Prot=6 ICMP_IPV4_TYPE=- ICMP_IPV4_CODE=- XLATE_SRC_ADDR_IPV4=- XLATE_DST_ADDR_IPV4=- XLATE_SRC_PORT=- XLATE_DST_PORT=- FW_EVENT=- FW_EXT_EVENT=- EVENT_TIME_MSEC=- IN_PERMANENT_BYTES=- DETAILS=CONN_ID=1632431052 ICMP_IPV4_TYPE=0 ICMP_IPV4_CODE=0 XLATE_SRC_ADDR_IPV4=1.1.1.1 XLATE_DST_ADDR_IPV4=1.1.1.1\\nXLATE_SRC_PORT=61695\\nXLATE_DST_PORT=8080 FW_EVENT=2 FW_EXT_EVENT=2015 EVENT_TIME_MSEC=1392835229440 IN_PERMANENT_BYTES=8807 DefaultDevice TemplateID=263\\nXLATE_SRC_PORT shows the translation IP’s source (origin) port. In a network flow context, origin and source are synonymous.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nNetwork Tab\\n', 'Origin Port': 'The port from which activity originated (for example, client or attacker port).\\n', 'Data Type': 'Integer\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, TCP/UDP Port (Origin)\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, TCP/UDP Port (Origin)\\nElasticsearch Field Name, originPort\\nRule Builder Column Name, SPort\\nRegex Pattern, <sport>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nTCP/UDP Port (Origin)\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nTCP/UDP Port (Origin)\\nElasticsearch Field Name\\noriginPort\\nRule Builder Column Name\\nSPort\\nRegex Pattern\\n<sport>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'SIP\\nSIPv4\\nSIPv6\\nSIPv6E\\nOrigin Hostname\\nOrigin Hostname or IP\\nOrigin NAT IP\\nDIP\\nDIPv4\\nDIPv6\\nDIPv6E\\nImpacted Hostname\\nImpacted Hostname or IP\\nImpacted NAT IP\\nOrigin NAT Port\\nImpacted Port\\nImpacted NAT Port\\nOrigin MAC Address\\nImpacted MAC Address\\nOrigin Interface\\nImpacted Interface\\nOrigin Domain\\nImpacted Domain\\nOrigin Login\\nImpacted Account\\nIANA Protocol Number\\nIANA Protocol Name\\n', 'Common Applications': 'Any network connected application or device.\\n', 'Use Case': 'Host and application contexts.\\n', 'MPE/Data Masking Manipulations': 'Used to help in determining Application.\\n', 'Usage Standards': 'Use to indicate the origin port number associated with a client or attacker host.\\nOrigin is Client (In Client-Server Model).\\nOrigin is Attacker (In Attacker-Target Model).\\n', 'Examples': 'FireEye Web MPS\\n02 01 2016 17:13:19 1.1.1.1 <LOC4:WARN> fenotify-609081.warning: CEF:0|FireEye|MPS|1.1.1.1875|IM|infection-match|1|rt=Feb 01 2016 23:13:10 UTC src=1.1.1.1 cn3Label=cncPort cn3=80 cn2Label=sid cn2=84575103 shost= USABLDRRECFLOW01proto=tcp spt=51997 dst=1.1.1.1 cs5Label=cncHost cs5=1.1.1.1 dvchost= USABLDRRECFLOW01 dvc=1.1.1.1 smac=00:00:00:00:00:00 cn1Label=vlan cn1=0\\ndpt=80\\nexternalId=609081 cs4Label=link cs4=STUFF dmac=00:00:00:00:00:00 cs1Label=sname cs1=Exploit.Kit.AnglerDIPv4\\nDpt= is Origin in this case as it is the port used by the attacker ip (dst).\\nCisco\\nNext Generation\\nFirewall\\nCISCONGFW EVENT Ev_Id=610 Ev_Severity=6 Ev_TypeId=HTTP_COMPLETE Ev_SrcId=32 Ev_RecvTime=2/24/2013 10:04:34 PM Ev_MetaData=0 Smx_Config_Version=2 Identity_Source=0 Smx_Policy_Id=0 Flow_ConnId=456 Smx_Egress_Interface_Id=0 Smx_Ingress_Interface_Id=0 Avc_App_Id=300003 Ev_GenTime=2/24/2013 10:04:09 PM Flow_Protocol=6 Flow_SrcIp=1.1.1.1 Flow_DstIp=1.1.1.1\\nFlow_SrcPort=60221\\nFlow_DstPort=80 Ev_Producer_Id=5 Flow_Transaction_Id=0 Url=\\nrecordflow.biz\\nFlow_DstHostName=recordflow.bizSmx_Policy_Id=0 Flow_Bytes_Sent=391 Http_Response_Status=302 Flow_Bytes_Received=647\\nOrigin port (source in a network traffic flow context).\\nCisco ISE\\n02 10 2014 13:54:24 1.1.1.1 <LOC6:NOTE> Feb 10 13:54:43 USABLDRRECFLOW01 CISE_Failed_Attempts 0000217969 2 0 2014-02-10 13:54:43.264 +02:00 0008145644 5413 NOTICE Failed-Attempt: RADIUS Accounting-Request dropped, ConfigVersionId=143, Device IP Address=1.1.1.1,\\nDevice Port=1646\\n, DestinationIPAddress=1.1.1.1, DestinationPort=1646, Protocol=Radius, NetworkDeviceName=Switch_3560-X_2, NAS-IP-Address=1.1.1.1, NAS-Port=50023, Service-Type=Framed, Acct-Status-Type=Start, Acct-Delay-Time=20, Acct-Session-Id=00002222, Acct-Authentic=Local, NAS-Port-Type=Ethernet, NAS-Port-Id=GigabitEthernet0/23, cisco-av-pair=connect-progress=Call Up, AcsSessionID= USABLDRRECFLOW01/151856948/212124, FailureReason=11038 RADIUS Accounting-Request header contains invalid Authenticator field, Step=11004, Step=11017, Step=11038, Step=5413, NetworkDeviceGroups=Device Type#All Device Types#Switch, NetworkDeviceGroups=Location#All Locations#HQ, NetworkDeviceGroups=Unit#All Units#Networking, NetworkDeviceGroups=ACS Group#All ACS Groups, ACS Group=ACS Group#All ACS Groups,\\nDevice Port shows the originating RADIUS request Port for the corresponding device IP. Destination (Impacted) is the server being authenticated against (Client-Server relationship).\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nOther MPE Fields\\n', 'Items In': 'Items—not otherwise defined specifically—received from a device, system, or process.\\n', 'Data Type': 'Double\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Not applicable\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Not applicable\\nElasticsearch Field Name, itemsPacketsIn\\nRule Builder Column Name, ItemsIn\\nRegex Pattern, <itemsin>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nNot applicable\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nNot applicable\\nElasticsearch Field Name\\nitemsPacketsIn\\nRule Builder Column Name\\nItemsIn\\nRegex Pattern\\n<itemsin>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Packets In\\nPackets Out\\nBytes In/Bytes Out\\n', 'Common Applications': 'Devices that send and receive nonspecific item types.\\n', 'Use Case': 'Inventory control\\nPhone logs\\n', 'MPE/Data Masking Manipulations': 'Polyfield\\n<items> tag can be used for a single item value.\\nIn rule builder, parses in itemsin/itemsout.\\n', 'Usage Standards': 'Use when bytes, bits, or packets in field is not appropriate\\nUse for the number of objects transferred in.\\n', 'Examples': \"A10 Networks Load Balancer\\n09 08 2011 12:36:04 1.1.1.1 <LOC0:INFO> USABLDRRECFLOW01: [HA]<6> Sent 577,\\nReceived 559\\n, Duplicate Id's 0, Wrong Group 0, Missed 0, Inaccurate Time 0\\nTotal received Items.\\nSharePoint Audit\\n9/5/2008 5:03:44 PM event=100 account=safaware\\\\pete.store userid=922 machinename= machineip= doclocation=ncsportal locationtype=0 eventname= eventsource=1 sourcename= eventdata=<Export><RequestedBy>safaware\\\\pete.store</RequestedBy><Completed />\\n<TotalItems>5</TotalItems>\\n<TotalSizeInBytes>120703</TotalSizeInBytes></Export>\\nTotal Items could be parsed into <items>.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nOther MPE Fields\\n', 'Items Out': 'Items—not otherwise defined specifically—received from a device, system, or process.\\n', 'Data Type': 'Double\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Not applicable\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Not applicable\\nElasticsearch Field Name, itemsPacketsOut\\nRule Builder Column Name, ItemsOut\\nRegex Pattern, <itemsout>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nNot applicable\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nNot applicable\\nElasticsearch Field Name\\nitemsPacketsOut\\nRule Builder Column Name\\nItemsOut\\nRegex Pattern\\n<itemsout>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Items In\\nPackets In\\nPackets Out\\nBytes In/Bytes Out\\n', 'Common Applications': 'Devices that send and receive nonspecific item types.\\n', 'Use Case': 'Inventory control\\nPhone logs\\n', 'MPE/Data Masking Manipulations': 'Polyfield\\n<items> tag can be used for a single item value.\\nIn rule builder, parses into itemsin/itemsout.\\n', 'Usage Standards': 'Use when bytes, bits, or packets out field is not appropriate.\\nNumber of objects transferred out.\\n', 'Examples': \"A10 Networks Load Balancer\\n09 08 2011 12:36:04 1.1.1.1 <LOC0:INFO> USABLDRRECFLOW01: [HA]<6> Sent\\n577\\n, Received 559, Duplicate Id's 0, Wrong Group 0, Missed 0, Inaccurate Time 0\\nTotal received Items.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nLogRhythm Schema Dictionary and Guide\\n/\\nOther MPE Fields\\n', '[Tag1-Tag5]': 'Used only for subrules, and are invisible to the end user.\\n', 'Data Type': 'String\\n', 'Aliases': 'Use, Alias\\nClient Console Full Name, Not applicable\\nClient Console Short Name, Not applicable\\nWeb Console Tab/Name, Not applicable\\nElasticsearch Field Name, Not applicable\\nRule Builder Column Name, Tag1, Tag2, Tag3, Tag4, Tag5\\nRegex Pattern, <tag1>, <tag2>, <tag3>, <tag4>, <tag5>\\nNetMon Name, Not applicable\\nClient Console Full Name\\nNot applicable\\nClient Console Short Name\\nNot applicable\\nWeb Console Tab/Name\\nNot applicable\\nElasticsearch Field Name\\nNot applicable\\nRule Builder Column Name\\nTag1, Tag2, Tag3, Tag4, Tag5\\nRegex Pattern\\n<tag1>, <tag2>, <tag3>, <tag4>, <tag5>\\nNetMon Name\\nNot applicable\\n', 'Field Relationships': 'Any field you do not use to create subrules—for example, command.\\n', 'Common Applications': 'Not applicable.\\n', 'Use Case': 'Creating subrules not based on VMID, ThreatID, or Severity.\\n', 'MPE/Data Masking Manipulations': 'They are invisible outside of MPE Rule Builder.\\n', 'Usage Standards': 'If you want to create a subrule of a value not captured into VMID, ThreatID, or Severity, a tag must be nested within the existing metatag.\\n', 'Examples': 'These tags can be used in a wide variety of situations. Because these fields do not appear as parsed fields outside of the rule builder, refer to the usage standards to determine when to use these fields.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nOther LogRhythm Applications\\n', 'LogRhythm Diagnostics Tool': '', 'Diagnostics Tool v.2.4.0': 'The LogRhythm Diagnostics Tool is a standalone application that collects log and data files from LogRhythm components, runs Platform Manager database queries, and performs health, capacity, and oversubscription analysis on a LogRhythm deployment. The data is consolidated into a local .zip file for subsequent evaluation, capacity analysis and planning, and troubleshooting.\\nThe LogRhythm Diagnostics Tool is made up of two components—the Diagnostics Tool itself and the LogRhythm Diagnostics Agent. The Diagnostics Agent must be installed on each LogRhythm Windows node (Platform Manager, Data Processor, and AI Engine) in the deployment.\\n', 'Background': 'For LogRhythm Customer Support technicians, determining the cause of problems coming in from the field requires manually collecting log files, performance counters, SQL table data and job histories, Elasticsearch index data, configuration files, state repositories, and more. The LogRhythm technician must request files and other data from each component in the deployment, and often must help the customer gather that data. If the deployment is more than an XM, this means gathering data from more than one machine, a process that is time-consuming and could lead to human error.\\nThe LogRhythm Diagnostics Tool allows customers and LogRhythm technicians to perform deep analysis of a LogRhythm deployment’s operational characteristics by accessing, executing, and interpreting results with ease. The tool enables users to gather all pertinent logs, metrics, queries, counters, and other data from a LogRhythm deployment quickly, easily, consistently, and locally—there are no online components. All data collection is read-only, so there is negligible performance impact on the deployment itself.\\nUsers can also determine whether the deployment is healthy and in specification with respect to platform and licensing settings. If the deployment is not in a good state, the Diagnostics Tool provides all the logs and data in one local .zip file for further analysis by either the LogRhythm Administrator at the customer site or the LogRhythm support technician who receives the .zip file from the customer support ticket.\\n', 'Functionality': 'The LogRhythm Diagnostics Tool offers the following functionality. For a full list of log files and data points collected and consolidated by the Diagnostics Tool, see\\nLog Files and Data Collected by the Diagnostic Tool\\n.\\nProvides the current performance and capacity of the LogRhythm SIEM data pipeline, as measured against the Sustained Rate and Peak Rate definitions published by LogRhythm Solutions.\\nEmpirically demonstrates where the deployment is operating against the prescribed rates. Illustrates how much capacity remains before the deployment would be considered oversubscribed, or if the deployment is already oversubscribed.\\nAutomates the analysis of a deployment’s current data processing pipeline, per the Solutions Sizing Guide. This analysis makes it easy for field personnel and even customers to understand the deployment’s current capacity and performance.\\nInstalls and runs as a standalone application on any Windows host that can access LogRhythm Diagnostics Agents, consolidates files and data on a Windows host into a .zip file, and presents the files and data for immediate review.\\nCollects files and data in a passive, read-only manner. Collected data includes information about LogRhythm components, the operating systems that host those components, and the hardware that runs on those hosts.\\nDoes not make changes to the LogRhythm SIEM deployment during operation.\\nRuns on many versions of LogRhythm SIEM (currently 7.3.x and later).\\n', 'Release Notes': '', 'Features Overview': 'The LogRhythm Diagnostics Tool is a standalone application that collects log files and data from a LogRhythm deployment and consolidates the collected information into a local .zip file. The tool also provides automated performance and oversubscription analysis and presents the information for immediate review and problem determination.\\nVersion 2.4.0 introduces the following improvements from version 2.3.0:\\nCreated a better initial tool login experience when logging in and waiting for initial data load.\\nAdded missing LogRhythm Mediator: Messaging performance counters.\\nRevised the DP Spool File Information component to add:\\nCount and size of Unprocessed Archives Quarantined folder\\nCount and size of Processed Logs folder\\nCount and size of Active Archive\\nCount and size of Unprocessed Archives Quarantined folder\\nCount and size of Processed Logs folder\\nCount and size of Active Archive\\nAdded DX service and install logs.\\nLinux:\\n/var/log/persistent\\n/var/log/elasticsearch\\n/var/log/nginx\\nsudo journalctl -u LogRhythmServiceRegistry -n1000 > serviceregistry.log\\nWindows:\\n%DXPATH%\\\\logs\\xa0(usually\\xa0C:\\\\Program Files\\\\LogRhythm\\\\Data Indexer\\\\logs)\\n%DXPATH%\\\\elasticsearch\\\\logs\\n%DXPATH%\\\\elasticsearch\\\\bin\\\\LimitWorkingSet.log\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Common\\\\logs\\nLinux:\\n/var/log/persistent\\n/var/log/elasticsearch\\n/var/log/nginx\\nsudo journalctl -u LogRhythmServiceRegistry -n1000 > serviceregistry.log\\n/var/log/persistent\\n/var/log/elasticsearch\\n/var/log/nginx\\nsudo journalctl -u LogRhythmServiceRegistry -n1000 > serviceregistry.log\\nWindows:\\n%DXPATH%\\\\logs\\xa0(usually\\xa0C:\\\\Program Files\\\\LogRhythm\\\\Data Indexer\\\\logs)\\n%DXPATH%\\\\elasticsearch\\\\logs\\n%DXPATH%\\\\elasticsearch\\\\bin\\\\LimitWorkingSet.log\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Common\\\\logs\\n%DXPATH%\\\\logs\\xa0(usually\\xa0C:\\\\Program Files\\\\LogRhythm\\\\Data Indexer\\\\logs)\\n%DXPATH%\\\\elasticsearch\\\\logs\\n%DXPATH%\\\\elasticsearch\\\\bin\\\\LimitWorkingSet.log\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Common\\\\logs\\nAdded DX configuration files.\\nLinux:\\n/usr/local/logrhythm/configserver/conf\\n/etc/systemd/system/LogRhythmServiceRegistry.service.d/LogRhythmServiceRegistry.conf\\nWindows:\\n%DXPATH%\\\\configserver\\\\conf\\xa0(usually\\xa0C:\\\\Program Files\\\\LogRhythm\\\\Data Indexer\\\\configserver\\\\conf)\\n%DXPATH%\\\\elasticsearch\\\\config\\nLinux:\\n/usr/local/logrhythm/configserver/conf\\n/etc/systemd/system/LogRhythmServiceRegistry.service.d/LogRhythmServiceRegistry.conf\\n/usr/local/logrhythm/configserver/conf\\n/etc/systemd/system/LogRhythmServiceRegistry.service.d/LogRhythmServiceRegistry.conf\\nWindows:\\n%DXPATH%\\\\configserver\\\\conf\\xa0(usually\\xa0C:\\\\Program Files\\\\LogRhythm\\\\Data Indexer\\\\configserver\\\\conf)\\n%DXPATH%\\\\elasticsearch\\\\config\\n%DXPATH%\\\\configserver\\\\conf\\xa0(usually\\xa0C:\\\\Program Files\\\\LogRhythm\\\\Data Indexer\\\\configserver\\\\conf)\\n%DXPATH%\\\\elasticsearch\\\\config\\nC:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Common\\\\logs\\n', 'Bug Fixes': 'The following bugs have been fixed in the version 2.4.0 release:\\nBug, Description\\nTOOLS-111, Linux DX iowait - Get/show CPU and Disk I/O wait for DX\\nTOOLS-369, HealthCheck report showing duplicate data for XM\\nTOOLS-450, Filtering is case-sensitive on export settings grid\\nTOOLS-451, Filters are not getting cleared when switched between export profiles\\nTOOLS-452, LRD app Credentials tab still says auth successful even after agent creds are changed\\nTOOLS-453, LRD Agent config UI allows blank password\\nTOOLS-462, Add MPE Log Level to LRD Client interface\\nTOOLS-463, Agent picking up duplicate log samples\\nTOOLS-529, Error visibly for bad password characters. For example, Credentials page for DX nodes – the plink/SSH password cannot contain quotes (single/double) or spaces.\\nBug\\nDescription\\nTOOLS-111\\nLinux DX iowait - Get/show CPU and Disk I/O wait for DX\\nTOOLS-369\\nHealthCheck report showing duplicate data for XM\\nTOOLS-450\\nFiltering is case-sensitive on export settings grid\\nTOOLS-451\\nFilters are not getting cleared when switched between export profiles\\nTOOLS-452\\nLRD app Credentials tab still says auth successful even after agent creds are changed\\nTOOLS-453\\nLRD Agent config UI allows blank password\\nTOOLS-462\\nAdd MPE Log Level to LRD Client interface\\nTOOLS-463\\nAgent picking up duplicate log samples\\nTOOLS-529\\nError visibly for bad password characters. For example, Credentials page for DX nodes – the plink/SSH password cannot contain quotes (single/double) or spaces.\\n', 'Known Issues': 'The following issues are known in the version 2.4.0 release and are currently targeted for remediation in a subsequent release:\\nPriority, Description\\nMedium, The LogRhythm Diagnostics Tool does not automatically close when uninstalling.\\nMedium, The LogRhythm Diagnostics Agent cannot use certificates from the CurrentUser location in the Windows Certificate Store.\\nPriority\\nDescription\\nMedium\\nThe LogRhythm Diagnostics Tool does not automatically close when uninstalling.\\nMedium\\nThe LogRhythm Diagnostics Agent cannot use certificates from the CurrentUser location in the Windows Certificate Store.\\n', 'Limitations': 'Some known limitations of the LogRhythm Diagnostics Tool include:\\nThe Diagnostics Tool should only be launched from the Windows Start Menu. Attempting to launch from the command line or Windows Explorer may result in an error.\\nThe Diagnostics Tool cannot determine model or processing rate information for AI Engines not running on the PM.\\nUsers cannot set the rates for Unknown or Custom component models: processing (DP and AIE), indexing, archiving, events, and LogMart.\\nThe licensed rate for DPs cannot be determined when a Deployment (MPS) license is in use.\\nWhen attempting to upgrade the Diagnostics Tool from a previous version, you might receive the following error:\\nError 0x80070643: Failed to install MSI package\\nIf you receive this error, uninstall your current version of the Diagnostics Tool from the Windows Control Panel (Control Panel > Programs and Features), and then install a new version as outlined in\\nInstall the Diagnostics Agent and Diagnostics Tool\\n.\\nWhen attempting to upgrade the Diagnostics Tool from a previous version, you might receive the following error:\\nError 0x80070643: Failed to install MSI package\\nIf you receive this error, uninstall your current version of the Diagnostics Tool from the Windows Control Panel (Control Panel > Programs and Features), and then install a new version as outlined in\\nInstall the Diagnostics Agent and Diagnostics Tool\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nOther LogRhythm Applications\\n', 'LogRhythm Echo': '', 'Echo v.2.0.3': 'LogRhythm users need a straightforward way to:\\nTest the AI Engine (AIE) and Alarm rules that their analysts develop so they know that Alarms will generate as expected and that users can reliably and repeatedly replicate the inputs to the rule.\\nVerify out-of-the-box (OOTB) AIE, Alarm, and Message Processing Engine (MPE) content, MPE rule regression and performance testing, and system load and stress testing.\\nDemonstrate LogRhythm’s capabilities to prospects, customers, partners, and system integrators.\\nSeamlessly author new use cases as needed to demonstrate or verify system behaviors—such as ransomware, financial fraud, and data exfiltration—that are specific to the target environment.\\nLogRhythm Echo provides these capabilities. Echo is a standalone Windows application with web and command line interfaces that simulates a LogRhythm System Monitor Agent and allows users to replay native raw logs and PCAPs into LogRhythm for demonstration, validation, and verification purposes. Easy to install, configure, and use, Echo leverages OOTB log source types and processing rules to enable users to quickly build, demo, validate, verify, and tear down security use cases. Echo comes with more than 30 use cases ready for replay, and users can create, modify, and share use cases using the web interface or a text editor.\\n', 'Features': 'Echo’s features allow users to:\\nLoad more than 30 verified, consistent, proven use cases that are easy to understand and explain.\\nUse OOTB content for log source types, processing rules, AIE rules, and Alarm rules. Automatically create and delete required objects in the Platform Manager database.\\nQuickly build, validate, demo, and tear down security use cases to test their LogRhythm deployment.\\nEdit the included use cases and create new ones.\\nEmploy exotic log source types to create compelling and targeted security use cases.\\nUse the LLX File Browser to add raw logs from the deployment to use cases.\\nImport and export use cases, including raw logs and PCAPs, to share with other users.\\nOn-demand and continuous/predetermined use case replay.\\nUse case log replay through a simulated Agent in native formats, such as APIs, Syslog, NetFlow, Check Point, flat files, and more. There are no custom log source types, raw logs, or special tags required.\\nRun use cases by invoking the REST API from the command line (for instance, using cURL) or your favorite scripting language (such as PowerShell).\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nOther LogRhythm Applications\\n', 'Threat Intelligence Service': '', 'TIS 1.9.6': 'The LogRhythm Threat Intelligence Service (TIS) and the LogRhythm Threat Intelligence Module work together to collect and analyze data published by reputable threat data providers to alert users to threats in their environments.\\nTIS 1.9.6 is a general availability (GA) release.\\n', 'Release Notes': 'No features were added in this release.\\nNo improvements were added in this release.\\nNo improvements were added in this release.\\nNo features were deprecated in this release.\\nBug ID, Ticket Number, Found in Version, Release Notes\\nENG-11196, 448835, 1.9.5, Symantec feed was removed from the TIS UI but can still be configured using the Custom feed option.\\nENG-27104, 455851, 1.9.5, For STIX/TAXII feeds, NumofBackDaysData can now be configured within the UI.\\nENG-39749, N/A, 1.9.5, The object reference error no longer occurs when upgrading Threat Intelligence Service.\\nENG-40039, 471544, 1.9.5, TIS Open Source SANS-ISC feed was updated to accommodate a change by the vendor and fix download failures.\\nENG-34698, 465845, 1.9.5, The StrikeReady Custom TIS configuration now imports lists properly.\\nENG-42802, 469285, 1.9.5, The oAuth token for Crowdstrike was renewed to extend an upcoming expiration date.\\n471544\\nTIS Open Source SANS-ISC feed was updated to accommodate a change by the vendor and fix download failures.\\nSecurity-related issues resolved with this release are available for customers to view on the\\nCommunity\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nOther LogRhythm Applications\\n', 'TrueIdentity Sync Client User Guide': '', 'TrueIdentity Sync Client v.1.4.0': \"This guide provides information about the TrueIdentity Sync Client and how to use the tool to import identity information into your deployment.\\nIf you have installed a previous version of the TrueIdentity Sync Client, you must uninstall the previous version before installing version 1.4.0.\\nThe TrueIdentity Sync Client queries Identity and Access Management (IAM) platforms, such as Active Directory, to create and update TrueIdentities in your LogRhythm deployment. The TrueIdentity Sync Client can be scheduled to run on a continuous basis, automatically creating and updating new TrueIdentities as they appear in your IAM.\\nIf using a remote TrueIdentity Sync Client, your network, Active Directory LDAP server, and the host running the TrueIdentity Sync Client must support TLS 1.2.\\nActive Directory is the only IAM supported in this release. If you are using a different IAM, you can get identity data using LogRhythm's REST-based Admin API.\\nSyncing multiple Active Directory domains with overlapping users could cause conflicts. Conflicts occur when multiple TrueIdentities have the same Identifiers, and LogRhythm is unable to assign a TrueIdentity. The following is recommended:\\nIf you have 100% overlap between AD Domains, consider only syncing one domain.\\nIf you have partial overlap between AD Domains, leverage the Sync Client Filter to remove the overlapping accounts.\\nDisable Identifiers from TrueIdentity Administration in the Web Console.\\nRemove the overlapping Identifiers field from one of the Sync Jobs.\\nSync TrueIdentities into specific entities.\\nMerge overlapping TrueIdentities or disable conflicting Identifiers via the LogRhythm Admin API. For more information on the LogRhythm Admin API,\\nsee the\\nAdmin API\\ndocumentation\\n.\\n\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nOther LogRhythm Applications\\n/\\nLogRhythm Diagnostics Tool\\n', 'Install the Diagnostics Agent and Diagnostics Tool': '', 'System Requirements for Diagnostics Tool v.2.4.0': 'LogRhythm SIEM 7.3 or later.\\nRead-only access to the LogRhythm EMDB and LogMart SQL Server databases. SQL client connections use TCP port 1433. For instructions on setting up a least-privilege, read-only SQL Server user for this purpose, see\\nCreate a Least-Privilege SQL Server User for Querying LogRhythm Databases\\n.\\nThe LogRhythm Diagnostics Agent must be installed on each LogRhythm Windows component node (Platform Manager, Data Processors, AI Engines, and standalone Web Consoles). The Diagnostics Agent is required even for single-node LogRhythm XM deployments.\\nFor Data Indexer (DX) connections, the Diagnostics Tool application (client) uses SSH/SFTP to query system information and collect log data and does not require a Diagnostics Agent.\\nFor Data Indexer (DX) connections, the Diagnostics Tool application (client) uses SSH/SFTP to query system information and collect log data and does not require a Diagnostics Agent.\\nThe LogRhythm Diagnostics Tool application (client) must be installed on a Windows host that has TCP 1433 connectivity to the Platform Manager, TCP 22 connectivity to each Data Indexer, and TCP 33334 connectivity to each Diagnostics Agent on each Windows component.\\nIf there is firewall software on the LogRhythm components hosting the Diagnostics Agent, a rule must be enabled for the Diagnostics Agent’s incoming port (default is 33334).\\nEnsure that your firewall allows you to download the installer and reference materials from the\\nLogRhythm Community\\n, and that your antivirus software allows the installation of the Diagnostics Agent and Diagnostics Tool.\\n', 'Installation Steps': '', 'Install and Configure the LogRhythm Diagnostics Agent': 'As part of the Diagnostics Agent installation, a Windows Service called “LogRhythm Diagnostics Agent” is installed on your system. The software installs to C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Diagnostics Agent, and configuration is accessible via the LogRhythm Diagnostics Agent Windows shortcut.\\nRun the LogRhythm Diagnostics Agent installer, available on the\\nLogRhythm Community\\n.\\nWhen the installer is finished, the configuration window appears.\\nConfigure the following settings in the LogRhythm Diagnostics Agent user interface:\\nAgent Configuration\\nIP Address.\\nThe public routable IP address of the LogRhythm Windows host.\\nThis is the IP address of the host running the Agent, not the host running the LogRhythm Diagnostics Tool.\\nPort.\\nConfigurable port—the default is 33334.\\nLog Level.\\nLogging is set to Informational by default, but for troubleshooting purposes, logging level can be set to Debug level.\\nAuthentication Configuration\\nUser Name.\\nUser-supplied username for HTTP basic authentication. This value does not need to be an existing LogRhythm or Windows user account.\\nPassword.\\nUser-supplied password for HTTP basic authentication.\\nThe basic HTTP authentication credentials and port for each Diagnostics Agent are used to configure and authenticate LogRhythm nodes on the Settings page in the LogRhythm Diagnostics Tool.\\nA Diagnostics Agent is Windows-only and is not installed on LogRhythm Linux DX nodes—for these nodes, valid SSH credentials are used for authentication.\\nThe password is salted (512 bytes) and hashed (HMAC-SHA512). The username, salt, and hash are stored in the AgentConfig.json file in the ProgramData directory of the Agent system. The ProgramData directory is read-only except for administrators. Users can configure mutual, certificate-based authentication for the Agent service and the Client application. For more information, see the next section.\\n(Optional)\\nHTTPS SSL Certificate Configuration\\nHTTPS is used for communication between the Diagnostics Tool and individual Diagnostics Agents. By default, the Diagnostics Agent uses a dynamically generated self-signed server certificate. For additional security, users can utilize their own self-signed certificates, a valid third-party signed certificate, or a valid certificate from their PKI infrastructure.\\nUse Generated Certificate.\\nSelect this option to use a dynamically generated self-signed certificate (default).\\nUse Certificate From Store.\\nSelect this option to use your own certificate. This option assumes that a usable certificate is already in the server’s certificate store.\\nWhen using a certificate from the local certificate store, the certificate’s private key must be exportable. If the certificate is a valid signed-certificate, the certificate must have a root signing certificate in the machine’s Trusted Root Certificate store.\\nStore.\\nSelect\\nMy\\nor\\nRoot\\n.\\nLocation.\\nSelect\\nLocal Machine\\nor\\nCurrent User\\n.\\nSubject.\\nEnter in the format\\nCN=<subject name\\n>, where subject name is a FQDN, hostname, or IP address. Ensure that there are no spaces surrounding or between the “CN,” the “=,” and the subject.\\nIP Address.\\nThe public routable IP address of the LogRhythm Windows host.\\nThis is the IP address of the host running the Agent, not the host running the LogRhythm Diagnostics Tool.\\nIP Address.\\nThe public routable IP address of the LogRhythm Windows host.\\nPort.\\nConfigurable port—the default is 33334.\\nPort.\\nConfigurable port—the default is 33334.\\nLog Level.\\nLogging is set to Informational by default, but for troubleshooting purposes, logging level can be set to Debug level.\\nLog Level.\\nLogging is set to Informational by default, but for troubleshooting purposes, logging level can be set to Debug level.\\nUser Name.\\nUser-supplied username for HTTP basic authentication. This value does not need to be an existing LogRhythm or Windows user account.\\nUser Name.\\nUser-supplied username for HTTP basic authentication. This value does not need to be an existing LogRhythm or Windows user account.\\nPassword.\\nUser-supplied password for HTTP basic authentication.\\nThe basic HTTP authentication credentials and port for each Diagnostics Agent are used to configure and authenticate LogRhythm nodes on the Settings page in the LogRhythm Diagnostics Tool.\\nA Diagnostics Agent is Windows-only and is not installed on LogRhythm Linux DX nodes—for these nodes, valid SSH credentials are used for authentication.\\nThe password is salted (512 bytes) and hashed (HMAC-SHA512). The username, salt, and hash are stored in the AgentConfig.json file in the ProgramData directory of the Agent system. The ProgramData directory is read-only except for administrators. Users can configure mutual, certificate-based authentication for the Agent service and the Client application. For more information, see the next section.\\nPassword.\\nUser-supplied password for HTTP basic authentication.\\nThe basic HTTP authentication credentials and port for each Diagnostics Agent are used to configure and authenticate LogRhythm nodes on the Settings page in the LogRhythm Diagnostics Tool.\\nA Diagnostics Agent is Windows-only and is not installed on LogRhythm Linux DX nodes—for these nodes, valid SSH credentials are used for authentication.\\nThe password is salted (512 bytes) and hashed (HMAC-SHA512). The username, salt, and hash are stored in the AgentConfig.json file in the ProgramData directory of the Agent system. The ProgramData directory is read-only except for administrators. Users can configure mutual, certificate-based authentication for the Agent service and the Client application. For more information, see the next section.\\nHTTPS is used for communication between the Diagnostics Tool and individual Diagnostics Agents. By default, the Diagnostics Agent uses a dynamically generated self-signed server certificate. For additional security, users can utilize their own self-signed certificates, a valid third-party signed certificate, or a valid certificate from their PKI infrastructure.\\nUse Generated Certificate.\\nSelect this option to use a dynamically generated self-signed certificate (default).\\nUse Generated Certificate.\\nSelect this option to use a dynamically generated self-signed certificate (default).\\nUse Certificate From Store.\\nSelect this option to use your own certificate. This option assumes that a usable certificate is already in the server’s certificate store.\\nWhen using a certificate from the local certificate store, the certificate’s private key must be exportable. If the certificate is a valid signed-certificate, the certificate must have a root signing certificate in the machine’s Trusted Root Certificate store.\\nUse Certificate From Store.\\nSelect this option to use your own certificate. This option assumes that a usable certificate is already in the server’s certificate store.\\nWhen using a certificate from the local certificate store, the certificate’s private key must be exportable. If the certificate is a valid signed-certificate, the certificate must have a root signing certificate in the machine’s Trusted Root Certificate store.\\nStore.\\nSelect\\nMy\\nor\\nRoot\\n.\\nStore.\\nSelect\\nMy\\nor\\nRoot\\n.\\nLocation.\\nSelect\\nLocal Machine\\nor\\nCurrent User\\n.\\nLocation.\\nSelect\\nLocal Machine\\nor\\nCurrent User\\n.\\nSubject.\\nEnter in the format\\nCN=<subject name\\n>, where subject name is a FQDN, hostname, or IP address. Ensure that there are no spaces surrounding or between the “CN,” the “=,” and the subject.\\nSubject.\\nEnter in the format\\nCN=<subject name\\n>, where subject name is a FQDN, hostname, or IP address. Ensure that there are no spaces surrounding or between the “CN,” the “=,” and the subject.\\nClick\\nSave\\n, and then click\\nClose\\nto exit the configuration.\\n', 'Install the LogRhythm Diagnostics Tool': 'Typically, the LogRhythm Diagnostics Tool installs on the Platform Manager or XM. However, the Diagnostics Tool does not need to be installed on the LogRhythm deployment itself. The Diagnostics Tool requires TCP 1433 connectivity to the PM, TCP 22 connectivity to Linux DX nodes, and connectivity (default TCP 33334) to the LogRhythm Diagnostics Agents. The application installs to C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Diagnostics.\\nRun the LogRhythm Diagnostics Tool installer, available on the\\nLogRhythm Community\\n.\\nLaunch the application—click\\nStart\\n, click\\nLogRhythm\\n, and then click\\nLogRhythm Diagnostics\\n.\\nThe LogRhythm Diagnostics login page appears.\\nEnter the Platform Manager IP address, a suitable LogRhythm EMDB database account name, and the account password. For high availability (HA) deployments, use the virtual IP address (VIP) or shared address for the Platform Manager. To create a SQL Server user for the Diagnostics Tool to use, see\\nCreate a Least-Privilege SQL Server User for Querying LogRhythm Databases\\n.\\nThe LogRhythmAdmin user is not supported in the LogRhythm Diagnostics client.\\nEnter the Platform Manager IP address, a suitable LogRhythm EMDB database account name, and the account password. For high availability (HA) deployments, use the virtual IP address (VIP) or shared address for the Platform Manager. To create a SQL Server user for the Diagnostics Tool to use, see\\nCreate a Least-Privilege SQL Server User for Querying LogRhythm Databases\\n.\\nTo begin collecting data from the deployment, click\\nSubmit\\n.\\n', 'Create a Least-Privilege SQL Server User for Querying LogRhythm Databases': 'This section explains how to create a least-privilege SQL Server user (read-only) for the LogRhythm Diagnostics Tool to use when querying the LogRhythm SQL Server databases. For convenience, helper scripts to create and delete the user are provided with the installer in the databasescripts directory.\\nOn the LogRhythm Platform Manager, open the File Explorer and navigate to C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Diagnostics\\\\LogRhythm Diagnostics\\\\databasescripts.\\nDouble-click either the\\ncreate_lpu.ps1\\nscript (PowerShell) or the\\ncreate_lpu.bat\\n(Windows Batch) script.\\nEnter the password for a SQL Server administrative user (for example, “sa”).\\nEnter the password for the new lrdiagnostics user.\\nThe script creates a user account called “lrdiagnostics” with the password you specified.\\nUse these credentials to connect to the Platform Manager database on the Diagnostics Tool’s login screen.\\nOn the LogRhythm Platform Manager, open the File Explorer and navigate to C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Diagnostics\\\\LogRhythm Diagnostics\\\\databasescripts.\\nDouble-click either the\\ndelete_lpu.ps1\\nscript (PowerShell) or the\\ndelete_lpu.bat\\n(Windows Batch) script.\\nEnter the password for a SQL Server administrative user (for example, “sa”).\\nThe script removes the “lrdiagnostics” user account from SQL Server.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nOther LogRhythm Applications\\n/\\nLogRhythm Diagnostics Tool\\n', 'Log Files and Data Collected by the Diagnostic Tool': 'The following log files and data points are collected and consolidated by the LogRhythm Diagnostics Tool into a compressed .zip file in the specified output directory. All Items are collected immediately upon logging in to the Diagnostics Tool, except for the items in\\nitalics\\n, which are only collected on demand.\\n', 'Overview': 'Deployment Message Per Second – Last 30 Days\\nDeployment Message Per Second – Last 30 Days\\nSystem Monitor by OS\\nSystem Monitor by OS\\nLog Source by Type\\nLog Source by Type\\nDeployment Topology (mapping of LogRhythm components)\\nDeployment Topology (mapping of LogRhythm components)\\nDX Cluster Topology (mapping of DX clusters and nodes)\\nDX Cluster Topology (mapping of DX clusters and nodes)\\nStandalone Web Console nodes\\nStandalone Web Console nodes\\nNetwork Monitors\\nNetMons do not appear unless they are registered in the LogRhythm Client Console.\\nNetwork Monitors\\nNetMons do not appear unless they are registered in the LogRhythm Client Console.\\n', 'Platform Manager (PM)': 'Percentage Disk Used\\nPercentage Disk Used\\nDisk Status\\nFilesystem\\nMount\\nSize (MB)\\nFree (MB)\\n% Used\\nDisk Status\\nFilesystem\\nFilesystem\\nMount\\nMount\\nSize (MB)\\nSize (MB)\\nFree (MB)\\nFree (MB)\\n% Used\\n% Used\\nEnabled Global Log Processing Rules (GLPRs)\\nName\\nSort Order\\nDate Updated\\nDate Expires\\nEnabled Global Log Processing Rules (GLPRs)\\nName\\nName\\nSort Order\\nSort Order\\nDate Updated\\nDate Updated\\nDate Expires\\nDate Expires\\nEnabled Alarm Rules\\nName\\nRule Group\\nType\\nDate Updated\\nEnabled Alarm Rules\\nName\\nName\\nRule Group\\nRule Group\\nType\\nType\\nDate Updated\\nDate Updated\\nKnowledge Base (KB)\\nVersion\\nDate Updated\\nKB Download Statistics\\nKnowledge Base (KB)\\nVersion\\nVersion\\nDate Updated\\nDate Updated\\nKB Download Statistics\\nKB Download Statistics\\nEnabled KB Modules\\nModule\\nVersion\\nDate Updated\\nEnabled KB Modules\\nModule\\nModule\\nVersion\\nVersion\\nDate Updated\\nDate Updated\\nLogRhythm Diagnostic Alarms – Last 24 Hours\\nAlarm ID\\nEntity\\nDate\\nStatus\\nName\\nAssigned To\\nLogRhythm Diagnostic Alarms – Last 24 Hours\\nAlarm ID\\nAlarm ID\\nEntity\\nEntity\\nDate\\nDate\\nStatus\\nStatus\\nName\\nName\\nAssigned To\\nAssigned To\\nProcessing (DP and AIE), Indexing, Archiving, LogMart, and Event Performance/Capacity/Oversubscription Analysis\\nProcessing (DP and AIE), Indexing, Archiving, LogMart, and Event Performance/Capacity/Oversubscription Analysis\\nLog Volume by:\\nData Processor\\nSystem Monitor\\nLog Source Type\\nLog Source\\nLog Volume by:\\nData Processor\\nData Processor\\nSystem Monitor\\nSystem Monitor\\nLog Source Type\\nLog Source Type\\nLog Source\\nLog Source\\nSystem Monitors Pending Acceptance\\nSystem Monitors Pending Acceptance\\nLog Sources Pending Acceptance\\nLog Sources Pending Acceptance\\nQuiet Log Sources\\nQuiet Log Sources\\nQuiet Agents\\nQuiet Agents\\nSQL Server Databases and Utilization\\nSQL Server Version\\nLogRhythm DB Versions and Last Updates\\nDatabase File Locations, Free Space, and Utilizations\\nLogRhythm Maintenance Job History\\nSQL Server Databases and Utilization\\nSQL Server Version\\nSQL Server Version\\nLogRhythm DB Versions and Last Updates\\nLogRhythm DB Versions and Last Updates\\nDatabase File Locations, Free Space, and Utilizations\\nDatabase File Locations, Free Space, and Utilizations\\nLogRhythm Maintenance Job History\\nLogRhythm Maintenance Job History\\nPending Agents and Log Sources\\nPending Agents and Log Sources\\nLPS Detail Report\\nLPS Detail Report\\nPerformance Counters\\nARM\\nLogical Disks\\nPerformance Counters\\nARM\\nARM\\nLogical Disks\\nLogical Disks\\nLogRhythm Services\\nService status (running, stopped)\\nLogRhythm Services\\nService status (running, stopped)\\nService status (running, stopped)\\nLogical Disk Utilization\\nDisk Sizes\\nUsed Space\\nLogical Disk Utilization\\nDisk Sizes\\nDisk Sizes\\nUsed Space\\nUsed Space\\nLogRhythm Application Logs\\nCommon Components\\nLogRhythm API Gateway\\nLogRhythm API Gateway_ErrWarn\\nLogRhythm Metrics Collection\\nLogRhythm Metrics Collection_ErrWarn\\nLogRhythm Service Registry\\nLoGRhythm Service Registry_ErrWarn\\nAlarming and Response Manager (ARM)\\nscarm\\nJob Manager\\nlrjobmgr\\nlrjobmgr_ErrWarn\\nAuthentication\\nLogRhythm Authentication API\\nLogRhythm Authentication API_ErrWarn\\nLogRhythm Windows Authentication Service\\nLogRhythm Windows Authentication Service_ErrWarn\\nSystem Monitor Agent (scsm)\\nLogRhythm Application Logs\\nCommon Components\\nLogRhythm API Gateway\\nLogRhythm API Gateway_ErrWarn\\nLogRhythm Metrics Collection\\nLogRhythm Metrics Collection_ErrWarn\\nLogRhythm Service Registry\\nLoGRhythm Service Registry_ErrWarn\\nCommon Components\\nLogRhythm API Gateway\\nLogRhythm API Gateway\\nLogRhythm API Gateway_ErrWarn\\nLogRhythm API Gateway_ErrWarn\\nLogRhythm Metrics Collection\\nLogRhythm Metrics Collection\\nLogRhythm Metrics Collection_ErrWarn\\nLogRhythm Metrics Collection_ErrWarn\\nLogRhythm Service Registry\\nLogRhythm Service Registry\\nLoGRhythm Service Registry_ErrWarn\\nLoGRhythm Service Registry_ErrWarn\\nAlarming and Response Manager (ARM)\\nscarm\\nAlarming and Response Manager (ARM)\\nscarm\\nscarm\\nJob Manager\\nlrjobmgr\\nlrjobmgr_ErrWarn\\nJob Manager\\nlrjobmgr\\nlrjobmgr\\nlrjobmgr_ErrWarn\\nlrjobmgr_ErrWarn\\nAuthentication\\nLogRhythm Authentication API\\nLogRhythm Authentication API_ErrWarn\\nLogRhythm Windows Authentication Service\\nLogRhythm Windows Authentication Service_ErrWarn\\nAuthentication\\nLogRhythm Authentication API\\nLogRhythm Authentication API\\nLogRhythm Authentication API_ErrWarn\\nLogRhythm Authentication API_ErrWarn\\nLogRhythm Windows Authentication Service\\nLogRhythm Windows Authentication Service\\nLogRhythm Windows Authentication Service_ErrWarn\\nLogRhythm Windows Authentication Service_ErrWarn\\nSystem Monitor Agent (scsm)\\nSystem Monitor Agent (scsm)\\n', 'Advanced Intelligence Engine (AIE)': 'Logical Disk Utilization\\nDisk Sizes\\nUsed Space\\nLogical Disk Utilization\\nDisk Sizes\\nDisk Sizes\\nUsed Space\\nUsed Space\\nEnabled AIE Rules\\nName\\nStatus\\nAlarm Enabled\\nDate Updated\\nEnabled AIE Rules\\nName\\nName\\nStatus\\nStatus\\nAlarm Enabled\\nAlarm Enabled\\nDate Updated\\nDate Updated\\nAIE Rule Performance\\nName\\nRuntime Cost\\nUnshared Memory Cost\\nUnshared Memory (MB)\\nRecent Events Forwarded Minutes\\nRecent Event Feedback Minutes\\nAIE Rule Performance\\nName\\nName\\nRuntime Cost\\nRuntime Cost\\nUnshared Memory Cost\\nUnshared Memory Cost\\nUnshared Memory (MB)\\nUnshared Memory (MB)\\nRecent Events Forwarded Minutes\\nRecent Events Forwarded Minutes\\nRecent Event Feedback Minutes\\nRecent Event Feedback Minutes\\nSpool File Information\\nData Files\\nSize Data Files (MB)\\nData Error Files\\nSize Data Error Files (MB)\\nData Read Files\\nSize Data Read Files (MB)\\nSpool File Information\\nData Files\\nData Files\\nSize Data Files (MB)\\nSize Data Files (MB)\\nData Error Files\\nData Error Files\\nSize Data Error Files (MB)\\nSize Data Error Files (MB)\\nData Read Files\\nData Read Files\\nSize Data Read Files (MB)\\nSize Data Read Files (MB)\\nService Status\\nService\\nDisplay Name\\nStatus\\nService Status\\nService\\nService\\nDisplay Name\\nDisplay Name\\nStatus\\nStatus\\nPerformance Counters\\nAIE Communication Manager\\nAI Engine Server\\nLogical Disks\\nPerformance Counters\\nAIE Communication Manager\\nAIE Communication Manager\\nAI Engine Server\\nAI Engine Server\\nLogical Disks\\nLogical Disks\\n', 'Data Processor (DP)': 'Processed and Unprocessed Queue files (numbers and sizes)\\nSpooled Unprocessed Archives\\nSpooled Events\\nSpooled Unprocessed Logs\\nSpooled AIE Data Provider Logs\\nDX Reliable Persist\\nProcessed and Unprocessed Queue files (numbers and sizes)\\nSpooled Unprocessed Archives\\nSpooled Unprocessed Archives\\nSpooled Events\\nSpooled Events\\nSpooled Unprocessed Logs\\nSpooled Unprocessed Logs\\nSpooled AIE Data Provider Logs\\nSpooled AIE Data Provider Logs\\nDX Reliable Persist\\nDX Reliable Persist\\nPerformance Counters\\nLDS\\nLogMart\\nProcessing\\nStats\\nData Provider\\nLogical Disks\\nPerformance Counters\\nLDS\\nLDS\\nLogMart\\nLogMart\\nProcessing\\nProcessing\\nStats\\nStats\\nData Provider\\nData Provider\\nLogical Disks\\nLogical Disks\\nLogRhythm Services\\nService status (running, stopped)\\nLogRhythm Services\\nService status (running, stopped)\\nService status (running, stopped)\\nLogical Disk Utilization\\nDisk Sizes\\nUsed Space\\nLogical Disk Utilization\\nDisk Sizes\\nDisk Sizes\\nUsed Space\\nUsed Space\\n', 'Data Indexer (DX)': 'Elasticsearch Metrics\\nElasticsearch Metrics\\nLogRhythm Services\\nService status (running, stopped)\\nLogRhythm Services\\nService status (running, stopped)\\nService status (running, stopped)\\nLogical Disk Utilization\\nDisk Sizes\\nUsed Space\\nLogical Disk Utilization\\nDisk Sizes\\nDisk Sizes\\nUsed Space\\nUsed Space\\n', 'Web Console (Web UI)': 'LogRhythm Services\\nService status (running, stopped)\\nService status (running, stopped)\\nLogical Disk Utilization\\nDisk Sizes\\nUsed Space\\nDisk Sizes\\nUsed Space\\n', 'Reports': 'Health Check\\n', 'Utilization': 'Deployment Messages Per Second – Last 30 Days\\nDeployment Messages Per Second – Last 30 Days\\nTop 10 Charts\\nTop 10 System Monitors by Volume – Last 24 Hours\\nTop 10 Log Sources by Volume – Last 24 Hours\\nTop 10 Log Source Types by Volume – Last 24 Hours\\nTop 10 Alarms – Last 24 Hours\\nTop 10 Charts\\nTop 10 System Monitors by Volume – Last 24 Hours\\nTop 10 System Monitors by Volume – Last 24 Hours\\nTop 10 Log Sources by Volume – Last 24 Hours\\nTop 10 Log Sources by Volume – Last 24 Hours\\nTop 10 Log Source Types by Volume – Last 24 Hours\\nTop 10 Log Source Types by Volume – Last 24 Hours\\nTop 10 Alarms – Last 24 Hours\\nTop 10 Alarms – Last 24 Hours\\nCurrent Platform Manager Rates (MPS)\\nEvents\\nLogMart\\nAlarm Counts\\nCurrent Platform Manager Rates (MPS)\\nEvents\\nEvents\\nLogMart\\nLogMart\\nAlarm Counts\\nAlarm Counts\\nCurrent Data Processor Rates (MPS)\\nProcessing\\nArchiving\\nCurrent Data Processor Rates (MPS)\\nProcessing\\nProcessing\\nArchiving\\nArchiving\\nCurrent DX Indexing Rates (MPS)\\nDX Cluster Indexing\\nData Processing Indexing\\nCurrent DX Indexing Rates (MPS)\\nDX Cluster Indexing\\nDX Cluster Indexing\\nData Processing Indexing\\nData Processing Indexing\\nCurrent AIE Engine Rates\\nProcessing\\nCurrent AIE Engine Rates\\nProcessing\\nProcessing\\nLog Volume Trends\\nTop 10 System Monitors by Volume – Last 24 Hours\\nTop 10 Log Source Type by Volume – Last 24 Hours\\nLog Volume Trends\\nTop 10 System Monitors by Volume – Last 24 Hours\\nTop 10 System Monitors by Volume – Last 24 Hours\\nTop 10 Log Source Type by Volume – Last 24 Hours\\nTop 10 Log Source Type by Volume – Last 24 Hours\\nLog Volume by System Monitor (Top 25) – Last 30 Days\\nLog Volume by System Monitor (Top 25) – Last 30 Days\\nLog Volume by Log Source Type – Last 30 Days\\nLog Volume by Log Source Type – Last 30 Days\\nLog Volume by Data Processor by Day – Last 30 Days\\nLog Volume by Data Processor by Day – Last 30 Days\\nDatabase Overview\\nName\\nVersion\\nLast Update\\nSize (MB)\\nMax Size (MB)\\n% Used\\nDatabase Overview\\nName\\nName\\nVersion\\nVersion\\nLast Update\\nLast Update\\nSize (MB)\\nSize (MB)\\nMax Size (MB)\\nMax Size (MB)\\n% Used\\n% Used\\nData Backup Information (note: database backup information is only accurate if using MSSQL database backups)\\nName\\nFile Name\\nLast Backup\\nBackup File\\nData Backup Information (note: database backup information is only accurate if using MSSQL database backups)\\nName\\nName\\nFile Name\\nFile Name\\nLast Backup\\nLast Backup\\nBackup File\\nBackup File\\nLicense Report\\nLicense Type\\nExpires\\nLicense Qty\\nAssigned Qty\\nAvailable Qty\\nLicense Report\\nLicense Type\\nLicense Type\\nExpires\\nExpires\\nLicense Qty\\nLicense Qty\\nAssigned Qty\\nAssigned Qty\\nAvailable Qty\\nAvailable Qty\\nMax Hourly MPS BY Day\\nDate\\nHour\\nLicensed MPS\\nMPS\\nMax Hourly MPS BY Day\\nDate\\nDate\\nHour\\nHour\\nLicensed MPS\\nLicensed MPS\\nMPS\\nMPS\\nCapacity Planning\\nHours Over Maximum Sustained Rate\\nPlatform Manager Event Rate\\nPlatform Manager Logmart Rate\\nData Processor Processing Rate\\nData Processor Archiving Rate\\nDX Cluster Indexing Rate\\nAI Engine Processing Rate\\nMinutes Over Maximum Peak Rate\\nPlatform Manager Event Rate\\nPlatform Manager Logmart Rate\\nData Processor Processing Rate\\nData Processor Archiving Rate\\nDX Cluster Indexing Rate\\nCapacity Planning\\nHours Over Maximum Sustained Rate\\nPlatform Manager Event Rate\\nPlatform Manager Logmart Rate\\nData Processor Processing Rate\\nData Processor Archiving Rate\\nDX Cluster Indexing Rate\\nAI Engine Processing Rate\\nHours Over Maximum Sustained Rate\\nPlatform Manager Event Rate\\nPlatform Manager Event Rate\\nPlatform Manager Logmart Rate\\nPlatform Manager Logmart Rate\\nData Processor Processing Rate\\nData Processor Processing Rate\\nData Processor Archiving Rate\\nData Processor Archiving Rate\\nDX Cluster Indexing Rate\\nDX Cluster Indexing Rate\\nAI Engine Processing Rate\\nAI Engine Processing Rate\\nMinutes Over Maximum Peak Rate\\nPlatform Manager Event Rate\\nPlatform Manager Logmart Rate\\nData Processor Processing Rate\\nData Processor Archiving Rate\\nDX Cluster Indexing Rate\\nMinutes Over Maximum Peak Rate\\nPlatform Manager Event Rate\\nPlatform Manager Event Rate\\nPlatform Manager Logmart Rate\\nPlatform Manager Logmart Rate\\nData Processor Processing Rate\\nData Processor Processing Rate\\nData Processor Archiving Rate\\nData Processor Archiving Rate\\nDX Cluster Indexing Rate\\nDX Cluster Indexing Rate\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nUnderstand the LogRhythm Architecture\\n', 'Component Reference': '', 'Operating System': 'Windows Server\\nWindows Server\\n', 'Databases': 'No Databases\\nNo Databases\\n', 'LogRhythm Services': 'Service, LogRhythm Services\\nAI Engine*, Evaluates logs to determine if they match AIE Rules.\\nAI Engine Communication Manager*, Sends logs from the Mediator to the AI Engine for evaluation.\\nService\\nLogRhythm Services\\nAI Engine*\\nEvaluates logs to determine if they match AIE Rules.\\nAI Engine Communication Manager*\\nSends logs from the Mediator to the AI Engine for evaluation.\\n*These services are installed optionally on the PM\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n', 'LogRhythm Applications': 'Client Console\\nClient Console\\nConfiguration Manager\\nConfiguration Manager\\nInfrastructure Installer\\nInfrastructure Installer\\n', 'LogRhythm Archives': 'Active and Inactive Archives\\nActive and Inactive Archives\\n', 'Applications': 'Configuration Manager\\nConfiguration Manager\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nUnderstand the LogRhythm Architecture\\n', 'Licensing': 'LogRhythm licensing has been designed to allow licenses to be assigned and transferred between components centrally. There is no need to type license keys directly into each LogRhythm component, making deployment much simpler. Instead, you import your license file into the LogRhythm License Manager and assign available licenses to the deployed components.\\n', 'LogRhythm Master License File': 'The LogRhythm Solution requires a LogRhythm license file which contains a LogRhythm Master License and Component Licenses. The Master License is tied to an individual customer for a single deployment of LogRhythm (1 Platform Manager and 1 or more Data Processors). Component Licenses fall within the Master License and are used to license specific LogRhythm components within the same LogRhythm deployment.\\nA LogRhythm license file can contain the following component and subscription licenses:\\nPlatform Manager License (always included)\\nData Processor License(s)\\nSoftware License\\nAppliance License\\nSoftware License\\nAppliance License\\nLog Message Source License(s)\\nQuantity License\\nUnlimited License\\nQuantity License\\nUnlimited License\\nSystem Monitor Lite License\\nSystem Monitor Pro License\\nSystem Monitor Collector license\\nAdvanced Intelligence Engine License (separate volume license)\\nGeoIP Resolution Subscription License\\n', 'Licensing Considerations': 'The License for Platform Manager is automatically assigned. Licenses for all other components are assigned when the component is created or assigned via the LogRhythm Deployment Manager.\\nThe Deployment Manager attempts to license all newly created components. If a license is unavailable, you are notified. A license can later be assigned via the Deployment Manager.\\nThe Deployment Manager first tries to assign a System Monitor Pro license to an agent, if one is available; otherwise, it assigns a System Monitor Lite license.\\nWhen a Data Processor starts, it validates its license. If a license is not assigned, has expired, or has been tampered with, the Data Processor Mediator Server process terminates.\\nWhen the Data Processor Mediator Server process authenticates System Monitor Agents, it validates the license of the Agent and all reporting Log Message Sources.\\nIf the Agent is not assigned a license, has expired, or been tampered with, the Agent is not allowed to connect to the Data Processor.\\nIf a Data Processor has exceeded the assigned number of Message (Log) Source licenses (in limited licensing mode), additional log sources are not able to send log messages to the Data Processor.\\n', 'Data Processor Licensing': 'A LogRhythm Data Processor is licensed in one of two modes:\\nSoftware Mode\\n. Used if you purchased the LogRhythm licenses as a software package.\\nAppliance Mode\\n. Used if you purchased the LogRhythm licenses as part of a LogRhythm appliance.\\nEach Data Processor also has a Log Source licensing mode that determines the number of log sources the Data Processor is licensed to handle:\\nLimited Mode\\n. Data Processor is licensed to handle a fixed number of log sources.\\nUnlimited Mode\\n. Data Processor is licensed to handle an unlimited number of log sources.\\n', 'Log Message Source Licensing': 'Each Log Message Source from which an Agent collects logs must have a corresponding license, except for the following log sources (which are considered part of the Agent): Data Loss Defender (DLD), User Activity Monitor (UAM), Process Monitor (PM), Network Connection Monitor (NCM), File Integrity Monitor (FIM), Syslog Server, and IPFIX/NetFlow/J-Flow Server. However, virtualized Log Message Sources collected by the Syslog or NetFlow/J-Flow Servers do need Log Message Source licenses.\\nLog Message Source licenses are available in packs of varying size. Data Processors use license packs as a whole, as assigned in the Data Processor Licensing Wizard. As Agents connect, they authenticate Log Message Sources, which consume licenses on a first come, first served basis. As Agent connections to the Data Processor close, the Log Message Source licenses are returned to an unclaimed state, and can be consumed by the next connecting Agent.\\n', 'System Monitor Licensing': 'You must license each LogRhythm System Monitor to connect to a Data Processor and forward data. LogRhythm provides three types of System Monitor licenses:\\nSystem Monitor Lite\\nSystem Monitor Pro\\nSystem Monitor Collector\\nWhen a System Monitor is registered in the Deployment Manager, it is automatically assigned a System Monitor Pro license, if one is available; otherwise it assigns a System Monitor Lite license. To view the features associated with System Monitor Lite and Pro licenses, see the\\nSystem Monitor Functionality by License: Lite, Pro, and Collector\\ntable in LogRhythm Compatibility and System Monitor Functionality Guide.\\n', 'SQL Server and CAL Licensing': 'LogRhythm includes SQL Server enterprise Runtime as part of the LogRhythm Solution (Appliance or Software). LogRhythm also provides an initial number of User Client Access Licenses (CALs) for SQL Server Licensing. The initial CALs are included in the purchase of the LogRhythm Solution; however, if you require additional CALs above the initial set included, they must be purchased from LogRhythm.\\nCALs apply to a single deployment for LogRhythm (1 Platform Manager and 1 or more Data Processors). Because CALs apply to a LogRhythm deployment, they are only provided with EM or XM Appliances and EM or XM Software Sales.\\nEither 3 or 5 user CALs are included with a LogRhythm purchase depending on the software and/or appliance purchased. Client Access Licenses (CALs) provide one device CAL for the appliance services and allow up to four simultaneous LogRhythm Client Console connections. Deployments that require more than four must purchase additional CALs to ensure license compliance. If you require additional SQL Server CALs, contact your Customer Relationship Manager (CRM).\\nThe LogRhythm Solution will come with a SQL Server End User License Agreement (EULA) for the specific appliance purchased. View your license to determine the number of CALs you have purchased.\\nEvery user who has a login for LogRhythm requires one user CAL. Please note the following:\\n1 CAL is automatically used by the LogRhythm Administrator default account\\n1 CAL is automatically used by the LogRhythm Analyst default account\\nTo determine the number of CALs a LogRhythm deployment requires, refer to the\\nPerson tab\\nin Deployment Manager. Count every Person record where Has Login is selected. This is the number of CALs required.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nUnderstand the LogRhythm Architecture\\n', 'Log Processing': \"LogRhythm processes your organization's raw log data and presents it in a way that makes it easier to analyze and protect your network operations. For a complete list of metadata fields that LogRhythm parses, calculates, and derives from raw log data, see the\\nLogRhythm Schema Dictionary and Guide\\n. Note that while all metadata fields are available in the Web Console, not all are available in the Client Console.\\nLogRhythm components collect and process log messages as follows:\\nLogRhythm\\nAgents\\nmonitor devices in the network (servers, routers, etc.), where they collect raw log data and forward it to a Data Processor. Agents can be installed on both Windows and UNIX platforms.\\nThe\\nData Processor\\nis the central processing engine for log messages. Its integrated Mediator Server contains the Message Processing Engine (MPE), which is responsible for the following:\\nAssigning a Log Source based on where the log originated. For example, a Log could be from a Windows server, a UNIX host, a networking device, or an application.\\nIdentifying a Log Type (Common Event), which amounts to a short, plain-language description of the log.\\nAssigning a Log Classification that includes one of three major classifications (Operations, Audit, or Security) and a specific sub-classification.\\nIdentifying Events, which are important logs that may be of interest or concern (typically less than 5% of your total log activity).\\nParsing and deriving metadata from the raw logs, and when applicable, adding contextual information such as the known application or geographic location.\\nAssigning a Log Source based on where the log originated. For example, a Log could be from a Windows server, a UNIX host, a networking device, or an application.\\nIdentifying a Log Type (Common Event), which amounts to a short, plain-language description of the log.\\nAssigning a Log Classification that includes one of three major classifications (Operations, Audit, or Security) and a specific sub-classification.\\nIdentifying Events, which are important logs that may be of interest or concern (typically less than 5% of your total log activity).\\nParsing and deriving metadata from the raw logs, and when applicable, adding contextual information such as the known application or geographic location.\\nThe Data Processor forwards logs categorized as MPE events to the\\nPlatform Manager\\n. If the Advanced Intelligence Engine (AI Engine) is integrated into the LogRhythm SIEM deployment, the Data Processor can also send copies of log messages to the AI Engine.\\nThe Data Processor forwards logs categorized as MPE events to the\\nPlatform Manager\\n. If the Advanced Intelligence Engine (AI Engine) is integrated into the LogRhythm SIEM deployment, the Data Processor can also send copies of log messages to the AI Engine.\\nThe\\nAI Engine\\n(if integrated) evaluates logs using a pattern matching and behavioral rule set that can correlate and detect complex issues such as sophisticated intrusions, insider threats, operational issues, and compliance issues. If a log triggers one of the AIE rules, the AI Engine generates a new AIE event for the Platform Manager Database.\\nThe\\nAI Engine\\n(if integrated) evaluates logs using a pattern matching and behavioral rule set that can correlate and detect complex issues such as sophisticated intrusions, insider threats, operational issues, and compliance issues. If a log triggers one of the AIE rules, the AI Engine generates a new AIE event for the Platform Manager Database.\\nThe\\nPlatform Manager\\nreceives event data from the Data Processors and the AI Engine. It includes an Alarming and Response Manager (ARM), which evaluates the events against rules for alarms and initiates the appropriate response. The Platform Manager also serves as the central point of access for LogRhythm SIEM. It houses the databases for events, alerts, and metadata, and includes all the configuration information.\\nThe\\nPlatform Manager\\nreceives event data from the Data Processors and the AI Engine. It includes an Alarming and Response Manager (ARM), which evaluates the events against rules for alarms and initiates the appropriate response. The Platform Manager also serves as the central point of access for LogRhythm SIEM. It houses the databases for events, alerts, and metadata, and includes all the configuration information.\\nIf an\\nalarm\\nis generated, one or both of the following actions can be triggered:\\nNotification\\n.\\nAn alert is sent to administrators via SNMP traps, email (SMTP), or text files.\\nRemediation (SmartResponse action).\\nAn automated script responds with an action to resolve the issue.\\nIf an\\nalarm\\nis generated, one or both of the following actions can be triggered:\\nNotification\\n.\\nAn alert is sent to administrators via SNMP traps, email (SMTP), or text files.\\nNotification\\n.\\nAn alert is sent to administrators via SNMP traps, email (SMTP), or text files.\\nRemediation (SmartResponse action).\\nAn automated script responds with an action to resolve the issue.\\nRemediation (SmartResponse action).\\nAn automated script responds with an action to resolve the issue.\\n\\n\", 'Debug/Verbose\\xa0Logging': 'LogRhythm Message Processing Engine (MPE) rules are designed with the intent of parsing log messages at the Information (syslog severity) level and above. By their very nature,\\nDebug\\nand\\nVerbose\\nlog messages contain low-level information that would not normally appear (using default logging configurations) within typical operational, audit, or security log messages. Given this, the lack of parsing/normalization of log messages at the\\nDebug\\n(or\\nVerbose\\n) logging levels is intentional and for several reasons, some of which are conceptual and others more mechanical.\\nMost devices will generate an order of magnitude greater log volume when set to the\\nVerbose\\nor\\nDebug\\nlogging levels. The result of this is system impacting on multiple fronts with the most critical being processing via the MPE and indexing via the Data Indexer (DX). Specifically, while\\nVerbose\\nand\\nDebug\\nlogs will inevitably hit Catch All rules, they will not only cause an immense MPE slow down, but also many stalled/disabled rules, spooling, and overall poor performance as they attempt to process through every rule in the policy. In addition to this, indexing will be impacted, whereas the logs cause a backup of spooled reliable persist files, resulting in poor DX performance.\\nAgain, while\\nDebug\\nand\\nVerbose\\nlogging may be beneficial in development and system troubleshooting scenarios, heavy volume log sources and/or enabling such logs for longer periods of time could potentially result in a drastic impact on overall system performance, so normalization of these log messages does not occur as part of the LogRhythm MPE feature.\\n', 'Log Processing Basics': 'The devices in your network are generating thousands of raw logs at every moment. These logs are generated in a wide variety of formats, and they represent varying degrees of importance in maintaining and protecting your network. LogRhythm processes raw log data to make information available to you in a meaningful and uniform context.\\nUnderstanding how LogRhythm processes the raw log data helps you configure your LogRhythm deployment to get the fullest benefit and most useful output. LogRhythm log processing includes:\\nInitial Processing\\nAssign a Log Source\\nIdentify a Common Event\\nAssign a Classification\\nIdentify Events\\nAssign a Log Source\\nIdentify a Common Event\\nAssign a Classification\\nIdentify Events\\nMetadata Processing\\nParsed data\\nCalculated\\nDerived data\\nParsed data\\nCalculated\\nDerived data\\nIn the following examples, we will use this raw log:\\n08 13 2009 15:21:19 1.1.2.1 <LOC4:ERRR> Aug 13 2009 15:21:19 GSC-Internet-FW: %ASA-3-106014:\\nDeny inbound icmp src INSIDE:4.2.1.3 dst INSIDE:4.1.1.1 (type 0, code 0)\\nAfter the example log is reviewed, examples are provided for other common types of logs.\\n', 'Initial Processing': '', 'Assign a Log Source': 'Log Sources are unique log originators on a specific Host. A Host can have more than one Log Source. For example, a typical Windows Server Host would include System Event Logs, Application Event Logs, and Security Event Logs.\\nLogRhythm identifies the Log Source to:\\nDetermine where the log originated.\\nAssign the Log Source to the correct set of base rules called a Message Processing Engine (MPE) policy.\\nProcess the log against the assigned MPE policy. Processing against an MPE policy instead of the complete set of rules is a tremendous gain in efficiency. The information in the example log allows LogRhythm to identify it as a Cisco ASA Log Source. Now LogRhythm can process the log against a specific rule base.\\n', 'Identify a Common Event': 'Processing the log against the appropriate rule base identifies the Common Event—a short, plain-language description of the log.\\n', 'Assign a Classification': 'Based on the Common Event, LogRhythm can assign a classification which includes one of three\\nmajor\\nclassifications–Operations, Audit, or Security–and a more specific\\nsub-classification\\n. Here are some examples:\\nAudit: Authentication Failure\\nOperations: Network Deny\\nSecurity: Suspicious\\nResults for initial processing of our example log:\\nLog Source = Cisco ASA\\nMatched Rule = PIX-106014: Denied Packet\\nCommon Event = Denied Packet\\nClassification = Operations: Network Deny\\n', 'Identify Events': \"LogRhythm recognizes that some logs are more important to your organization's operation, security, and compliance than others. In the identification process, more important logs are designated as Events–generally this will be around 10% of your total log activity.\\n\", 'Metadata Processing': 'LogRhythm parses, calculates, and derives metadata from logs. The metadata fields go into a database to help speed performance when you use LogRhythm search tools such as Investigator, Personal Dashboard, and Reporting. Logs identified as Events and the associated metadata are also sent to LogMart unless specifically configured not to do so.\\nFor a complete list of metadata fields, see the\\nLogRhythm Schema Dictionary and Guide\\n. Note that while all metadata fields are available in the Web Console, not all are available in the Client Console.\\nLogRhythm derived metadata fields store network and host information pulled from the log message.\\nWhere space is restricted such as column headings, reports, and grids, i and o are used as abbreviations for Impacted and Origin. For example, Impacted Zone and Origin Zone may appear as iZone and oZone. Other metadata fields also use abbreviations or short names, in report column headings when space is restricted.\\nAfter additional processing, the following information is available for our example log:\\nRaw Log\\n08 13 2009 15:21:19 1.1.2.1 <LOC4:ERRR> Aug 13 2009 15:21:19 GSC-Internet-FW: %ASA-3-106014:\\nDeny inbound icmp src INSIDE:4.2.1.3 dst INSIDE:4.1.1.1 (type 0, code 0)\\nLog Processed Information:\\nLog Source = Cisco ASA\\nMatched Rule = PIX-106014: Denied Packet\\nCommon Event = Denied Packet\\nClassification = Operations/Network Deny\\nMetadata:\\nVendor Message ID = %ASA-4-106014\\nProtocol = ICMP\\nOrigin Host = 4.2.1.3\\nImpacted Host = 4.1.1.1\\n', 'Windows Event Log Example': 'Raw Windows Event Log\\n8/20/2008 11:17 AM TYPE=SuccessAudit USER=NT AUTHORITY\\\\SYSTEM COMP=ServerOne SORC=Security CATG=Logon/Logoff EVID=540 MESG=Successful Network Logon: User Name: john.smith Domain:LEARNING Logon ID:(0x0,0x18DF 15 ) Logon Type:3 Logon Process:Kerberos Authentication Package: Kerberos Workstation Name:Logon GUID:{06cc19fa-e96f-81ba-9ccb-17f0a4319ff4} Caller User Name:- Caller Domain:- Caller Logon ID:- Caller Process ID: - Transited Services: - Source Network Address: 10.1.1.100 Source Port:2678\\nWindows Event Log Processed Information\\nLog Source = Microsoft Event Log for XP/2000/2003 – Security\\nMatched Rule = EVID 540: Successful Logon\\nCommon Event = Network Authentication - Admin\\nClassification = Audit / Authentication Success\\nMetadata Fields:\\nVendor Message ID = 540\\nOrigin Host = 10.1.1.100\\nDomain = Learning\\nSession = 0x0,0x18DF15\\nProcess = Kerberos\\nLogin = john.smith\\n', 'Flat File Log Example': 'Raw Flat File Log\\n917322,2009-01-26 15:07:33.250,516,\"POS1050.pcommerce.local\",\"192.168.1.100\",\"W\",\"Alert\",\"File access control\",\"TESTMODE: The process \\'<remote application>\\' (as user SFORCE\\\\Stuart.Young) attempted to access \\'C:\\\\Iris\\\\Bin\\\\RestartSVS.bat\\'. The attempted access was a write (operation = OPEN/CREATE). The operation would have been denied.\",\"FACL_DENY_TESTMODE\",\"RestartSVS.bat\",\"<remote application >\",,,,,867,\"Remote applications, read/write all files (file access via network share)\",122,\"Microsoft SQL Server\",,\" SFORCE\\\\Stuart.Young\"\\nFlat File Processed Information\\nLog Source = Flat File – Cisco Security Agent\\nMatched Rule = FACL_DENY_TESTMODE: Alert\\nCommon Event: File Access Denied\\nClassification = Audit / Access Failure\\nMetadata Fields:\\nVendor Message ID = FACL_DENY_TESTMODE\\nOrigin Login = Stuart.Young\\nDomain = SFORCE\\nProcess = remote application\\nObject = RestartSVS.bat\\n', 'UDLA Log Example': 'Raw UDLA Log\\nDATE_TIME=1/15/2009 8:40:12 AM DURATION=0 DISPOSITION_CODE=1026 CATEGORY=9 FILE_TYPE_ID= HITS=1 BYTES_SENT=8503 BYTES_RECEIVED=4712 RECORD_NUMBER=500000024145 USER_ID=2498 SOURCE_IP=2.8.3.5 SOURCE_SERVER_IP=1.1.1.1 DESTINATION_IP=3.1.6.3 PORT=80 PROTOCOL_ID=1 URL=Host126 FULL_URL=\\nhttp://Host126/b/ss/seatimesseattletimescom,seatimesglobalprod/1/=\\nKEYWORD_ID=\\nUDLA Log Processed Information\\nLog Source = UDLA – WebSense\\nMatched Rule = EVID 1026: URL Access Allowed\\nCommon Event = URL Access Allowed\\nClassification: Audit / Access Success\\nMetadata Fields:\\nVendor Message ID = 1026\\nOrigin Host = 2.8.3.5\\nImpacted Host = 3.1.6.3\\nImpacted Port = 80\\nURL =\\nhttp://Host126/b/ss/seatimesseattletimescom,seatimesglobalprod/1/\\nBytes In = 4712\\nBytes Out = 8503\\n', 'Log Message Classifications': 'LogRhythm uses classifications to group similar log messages into logical containers. These classifications provide organization to vast amounts of log data, making it easier to sort through and understand. Classifications fall under three main categories:\\nAudit\\nSecurity\\nOperations\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nUnderstand the LogRhythm Architecture\\n', 'LogRhythm SIEM Databases': \"The Web Console draws information from the following LogRhythm SIEM databases.\\nThis Web Console function..., Extracts data from this database...\\nAlarms, Alarms(LogRhythm_Alarms):The Alarms Database includes data related to all alarms, alarm notifications, and alarm histories generated by the LogRhythm Alarming and Response Manager (ARM).\\nCase Management, CMDB(LogRhythm_CMDB):The Case Management Database includes data for all cases as well as most of the associated evidence.\\nDashboard Events Analyzer drill down, Events Database(LogRhythm_Events):Contains log data that qualified as an Event.\\nDashboard Rate gauge/ Dashboard Trend chart, LogMart(LogRhythm_LogMart):Contains log metadata that qualified as an Event, or data that was sent because of a processing rule. LogMart also includes tracking statistics for the log data volume.\\nList Management, EMDB(LogRhythmEMDB):The Platform Manager Database includes all configuration information.\\nReports, Alarms(LogRhythm_Alarms):The Alarms Database includes data related to all alarms, alarm notifications, and alarmhistories generated by the LogRhythm Alarming and Response Manager (ARM).\\nSearch, Data Indexer(Elasticsearch):The Data Indexer's Elasticsearch contains all the collected log data (both raw logs and associated metadata).\\nUser Preferences (layouts, settings, etc.), EMDB(LogRhythmEMDB):The Platform Manager Database includes all configuration information.\\nAlarms\\n(LogRhythm_Alarms):\\nThe Alarms Database includes data related to all alarms, alarm notifications, and alarm histories generated by the LogRhythm Alarming and Response Manager (ARM).\\nCMDB\\n(LogRhythm_CMDB):\\nThe Case Management Database includes data for all cases as well as most of the associated evidence.\\nEvents Database\\n(LogRhythm_Events):\\nContains log data that qualified as an Event.\\nLogMart\\n(LogRhythm_LogMart):\\nContains log metadata that qualified as an Event, or data that was sent because of a processing rule. LogMart also includes tracking statistics for the log data volume.\\nEMDB\\n(LogRhythmEMDB):\\nThe Platform Manager Database includes all configuration information.\\nAlarms\\n(LogRhythm_Alarms):\\nThe Alarms Database includes data related to all alarms, alarm notifications, and alarm\\nhistories generated by the LogRhythm Alarming and Response Manager (ARM).\\nData Indexer\\n(Elasticsearch):\\nThe Data Indexer's Elasticsearch contains all the collected log data (both raw logs and associated metadata).\\nEMDB\\n(LogRhythmEMDB):\\nThe Platform Manager Database includes all configuration information.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nUnderstand the LogRhythm Architecture\\n', 'Logs, Events, and Alarms': 'Administrators can use either the Web Console or the Client Console to access logs, events, and alarms generated from the LogRhythm SIEM deployment:\\nThe Web Console is a convenient web browser tool that both analysts and administrators can use from a laptop or other remote device. The Web Console components can reside on a dedicated server or on the Platform Manager appliance. For more information, see the\\nWeb Console User Guide\\n.\\nThe Client Console is a component installed on a desktop machine (a thick client), which administrators can use for all SIEM tasks, including central administration and configuration.\\nThe Client Console is a component installed on a desktop machine (a thick client), which administrators can use for all SIEM tasks, including central administration and configuration.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nUnderstand the LogRhythm Architecture\\n', 'Networking and Communication': '', 'LogRhythm Networking Considerations': 'There are general guidelines, considerations, and standards to consider prior to deploying your solution within a network. This page covers the networking and communication considerations and requirements to help you deploy your solution.\\nLogRhythm Server IP Addresses\\n. LogRhythm appliances include multiple network interfaces to accommodate different deployment topologies. All IP addresses should be statically assigned or reserved to avoid IP changes. For many topologies, best practice is to use the dedicated out-of-band management 1Gb interfaces (iDRAC) and one of the 10Gb interfaces for data. Each LogRhythm Server should only have 1 IP address presented to the Operating System.\\nDNS Resolution\\n. It is recommended that the LogRhythm server acting as the Platform Manager be entered into DNS so it is addressable by name.\\nDomain Membership\\n. A LogRhythm server does not need to be a member of the Windows Domain to function correctly. However, LogRhythm recommends adding it to make remote event log collection easier to manage.\\nRemote Event Log Collection User Account\\n. A special user account must be created on the domain for remote event log collection. For more information, see\\nWindows Event Log Collection\\n.\\nNetwork Address Translation\\n. Network address translation (NAT) cannot be used between core components (AIE, DP, DX, PM, Web). All communications between these components must be real IP to real IP.\\nMTU.\\nLogRhythm backend components should all use matching MTU configuration and path-MTU-discovery (ICMP-Type3, Code4) must be allowed between all LogRhythm Components, Agents, and externally dependent services (NAS for archives, backups, etc). Fragmentation issues traversing network paths can cause significant reductions in performance.\\nLogRhythm components communicate over TCP, UDP, or HTTPS on specific ports. TLS is used when receiving logs at the Data Processor from the LogRhythm System Monitor and also when sending logs from the Data Processor to AI Engine. The diagram below shows the communication between the components and the specific protocols and ports used.\\n\\n\\nThe following tables list all network communications and interactions within a LogRhythm deployment. They can assist system and network administrators with configuration of network access control devices and software.\\n\\nComponents\\nClient: AI Engine\\nClient Port, Server, Server Port, Protocol, Purpose\\n8300, Platform Manager, 8300, TCP, Incoming RPC requests from client Consul instances\\n8501, Platform Manager, 8501, HTTPS, Auth/config/search requests between API Gateway on AIE and PM\\n8301, Platform Manager, 8301, TCP/UDP, Cluster membership and inter-node communications between Consul instancesPort 8301 must be opened for TCP and UDP traffic on all hosts (PM, DP, DX, AIE, Web) in your deployment, with the exception of Client Console and Agent hosts. 8301 is the bi-directional communication port used between all Consul hosts. If the port is blocked, hosts in your deployment will not be able to join the Consul cluster. No log data or customer data is passed between hosts on this port It is only used for membership communication between LR hosts.\\nRandom, Platform Manager, 1433, TCP, Configuration details from EMDB on PM\\n3334, 3335, Data Processor, 30000, 30001, TCP, AIE Data Provider on DP forwarding log data to AIE Comm Manager\\nClient: Client Console\\nClient Port, Server, Server Port, Protocol, Purpose\\n8501, Data Indexer, 8501, HTTPS, Auth/config/search requests between API Gateway on Console and DX\\n8501, Platform Manager, 8501, HTTPS, Auth/config/search requests between API Gateway on Console and PM\\nRandom, Platform Manager, 1433, TCP, Console SQL Server access to PM EMDB\\nClient: Common Components\\nClient Port, Server, Server Port, Protocol, Purpose\\nRandom, Metrics Database (InfluxDB), 8076, TCP, Persistence layer for time-series metrics\\nRandom, Metrics Collection (Telegraf), 8125, TCP, Collects system-level metrics and reports metrics to the data storeCollects performance counters on Windows-based operating systemsCollects system information such as disk, ram, cpu, and port metrics on all systems\\nRandom, Metrics Web UI (Grafana), 3000, TCP, User interface for viewing and exploring metrics\\nClient: Data Indexer\\nClient Port, Server, Server Port, Protocol, Purpose\\nRandom, Platform Manager, 1433, TCP, DX SQL Server access to PM EMDB\\n8501, Platform Manager, 8501, HTTPS, Auth/config/search requests between API Gateway on DX and PM\\n8300, Platform Manager, 8300, TCP, Incoming RPC requests from client Consul instances\\n8301, Platform Manager, 8301, TCP/UDP, Cluster membership and inter-node communications between Consul instancesPort 8301 must be opened for TCP and UDP traffic on all hosts (PM, DP, DX, AIE, Web) in your deployment, with the exception of Client Console and Agent hosts. 8301 is the bi-directional communication port used between all Consul hosts. If the port is blocked, hosts in your deployment will not be able to join the Consul cluster. No log data or customer data is passed between hosts on this port. It is only used for membership communication between LR hosts.\\nClient: Data Processor\\nClient Port, Server, Server Port, Protocol, Purpose\\n8501, Data Indexer, 8501, HTTPS, Auth/config/search requests between API Gateway on DP and DX\\nClient: LR API\\nClient Port, Server, Server Port, Protocol, Purpose\\nRandom, Platform Manager, 1433, TCP, Bidirectional connection between LR API and PM\\nClient: LR KB Update\\nClient Port, Server, Server Port, Protocol, Purpose\\nN/A, Platform Manager, 80, 443, TCP, Bidirectional connection for KB updates\\nClient: Open Collector\\nDirection, Source > Destination, Server Port, Protocol, Purpose\\nOutbound, Open Collector >*.github.com, 443, HTTPS, Identify latest container versionsThis is only used during an installation or upgrade of the Open Collector.\\nOutbound, Open Collector >*.gcr.io, 443, HTTPS, Download latest Open Collector softwareThis is only used during an installation or upgrade of the Open Collector.\\nOutbound, Open Collector > Windows System Monitor Agent, 514, HTTPS, Syslog feed of data to LogRhythm SIEM\\nInbound, User Machine > Open Collector, 3000, HTTP, View Open Collector metrics in Grafana\\nInbound, User Machine > Open Collector, 22, SSH, Interact with Open Collector\\nClient: Platform Manager\\nClient Port, Server, Server Port, Protocol, Purpose\\n8300, Data Processor, 8300, TCP, Incoming RPC requests from client Consul instances\\n8301, Data Processor, 8301, TCP/UDP, Cluster membership and inter-node communications between Consul instancesPort 8301 must be opened for TCP and UDP traffic on all hosts (PM, DP, DX, AIE, Web) in your deployment, with the exception of Client Console and Agent hosts. 8301 is the bi-directional communication port used between all Consul hosts. If the port is blocked, hosts in your deployment will not be able to join the Consul cluster. No log data or customer data is passed between hosts on this port. It is only used for membership communication between LR hosts.\\n8501, Data Processor, 8501, HTTPS, Auth/config/search requests between API Gateway on DP and PM\\nRandom, Data Processor, 1433, TCP, DP SQL Server access to PM EMDB\\nClient: System Monitor/Data CollectorAgents communicate with Data Processors via a secure, proprietary TCP-based application protocol. Communications are encrypted with TLS using either unilateral or bilateral authentication. The TCP port Agents send data from, and the TCP port Data Processors listen on, is user configurable.\\nClient Port, Server, Server Port, Protocol, Purpose\\n0 (formerly 3333), Data Processor, 40000, TCP, Forwards raw log data to the DP when running in Unidirectional Agent mode\\n0 (formerly 3333), Data Processor, 443, TCP, Forwards raw log data to the DP when running in Bidirectional Mode\\nClient: Web Browser\\nClient Port, Server, Server Port, Protocol, Purpose\\nRandom, Web Console, 8443, HTTPS, The SSL port to use for accessing the Web Console.\\nClient: Web Console\\nClient Port, Server, Server Port, Protocol, Purpose\\n8300, Platform Manager, 8300, TCP, Incoming RPC requests from client Consul instances\\n8501, Platform Manager, 8501, HTTPS, Auth/config/search requests between API Gateway on Web and PM\\n8501, Data Indexer, 8501, HTTPS, Auth/config/search requests between API Gateway on Web and DX\\nRandom, Platform Manager, 1433, TCP, Web Console SQL Server access to PM Events DB.\\n8301, Platform Manager, 8301, TCP/UDP, Cluster membership and inter-node communications between Consul instancesPort 8301 must be opened for TCP and UDP traffic on all hosts (PM, DP, DX, AIE, Web) in your deployment, with the exception of Client Console and Agent hosts. 8301 is the bi-directional communication port used between all Consul hosts. If the port is blocked, hosts in your deployment will not be able to join the Consul cluster. No log data or customer data is passed between hosts on this port. It is only used for membership communication between LR hosts.\\n43, WHOIS, 43, TCP, Run a whois query usingcontextualization\\nClient: Web Console Case API\\nClient Port, Server, Server Port, Protocol, Purpose\\n†, †, †, †, The Web Console Case API uses dynamic ports in the range of 20000-30000. These are listening ports used for loopback purposes and do not require any firewall changes.\\nClient: TrueIdentity Sync Client\\nClient Port, Server, Server Port, Protocol, Purpose\\n389, AD Server, 389, LDAP, TrueIdentity Sync Client access to the LDAP server\\n636, AD Server, 636, LDAP, TrueIdentity Sync Client access to the secure LDAP server\\n8505 (local requests), Admin API, Platform Manager, 8505 (local requests), HTTPS, Connection to the Admin API\\n8501 (remote requests), Admin API, Platform Manager, 8501 (remote requests), HTTPS, Connection to the Admin API\\n', 'Components': 'Client: AI Engine\\nCluster membership and inter-node communications between Consul instances\\nPort 8301 must be opened for TCP and UDP traffic on all hosts (PM, DP, DX, AIE, Web) in your deployment, with the exception of Client Console and Agent hosts. 8301 is the bi-directional communication port used between all Consul hosts. If the port is blocked, hosts in your deployment will not be able to join the Consul cluster. No log data or customer data is passed between hosts on this port It is only used for membership communication between LR hosts.\\nClient: Client Console\\nClient: Common Components\\nPersistence layer for time-series metrics\\nCollects system-level metrics and reports metrics to the data store\\nCollects performance counters on Windows-based operating systems\\nCollects system information such as disk, ram, cpu, and port metrics on all systems\\nClient: Data Indexer\\nCluster membership and inter-node communications between Consul instances\\nPort 8301 must be opened for TCP and UDP traffic on all hosts (PM, DP, DX, AIE, Web) in your deployment, with the exception of Client Console and Agent hosts. 8301 is the bi-directional communication port used between all Consul hosts. If the port is blocked, hosts in your deployment will not be able to join the Consul cluster. No log data or customer data is passed between hosts on this port. It is only used for membership communication between LR hosts.\\nClient: Data Processor\\nClient: LR API\\nClient: LR KB Update\\nClient: Open Collector\\nIdentify latest container versions\\nThis is only used during an installation or upgrade of the Open Collector.\\nDownload latest Open Collector software\\nThis is only used during an installation or upgrade of the Open Collector.\\nClient: Platform Manager\\nCluster membership and inter-node communications between Consul instances\\nPort 8301 must be opened for TCP and UDP traffic on all hosts (PM, DP, DX, AIE, Web) in your deployment, with the exception of Client Console and Agent hosts. 8301 is the bi-directional communication port used between all Consul hosts. If the port is blocked, hosts in your deployment will not be able to join the Consul cluster. No log data or customer data is passed between hosts on this port. It is only used for membership communication between LR hosts.\\nClient: System Monitor/Data Collector\\nAgents communicate with Data Processors via a secure, proprietary TCP-based application protocol. Communications are encrypted with TLS using either unilateral or bilateral authentication. The TCP port Agents send data from, and the TCP port Data Processors listen on, is user configurable.\\nForwards raw log data to the DP when running in Unidirectional Agent mode\\n\\nClient: Web Browser\\nThe SSL port to use for accessing the Web Console.\\nClient: Web Console\\nCluster membership and inter-node communications between Consul instances\\nPort 8301 must be opened for TCP and UDP traffic on all hosts (PM, DP, DX, AIE, Web) in your deployment, with the exception of Client Console and Agent hosts. 8301 is the bi-directional communication port used between all Consul hosts. If the port is blocked, hosts in your deployment will not be able to join the Consul cluster. No log data or customer data is passed between hosts on this port. It is only used for membership communication between LR hosts.\\nClient: Web Console Case API\\nNotifications and Alerts\\nClient, Client Port, Server, Server Port, Protocol, Purpose\\nLogRhythm Platform Manager and Web Console, Random, SMTP Server, 25, TCP, Unidirectional, Client Initiated\\nLogRhythm Platform Manager, Random, SNMP Manager, 162, UDP, Unidirectional, Client Initiated\\nLogRhythm Platform Manager, **, McAfee ePO Server, **, **, **LogRhythm alarms are forwarded to EPO via the McAfee agent installed on a Platform Manager. To determine the ports utilized by McAfee agents and EPO server, see your McAfee ePO documentation and configuration.\\n', 'Notifications and Alerts': '**\\nLogRhythm alarms are forwarded to EPO via the McAfee agent installed on a Platform Manager. To determine the ports utilized by McAfee agents and EPO server, see your McAfee ePO documentation and configuration.\\nDevices Sending Logs\\nClient, Client Port, Server, Server Port, Protocol, Purpose\\nUDP Syslog Device, Random, LogRhythm Agent, 514, UDP, Unidirectional\\nTCP Syslog Device, Random, LogRhythm Agent, 514, TCP, Unidirectional\\nNetFlow v1, v5 or v9 Device, Configurable, LogRhythm Agent, 5500, UDP, Unidirectional\\nIPFIX Device, Configurable, LogRhythm Agent, 5500, UDP, Unidirectional\\nJ-Flow Device, Configurable, LogRhythm Agent, 5500, UDP, Unidirectional\\nsFlow Device, Configurable, LogRhythm Agent, 6343, UDP, Unidirectional\\nSNMP Trap Device, Configurable, LogRhythm Agent, 161, UDP, Unidirectional\\n', 'Devices Sending Logs': 'Remote Log Collection\\nClient, Client Port, Server, Server Port, Protocol, Purpose\\nLogRhythm Agent, Random, Windows Host (Windows Event Logs), 135, 137, 138, 139,445, TCP/RPC, Bidirectional, Client Initiated\\nLogRhythm Agent, Random, Database Server (UDLA), DB Server dependentThe server port for UDLA collection will vary based on the database server being queried.(SQL Server default = TCP 1433; MySQL default 3306; Oracle default = TCP 1521; DB2 default = TCP 50000), TCP/ODBC, Bidirectional, Client Initiated\\nLogRhythm Agent, Random, Check Point Firewall, 18184, TCP/OPSEC LEA, Bidirectional, Client Initiated\\nLogRhythm Agent, Random, Cisco IDS (SDEE), 443, TCP/HTTPS, Bidirectional, Client Initiated\\nLogRhythm Agent, Random, Nessus Server, 8834, TCP/HTTPS, Bidirectional, Client Initiated\\nLogRhythm Agent, Random, Qualys Server, 443, TCP/HTTPS, Bidirectional, Client Initiated\\nLogRhythm Agent, Random, Metasploit Server, 3790, TCP/HTTPS, Bidirectional, Client Initiated\\nLogRhythm Agent, Random, Nexpose Server, 3780, TCP/HTTPS, Bidirectional, Client Initiated\\nLogRhythm Agent, Random, Retina Server, 1433, TCP/ODBC, Bidirectional, Client Initiated\\nLogRhythm Agent, 4444, eStreamer Server, 8302, TCP/HTTPS, Bidirectional, Client Initiated\\n', 'Remote Log Collection': 'DB Server dependent\\nThe server port for UDLA collection will vary based on the database server being queried.\\n(SQL Server default = TCP 1433; MySQL default 3306; Oracle default = TCP 1521; DB2 default = TCP 50000)\\nData Indexer - Inbound Ports\\nAppliance, Protocol, Inbound Port, Received From..., Operating System, Purpose\\nPM - Disaster Recovery, TCP, 5022, Inter-node Disaster Recovery communication, Windows, Port used for replication requests in Disaster Recovery deployments\\nPM - SQL, TCP, 1433, Carpenter and Bulldozer on DX, Windows & Linux, SQL Server access to EMDB\\nLogRhythm API Gateway, HTTPS, 8501, API Gateway, Windows & Linux, Enables secure, load balanced, and discoverable service to service communication. Required to use the JWT from the Authentication API.\\nConsul, TCP/UDP, 8300, 8301, Service Registry, Windows & Linux, Establishes a secure cluster between the LogRhythm hosts in a deployment, not including agents\\n', 'Data Indexer - Inbound Ports': 'Data Indexer - Local Ports\\nService, Protocol, Port, Direction, Operating System, Purpose\\nColumbo, TCP, 13131, 13133, DX Local Only, Windows & Linux, Columbo internal processing\\nConsul, TCP/UDP, 8300, 8301, Inter-node, Windows & Linux, Nodes in cluster sharing keys\\n8500, DX Local Only, Windows, Consul administration dashboard\\nElasticsearch, TCP, 9200, DX Local Only, Windows & Linux, Curl queries to Elasticsearch\\n9300-9400, Inter-node, Linux, Replication and federation across nodes\\n', 'Data Indexer - Local Ports': 'Open Collector\\nDirection, Port, Protocol, Source, Destination, Purpose\\nOutbound, 443, HTTPS, Open Collector, *.github.com, Identify latest container versionsThis is only used during an installation or upgrade of the Open Collector.\\nOutbound, 443, HTTPS, Open Collector, *.gcr.io, Download latest Open Collector softwareThis is only used during an installation or upgrade of the Open Collector.\\nInbound, 3000, HTTP, User machine, Open Collector, View Open Collector metrics in Grafana\\nInbound, 22, SSH, User machine, Open Collector, Interact with Open Collector\\nOutbound, 514, HTTPS, Open Collector, Windows System Monitor Agent, Syslog feed of data to LogRhythm SIEM\\nInbound, 8400, HTTPS, User machine, OC-Admin, Allow beat access to the OC Admin interface\\nOutbound, 1433, TCP, Open Collector, Your PM or XM, Allows OC Admin to connect to the PM or XM SQL server to fetch information about log sources and to create and update log sources, log source virtualizations, parsing rules, and processing policies.\\nBeats\\nDirection, Port, Protocol, Source, Destination, Purpose\\nOutbound, 443, HTTPS, Beats, *.windows.net, Collection from any active beat: Azure Event Hub, AWS S3, Gmail Message Tracking, GSuite, Pub/Sub, Sophos Central\\nOutbound, 5671, AMQPS, Event Hub Beat, *.windows.net, Azure collection from Event Hub\\n', 'Open Collector': 'Identify latest container versions\\nThis is only used during an installation or upgrade of the Open Collector.\\nDownload latest Open Collector software\\nThis is only used during an installation or upgrade of the Open Collector.\\n', 'Beats': 'Unidirectional Agent CommunicationLogRhythm provides support for secure transmission from an unclassified server to a top secret server. The System Monitor Agents support unidirectional communication without receiving any control or data transmissions from the Data Processor or Platform Manager. The table below shows the unidirectional communication from the Agent(s) within the unclassified sector to the Data Processor within the top secret sector.\\nClient, Client Port, Server, Server Port, Protocol, Commnunications\\nLogRhythm Agent, 3333, LogRhythm Data Processor, 40000, TCP, Unidirectional\\nWeb Console Client, Random, LogRhythm Web Server, 8443, HTTPS, Bidirectional, Client Initiated\\nWeb Console Client, Random, Data Indexer, 13130, 13132, TCP, Bidirectional, Client Initiated\\n', 'Unidirectional Agent Communication': 'LogRhythm provides support for secure transmission from an unclassified server to a top secret server. The System Monitor Agents support unidirectional communication without receiving any control or data transmissions from the Data Processor or Platform Manager. The table below shows the unidirectional communication from the Agent(s) within the unclassified sector to the Data Processor within the top secret sector.\\n40000\\nUnidirectional\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nUnderstand the LogRhythm Architecture\\n/\\nLog Processing\\n', 'Audit Classifications': 'The following tables provide Audit classification information. This table lists descriptions and examples.\\nClassification, Description, Examples Of\\nStartup and Shutdown, Logs reporting on activity pertaining to the starting and stopping of a system, device, application, or other relevant object.Server or provider Services, Daemons, Windows Services.Critical Service – prevent network access; related to infrastructure service, security or auditing, authentication, accessibility (most likely due to shutdown caused by failures), System StartedSystem RebootedAudit Process StartedIPSEC Agent StartedHTTPD Service StartedSQL Server Service\\xa0 StoppedUnexpectedlyAnti Virus Stopped\\nConfiguration, Logs reporting on activity pertaining to the state or configuration of a system where not related to a Policy.Critical Service – changes to devices that can prevent network access; are related to infrastructure service, security or auditing, authentication, accessibilityEnsure the following have RR = 0 -- Normal Registry and Active Directory modifications, Software installedConfiguration changedSoftware removedAnti Virus Scheduled Scan deletedService Startup configuration changesActive Directory Configuration changed (rr=3)Active Directory Content changed (rr=0)Enabling / Disabling Services and or Protocols\\nPolicy, Logs reporting on activity pertaining to the policy of a network, system, device, or other relevant object. Includes configuration changes related to a PolicyIn general, most of the Policy changes will be set to RR=3 & forwarded as it will be difficult to know if it is a user level change., Domain Policy changedAudit Policy setAccess Control Policy changedContent Management modifiedUser Level/Workstation LevelPolicy changed (Screensaver settings)\\nAccount Created, Logs reporting on activity related to user or system/computer account creation., User account/group created\\nAccountModified, Logs reporting on the modification of a user or group outside granting/revoking access. No group level or access level changes., User account properties (for example, name) changedPassword changed\\nAccount Deleted, Logs reporting on activity related to user or system/computer account deletion., User account/group deleted\\nAccess Granted, Logs reporting on activity related to granting of access rights and privileges.User account was modified to grant access on a permanent state., User added to groupAccess to file grantedAccess to program grantedAdministrator role grantedBackup role granted\\nAccess Revoked, Logs reporting on activity related to revocation of access rights and privileges., User removed from groupAccess to file revokedAccess to program revokedAdministrator role revokedBackup role revoked\\nAuthentication Success, Logs reporting success user and system authentication activity.\\xa0 User or system gaining access through any method of authentication., User logged on locallyUser logged on remotelyUser VPN’s inProgram or system authenticated locally/remotely\\nAuthentication Failure, Logs reporting failed user and system authentication activity.\\xa0 Due to bad credentials or unauthorized attempt (user not allowed to log in), User login failedVPN login failedProgram or system authentication failed\\nAccess Success, Logs reporting successful read, write, or execute access on files, programs, and other relevant objects.Client Applications, Desktop Applications, Scripts, File readFile modifiedFile deletedProgram executed\\nAccessFailure, Logs reporting failed read, write, or execute access on files, programs, and other relevant objects. Client Applications, Desktop Applications, Scripts, Unauthorized file read attemptUnauthorized file modification attemptUnauthorized file deletion attemptUnauthorized program execution attempt\\nOther Audit Success, Logs reporting on successful audited activity not otherwise classifiable., Successful authentication/authorizationKerberos ticket exchange messagesSuccessful Credential Passing\\nOther Audit Failure, Logs reporting on failed audited activity not otherwise classifiable., Failed authentication/authorization Kerberos ticket exchange messages\\nOther Audit, Logs reporting on audited activity not otherwise classifiable., \\nStartup and Shutdown\\nLogs reporting on activity pertaining to the starting and stopping of a system, device, application, or other relevant object.\\nServer or provider Services, Daemons, Windows Services.\\nCritical Service – prevent network access; related to infrastructure service, security or auditing, authentication, accessibility (most likely due to shutdown caused by failures)\\nSystem Started\\nSystem Rebooted\\nAudit Process Started\\nIPSEC Agent Started\\nHTTPD Service Started\\nSQL Server Service\\xa0 Stopped\\nUnexpectedly\\nAnti Virus Stopped\\nConfiguration\\nLogs reporting on activity pertaining to the state or configuration of a system where not related to a Policy.\\nCritical Service – changes to devices that can prevent network access; are related to infrastructure service, security or auditing, authentication, accessibility\\nEnsure the following have RR = 0 -- Normal Registry and Active Directory modifications\\nSoftware installed\\nConfiguration changed\\nSoftware removed\\nAnti Virus Scheduled Scan deleted\\nService Startup configuration changes\\nActive Directory Configuration changed (rr=3)\\nActive Directory Content changed (rr=0)\\nEnabling / Disabling Services and or Protocols\\nPolicy\\nLogs reporting on activity pertaining to the policy of a network, system, device, or other relevant object. Includes configuration changes related to a Policy\\nIn general, most of the Policy changes will be set to RR=3 & forwarded as it will be difficult to know if it is a user level change.\\nDomain Policy changed\\nAudit Policy set\\nAccess Control Policy changed\\nContent Management modified\\nUser Level/Workstation Level\\nPolicy changed (Screensaver settings)\\nUser account/group created\\nUser account properties (for example, name) changed\\nPassword changed\\nUser account/group deleted\\nAccess Granted\\nLogs reporting on activity related to granting of access rights and privileges.\\nUser account was modified to grant access on a permanent state.\\nUser added to group\\nAccess to file granted\\nAccess to program granted\\nAdministrator role granted\\nBackup role granted\\nAccess Revoked\\nLogs reporting on activity related to revocation of access rights and privileges.\\nUser removed from group\\nAccess to file revoked\\nAccess to program revoked\\nAdministrator role revoked\\nBackup role revoked\\nAuthentication Success\\nLogs reporting success user and system authentication activity.\\xa0 User or system gaining access through any method of authentication.\\nUser logged on locally\\nUser logged on remotely\\nUser VPN’s in\\nProgram or system authenticated locally/remotely\\nAuthentication Failure\\nLogs reporting failed user and system authentication activity.\\xa0 Due to bad credentials or unauthorized attempt (user not allowed to log in)\\nUser login failed\\nVPN login failed\\nProgram or system authentication failed\\nAccess Success\\nLogs reporting successful read, write, or execute access on files, programs, and other relevant objects.\\nClient Applications, Desktop Applications, Scripts\\nFile read\\nFile modified\\nFile deleted\\nProgram executed\\nAccess\\nFailure\\nLogs reporting failed read, write, or execute access on files, programs, and other relevant objects. Client Applications, Desktop Applications, Scripts\\nUnauthorized file read attempt\\nUnauthorized file modification attempt\\nUnauthorized file deletion attempt\\nUnauthorized program execution attempt\\nOther Audit Success\\nLogs reporting on successful audited activity not otherwise classifiable.\\nSuccessful authentication/authorization\\nKerberos ticket exchange messages\\nSuccessful Credential Passing\\nOther Audit Failure\\nLogs reporting on failed audited activity not otherwise classifiable.\\nFailed authentication/authorization Kerberos ticket exchange messages\\nOther Audit\\nLogs reporting on audited activity not otherwise classifiable.\\n\\n', 'Audit Classification Defaults': 'This table gives Audit Classification defaults for Risk Rating (RR), Event Forwarding, and LogMart Forwarding.\\nClassification, Default Risk Rating*, Default Event Forwarding**, Default LogMart Forwarding\\nStartup and Shutdown, 0 / 3 (Critical Service), If RR > 0, If RR > 0\\nConfiguration, 2, Yes, Yes\\nPolicy, 2, Yes, Yes\\nAccount Created, 3, Yes, Yes\\nAccount Modified, 1, Yes, Yes\\nAccount Deleted, 0, Yes, Yes\\nAccess Granted, 3 / 5 if admin privilege granted, Yes, Yes\\nAccess Revoked, 0, No, Yes\\nAuthentication Success, 0 / 1 if privileged user, If RR > 0, Yes\\nAuthentication Failure, 0, Yes, Yes\\nAccess Success, 0, No, Yes\\nAccess Failure, 1, Yes, Yes\\nOther Audit Success, 0, No, No\\nOther Audit Failure, 1, Yes, Yes\\nOther Audit, 0, No, No\\n*\\nThis is the usual Risk Rating assigned to a Common Event associated with this classification.\\xa0 However, Risk Ratings varies by Common Event within the same classification.\\xa0 This value is a general default, not strictly enforced.\\n**\\nThis is the default setting for forwarding the log to the Platform Manager assigned to a Common Event associated with this classification.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nUnderstand the LogRhythm Architecture\\n/\\nLog Processing\\n', 'Operations Classifications': 'The following tables provide Operations classification information. This table lists descriptions and examples.\\nClassification, Description, Examples Of\\nCritical, Logs reporting critical conditions., Power supply failureUnrecoverable errorCPU overheating\\nError, Logs reporting error conditions., Socket Initialization FailureCertificate validation packet received with errorHTTP – 64 Server Error Failed Connection Attempt\\nWarning, Logs reporting warnings., Notification Limit ExceededWireless Device Decreasing RX/TX Power\\nInformation, Logs reporting general information., Configuration File LoadedInterface status OKHTTP – 200 Success Response\\nNetwork Allow, Logs reporting on network activity that was allowed per a device policy., Allowed ConnectionAllowed ProtocolAllowed Packet\\nNetwork Deny, Logs reporting on network activity that was not allowed per a device policy., Denied ConnectionDenied/ ProtocolDenied/dropped Packet\\nNetwork Traffic, Logs reporting on network traffic activity such as flows, connections, and usage statistics, Network Flow LogsNetwork Accounting LogsPacket Logs\\nOther Operations, Logs reporting on operations activity not otherwise classifiable, \\nPower supply failure\\nUnrecoverable error\\nCPU overheating\\nSocket Initialization Failure\\nCertificate validation packet received with error\\nHTTP – 64 Server Error Failed Connection Attempt\\nNotification Limit Exceeded\\nWireless Device Decreasing RX/TX Power\\nConfiguration File Loaded\\nInterface status OK\\nHTTP – 200 Success Response\\nAllowed Connection\\nAllowed Protocol\\nAllowed Packet\\nDenied Connection\\nDenied/ Protocol\\nDenied/dropped Packet\\nNetwork Flow Logs\\nNetwork Accounting Logs\\nPacket Logs\\n', 'Operation Classification Defaults': 'This table gives defaults for Risk Rating (RR), Event Forwarding, and LogMart Forwarding.\\nClassification, Default Risk Rating *, Default EventForwarding **, Default LogMart Forwarding\\nCritical, 9, Yes, Yes\\nError, 7, Yes, Yes\\nWarning, 5, Yes, Yes\\nInformation, 0, No, No\\nNetwork Allow, 0, No, No\\nNetwork Deny, 1, No, No\\nNetwork Traffic, 0, No, No\\nOther Operations, 0, No, No\\n*This is the usual Risk Rating assigned to a Common Event associated with this classification.\\xa0 However, Risk Ratings varies by Common Event within the same classification.\\xa0 This value is a general default, not strictly enforced.\\n**This is the default setting for forwarding the log to the Platform Manager assigned to a Common Event associated with this classification.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nUnderstand the LogRhythm Architecture\\n/\\nLog Processing\\n', 'Security Classifications': 'The following tables provide Security classification information. This table lists descriptions and examples.\\nClassification, Description, Examples Of\\nCompromise, Logs reporting on a successful system or network compromise.** Seen more on Host Intrusion Detection Systems (HIDS) than network based detection mechanisms. **, Admin privileges gainedUnauthorized data accessSeizing control of the logical flow of program executionModification of any critical file.Creation of unauthorized processes.Modification a system configuration via use of an exploit.\\nAttack, Logs reporting on activity indicative of a system or network attack where it is either assumed to have been successful or cannot be assumed to have failed.\\xa0 Attack is known to have originated from a “Bad Guy” source., Buffer overflowSQL Injection attackForceful BrowsingSession HijackingPassword Guessing (Dictionary)Known Exploits\\nDenial of Service, Logs reporting on activity indicative a denial of service where it is assumed to have succeeded or cannot be assumed to have failed., DOS AttackDistributed DOS AttackResource StarvationSpinning (process starving CPU)SynFlood AttackPing of DeathWin NukeSpam FloodingTeardrop\\nMalware, Logs reporting on activity indicative of malware installation, propagation, or use.This classification is set to RR=9 because malware is indicative of complex control of systems within the environment possibly leading to data loss with malicious intent, theft, tampering, etc., Trojan horse installedBackdoor traffic observedWorm propagatedVirus activity observedSpyware software installed\\nSuspicious, Logs reporting on activity that is suspicious but not known to be an attack or unauthorized., Multiple failed login attempts (5 – 10 times)Packets with abnormal payloadsUse of default user accounts (root, administrator, guest) detected by an ids and not an audit log.Access from outside anticipated use zone(s).\\nReconnaissance, Logs reporting on activity indicative of or directly indicating system or network reconnaissance., Port ScanPort ProbeService enumerationProgram enumerationUser list enumerationDirectory enumerationWeb crawling\\nMisuse, Logs reporting on activity indicative of system or network misuse., Public webmail usagePornographic content observedUnauthorized program accessContent policy violationP2P Usage\\nActivity, Logs reporting on general system or network activity., Packet type observedPacket payload dumpInterface set in promiscuous modeAttack ResponseForensic related activity\\nFailed Attack, Logs reporting on attack activity that was not successful, possibly due to preventative measures., Buffer overflow droppedSQL Injection dropped\\nFailed Denial of Service, Logs reporting on denial of service activity that was not successful, possibly due to preventative measures., DOS attack preventedDistributed DOS attack prevented\\nFailed Malware, Logs reporting on malware activity that was not successful, possibly due to preventative measures., Trojan horse installation detected and droppedWorm propagation blocked\\nFailed Suspicious, Logs reporting on suspicious activity that was not successful, possibly due to preventative measures., Packet with abnormal payload droppedHotmail usage blockedPornographic content blockedUnauthorized program access denied\\nFailed Activity, Logs reporting on general system or network activity that was not successful, possibly due to preventative measures, Drop Peer to PeerFTP Command Denied\\nOther Security, Logs reporting on security activity not otherwise classifiable, \\nAdmin privileges gained\\nUnauthorized data access\\nSeizing control of the logical flow of program execution\\nModification of any critical file.\\nCreation of unauthorized processes.\\nModification a system configuration via use of an exploit.\\nBuffer overflow\\nSQL Injection attack\\nForceful Browsing\\nSession Hijacking\\nPassword Guessing (Dictionary)\\nKnown Exploits\\nDOS Attack\\nDistributed DOS Attack\\nResource Starvation\\nSpinning (process starving CPU)\\nSynFlood Attack\\nPing of Death\\nWin Nuke\\nSpam Flooding\\nTeardrop\\nTrojan horse installed\\nBackdoor traffic observed\\nWorm propagated\\nVirus activity observed\\nSpyware software installed\\nMultiple failed login attempts (5 – 10 times)\\nPackets with abnormal payloads\\nUse of default user accounts (root, administrator, guest) detected by an ids and not an audit log.\\nAccess from outside anticipated use zone(s).\\nPort Scan\\nPort Probe\\nService enumeration\\nProgram enumeration\\nUser list enumeration\\nDirectory enumeration\\nWeb crawling\\nPublic webmail usage\\nPornographic content observed\\nUnauthorized program access\\nContent policy violation\\nP2P Usage\\nPacket type observed\\nPacket payload dump\\nInterface set in promiscuous mode\\nAttack Response\\nForensic related activity\\nBuffer overflow dropped\\nSQL Injection dropped\\nDOS attack prevented\\nDistributed DOS attack prevented\\nTrojan horse installation detected and dropped\\nWorm propagation blocked\\nPacket with abnormal payload dropped\\nHotmail usage blocked\\nPornographic content blocked\\nUnauthorized program access denied\\nDrop Peer to Peer\\nFTP Command Denied\\n', 'Security Classification Defaults': 'This table gives defaults for Risk Rating (RR), Event Forwarding, and LogMart Forwarding.\\nClassification, Default Risk Rating (RR)*, Default EventForwarding**, Default LogMartForwarding\\nCompromise, 9, Forward All, Forward All\\nAttack, 8, Forward All, Forward All\\nDenial of Service, 8, Forward All, Forward All\\nMalware, 9, Forward All, Forward All\\nSuspicious, 6, Forward All, Forward All\\nReconnaissance, 4, Forward All, Forward All\\nMisuse, 5, Forward All, Forward All\\nActivity, 0, Forward If, Forward Events\\nFailed Attack, 0, Forward None, Forward All\\nFailed Denial of Service, 0, Forward None, Forward All\\nFailed Malware, 0, Forward None, Forward All\\nFailed Suspicious, 0, Forward None, Forward All\\nFailed Activity, 0, Forward None, Forward None\\nOther Security, 0, Case by Case, Forward Events\\n*This is the usual Risk Rating assigned to a Common Event associated with this classification.\\xa0 However, Risk Ratings will vary by Common Event within the same classification.\\xa0 This value is a general default, not strictly enforced.\\n**This is the default setting for forwarding the log to the Platform Manager assigned to a Common Event associated with this classification.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n', 'Alarms': '\\n', 'What is an Alarm?': 'An alarm is a record of an event, or series of events, that triggered an alarm rule. In LogRhythm SIEM, alarm rules watch for certain conditions such as attacks on the network, compliance issues, system errors, and so on. For example, if log data reveals that a Trojan attempted to enter the network, an alarm rule such as \"Alarm on Malware\" is triggered that notifies administrators. The alarm rule can also trigger remediation (SmartResponse) actions, such as scripts for disabling an Active Directory account or killing a running process.\\nLogRhythm SIEM provides a wide variety of predefined rules, which administrators can load through the Knowledge Base Import process. Alarm rules are configured and managed in the Client Console. For more information, see\\nAlarm Rules\\nin the Client Console (Administrator\\'s Guide).\\n', 'How Alarms are Triggered': 'An alarm can be triggered in LogRhythm SIEM, as follows:\\nThe Data Processor receives logs from Agents. The log processing engine, called the Message Processing Engine (MPE), then processes log data and classifies a subset as MPE Events. For more details, see the\\nLogRhythm Architecture\\n.\\nThe Data Processor receives logs from Agents. The log processing engine, called the Message Processing Engine (MPE), then processes log data and classifies a subset as MPE Events. For more details, see the\\nLogRhythm Architecture\\n.\\n\\nThe Data Processor forwards MPE events to the Platform Manager. If the Advanced Intelligence (AI) Engine is configured in the LogRhythm SIEM deployment, the Data Processor can also send copies of logs to the AI Engine for additional analysis. The AI Engine evaluates the logs against its AIE Correlation Rules. If a log triggers an AIE Rule, the AI Engine sends an AIE event to the Platform Manager (with Alarm rules already applied).\\nAs events move into the Platform Manager, the integrated Alarming and Response Manager (ARM) applies Alarm rules to the live stream of events data. If an Alarm rule matches an event, an alarm is created.\\nAlarms can trigger one or both of the following actions:\\nNotification\\n. An alert is sent to administrators via SNMP traps, email (SMTP), or text files.\\nRemediation (SmartResponse)\\n. An automated script responds with an action to resolve the issue.\\nAlarms can trigger one or both of the following actions:\\nNotification\\n. An alert is sent to administrators via SNMP traps, email (SMTP), or text files.\\nNotification\\n. An alert is sent to administrators via SNMP traps, email (SMTP), or text files.\\nRemediation (SmartResponse)\\n. An automated script responds with an action to resolve the issue.\\nRemediation (SmartResponse)\\n. An automated script responds with an action to resolve the issue.\\n', 'SmartResponse Actions': 'SmartResponse actions are automated defensive or operational responses to triggered alarm rules. The following examples describe some of the different functions that SmartResponse actions can perform:\\nWhen compromised systems are detected, SmartResponse actions can perform vulnerability scans or packet captures on the target hosts.\\nSmartResponse actions can kill inappropriate processes (such as BitTorrent or a Peer2Peer application) detected on a server.\\nWhen LogRhythm SIEM observes concurrent successful logins to the same account from two different countries, SmartResponse actions can disable the account.\\nSmartResponse actions can automatically set network devices to debug-level logging when LogRhythm SIEM observes critical operations issues on them.\\nAn alarm rule can be configured to start up to 10 SmartResponse actions when triggered. Actions can be run immediately or after a quorum-approval process. In a quorum process, individuals or groups are required to approve the action before it runs (up to three levels of approval may be configured). When multiple individuals are assigned to the same level, only one person needs to provide approval or denial.\\nFrom the Web Console, you can use the Inspector panel to view the details of SmartResponse actions and manage their approval statuses. For more information, see\\nView Additional Alarm Information\\nand\\nApprove or Deny SmartResponse Actions\\n.\\nYou cannot create, configure, or remove SmartResponse actions with the Web Console. These tasks can only be performed in the Client Console.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n', 'Analyzer Grid': '\\nLogRhythm Agents collect raw log data from various devices and also monitor hosts to gather forensic data. The Agents then send that collected data to Data Processors, which parse the raw logs into relevant metadata. For any logs that meet certain criteria (immediate operational, security, or compliance relevance), the Data Processor categorizes those important logs as \"Events.\" For more information, see the\\nUnderstand the LogRhythm Architecture\\ntopic in the SIEM Help.\\nIn the Web Console, you can view the following types of data:\\nEvents\\n. The high-level data shown on the Dashboards page. Events typically include logs that indicate errors, failures, or attacks. Either the Data Processor or the AI Engine (if integrated) can classify a log as an event:\\nMPE Events\\n. Classified by the Data Processor\\'s Message Processing Engine (MPE).\\nAIE Event\\n. Classified by the AIE\\'s rules. Event data is displayed on the Dashboards in a variety of chart types.\\nMPE Events\\n. Classified by the Data Processor\\'s Message Processing Engine (MPE).\\nAIE Event\\n. Classified by the AIE\\'s rules. Event data is displayed on the Dashboards in a variety of chart types.\\nMetadata\\n. The parsed log data available in the Analyzer grid. Data Processors derive metadata from the raw logs, and when applicable, also add contextual information such as the known application or geographic location. Metadata can provide such information as impacted hosts, IP addresses, and origin of the data.\\nRaw Logs\\n. The unprocessed data sent from Agents. You can view the raw log by selecting an entry (row) in the grid and then clicking on the\\nLog Message\\ntab in the Details & Actions pane.\\nThe Analyzer grid provides details on the log activities that generate events. Each line in the grid shows the metadata associated with a single event or log.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n', 'Case Management': 'The Case Management feature is a collaborative forensic tool for creating cases to track and document suspicious logs and alarms that are believed to be related to the same threat. The ability to create, own, and tag cases, as well as to collaborate on cases that are created and owned by others, is extended only to Web Console users who are granted permission. These permissions are configured in the Client Console. For information about permission,\\xa0see the\\nModify User Profile Management Permissions\\ntopic in the LogRhythm SIEM Help.\\nBy default, all user roles have access to the Case Management feature. To hide the Case Management feature from a user role, open the Client Console and do the following:\\nFrom the Tools menu in the Deployment Manager window, select\\nAdministration\\n, and then click\\nUser Profile Manager\\n.\\nIn the User Profile Manager window, double-click the user role that you want to modify.\\nThe User Profile Properties dialog box appears.\\nFrom the General tab, clear the\\nLogRhythm Case Management Access\\ncheck box.\\nFor more information on configuring Case Management user roles in the Client Console, see the\\nUser Profile Manager\\nsection in the LogRhythm SIEM Help.\\nFrom the Current Case panel on the Dashboards page, Alarms page, and Analyze page, you can create new cases and build upon existing ones whenever you encounter logs, alarms, or files that can be used as evidence. The Cases page provides an expanded layout and customizable dashboards for you to further view and manage the cases you are working on.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n', 'Cloud to Cloud Log Collection': 'Currently, Cloud to Cloud log collection is available only for LogRhythm Cloud customers.\\nLogRhythm Cloud to Cloud (C2C) facilitates the creation, management, and collection of cloud log source information through a user interface in the Web Console. C2C credentials are used to safely and securely provision an appropriate collection method (either Open Collector with Beats or a System Monitor Agent).\\nIn a future release, LogRhythm will host a System Monitor Agent in the cloud for collection of syslog from the Open Collector. This System Monitor Agent will also be able to collect cloud log sources that use the System Monitor Agent as their primary collection method. The Agent will have a maximum collection rate of\\xa05000 MPS. Request for a System Monitor Agent is unnecessary.\\nAs of LogRhythm 7.8.0, the\\nfollowing beats are supported for C2C collection:\\nAzure Event Hub Beat\\nCarbon Black Cloud Beat\\nCisco AMP Beat\\nDuo Authentication Security Beat\\nGmail Message Tracking Beat\\nOkta Beat\\nPubSub Beat\\nSophos Central Beat\\n\\nAPI log sources:\\nOffice365 Management activity\\nOffice365 Message Tracking\\nAWS CloudTrail Events\\nAWS CloudWatch Events and Alarms\\nAWS Config Events\\nAWS Simple Storage Service (S3) Events\\nAWS S3 CloudTrail Events\\n\\nFor more details on configuring and initializing C2C collection using beats, see\\nOCBeats\\n.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n', 'Dashboards': '\\nDashboards refer to the interchangeable widget-based user interfaces on the Dashboards page, Analyze page, Cases page, and Reports page. Predefined dashboards are available for these pages, but you can also create, customize, and save additional dashboards to accommodate your different information needs.\\nWhen you first log in to the Web Console, the Dashboards page displays. This is your main view for reviewing real-time Events data as it is processed through LogRhythm SIEM in easy-to-read charts and graphs that automatically update their displays to reflect changes in live data. The Web Console can display up to the last 250,000 Events (approximately) in the cache.\\nIf you are logged in as a restricted user, the Processing Rate gauge, Trend chart, Component Status widget, System Database Usage widget, and Threat Activity Map do not appear on the Dashboards page. Global Admins can set\\nManagement Permissions\\nin the Client Console to allow Restricted Admins view permissions for the\\nDatabase Usage, Component Status, and Processing widgets.\\nThe name next to the Dashboard icon on the upper-right side of the relevant pages tells you which dashboard displays.\\n\\n', 'Public vs. Private Dashboard Layouts': 'Public dashboards can be accessed by all Web Console users, but only Global Administrators can create or modify them. A private dashboard view can be accessed and viewed only by the individual user who created it. Permission to create and manage private dashboards extends to all users.\\nYou can download Dashboards by going to the\\nLogRhythm Community\\nand clicking on the\\nShareables\\nlink on menu at the top of the page. The filters allow you to choose from supported and unsupported Dashboards, as well as ones created by LogRhythm or by other users.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n', 'Lists in Web Console': '\\nLists are an important part of the LogRhythm, Inc. software and are available in both the Client Console and the Web Console. Currently, the Web Console provides limited functionality for list management and use. Before using lists, it is important to understand list types, use contexts, multi-type lists, lists within lists, and permissions. For more background information about lists, see\\nLists in the Client Console\\n.\\nThe Web Console does not allow you to import lists, retire lists, or delete lists. All of these actions must be done in the Client Console.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n', 'Log Collection in Web Console': 'LogRhythm version 7.14 introduces Open Collector and SIEM integration, allowing users to view and manage Open Collectors and Beats from the Web Console. After updating the SIEM to 7.14 and the Open Collector to the latest version, the Long-Running LRCTL service needs to be configured and initialized. This service runs in the background on the Open Collector and manages the configurations applied in the LogRhythm Web Console.\\nYou must initialize the Long-Running LRCTL service to work with Open Collectors and Beats in the Web Console. For instructions on how to initialize the service, see\\nConfigure Open Collector Connection to the SIEM\\n.\\nThe following Beats are available to configure in the Web Console:\\nAWS S3\\nAWS S3\\nAzure Event Hub\\nAzure Event Hub\\nCarbon Black Cloud\\nCarbon Black Cloud\\nCisco AMP\\nCisco AMP\\nDarktrace\\nDarktrace\\nDuo Authentication Security\\nDuo Authentication Security\\nGmail Message Tracking\\nGmail Message Tracking\\nGSuite\\nGSuite\\nKafka\\nKafka\\nMicrosoft Graph API\\nMicrosoft Graph API\\nOkta\\nOkta\\nPrisma Cloud\\nPrisma Cloud\\nProofpoint\\nProofpoint\\nPubSub\\nPubSub\\nQualys FIM\\nQualys FIM\\nSophos Central\\nSophos Central\\nSymantec WSS\\nSymantec WSS\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n', 'Playbooks': '\\nPlaybooks represent a way to store and manage standard procedures, including documentation of those procedures. Playbooks could be used for malware, phishing, or other processes such as unapproved software installations.\\nFor many types of security incidents, there are standard and consistent steps that must be taken by security analysts. For example, if a user’s account is suspected to be compromised, a Suspected Account Compromise playbook may contain the following steps:\\nLocking down their account.\\nContacting the suspicious user.\\nContacting the suspicious user’s supervisor.\\nInvestigating if that user name was associated with any suspicious activity.\\nAn analyst would open a case, and import the\\xa0Suspected Account Compromise\\xa0playbook to auto-populate the above-described series of steps. The analyst could then optionally assign these to collaborators and track progress. This approach helps ensure that a consistent procedure is followed regardless of who is running the case.\\nYou can download Playbooks\\ndesigned by the LogRhythm Threat Research Team\\nby going to the\\nLogRhythm Community\\nand clicking on the\\nShareables\\nlink on menu at the top of the page.\\nYou can also manage playbooks through the REST API. For more information,\\xa0go to https://<hostname>:8501/lr-case-api/docs#tag/playbooks.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n', 'Reports': '\\nThe Reports page provides you with a customizable, widget-based web interface for direct access to your authorized report packages. Available report packages, including the individual reports inside them, are displayed in a grid format that can be filtered and sorted as needed. From the Reports grid you can also view additional package and report details, download reports in PDF format, and run new searches based on report criteria.\\nYou cannot access your reports on the Web Console unless you have been assigned the permission to do so. Report permissions are managed by administrators through the Scheduled Report Job Wizard in the Client Console. For more information, see\\nCreate Scheduled Reports\\nin the Client Console (Analyst Guide).\\nNote that if you change the Authorized User Profiles after a report has been run, users with newly granted access cannot see the report in the Web Console. You must run the report again for it to be visible to the new user profiles.\\nReports grids are displayed through Completed Reports widgets. The default Reports page dashboard layout features one Completed Reports widget covering multiple dashboard rows and columns. The blue counters in the Name column indicate the number of individual reports contained in each report package. To view the individual reports in a package, click the\\nPlus\\nicon to left of the package name.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n', 'Search': '\\nThe Search feature includes a wide range of filter and group selections along with Boolean logic for targeting specific data sets. Search results are displayed on the Analyze page, where you can view the queried information in charts and graphs.\\nThe tail option in search allows you to set up real-time queries that show whether logs or events matching a query are actively being generated and entering the system.\\nWhen searching by keyword, the term you enter needs to be an exact match with the item you are searching for. For example, if you wanted to search for \"Global Admin\" users, you would need to type\\nGlobal Admin\\ninto the Search field. To run searches for all items containing a particular term, you need to include the prefix sql: and insert wildcard symbols (%) as appropriate. For example, if you wanted to run a keyword search for all users with \"admin\" somewhere in their titles, you would type\\nsql:%admin%\\ninto the Search field.\\nWhen searching the Log Message field,\\nsql:\\nand\\n%\\nare not required.\\nThe only required parameter for running a search is a time frame for your results.\\nNote that in deployments utilizing multiple Web Consoles, users can only access search or drill down results on the Web Console server from which the search or drill down originated. For example, if you perform a search on Web Console A and then log in to Web Console B, the search initiated on server A will not be available to you.\\n', 'Search Filters': 'The following table describes the search filters available from the Search lists.\\nSearch Filter, Description\\nAccount by Active Directory Group, The accounts with an Active Directory Group that are the recipients of the action.\\nAddress, The email address involved in the activity, either the sender or recipient. In the Search Term field, type a full email address (for example,name@company.com).\\nCommand, The name of an executed command within the metadata (for example: login, get, or put).\\nCommon Event, A short, plain-language description of the log that determines its classification.When you select Common Event, the Search Term field becomes a typeahead field. For example, if you type \"audit,\" a list opens with all Common Events that match \"audit.\" You can then select an item from the list.\\nDomain, Windows or DNS\\xa0domain either referenced by a log or impacted by log activity.\\nGroup, User group or role referenced or impacted by the log activity. This group is typically an Active Directory group name or other type of logical container.\\nHost List (Impacted)Host List (Origin or Impacted)Host List (Origin), The host involved in the log activity, which may include the IP address, host name, or Ethernet address:Host (Impacted) is the destination.Host (Origin) is the source.With Host filters, you can attain results for a Host List, IP\\xa0Address List, or IP\\xa0Range List as follows:Host List. Begin typing the name of a Host List in the Search field to display the available lists containing matching characters. Search results are based on the contents of the Host List that you select from the list.IP Address ListorIP Range List. Type an IP\\xa0Address or IP\\xa0Range List name in the Search field. Search results are based on the contents of the IP Address List or the IP Range List that you select from the list.To run a Host List search, you need to select from the host lists that have already been created in theClient Console. You cannot create new host lists on the Web Console, and you cannot type free text or non-lists as search criteria for the Host List filter.\\nHostname (Impacted)Hostname (Origin orImpacted)Hostname (Origin), The name of the host involved in the log activity (for example, a DNS name or a Netbios name):Hostname (Impacted) is the destination.Hostname (Origin) is the source.\\nInterface (Impacted)Interface (Origin or Impacted)Interface (Origin), The interface number of a device or physical port number of a switch:Interface (Impacted) is the destination interface.Interface (Origin)\\xa0is the source interface.\\nIP\\xa0Address (Impacted)IP\\xa0Address (Origin or Impacted)IP\\xa0Address (Origin), The IP\\xa0addresses for the log activity:IP Address (Impacted) is the destination address.IP\\xa0Address (Origin) is the source address.\\nKnown Application, Known application or service, such as HTTP, POP3, or Telnet. An application is \"known\" if LogRhythm SIEM can match the protocol number from the log to a service name in the Events Database.\\nKnown Host (Impacted)Known Host (Origin or Impacted)Known Host (Origin), The host record associated with a specific Entity:Known Host (Origin) is the source of the log activity.Known Host (Impacted) is the destination of the log activity.When you select one of theKnown Hostfields, the Search Term field becomes a typeahead field.\\nLocation (Impacted)Location (Origin or Impacted)Location (Origin), The geographic area involved in the log activity:Location (Origin) is the source area.Location (Impacted) is the destination area.When you select one of theLocationfields, the Search Term field becomes a typeahead field.The Location values are derived from the LogRhythm SIEM\\'s GeoLocation feature.\\nLog Source Entity, A logical collection of unique networks, devices, and systems.When you selectLog Source Entity, the Search Term field becomes a typeahead field.\\nLog Source Root Entity, The parent for a logical collection (Log Source Entity).When you selectLog Source Root Entity, the Search Term field becomes a typeahead field.\\nLog Source Type, Type of facility or source where the log originated.When you selectLog Source Type, the Search Term field becomes a typeahead field. For example, if you type \"sys,\" a list opens with all log source types that match \"sys.\" You can then select an item from the list.\\nMAC Address (Impacted)MAC Address (Origin or Impacted)MAC Address (Origin), The MAC address involved in the log message:MAC Address (Origin) is the source.MAC Address (Impacted) is the destination.When searching for MAC addresses, you must separate character strings using a colon (:) or a hyphen (-). For example:AX:4T:77:98:KD:F6:L0orAX-4T-77-98-KD-F6-L0\\nMPE Rule Name, Message Processing Engine(MPE) rule, which identifies and normalizes log messages and then assigns them to a Log Type (Common Event).When you selectMPE Rule, the Search Term field becomes a typeahead field.\\nNAT IP\\xa0Address (Impacted)NAT IP\\xa0Address (Origin or Impacted)NAT IP\\xa0Address (Origin), The IP address that was translated via NAT\\xa0device logs:NAT\\xa0IP\\xa0Address (Origin)\\xa0is the source.NAT\\xa0IP\\xa0Address (Impacted) is the destination.\\nNAT TCP/UDP Port (Impacted)NAT TCP/UDP Port (Origin or Impacted)NAT TCP/UDP Port (Origin), The TCP/UDP port that was translated via NAT\\xa0device logs:NAT\\xa0TCP/UDP\\xa0Port (Origin)\\xa0is the source.NAT\\xa0TCP/UDP\\xa0Port (Impacted) is the destination.\\nNetwork (Impacted)Network (Impacted or Origin)Network (Origin), Network involved in the log activity:Network (Origin) is the source network.Network (Impacted) is the destination network.When you select one of theNetworkfields, the Search Term field becomes a typeahead field.\\nObjectObject Name, Resource that is referenced or impacted by the log activity. An \"object\" can include a file, file path, registry key, etc.The Object field contains the full path and name, but ObjectName only stores the object name.\\nOrigin Login by Active Directory Group, The users within an Active Directory group that are the source of the log activity.When you selectOrigin Login by Active Directory Group, the Term field to the left becomes a typeahead field.\\nPort, The port involved in the activity.The Search Termfield requires an exact value for a specific port, such as 80 or 8080.\\nProcess ID, The ID associated with a process.\\nProcess Name, Name or value that identifies a process (for example, \"inetd\" or \"sshd\").\\nProtocol, Network protocol applicable to the log message.When you selectProtocol, the Search Term field becomes a typeahead field.\\nRecipient, Email address or VOIP\\xa0caller number. For non-email logs, this field could represent the user who received a form of information.\\nSender, Email originator or VOIP\\xa0caller number. For non-email logs, this field could represent the user who received a form of information.\\nSession, The user, system, or application session.\\nSeverity, A value indicating the severity of the log.\\nSubject, Email subject line. For non-email logs, this field could represent the subject in some form of communicated information.\\nTCP/UDP Port (Impacted)TCP/UDP Port (Origin or Impacted)TCP/UDP Port (Origin), The TCP or UDP port number:TCP/UDP Port (Origin) is the source.TCP/UDP Port (Impacted) is the destination.\\nURL, URL referenced or impacted by the log activity.\\nUser (Impacted), The user account that is the recipient of the action (for example, a password reset on a user account).When you select theAccountfilter, you can get results for either an Active Directory Group or a user name string, as follows:Active Directory Group. As you begin typing characters in the Search Term field, it displays a list of all Active Directory Group names that match those characters. If you select a group from the displayed list or if the text you typed matches an Active Directory Group name, results appear for the Active Directory Group.User name string. Type the user name in the Search Term field. If the text you type does not match an Active Directory Group name, results appear for the corresponding user field (Login or Account, or both).\\nUser (Login or Account), The user login or account that is the source of the log activity.When you select theUser (Login or Account)filter, you can get results for either an Active Directory Group or a user name string, as follows:Active Directory Group. As you begin typing characters in the Search Term field, it displays a list of all Active Directory Group names that match those characters. If you select a group from the displayed list or if the text you typed matches an Active Directory Group name, results appear for the Active Directory Group.User name string. Type the user name in the Search Term field. If the text you type does not match an Active Directory Group name, results appear for the corresponding user field (Login or Account, or both).\\nUser (Origin), The user login that is the source of the log activity.When you select theUser (Origin)filter, you can get results for either an Active Directory Group or a user name string, as follows:Active Directory Group. As you begin typing characters in the Search Term field, it displays a list of all Active Directory Group names that match those characters. If you select a group from the displayed list or if the text you typed matches an Active Directory Group name, results appear for the Active Directory Group.User name string. Enter the user name in the Search Term field. If the text you enter does not match an Active Directory Group name, results appear for the corresponding user field (Login or Account, or both).\\nUser by Active Directory Group, The user login within an Active Directory group that is the source of the log activity.When you selectUser Active Directory Group, the Search Term field becomes a typeahead field.\\nVendor Message ID, Unique vendor-assigned value that identifies the log message.\\nVersion, A value that represents a version (OS version, patch version, doc version, etc.).\\nSearch Filter\\nAccount by Active Directory Group\\nThe accounts with an Active Directory Group that are the recipients of the action.\\nAddress\\nThe email address involved in the activity, either the sender or recipient. In the Search Term field, type a full email address (for example,\\nname@company.com\\n).\\nCommand\\nThe name of an executed command within the metadata (for example: login, get, or put).\\nCommon Event\\nA short, plain-language description of the log that determines its classification.\\nWhen you select Common Event, the Search Term field becomes a typeahead field. For example, if you type \"audit,\" a list opens with all Common Events that match \"audit.\" You can then select an item from the list.\\nDomain\\nWindows or DNS\\xa0domain either referenced by a log or impacted by log activity.\\nGroup\\nUser group or role referenced or impacted by the log activity. This group is typically an Active Directory group name or other type of logical container.\\nHost List (Impacted)\\nHost List (Origin or Impacted)\\nHost List (Origin)\\nThe host involved in the log activity, which may include the IP address, host name, or Ethernet address:\\nHost (Impacted) is the destination.\\nHost (Origin) is the source.\\nWith Host filters, you can attain results for a Host List, IP\\xa0Address List, or IP\\xa0Range List as follows:\\nHost List\\n. Begin typing the name of a Host List in the Search field to display the available lists containing matching characters. Search results are based on the contents of the Host List that you select from the list.\\nIP Address List\\nor\\nIP Range List\\n. Type an IP\\xa0Address or IP\\xa0Range List name in the Search field. Search results are based on the contents of the IP Address List or the IP Range List that you select from the list.\\nTo run a Host List search, you need to select from the host lists that have already been created in the\\nClient Console\\n. You cannot create new host lists on the Web Console, and you cannot type free text or non-lists as search criteria for the Host List filter.\\nHostname (Impacted)\\nHostname (Origin or\\nImpacted)\\nHostname (Origin)\\nThe name of the host involved in the log activity (for example, a DNS name or a Netbios name):\\nHostname (Impacted) is the destination.\\nHostname (Origin) is the source.\\nInterface (Impacted)\\nInterface (Origin or Impacted)\\nInterface (Origin)\\nThe interface number of a device or physical port number of a switch:\\nInterface (Impacted) is the destination interface.\\nInterface (Origin)\\xa0is the source interface.\\nIP\\xa0Address (Impacted)\\nIP\\xa0Address (Origin or Impacted)\\nIP\\xa0Address (Origin)\\nThe IP\\xa0addresses for the log activity:\\nIP Address (Impacted) is the destination address.\\nIP\\xa0Address (Origin) is the source address.\\nKnown Application\\nKnown application or service, such as HTTP, POP3, or Telnet. An application is \"known\" if LogRhythm SIEM can match the protocol number from the log to a service name in the Events Database.\\nKnown Host (Impacted)\\nKnown Host (Origin or Impacted)\\nKnown Host (Origin)\\nThe host record associated with a specific Entity:\\nKnown Host (Origin) is the source of the log activity.\\nKnown Host (Impacted) is the destination of the log activity.\\nWhen you select one of the\\nKnown Host\\nfields, the Search Term field becomes a typeahead field.\\nLocation (Impacted)\\nLocation (Origin or Impacted)\\nLocation (Origin)\\nThe geographic area involved in the log activity:\\nLocation (Origin) is the source area.\\nLocation (Impacted) is the destination area.\\nWhen you select one of the\\nLocation\\nfields, the Search Term field becomes a typeahead field.\\nThe Location values are derived from the LogRhythm SIEM\\'s GeoLocation feature.\\nLog Source Entity\\nA logical collection of unique networks, devices, and systems.\\nWhen you select\\nLog Source Entity\\n, the Search Term field becomes a typeahead field.\\nLog Source Root Entity\\nThe parent for a logical collection (Log Source Entity).\\nWhen you select\\nLog Source Root Entity\\n, the Search Term field becomes a typeahead field.\\nLog Source Type\\nType of facility or source where the log originated.\\nWhen you select\\nLog Source Type\\n, the Search Term field becomes a typeahead field. For example, if you type \"sys,\" a list opens with all log source types that match \"sys.\" You can then select an item from the list.\\nMAC Address (Impacted)\\nMAC Address (Origin or Impacted)\\nMAC Address (Origin)\\nThe MAC address involved in the log message:\\nMAC Address (Origin) is the source.\\nMAC Address (Impacted) is the destination.\\nWhen searching for MAC addresses, you must separate character strings using a colon (:) or a hyphen (-). For example:\\nAX:4T:77:98:KD:F6:L0\\nor\\nAX-4T-77-98-KD-F6-L0\\nMPE Rule Name\\nMessage Processing Engine\\n(\\nMPE\\n) rule, which identifies and normalizes log messages and then assigns them to a Log Type (Common Event).\\nWhen you select\\nMPE Rule\\n, the Search Term field becomes a typeahead field.\\nNAT IP\\xa0Address (Impacted)\\nNAT IP\\xa0Address (Origin or Impacted)\\nNAT IP\\xa0Address (Origin)\\nThe IP address that was translated via NAT\\xa0device logs:\\nNAT\\xa0IP\\xa0Address (Origin)\\xa0is the source.\\nNAT\\xa0IP\\xa0Address (Impacted) is the destination.\\n\\nNAT TCP/UDP Port (Impacted)\\nNAT TCP/UDP Port (Origin or Impacted)\\nNAT TCP/UDP Port (Origin)\\nThe TCP/UDP port that was translated via NAT\\xa0device logs:\\nNAT\\xa0TCP/UDP\\xa0Port (Origin)\\xa0is the source.\\nNAT\\xa0TCP/UDP\\xa0Port (Impacted) is the destination.\\nNetwork (Impacted)\\nNetwork (Impacted or Origin)\\nNetwork (Origin)\\nNetwork involved in the log activity:\\nNetwork (Origin) is the source network.\\nNetwork (Impacted) is the destination network.\\nWhen you select one of the\\nNetwork\\nfields, the Search Term field becomes a typeahead field.\\nObject\\nObject Name\\nResource that is referenced or impacted by the log activity. An \"object\" can include a file, file path, registry key, etc.\\nThe Object field contains the full path and name, but ObjectName only stores the object name.\\nOrigin Login by Active Directory Group\\nThe users within an Active Directory group that are the source of the log activity.\\nWhen you select\\nOrigin Login by Active Directory Group\\n, the Term field to the left becomes a typeahead field.\\nPort\\nThe port involved in the activity.\\nThe Search Term\\nfield requires an exact value for a specific port, such as 80 or 8080.\\nProcess ID\\nThe ID associated with a process.\\nProcess Name\\nName or value that identifies a process (for example, \"inetd\" or \"sshd\").\\nProtocol\\nNetwork protocol applicable to the log message.\\nWhen you select\\nProtocol\\n, the Search Term field becomes a typeahead field.\\nRecipient\\nEmail address or VOIP\\xa0caller number. For non-email logs, this field could represent the user who received a form of information.\\nSender\\nEmail originator or VOIP\\xa0caller number. For non-email logs, this field could represent the user who received a form of information.\\nSession\\nThe user, system, or application session.\\nSeverity\\nA value indicating the severity of the log.\\nSubject\\nEmail subject line. For non-email logs, this field could represent the subject in some form of communicated information.\\nTCP/UDP Port (Impacted)\\nTCP/UDP Port (Origin or Impacted)\\nTCP/UDP Port (Origin)\\nThe TCP or UDP port number:\\nTCP/UDP Port (Origin) is the source.\\nTCP/UDP Port (Impacted) is the destination.\\n\\nURL\\nURL referenced or impacted by the log activity.\\nUser (Impacted)\\nThe user account that is the recipient of the action (for example, a password reset on a user account).\\nWhen you select the\\nAccount\\nfilter, you can get results for either an Active Directory Group or a user name string, as follows:\\nActive Directory Group\\n. As you begin typing characters in the Search Term field, it displays a list of all Active Directory Group names that match those characters. If you select a group from the displayed list or if the text you typed matches an Active Directory Group name, results appear for the Active Directory Group.\\nUser name string\\n. Type the user name in the Search Term field. If the text you type does not match an Active Directory Group name, results appear for the corresponding user field (Login or Account, or both).\\nUser (Login or Account)\\nThe user login or account that is the source of the log activity.\\nWhen you select the\\nUser (Login or Account)\\nfilter, you can get results for either an Active Directory Group or a user name string, as follows:\\nActive Directory Group\\n. As you begin typing characters in the Search Term field, it displays a list of all Active Directory Group names that match those characters. If you select a group from the displayed list or if the text you typed matches an Active Directory Group name, results appear for the Active Directory Group.\\nUser name string\\n. Type the user name in the Search Term field. If the text you type does not match an Active Directory Group name, results appear for the corresponding user field (Login or Account, or both).\\nUser (Origin)\\nThe user login that is the source of the log activity.\\nWhen you select the\\nUser (Origin)\\nfilter, you can get results for either an Active Directory Group or a user name string, as follows:\\nActive Directory Group\\n. As you begin typing characters in the Search Term field, it displays a list of all Active Directory Group names that match those characters. If you select a group from the displayed list or if the text you typed matches an Active Directory Group name, results appear for the Active Directory Group.\\nUser name string\\n. Enter the user name in the Search Term field. If the text you enter does not match an Active Directory Group name, results appear for the corresponding user field (Login or Account, or both).\\nUser by Active Directory Group\\nThe user login within an Active Directory group that is the source of the log activity.\\nWhen you select\\nUser Active Directory Group\\n, the Search Term field becomes a typeahead field.\\nVendor Message ID\\nUnique vendor-assigned value that identifies the log message.\\nVersion\\nA value that represents a version (OS version, patch version, doc version, etc.).\\n', 'Event Classifications': 'Event classifications are log messages that are grouped into logical containers, which helps organize vast amounts of log data. You can view classifications in the Web Console data charts and also select them from the Search tool.\\nThe following table describes the Event classifications.\\nClassification, Description\\nAccess Failure, Failed read, write, or execute access on files, programs, and other relevant objects.\\nAccess Granted, Activity related to granting of access rights and privileges.\\nAccess Revoked, Activity related to revocation of access rights and privileges.\\nAccess Success, Successful read, write, or execute access on files, programs, and other relevant objects.\\nAccount Created, Activity related to user or system/computer account creation.\\nAccount Deleted, Activity related to user or system/computer account deletion.\\nAccount Modified, The modification of a user or group outside granting/revoking access. No group level or access level changes.\\nActivity, General system or network activity.\\nAttack, Activity that indicates a system or network attack, where it is either assumed to have been successful or cannot be assumed to have failed.\\nAuthentication Failure, Failed user and system authentication activity, due to bad credentials or unauthorized attempt (user not allowed to log in).\\nAuthentication Success, Successful user and system authentication activity, including a user or system gaining access through any method of authentication.\\nCompromise, Successful system or network compromise.These types of logs are seen more on Host Intrusion Detection Systems (HIDS) than on network-based detection mechanisms.\\nConfiguration, Activity pertaining to the state or configuration of a system where it is not related to a Policy.\\nCritical, Logs reporting critical conditions.\\nDenial of Service, Activity that indicates a Denial of Service attack, where it is assumed to have succeeded or cannot be assumed to have failed.\\nError, Logs reporting error conditions.\\nFailed Activity, General system or network activity that was not successful, possibly due to preventative measures.\\nFailed Attack, Attack activity that was not successful, possibly due to preventative measures.\\nFailed Denial of Service, Denial of Service activity that was not successful, possibly due to preventative measures.\\nFailed Malware, Malware activity that was not successful, possibly due to preventative measures.\\nFailed Misuse, Activity that indicates a system or network misuse that was not successful, possibly due to preventative measures.\\nFailed Suspicious, Suspicious activity that was not successful, possibly due to preventative measures.\\nInformation, Logs reporting general information.\\nMalware, Activity that indicates malware installation, propagation, or use.\\nMisuse, Activity that indicates system or network misuse.\\nNetwork Allow, Network activity that was allowed per a device policy.\\nNetwork Deny, Network activity that was not allowed per a device policy.\\nNetwork Traffic, Network traffic activity such as flows, connections, and usage statistics.\\nOther, Operations activity not otherwise classifiable.\\nOther Audit, Audited activity not otherwise classifiable.\\nOther Audit Failure, Failed audited activity not otherwise classifiable.\\nOther Audit Success, Successful audited activity not otherwise classifiable.\\nOther Security, Security activity not otherwise classifiable.\\nPolicy, Activity pertaining to the policy of a network, system, device, or other relevant object. Includes configuration changes related to a Policy.\\nReconnaissance, Activity that indicates system or network reconnaissance.\\nStartup and Shutdown, Activity pertaining to the starting and stopping of a system, device, application, or other relevant object.\\nSuspicious, Activity that is suspicious, but not known to be an attack or unauthorized.\\nVulnerability, Logs reporting vulnerabilities.\\nWarning, Logs reporting warnings.\\nAccess Failure\\nFailed read, write, or execute access on files, programs, and other relevant objects.\\nAccess Granted\\nActivity related to granting of access rights and privileges.\\nAccess Revoked\\nActivity related to revocation of access rights and privileges.\\nAccess Success\\nSuccessful read, write, or execute access on files, programs, and other relevant objects.\\nAccount Created\\nActivity related to user or system/computer account creation.\\nAccount Deleted\\nActivity related to user or system/computer account deletion.\\nAccount Modified\\nThe modification of a user or group outside granting/revoking access. No group level or access level changes.\\nActivity\\nGeneral system or network activity.\\nAttack\\nActivity that indicates a system or network attack, where it is either assumed to have been successful or cannot be assumed to have failed.\\nAuthentication Failure\\nFailed user and system authentication activity, due to bad credentials or unauthorized attempt (user not allowed to log in).\\nAuthentication Success\\nSuccessful user and system authentication activity, including a user or system gaining access through any method of authentication.\\nCompromise\\nSuccessful system or network compromise.\\nThese types of logs are seen more on Host Intrusion Detection Systems (HIDS) than on network-based detection mechanisms.\\nConfiguration\\nActivity pertaining to the state or configuration of a system where it is not related to a Policy.\\nCritical\\nLogs reporting critical conditions.\\nDenial of Service\\nActivity that indicates a Denial of Service attack, where it is assumed to have succeeded or cannot be assumed to have failed.\\nError\\nLogs reporting error conditions.\\nFailed Activity\\nGeneral system or network activity that was not successful, possibly due to preventative measures.\\nFailed Attack\\nAttack activity that was not successful, possibly due to preventative measures.\\nFailed Denial of Service\\nDenial of Service activity that was not successful, possibly due to preventative measures.\\nFailed Malware\\nMalware activity that was not successful, possibly due to preventative measures.\\nFailed Misuse\\nActivity that indicates a system or network misuse that was not successful, possibly due to preventative measures.\\nFailed Suspicious\\nSuspicious activity that was not successful, possibly due to preventative measures.\\nInformation\\nLogs reporting general information.\\nMalware\\nActivity that indicates malware installation, propagation, or use.\\nMisuse\\nActivity that indicates system or network misuse.\\nNetwork Allow\\nNetwork activity that was allowed per a device policy.\\nNetwork Deny\\nNetwork activity that was not allowed per a device policy.\\nNetwork Traffic\\nNetwork traffic activity such as flows, connections, and usage statistics.\\nOther\\nOperations activity not otherwise classifiable.\\nOther Audit\\nAudited activity not otherwise classifiable.\\nOther Audit Failure\\nFailed audited activity not otherwise classifiable.\\nOther Audit Success\\nSuccessful audited activity not otherwise classifiable.\\nOther Security\\nSecurity activity not otherwise classifiable.\\nPolicy\\nActivity pertaining to the policy of a network, system, device, or other relevant object. Includes configuration changes related to a Policy.\\nReconnaissance\\nActivity that indicates system or network reconnaissance.\\nStartup and Shutdown\\nActivity pertaining to the starting and stopping of a system, device, application, or other relevant object.\\nSuspicious\\nActivity that is suspicious, but not known to be an attack or unauthorized.\\nVulnerability\\nLogs reporting vulnerabilities.\\nWarning\\nLogs reporting warnings.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n', 'SecondLook - Web Console': 'Customers that install the SecondLook API and LRCloud customers who purchase extended archive storage can launch SecondLook restores from the Web Console. Running a restore from the Web Console will hand off the restore job to the SecondLook API.\\nTo access SecondLook in the Web Console:\\nLogin to the Web Console.\\nSelect the Administration menu in the upper right.\\nSelect the Secondlook menu option.\\nUsers that do not have the SecondLook menu option should contact their administrators.\\n', 'Saved Searches': 'In the Saved Searches tab, the following details are available:\\nActions:\\nPlay icon: The saved SecondLook searches are run.\\nEdit icon: The SecondLook Query window is opened.\\nDelete icon: The saved SecondLook searches are deleted.\\nName : The names of the saved SecondLook searches are displayed.\\nDescription : The description for the corresponding SecondLook search is displayed.\\nOwner Name : The name of the user that created the SecondLook search is displayed.\\nRead Permissions\\nWrite Permissions\\nCreated\\nModified\\nActions:\\nPlay icon: The saved SecondLook searches are run.\\nEdit icon: The SecondLook Query window is opened.\\nDelete icon: The saved SecondLook searches are deleted.\\nPlay icon: The saved SecondLook searches are run.\\nEdit icon: The SecondLook Query window is opened.\\nDelete icon: The saved SecondLook searches are deleted.\\nName : The names of the saved SecondLook searches are displayed.\\nDescription : The description for the corresponding SecondLook search is displayed.\\nOwner Name : The name of the user that created the SecondLook search is displayed.\\nRead Permissions\\nWrite Permissions\\nCreated\\nModified\\nThe user can filter any required data by entering the information in the row below the column title in all the above-mentioned columns other than the Actions column.\\n', 'Creating a New SecondLook Search': 'To open the SecondLook Search configuration window, click the\\nNew SecondLook search\\nbutton available at the top of the SecondLook Administration page.\\nConfigure the search criteria of the logs that needs to be restored.\\nUsers will be able to select their time frame, log source filter, and search filters.\\nMore information on the search filters can be found in the\\nWeb Console User Guide\\n.\\nIt is important to be as specific as possible in order to reduce the runtime of the SecondLook search.\\nUsers will be able to select their time frame, log source filter, and search filters.\\nMore information on the search filters can be found in the\\nWeb Console User Guide\\n.\\nIt is important to be as specific as possible in order to reduce the runtime of the SecondLook search.\\nMore information on the search filters can be found in the\\nWeb Console User Guide\\n.\\nIt is important to be as specific as possible in order to reduce the runtime of the SecondLook search.\\nUsers have the following options in the Properties pane:\\nName : Provide a name for the search to be saved and displayed on the Executed Searches tab. It is not necessary that the name must be unique.\\nSelect Log Repositories : Allows users to select the exact repository to which the logs need to be restored.\\nSpecify Recovery Settings:\\nMaximum log messages to recover\\nEntity\\nRead Permission\\nWrite Permission\\nDisable Data Masking for Restore - Personally Identifiable Information (PII), in which information will be masked when restored from the archive file.\\nDescription - Enter a description to describe what this search is about.\\nSave\\nCancel\\nName : Provide a name for the search to be saved and displayed on the Executed Searches tab. It is not necessary that the name must be unique.\\nSelect Log Repositories : Allows users to select the exact repository to which the logs need to be restored.\\nSpecify Recovery Settings:\\nMaximum log messages to recover\\nEntity\\nRead Permission\\nWrite Permission\\nMaximum log messages to recover\\nEntity\\nRead Permission\\nWrite Permission\\nDisable Data Masking for Restore - Personally Identifiable Information (PII), in which information will be masked when restored from the archive file.\\nDescription - Enter a description to describe what this search is about.\\nSave\\nCancel\\n\\n', 'Executed Searches Tab': 'The following columns, information, and actions are available in the Executed Searches tab:\\nActions:\\nPlay icon: The previous SecondLook search is run again. Displayed only for failed/completed searches.\\nEdit icon: Opens the SecondLook Query window with the search details and allows the user to edit the details before running again. Displayed only for failed/completed searches.\\nStop icon: Cancels a running or queued SecondLook search. Displayed only for running or queued SecondLook searches. Updates status to \"Canceled\" when clicked and stops the query.\\nQuick search icon: This icon is enabled only for completed searches. When a user clicks the quick search icon,\\na new search is initiated based on the search criteria mentioned in the corresponding saved search and a search card is displayed at the bottom left of the window. The user can click the search card after the search is complete to open the Analyze page in a new tab with all the search results.\\nName : The names of the saved SecondLook searches are displayed.\\nDescription : The description for the corresponding SecondLook search is displayed.\\nInitiated By : The name of the user that initiated the SecondLook search is displayed.\\nStatus: Shows the progress of the SecondLook search. The available status options are:\\nInProgress\\nQueued\\nCompleted\\nFailed\\nInitiatingStop\\nStopped\\nStart Date : Timestamp of when each SecondLook search was launched.\\nMessages : Displays information on the search such as the progress details, error messages, and information on completed searches including the number of logs found and restored.\\nJob ID : The Job ID number of the SecondLook search is displayed.\\nActions:\\nPlay icon: The previous SecondLook search is run again. Displayed only for failed/completed searches.\\nEdit icon: Opens the SecondLook Query window with the search details and allows the user to edit the details before running again. Displayed only for failed/completed searches.\\nStop icon: Cancels a running or queued SecondLook search. Displayed only for running or queued SecondLook searches. Updates status to \"Canceled\" when clicked and stops the query.\\nQuick search icon: This icon is enabled only for completed searches. When a user clicks the quick search icon,\\na new search is initiated based on the search criteria mentioned in the corresponding saved search and a search card is displayed at the bottom left of the window. The user can click the search card after the search is complete to open the Analyze page in a new tab with all the search results.\\nName : The names of the saved SecondLook searches are displayed.\\nDescription : The description for the corresponding SecondLook search is displayed.\\nInitiated By : The name of the user that initiated the SecondLook search is displayed.\\nStatus: Shows the progress of the SecondLook search. The available status options are:\\nInProgress\\nQueued\\nCompleted\\nFailed\\nInitiatingStop\\nStopped\\nStart Date : Timestamp of when each SecondLook search was launched.\\nMessages : Displays information on the search such as the progress details, error messages, and information on completed searches including the number of logs found and restored.\\nJob ID : The Job ID number of the SecondLook search is displayed.\\nActions:\\nPlay icon: The previous SecondLook search is run again. Displayed only for failed/completed searches.\\nEdit icon: Opens the SecondLook Query window with the search details and allows the user to edit the details before running again. Displayed only for failed/completed searches.\\nStop icon: Cancels a running or queued SecondLook search. Displayed only for running or queued SecondLook searches. Updates status to \"Canceled\" when clicked and stops the query.\\nQuick search icon: This icon is enabled only for completed searches. When a user clicks the quick search icon,\\na new search is initiated based on the search criteria mentioned in the corresponding saved search and a search card is displayed at the bottom left of the window. The user can click the search card after the search is complete to open the Analyze page in a new tab with all the search results.\\nPlay icon: The previous SecondLook search is run again. Displayed only for failed/completed searches.\\nEdit icon: Opens the SecondLook Query window with the search details and allows the user to edit the details before running again. Displayed only for failed/completed searches.\\nStop icon: Cancels a running or queued SecondLook search. Displayed only for running or queued SecondLook searches. Updates status to \"Canceled\" when clicked and stops the query.\\nQuick search icon: This icon is enabled only for completed searches. When a user clicks the quick search icon,\\na new search is initiated based on the search criteria mentioned in the corresponding saved search and a search card is displayed at the bottom left of the window. The user can click the search card after the search is complete to open the Analyze page in a new tab with all the search results.\\nName : The names of the saved SecondLook searches are displayed.\\nDescription : The description for the corresponding SecondLook search is displayed.\\nInitiated By : The name of the user that initiated the SecondLook search is displayed.\\nStatus: Shows the progress of the SecondLook search. The available status options are:\\nInProgress\\nQueued\\nCompleted\\nFailed\\nInitiatingStop\\nStopped\\nInProgress\\nQueued\\nCompleted\\nFailed\\nInitiatingStop\\nStopped\\nStart Date : Timestamp of when each SecondLook search was launched.\\nMessages : Displays information on the search such as the progress details, error messages, and information on completed searches including the number of logs found and restored.\\nJob ID : The Job ID number of the SecondLook search is displayed.\\n\\n', 'Quick Search': 'A quick search button has been added in the Actions column for all the completed searches in the\\nExecuted Searches page of the\\nWeb Console.\\nLog in to the Web Console.\\nOn the top navigation bar,\\nc\\nlick the\\nAdministration\\nicon, and then click\\nSecondLook\\n.\\nClick the\\nExecuted Searches\\ntab.\\nClick the\\nQuick Search\\nicon for the required SecondLook search row.\\nThe quick search icon is only available for completed searches. For searches that are queued, in-progress, or stopped, the quick search icon is disabled.\\nIf the user clicks the quick search icon for any completed search, a search is initiated based on the search criteria mentioned in the corresponding saved search, and a search card is displayed on the bottom left of the page.\\nWhen the search is complete, the user can click on the search card and the Analyze page loads in a new tab with all the search results.\\n\\n\\nFor any completed search, if the corresponding saved search is edited (like timeframe, log repository, or log sources:), then the quick search will return the result using the updated search criteria.\\nFor any completed search, if the corresponding saved search is deleted, then the quick search for that completed SecondLook search will not run and the pop-up message \"Cannot initiate quick search since it has been deleted from saved searches\" is displayed.\\n', 'Execute a Saved SecondLook Search': 'In the Saved Searches tab, click the\\nPlay\\nicon.\\nClick the\\nExecuted Searches\\ntab to view the status of the search.\\nOnly one SecondLook search can be executed at a time. Other searches are queued until the previous search has completed. Once a SecondLook search has completed, the user can do a search against the restored indices to see the restored logs.\\n', 'Searching for Restored SecondLook Data': 'At the top of the page, click\\nSearch\\n, and then click\\nAdvanced..\\n.\\nFill in the same data as used in the SecondLook search (for example, the time frame, log source filter, and search filters).\\nScroll down to\\nLog Repositories\\nand select the off logsar-restore(secondlook) checkbox.\\nClick\\nSearch\\n.\\nA task card appears at the bottom of the page and updates as the search progresses.\\nClick on the task to see the results.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n', 'Single Sign-On': \"LogRhythm Web Console Single Sign-On (SSO) uses industry-standard\\xa0Security Assertion Markup Language (SAML) and supported third-party Identity Providers (IdP) to authenticate and authorize Web Console users. With SSO, customers can manage their users' logons via supported Identity Providers, including Okta, PingOne, and Azure AD.\\nSAML 2.0 is an XML-based protocol that uses security tokens containing assertions to pass information about a security principal (usually an end user) between a SAML authority, named an Identity Provider (IdP), and a SAML consumer, named a Service Provider (SP).\\nExisting Web Console users can implement SSO with their previously-created credentials. New Web Console users can be auto-provisioned, resulting in new Person records (with an associated Login record and User Profile) in the Client Console.\\nFor an SSO user to successfully log in to the Web Console, the Login field from their Person record in the Client Console must match the nameID field from the IdP SAML assertion. For more information, see\\nSSO User Auto-Provisioning\\nand\\nSSO Known Issues and Recommendations\\n.\\n\\n\", 'Requirements and Assumptions': 'You must access the Web Console via a browser within a corporate network or with a correctly-configured VPN if your browser is outside the primary corporate network. This is important because you must be able to resolve and establish a connection to the internal FQDN, hostname, or IP address of the Web Console Server. Publicly-accessible configurations are possible but require additional setup of firewalls, routers, and publicly-trusted certificates.\\nIf you want multiple Web Consoles to support SSO, they must be in a load-balanced configuration. This is required because the configuration is part of the Authentication Service that is common to all Web Consoles. If you have multiple Web Consoles in a non-load-balanced configuration, you must choose one to use with SSO. You must specify which Web Console to use in the SSO configuration parameter Web Console Callback URL.\\nIn the LogRhythm Configuration Manager, ensure the following values are selected:\\nOpen the LogRhythm Configuration Manager.\\nIn the bottom-left next to Advanced View, click\\nShow\\n.\\nScroll down to the Authentication API section.\\nEnsure the parameters are set as follows:\\nParameter\\nSetting\\nWeb Console Multi-factor Authentication Type\\nOff: If you are not currently using Web Console MFA.\\nOn: If you have local logins and/or AD logins that do not use SSO.\\nThis setting applies only to local (SQL) or Active Directory logins. Web Console MFA will not be used for SSO logins.\\nWeb Console SQL Authentication\\nEnabled\\nWeb Console Active Directory Authentication\\nEnabled\\nThis setting may be turned off later to allow only SQL and SSO logins.\\nWeb Console Multi-factor Authentication Type\\nIf you want to use multi-factor authentication in conjunction with Web Console SSO, you must enable it in the same Identity Provider that you use for Web Console SSO so that all of your SSO authentication functions are housed in your preferred IdP.\\nEnsure the parameters are set as follows:\\nParameter, Setting\\nWeb Console Multi-factor Authentication Type, Off: If you are not currently using Web Console MFA.On: If you have local logins and/or AD logins that do not use SSO.This setting applies only to local (SQL) or Active Directory logins. Web Console MFA will not be used for SSO logins.\\nWeb Console SQL Authentication, Enabled\\nWeb Console Active Directory Authentication, EnabledThis setting may be turned off later to allow only SQL and SSO logins.\\nOff: If you are not currently using Web Console MFA.\\nOn: If you have local logins and/or AD logins that do not use SSO.\\nThis setting applies only to local (SQL) or Active Directory logins. Web Console MFA will not be used for SSO logins.\\nEnabled\\nThis setting may be turned off later to allow only SQL and SSO logins.\\nWeb Console Multi-factor Authentication Type\\nIf you want to use multi-factor authentication in conjunction with Web Console SSO, you must enable it in the same Identity Provider that you use for Web Console SSO so that all of your SSO authentication functions are housed in your preferred IdP.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n', 'TrueIdentity': 'TrueIdentities in the Web Console represent a collection of identifiers, such as logins and email addresses, that comprise a single identity. For example, the identity Sarah Smith might have two associated logins (sarah.smith and sarah.smith.sup) and one email address (s.smith@\\ngmail.com\\n) associated. With Identities, the following series of logs are united under the TrueIdentity Sarah Smith:\\nFirst Log Date, User (Origin), User (Origin) Identity, Classification, Common Event, Priority\\n7/22/2017 21:33, sarah.smith, Sarah Smith, Access Granted, Account Added to Group, 13\\n7/22/2017 21:07, sarah.smith_sup, Sarah Smith, Access Failure, Access Object Failure, 21\\n7/22/2017 21:05, sarah.smith, Sarah Smith, Access Granted, Account Added to Group, 10\\n7/22/2017 20:58, s.smith@gmail.com, Sarah Smith, Authentication Failure, User Logon Failure: Bad Password, 19\\nTo manage existing TrueIdentites, and create new TrueIdentities, see the\\nTrueIdentity Sync Client User Guide\\n.\\nIf you have a multi-tenant environment, go to C:\\\\Program Files\\\\LogRhythm\\\\LogRhythm Mediator Server\\\\config, and set the EnableIdentityEntitySegregation parameter in the scmedsvr.ini to\\nTrue\\n. When configuring Active Directory (AD) synchronization, select the root entity of your Data Processor and Agent hosts that contains the logs and log sources you would like to monitor with CloudAI.\\nFor more information, see the setting information in\\nthe\\nData Processor\\nsection of the SIEM Help\\n. and the\\nUEBACAI\\ndocumentation.\\nTo access the TrueIdentity page, on the top navigation bar, click the\\nAdministration\\nicon, and select\\nTrueIdentity\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n', 'User Interface': 'The Web Console user interface consists of a combination of pages, panels, and tools.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n', 'User Settings': '\\nThe Web Console User Settings allow you to perform several basic administration tasks.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n', 'Widgets': 'A widget is a mini-application for displaying information on the Dashboards page and Analyze page. You can review real-time event data in Current Processing Rate, Data Processing Trend, Node Link Graph, Timeline, and TopX data widgets. The widgets\\xa0update automatically to show the past 250,000 events (approximately) in the cache. You can resize and move widgets around to create new dashboard layouts, and configure widgets to display different types of information about case trends, component statuses, processing rates, data processing trends, system database usage, threat activity, and top events for dozens of metadata types.\\xa0While on the Analyze page, you can query further to redraw data in the displayed charts\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nAlarms\\n', 'Approve or Deny SmartResponse Actions in the Web Console': 'On an Alarm card, you can determine whether an alarm has SmartResponse actions that are pending approval by the status displayed in the bottom bar of the card.\\nPending SmartResponses are only visible in the Alarm grid view by selecting an alarm and looking in the SmartResponse Actions section of the Inspector panel.\\nYou can approve or deny SmartResponse actions from the Alarm card view on the Alarms page or wherever else you are able to view detailed alarm information (such as in the Current Case panel or the Inspector panel of the Alarm grid view).\\nTo approve or deny SmartResponse actions:\\nOn the navigation bar, click\\nAlarms\\n,\\nSelect an alarm with a pending SmartResponse.\\nClick the\\nInspector\\ntab to expand the Inspector panel, if necessary.\\nThe Inspector panel opens. In the SmartResponse actions section, Approve and Deny buttons are displayed for each pending SmartResponse action. At the bottom of the section, the action run order is indicated by one of the following messages:\\nRun actions at the same time\\n. Indicates that none of the SmartResponse actions depend upon each other, and that you can run any one of them regardless of whether the others are run.\\nRun actions in the order listed\\n. Indicates an interdependency that requires each action to run before the subsequent action can be run. To properly approve these interdependent actions, they need to be approved in the order that they are listed from top to bottom.\\nRun actions at the same time\\n. Indicates that none of the SmartResponse actions depend upon each other, and that you can run any one of them regardless of whether the others are run.\\nRun actions in the order listed\\n. Indicates an interdependency that requires each action to run before the subsequent action can be run. To properly approve these interdependent actions, they need to be approved in the order that they are listed from top to bottom.\\nClick either\\nApprove\\nor\\nDeny\\nfor each SmartResponse action in accordance with the order requirements.\\nIf you select\\nDeny\\n, the SmartResponse action does not run and its status in the Inspector panel changes to \"denied.\" Administrators on the approval list may receive an email regarding the action (depending on whether their SIEM Person records include a valid email address).\\nIf you select\\nApprove\\nand the SmartResponse action requires additional approvals, the Approved button dims to indicate that you have approved it. The number of additional approvals needed to run the action is displayed to the left of the button.\\nIf no additional approvals are needed for a SmartResponse action, the Approved button is replaced with a message indicating whether the action succeeded or failed.\\nAfter all the actions have been either approved or denied, the SmartResponse action status on the alarm card updates to one of the following depending on their collective rates of success, failure, and/or denial:\\nSucceeded\\nPartial Failure\\nFailed\\nPartial Denied\\nDenied\\nAdministrators on the approval list may also receive an email regarding the action results (depending on whether their SIEM Person records include a valid email address).\\nSucceeded\\nPartial Failure\\nFailed\\nPartial Denied\\nDenied\\nAdministrators on the approval list may also receive an email regarding the action results (depending on whether their SIEM Person records include a valid email address).\\n(Optional)\\nClick the arrow to collapse the Inspector panel.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nAlarms\\n', 'View Additional Alarm Information': 'You can use the Inspector panel to view alarm metadata as well as the details related to any SmartResponse actions, user comments, or AIE rules that are associated with an alarm. You can also use the Inspector panel to make changes to an alarm status, add the alarm to a case, and start a drill down search.\\nThe following procedure can also be directly applied to alarm cards displayed in case evidence outside the Alarms page.\\nTo view additional information or make changes using the Inspector panel:\\nOn the navigation bar, click\\nAlarms\\n.\\nSelect an alarm by doing one of the following:\\nIn the Alarm card view, click an Alarm card to select it. A glowing blue border appears around the selected Alarm card.\\nIn the Alarm grid view, click anywhere in a row on the Alarm grid. The row is filled light blue.\\nIn the Alarm card view, click an Alarm card to select it. A glowing blue border appears around the selected Alarm card.\\nIn the Alarm grid view, click anywhere in a row on the Alarm grid. The row is filled light blue.\\nOn the upper-right side of the Alarms page, click the\\nInspector\\ntab.\\nThe Inspector panel opens.\\nAlarm information in the Inspector panel is divided into sections for Data, Alarm Actions, SmartResponse Actions, Comments, and Details.\\nThe following are detailed descriptions of each section:\\nThe\\nData\\nsection includes the following information:\\nAlarm ID\\n. An internal number representing a unique alarm instance.\\nAlarm Date\\n. The date and time that the alarm was triggered.\\nAlarm Name\\n. The alarm name as defined in the alarm rule.\\nMetadata fields\\n. Each metadata field is listed individually. For descriptions of each\\nmetadata field,\\xa0see the \"Lucene Search Syntax\" table in\\nMetadata Fields\\n.\\nThe properties shown in the Data section are the same as the values shown in the Alarm Properties window in the Client Console.\\nIf the host listed in the Host (Origin) or Host (Impacted) field is a Known Host, an Information icon appears next to the text. Hover your mouse over the row where the metadata appears. The information shown is the information configured for the host in the Client Console.\\nThe\\nData\\nsection includes the following information:\\nAlarm ID\\n. An internal number representing a unique alarm instance.\\nAlarm ID\\n. An internal number representing a unique alarm instance.\\nAlarm Date\\n. The date and time that the alarm was triggered.\\nAlarm Date\\n. The date and time that the alarm was triggered.\\nAlarm Name\\n. The alarm name as defined in the alarm rule.\\nAlarm Name\\n. The alarm name as defined in the alarm rule.\\nMetadata fields\\n. Each metadata field is listed individually. For descriptions of each\\nmetadata field,\\xa0see the \"Lucene Search Syntax\" table in\\nMetadata Fields\\n.\\nThe properties shown in the Data section are the same as the values shown in the Alarm Properties window in the Client Console.\\nIf the host listed in the Host (Origin) or Host (Impacted) field is a Known Host, an Information icon appears next to the text. Hover your mouse over the row where the metadata appears. The information shown is the information configured for the host in the Client Console.\\nMetadata fields\\n. Each metadata field is listed individually. For descriptions of each\\nmetadata field,\\xa0see the \"Lucene Search Syntax\" table in\\nMetadata Fields\\n.\\nThe properties shown in the Data section are the same as the values shown in the Alarm Properties window in the Client Console.\\nIf the host listed in the Host (Origin) or Host (Impacted) field is a Known Host, an Information icon appears next to the text. Hover your mouse over the row where the metadata appears. The information shown is the information configured for the host in the Client Console.\\nThe\\nAlarm Actions\\nsection allows you to make changes to an alarm within the Inspector panel. You can update the following information:\\nStatus\\n. To open or close an alarm from the Inspector panell, click the list and click\\nOpen\\nor click\\nClosed\\n. To change the alarm status back to a new state, click\\nNew\\n.\\nAdd to Case\\n. To add the alarm to a case, click the list and select a case by either typing the case name in the typeahead filter or scrolling through the list. When the correct case is shown in the field, click\\nAdd\\n.\\nNew Case\\n. To create a new case with the selected alarm attached as evidence, click the\\nNew Case\\nbutton. The New Case from Alarm dialog box appears with the following default configurations, all of which you can change:\\nThe Name matches the alarm name.\\nThe Priority is based on the alarm\\'s risk status.\\nThe Due Date is one week from the date of new case creation.\\nThe Summary matches the alarm description. If the alarm has no description, this field is left blank.\\nThe\\nAlarm Actions\\nsection allows you to make changes to an alarm within the Inspector panel. You can update the following information:\\nStatus\\n. To open or close an alarm from the Inspector panell, click the list and click\\nOpen\\nor click\\nClosed\\n. To change the alarm status back to a new state, click\\nNew\\n.\\nStatus\\n. To open or close an alarm from the Inspector panell, click the list and click\\nOpen\\nor click\\nClosed\\n. To change the alarm status back to a new state, click\\nNew\\n.\\nAdd to Case\\n. To add the alarm to a case, click the list and select a case by either typing the case name in the typeahead filter or scrolling through the list. When the correct case is shown in the field, click\\nAdd\\n.\\nAdd to Case\\n. To add the alarm to a case, click the list and select a case by either typing the case name in the typeahead filter or scrolling through the list. When the correct case is shown in the field, click\\nAdd\\n.\\nNew Case\\n. To create a new case with the selected alarm attached as evidence, click the\\nNew Case\\nbutton. The New Case from Alarm dialog box appears with the following default configurations, all of which you can change:\\nThe Name matches the alarm name.\\nThe Priority is based on the alarm\\'s risk status.\\nThe Due Date is one week from the date of new case creation.\\nThe Summary matches the alarm description. If the alarm has no description, this field is left blank.\\nNew Case\\n. To create a new case with the selected alarm attached as evidence, click the\\nNew Case\\nbutton. The New Case from Alarm dialog box appears with the following default configurations, all of which you can change:\\nThe Name matches the alarm name.\\nThe Name matches the alarm name.\\nThe Priority is based on the alarm\\'s risk status.\\nThe Priority is based on the alarm\\'s risk status.\\nThe Due Date is one week from the date of new case creation.\\nThe Due Date is one week from the date of new case creation.\\nThe Summary matches the alarm description. If the alarm has no description, this field is left blank.\\nThe Summary matches the alarm description. If the alarm has no description, this field is left blank.\\nClick\\nSave\\nto create the case. The person who created the case becomes the case owner and the case status is set to Created.\\nSearch for Events Triggering Alarm\\n. Click\\nDrill Down\\nto drill into the selected alarm. A search task appears at the bottom of the screen. When the search is finished, click the\\nComplete: All Results\\nor\\nComplete: Max Results\\nlink at the bottom of the page.\\nIf you drill into an alarm that is in a New state, the alarm status is automatically set to Open. If the alarm is in a Closed or Open state, the status does not change during drill down.\\nSearch for Events Triggering Alarm\\n. Click\\nDrill Down\\nto drill into the selected alarm. A search task appears at the bottom of the screen. When the search is finished, click the\\nComplete: All Results\\nor\\nComplete: Max Results\\nlink at the bottom of the page.\\nIf you drill into an alarm that is in a New state, the alarm status is automatically set to Open. If the alarm is in a Closed or Open state, the status does not change during drill down.\\nThe\\nSmartResponse Actions\\nsection lists any SmartResponse actions that are triggered by the alarm. The following information is included for each action: Execution Target, Execution Time (ms), Standard Out, Standard Error, and the AutoApproved status for actions that do not require user approval.\\nIf you are listed as an approver for any non-AutoApproved SmartResponse actions attached to the alarm, you see Approve and Deny buttons in place of an AutoApproved status. At the bottom of the SmartResponse actions section, you also see a message indicating whether or not the actions need to run in the order that they are listed.\\nIf approvals are needed but you are not an approver, the word \"Pending\" is displayed followed by text displaying how many approvals are done (e.g. 0 of 3 Approved).\\nFor more details about the SmartResponse approval process, see Approve or Deny SmartResponse Actions.\\nThe\\nSmartResponse Actions\\nsection lists any SmartResponse actions that are triggered by the alarm. The following information is included for each action: Execution Target, Execution Time (ms), Standard Out, Standard Error, and the AutoApproved status for actions that do not require user approval.\\nIf you are listed as an approver for any non-AutoApproved SmartResponse actions attached to the alarm, you see Approve and Deny buttons in place of an AutoApproved status. At the bottom of the SmartResponse actions section, you also see a message indicating whether or not the actions need to run in the order that they are listed.\\nIf approvals are needed but you are not an approver, the word \"Pending\" is displayed followed by text displaying how many approvals are done (e.g. 0 of 3 Approved).\\nFor more details about the SmartResponse approval process, see Approve or Deny SmartResponse Actions.\\nThe\\nComments\\nsection allows you to view notes about the alarm from other users. You can also add your own comments for others to view.\\nThe\\nComments\\nsection allows you to view notes about the alarm from other users. You can also add your own comments for others to view.\\nThe\\nDetails\\nsection includes the following information:\\nAdded to Case(s)\\n. If the selected alarm is added to a case, a blue indicator appears on the alarm card. The case information is shown here along with a Go to Case button that, when clicked, links to the case. If the alarm is linked to multiple cases, a link to each case appears here.\\nIf you do not have permission to view the case the alarm was added to, this information does not appear in the Details section. This restriction pertains to non-global users and users that are not collaborators on the case(s) in which the alarm was added.\\nAlarm Description\\n. The Description field contains text information from the Brief Description field for an alarm in Client Console.\\nAdditional Details\\n. The Additional Details field contains the text from the \"Additional Details\" property of any alarm, whether it\\'s an AIE Rule or a regular alarm.\\nThe\\nDetails\\nsection includes the following information:\\nAdded to Case(s)\\n. If the selected alarm is added to a case, a blue indicator appears on the alarm card. The case information is shown here along with a Go to Case button that, when clicked, links to the case. If the alarm is linked to multiple cases, a link to each case appears here.\\nIf you do not have permission to view the case the alarm was added to, this information does not appear in the Details section. This restriction pertains to non-global users and users that are not collaborators on the case(s) in which the alarm was added.\\nAdded to Case(s)\\n. If the selected alarm is added to a case, a blue indicator appears on the alarm card. The case information is shown here along with a Go to Case button that, when clicked, links to the case. If the alarm is linked to multiple cases, a link to each case appears here.\\nIf you do not have permission to view the case the alarm was added to, this information does not appear in the Details section. This restriction pertains to non-global users and users that are not collaborators on the case(s) in which the alarm was added.\\nAlarm Description\\n. The Description field contains text information from the Brief Description field for an alarm in Client Console.\\nAlarm Description\\n. The Description field contains text information from the Brief Description field for an alarm in Client Console.\\nAdditional Details\\n. The Additional Details field contains the text from the \"Additional Details\" property of any alarm, whether it\\'s an AIE Rule or a regular alarm.\\nAdditional Details\\n. The Additional Details field contains the text from the \"Additional Details\" property of any alarm, whether it\\'s an AIE Rule or a regular alarm.\\n4.\\n(Optional)\\nClick the arrow to collapse the Inspector panel.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nAnalyzer Grid\\n', 'Inspector Panel': '\\nOn the lower-right side of the page, click the\\nLogs\\ntab. When you click on the\\nSettings\\nicon in a cell in the Analyzer grid, the Inspector panel displays a number of options, depending on the metadata type.\\nFor information on the search options available in the Inspector panel, see\\nPerform Pivot Searches\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nAnalyzer Grid\\n/\\nInspector Panel\\n', 'Use Contextualize': 'Contextualization provides information about a host, port, or user in a log or event. It also provides opportunities to retrieve additional information by executing whois, ping, and traceroute queries.\\nTo use contextualization:\\nOn the lower-right side of the page, click the\\nLogs\\ntab to open the Analyzer grid.\\nClick on a metadata field type that is supported by Contextualize. If the Inspector panel is not already open, click the\\nConfiguration\\nicon in the metadata cell or the\\nArrow\\nicon on the panel to open it and view the Contextualize tool. The following field types are supported:\\nHost (Impacted)\\nHost (Origin)\\nHostname (Impacted)\\nHostname (Origin)\\nIP Address (Impacted)\\nIP Address (Origin)\\nKnown Host (Impacted)\\nKnown Host (Origin)\\nRecipient\\nSender\\nTCP/UDP Port (Impacted)\\nTCP/UDP Port (Origin)\\nUser (Impacted)\\nUser (Origin)\\nWhen you click a field type that is not supported, the Contextualize interface does not appear in the Inspector panel.\\nHost (Impacted)\\nHost (Origin)\\nHostname (Impacted)\\nHostname (Origin)\\nIP Address (Impacted)\\nIP Address (Origin)\\nKnown Host (Impacted)\\nKnown Host (Origin)\\nRecipient\\nSender\\nTCP/UDP Port (Impacted)\\nTCP/UDP Port (Origin)\\nUser (Impacted)\\nUser (Origin)\\nWhen you click a field type that is not supported, the Contextualize interface does not appear in the Inspector panel.\\nUser (Origin)\\nWhen you click a field type that is not supported, the Contextualize interface does not appear in the Inspector panel.\\nScroll down to the Contextualize section, if necessary, to see additional information about the selected metadata. The following three types of information are available:\\nHosts\\n. For known hosts, the Contextualize feature returns information stored in the LogRhythm database. If no information is available, those fields do not appear in the Contextualize section. If an IP address exists in the database for the known host, you can run whois, trace, and ping queries. You can manually edit the IP address field with another IP address or Host. You can also click the\\nConfiguration\\nicon to configure parameters for those queries. Query settings do not persist and must be reset each time you refresh or browse away from the current page.\\nYou may need to configure your firewall to use contextualize. For more information, see the\\nNetworking and Communication\\ntopic in the LogRhythm SIEM Help.\\nPorts\\n. Returns information that is stored in the LogRhythm database. It allows you to see what the port name is, what it is used for, whether it is a system or custom port, and whether the port is mapped to an application. For more information on port settings, see\\nNetworking and Communication\\n.\\nUsers\\n. Queries domain user information. The domain is populated with the domain from the log if it is available. If it is not available, the Web Console auto-populates the domain that your LogRhythm Web Services Host API runs on. You can also manually edit the Domain field.\\nAll dates display in Coordinated Universal Time (UTC).\\nHosts\\n. For known hosts, the Contextualize feature returns information stored in the LogRhythm database. If no information is available, those fields do not appear in the Contextualize section. If an IP address exists in the database for the known host, you can run whois, trace, and ping queries. You can manually edit the IP address field with another IP address or Host. You can also click the\\nConfiguration\\nicon to configure parameters for those queries. Query settings do not persist and must be reset each time you refresh or browse away from the current page.\\nYou may need to configure your firewall to use contextualize. For more information, see the\\nNetworking and Communication\\ntopic in the LogRhythm SIEM Help.\\nHosts\\n. For known hosts, the Contextualize feature returns information stored in the LogRhythm database. If no information is available, those fields do not appear in the Contextualize section. If an IP address exists in the database for the known host, you can run whois, trace, and ping queries. You can manually edit the IP address field with another IP address or Host. You can also click the\\nConfiguration\\nicon to configure parameters for those queries. Query settings do not persist and must be reset each time you refresh or browse away from the current page.\\nYou may need to configure your firewall to use contextualize. For more information, see the\\nNetworking and Communication\\ntopic in the LogRhythm SIEM Help.\\nPorts\\n. Returns information that is stored in the LogRhythm database. It allows you to see what the port name is, what it is used for, whether it is a system or custom port, and whether the port is mapped to an application. For more information on port settings, see\\nNetworking and Communication\\n.\\nPorts\\n. Returns information that is stored in the LogRhythm database. It allows you to see what the port name is, what it is used for, whether it is a system or custom port, and whether the port is mapped to an application. For more information on port settings, see\\nNetworking and Communication\\n.\\nUsers\\n. Queries domain user information. The domain is populated with the domain from the log if it is available. If it is not available, the Web Console auto-populates the domain that your LogRhythm Web Services Host API runs on. You can also manually edit the Domain field.\\nAll dates display in Coordinated Universal Time (UTC).\\nUsers\\n. Queries domain user information. The domain is populated with the domain from the log if it is available. If it is not available, the Web Console auto-populates the domain that your LogRhythm Web Services Host API runs on. You can also manually edit the Domain field.\\nAll dates display in Coordinated Universal Time (UTC).\\nAt the bottom of the Contextualize section, click\\nAdd to Current Case\\nto add the information to the current case.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nCase Management\\n', 'Case Trend Widgets': '\\nCase Trend widgets are only available to Global Admins or Restricted Admins with elevated View and Manage privileges.\\nCase Trend widgets display bar charts that allow global users to monitor case status and priority trends as they relate to case creation dates. Case trending data provides an additional means for identifying threats and trends. It can also be used to help gauge user activity levels on the Web Console.\\nTwo types of Case Trend widgets are available: Case Trend by Status widget and Case Trend by Priority widget. Both of these widgets can be added on Dashboards and Cases page. For more information on the charts displayed by Case Trend widgets, see\\nRead Case Trend by Status Charts\\nand\\nRead Case Trend by Priority Charts\\n.\\nThe following graphic shows the predefined Case Management Dashboard view (available only to Global Administrators, Global Analysts, or Restricted Administrators with elevated privileges), which features three Case Trend widgets and two Case List widgets.\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nCase Management\\n/\\nCase Trend Widgets\\n', 'Read Case Trend by Priority Charts': \"Case Trend by Priority charts display case distribution trends as they relate to case creation dates and their current priority levels. Priority levels range from P1 to P5, with P1 cases being the highest priorities and P5 the lowest. Case priority levels should also be considered in conjunction with whether or not they have been flagged as Incidents.\\nIn Case Trend by Priority charts, the horizontal axis plots the range of creation dates while the vertical axis measures the total number of cases created. Color-coded stacked bars are used to break down the current priority levels of both Incident and non-Incident cases.\\nCase Trend by Priority charts include interactive features that allow you to do the following:\\nTo view the count values within a stacked bar, hover your cursor over the different color stacks to display them. The tooltip displays the number of cases for the highlighted segment, as well as a breakdown of the number of cases that are incidents or non-incidents.\\nTo focus the chart on a single priority, hover your cursor over a priority in the chart key. The tooltip displays the total number of cases assigned that priority.\\nDepending on a chart's width (as defined by the number of dashboard columns that it spans) and the scope of its time range, data bars may represent a group of consecutive dates as opposed to the single dates listed along the horizontal axis. For instance, group dates are standard for one- and two-column charts with time ranges greater than 10 days.\\nTo determine the exact date span that each bar represents, hover your cursor over the dates along the horizontal axis to display the information.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nCase Management\\n/\\nCase Trend Widgets\\n', 'Read Case Trend by Status Charts': \"Case statuses fall into four different buckets: open Incidents, closed Incidents, open non-Incidents, and closed non-Incidents. Case Trend by Status charts provide visual representations of case statuses and activity in terms of A) the number of cases created at different points in time and B) the relationship between the time cases were created and their current status.\\nIn Case Trend by Status charts, the horizontal axis plots the range of creation times while the vertical axis measures the total number of cases created. Color-coded stacked bars are used to break down the current statuses of the cases.\\nCase Trend by Status charts include interactive features that allow you to do the following:\\nTo view the count values within a stacked bar, hover your cursor over the different color segments to display them. The tooltip displays the number of cases for the highlighted segment, as well as a breakdown of the number of cases that are incidents or non-incidents.\\nTo focus the chart on a single status, hover your cursor over a status in the chart key below the horizontal axis. The tooltip displays the total number of cases for that status.\\nDepending on a chart's width (as defined by the number of dashboard columns that it spans) and the scope of its time range, data bars may represent a group of consecutive dates as opposed to the single dates listed along the horizontal axis. For instance, group dates are standard for one- and two-column charts with time ranges greater than 10 days.\\nTo determine the exact date span that each bar represents, hover your cursor over the dates along the horizontal axis to display the information.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nDashboards\\n', 'Filter Data with Lucene Searches': 'The LogRhythm Web Console allows you to filter data on dashboards, widgets, and the Analyze page by using Lucene search syntax. Lucene is an open source text retrieval library released under the Apache Software License.\\xa0For more information, see\\nLucene Search Syntax\\nor the Lucene wiki:\\nhttp://lucene.apache.org/core/2_9_\\n4/queryparsersyntax.html\\n.\\nThe Lucene Helper allows users to construct a Lucene query by providing syntax highlighting, field suggestions, and known value integrations. You can use Boolean operators when constructing the query.\\nTo filter data on the entire page using Lucene Helper:\\nOn the upper-right side of the page, click the\\nFilter\\nicon.\\nBegin typing your query.\\nAs you type, a list of suggested field names appears (for example, Direction).\\nClick a field name in the list to add it to the filter.\\nA list of available filter values appears (for example, External).\\nClick the value you want to filter.\\nClick\\nFilter Dashboard\\n.\\nFilter behavior within the LogRhythm Web Console:\\nIf a widget has a Lucene filter applied to it, whether within the widget configuration itself or through the dashboard configuration, a filter icon appears on the widget. Point to the filter icon to display the full set of filters being applied to the widget.\\nIf you filter data on the Dashboards page, the page shows the filtered data.\\nIf you filter data on the Analyze page, the charts are redrawn to show the newly filtered data.\\nDashboard-level filters do not apply to the Threat Activity Map.\\nClick\\nFilter Dashboard\\n.\\nIf a widget has a Lucene filter applied to it, whether within the widget configuration itself or through the dashboard configuration, a filter icon appears on the widget. Point to the filter icon to display the full set of filters being applied to the widget.\\nIf you filter data on the Dashboards page, the page shows the filtered data.\\nIf you filter data on the Analyze page, the charts are redrawn to show the newly filtered data.\\nDashboard-level filters do not apply to the Threat Activity Map.\\nFILTER\\nEXAMPLES\\nimpactedHost:\"hostname\" AND commonEventName:\"Detected Spyware Activity\"\\nlogin:\"joe.user\" AND classificationName:\"Misuse\" AND commonEventName:\"Unauthorized Activity\"\\ncommonEventName:\"Detected Backdoor Activity\" AND directionName:\"External\" AND originHost:\"106.194.190.227\"\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nDashboards\\n/\\nFilter Data with Lucene Searches\\n', 'Lucene Search Syntax': 'This guide provides an overview on building Lucene queries for use in the LogRhythm Web Console. For information on running queries that are more complex than those detailed in this guide, see the official Apache Lucene search website:\\nhttp://lucene.apache.org/core/2_9_4/queryparsersyntax.html\\n.\\nThis guide contains the following sections:\\n\\nApplications\\nClassification\\nHost\\nIdentity\\nKBytes and Packets\\nLocation\\nLog\\nNetwork\\n\\n\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nDashboards\\n/\\nFilter Data with Lucene Searches\\n/\\nLucene Search Syntax\\n', 'Basic Queries': 'Syntax for a basic query includes the following elements:\\nElement, Example\\nMetadata Field, classificationName\\nColon, :\\nStandard Open Quotation Mark, \"\\nTerm, Malware\\nStandard End Quotation Mark, \"\\nType a query using the following basic syntax:\\nmetadataField:\"term\"\\nEXAMPLE\\nTo run a query for all activity that falls under the Malware classification:\\nclassificationName:\"Malware\"\\nTo run a query for the impacted user account jon.smith:\\naccount:\"jon.smith\"\\nLucene search is case sensitive for the metadata field value. Therefore, when entering the metadata field value, you must use the correct capitalization. If your metadata field value does not exactly match the capitalization, the LogRhythm Web Console widgets return No data available error messages.\\nFor example, when searching on the metadata field classificationName:\\nMetadata Field Value Entered, Search Result\\nclassificationName, Filtered data\\nClassificationname, No data\\nclassificationname, No data\\nClassificationName, No data\\nIn contrast, Lucene search is not case sensitive the term value.\\nFor example, when searching on the term Malware:\\nTerm Value Entered, Search Result\\nMalware, Filtered data\\nmalware, Filtered data\\nMalWare, Filtered data\\nmalWare, Filtered data\\nFor more detailed information on metadata fields and correct capitalization, see the\\nMetadata Fields\\nsection.\\nTo escape a special character that is part of the query syntax, use a backslash before the character. Special characters that require this treatment are: + - && || ! ( ) { } [ ] ^ \" ~ * ? : \\\\\\nEXAMPLE\\nTo run a query for an origin user whose name is jon*:\\nlogin:\"jon\\\\*\"\\nTo run a query for an origin user whose name is jon.smith-miller:\\nlogin:\"jon.smith\\\\-miller\"\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nDashboards\\n/\\nFilter Data with Lucene Searches\\n/\\nLucene Search Syntax\\n', 'Complex Queries': '', 'Boolean Operators': '', 'OR Operator': 'When you use the OR operator, the filter displays activity that includes any of the values listed.\\nThe default Boolean operator is OR.\\xa0If you do not include an operator when searching on multiple criteria, the query runs as an OR search. You can also use || in place of OR.\\nEXAMPLE -\\nOR\\nTo run a query for all activity that falls under the Malware classification or that originated from a particular host, all of the following syntaxes are acceptable:\\nclassificationName:\"Malware\" originHost: \"106.194.190.210\"\\nclassificationName:\"Malware\" OR originHost: \"106.194.190.210\"\\nclassificationName:\"Malware\" || originHost: \"106.194.190.210\"\\n', 'AND Operator': 'When you use the AND operator, the filter displays activity that includes every value listed.\\nYou can also use && in place of AND.\\nEXAMPLE -\\nAND\\nTo run a query to see whether Malware activity originated from a particular host, you can use either of the following:\\nclassificationName:\"Malware\" AND originHost: \"106.194.190.210\"\\nclassificationName:\"Malware\" && originHost: \"106.194.190.210\"\\n', 'NOT Operator': 'When you use the NOT operator, the filter excludes activity associated with the value entered after NOT.\\nYou can also use ! in place of NOT.\\nEXAMPLE -\\nNOT\\nTo run a query to see activity associated with user account jon.smith that is not classified as Malware, you can use either of the following:\\nlogin:\"jon.smith\" NOT classificationName:\"Malware\"\\nlogin:\"jon.smith\" ! classificationName:\"Malware\"\\nTo run a NOT search by itself, use the following wildcard syntax:\\n*:* AND NOT classificationName:\"Malware\"\\n', 'TO Operator': 'To search by a range, include the TO operator between the parameters. To run an inclusive search, use square brackets [ ]. To run an exclusive search, use curly brackets { }.\\nEXAMPLE -\\nTO\\nTo run a query for the host from which a log activity originated that INCLUDES the first\\xa0and last IP addresses listed:\\noriginHost:[106.194.190.210 TO 106.194.190.250]\\nTo run a query for the host from which a log activity originated that EXCLUDES the first and last IP addresses listed:\\noriginHost:{106.194.190.210 TO 106.194.190.250}\\nTo run a query for a log of a certain priority ranking that INCLUDES a ranking 40 or greater:\\npriority:[40 TO *]\\n', 'Log Dates': 'To run a search on a log date, you must convert the time to epoch format in milliseconds. There are several online tools to help you make the conversion, including EpochConverter and Unix Time Stamp.\\nEXAMPLE -\\nDATE\\nTo run a query for all logs after October 30, 2016 at 9 A.M. local time:\\nnormalDate:{1477839600000 TO *}\\n', 'Grouping': 'You can run a query for multiple values in the same filter by enclosing all terms in parentheses. This is similar to using the OR operator, except that you can only search one metadata field with this syntax.\\nEXAMPLE -\\nGROUPING\\nTo run a query for all activity that falls under the Malware or Attack classifications:\\nclassificationName:(\"Malware\" \"Attack\")\\n', 'Field Grouping': 'To combine any of these query types into one query, use parentheses to group fields.\\nEXAMPLE -\\nFIELD GROUPING\\nTo run a query for the host from which Malware activity originated that excludes the first and last IP addresses in two different ranges:\\noriginHost:({106.194.190.210 TO 106.194.190.250} OR {106.194.190.256 TO 106.194.190.220}) AND classificationName:\"Malware\"\\nTo run a query for Malware or Compromise activity that impacted any of three separate users but that does not come from a particular IP address:\\nlogin:(\"jon.smith\" \"fred.miller\" \"janice.jones\") AND classificationName:(\"Malware\" \"Compromise\") AND NOT originHost:\"106.194.190.210\"\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nDashboards\\n/\\nFilter Data with Lucene Searches\\n/\\nLucene Search Syntax\\n', 'Metadata Fields': '\\nMetadata fields contain details of a log message in a simple format within the LogRhythm databases. Metadata is parsed directly from a log message (explicit) or can be inferred from a log message (implicit). Metadata might include such information as the direction of the data flow or the number of bytes in a data flow.\\nFor more detailed information about metadata fields, see the\\nLogRhythm Schema Dictionary and Guide\\n.\\nMetadata field names in LogRhythm do not always match the corresponding field in Lucene syntax. The following sections provide details around metadata field names in the Web Console, how they map to Lucene syntax, and a\\nbrief\\nfield description.\\n\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nDashboards\\n/\\nFilter Data with Lucene Searches\\n/\\nLucene Search Syntax\\n', 'Troubleshoot the Lucene Search': 'If your Lucene query returns a No data available error message or otherwise is not returning the results you expect, check the following:\\nUpper and lower case accuracy of the metadata field and the term\\nUse of quotation marks, forward slashes, and/or back slashes\\nUse of wild card characters\\nCapitalization of Boolean logic terms\\nUse of parentheses in complex queries\\nTime range\\nUse of dashboard filters\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nDashboards\\n/\\nFilter Data with Lucene Searches\\n/\\nLucene Search Syntax\\n', 'Wildcard Queries and Fuzzy Matches': 'In certain circumstances, you may need to use a wildcard query. For example, you may want to find data on any classification name that contains Malware in its name (Malware X, Malware Y, Malware Z, etc.). If you run a query using the term Malware, your search results will display only exact matches. You will see data for Malware but not for Malware X, Malware Y, or Malware Z. To get the data you are looking for, you need to use a wildcard query.\\nFor one-word wildcard filtering, remove the quotation marks and place an asterisk (*) where you would like to use a wildcard.\\nEXAMPLE - ONE WORD\\nTo run a query\\nfor all classifications containing the word Malware:\\nclassificationName:*Malware*\\nFor wildcard searches using multiple terms, use forward slashes (in place of quotation marks) to indicate regex syntax. In Lucene queries, the set of operators for wildcard searches is limited when compared to the full Java-supported regex.\\nFor single-character wildcards, use a period and question mark combination (.?).\\nEXAMPLE - SINGLE CHARACTER\\nTo run a query for impacted users named Jon, Jan, Jin, or Jen:\\nlogin:/J.?n/\\nFor multi-character wildcards, use an asterisk (*) when your search term contains a single word. When your search term contains multiple words, use a period and asterisk combination (.*).\\nEXAMPLE - MULTI CHARACTER\\nTo run a query for all common events that begin with \"AIE: SANS\":\\ncommonEventName:/AIE: SANS.*/\\nTo run a query for all impacted users whose name begins with Jo:\\nlogin:Jo*\\nTo run a query for all impacted users whose account ends with Smith:\\nlogin:*Smith\\nTo search for all classifications containing the word Malware:\\nclassificationName:*Malware*\\nYou can also use wildcard queries to filter results by blank or non-blank term fields.\\nEXAMPLE - BLANK and NON-BLANK\\nTo run a query for all log messages classified under any major activity group:\\nclassificationName:/.*/\\nTo run a query for all log messages NOT classified under any major activity group:\\n*:* AND NOT classificationName:/.*/\\nTo use a fuzzy match to locate terms similar to what you type, use a tilde (~) with no quotations marks or slashes.\\nEXAMPLE - FUZZY MATCH\\nTo run a query for impacted users whose names are similar to Jon, such as Ron or John:\\nlogin:Jon~\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nDashboards\\n/\\nFilter Data with Lucene Searches\\n/\\nLucene Search Syntax\\n/\\nMetadata Fields\\n', 'Applications': '\\nWeb Console Display Name, Lucene Search Syntax, Field Description\\nAction, action, An action taken by a device.\\nAmount, amount, Integer value representing a quantity.\\nApplication, portProtocol, A network protocol or a web application impacted by the event generated from the log message.The \"unknown\" category is an aggregation of applications that have not been classified.\\nCommand, command, The name of an executed command within the metadata (for example: login, get, or put).\\nDuration, duration, Running time of a session, job, activity, etc.\\nHash, hash, The digital signature, or mathematical equivalent, of the file that retrieves data from a URL or is the combination of other downloaded files.\\nKnown Application, serviceName, Known application or service, such as HTTP, POP3, or Telnet. An application is known if LogRhythm can match the protocol number from the log to a service name in the Events Database.\\nObjectObjectName, objectobjectName, Resource that is referenced or impacted by the log activity. An object can include a file, file path, registry key, etc.The Object field contains the full path and name, but objectName only stores the object name.\\nObject Type, objectType, A pair with an Object and an Object Name (for example, the content type from HTTP logs).\\nParent Process ID, parentProcessId, An ID number for a service or process running on a device, also known as PID.\\nParent Process Name, parentProcessName, The name of a process currently running on a system.\\nParent Process Path, parentProcessPath, The logical storage path for a given process.\\nPolicy, policy, The specific policy referenced (i.e., Firewall, Proxy) in a log message.\\nProcess Name, process, Name or value that identifies a process (for example, \"inetd\" or \"sshd\").\\nProcess ID, processId, The ID associated with a process.\\nQuantity, quantity, Item quantity.\\nRate, rate, Rate of an item.\\nReason, reason, The justification for an action or result when not an explicit policy.\\nResponse Code, responseCode, The explicit and well-defined response code for an action or command captured in a log. Response Code differs from Result in that response code should be well-structured and easily identifiable as a code.\\nResult, result, The outcome of a command operation or action (for example, the result of \"quarantine\" might be \"success\").\\nSession Type, sessionType, The type of session described in the log (e.g., console, CLI, web). Unique from IANA Protocol.\\nSize, size, The size of an item, which depends on the log type (for example, logs relating to firewalls may show the size or length of a packet).\\nStatus, status, The vendor\\'s perspective on the state of a system, process, or entity. Status should NOT be used as the result of an action.\\nSubject, subject, Email subject line. For non-email logs, this field could represent the subject in some form of communicated information.\\nThreat ID, threatId, An Identification Number specified for a given threat, as defined from a third-party security system or device, such as a firewall, IPS/IDS, AV, Endpoint Protection System, etc.\\nUser Agent, userAgent, The User Agent string from web server logs.\\nVersion, version, A value that represents a version (OS version, patch version, doc version, etc.).\\nAction\\naction\\nAn action taken by a device.\\nAmount\\namount\\nInteger value representing a quantity.\\nApplication\\nportProtocol\\nA network protocol or a web application impacted by the event generated from the log message.\\nThe \"unknown\" category is an aggregation of applications that have not been classified.\\nCommand\\ncommand\\nThe name of an executed command within the metadata (for example: login, get, or put).\\nDuration\\nduration\\nRunning time of a session, job, activity, etc.\\nHash\\nhash\\nThe digital signature, or mathematical equivalent, of the file that retrieves data from a URL or is the combination of other downloaded files.\\nKnown Application\\nserviceName\\nKnown application or service, such as HTTP, POP3, or Telnet. An application is known if LogRhythm can match the protocol number from the log to a service name in the Events Database.\\nObject\\nObject\\nName\\nobject\\nobjectName\\nResource that is referenced or impacted by the log activity. An object can include a file, file path, registry key, etc.\\nThe Object field contains the full path and name, but objectName only stores the object name.\\nObject Type\\nobjectType\\nA pair with an Object and an Object Name (for example, the content type from HTTP logs).\\nParent Process ID\\nparentProcessId\\nAn ID number for a service or process running on a device, also known as PID.\\nParent Process Name\\nparentProcessName\\nThe name of a process currently running on a system.\\nParent Process Path\\nparentProcessPath\\nThe logical storage path for a given process.\\nPolicy\\npolicy\\nThe specific policy referenced (i.e., Firewall, Proxy) in a log message.\\nProcess Name\\nprocess\\nName or value that identifies a process (for example, \"inetd\" or \"sshd\").\\nProcess ID\\nprocessId\\nThe ID associated with a process.\\nQuantity\\nquantity\\nItem quantity.\\nRate\\nrate\\nRate of an item.\\nReason\\nreason\\nThe justification for an action or result when not an explicit policy.\\nResponse Code\\nresponseCode\\nThe explicit and well-defined response code for an action or command captured in a log. Response Code differs from Result in that response code should be well-structured and easily identifiable as a code.\\nResult\\nresult\\nThe outcome of a command operation or action (for example, the result of \"quarantine\" might be \"success\").\\nSession Type\\nsessionType\\nThe type of session described in the log (e.g., console, CLI, web). Unique from IANA Protocol.\\nSize\\nsize\\nThe size of an item, which depends on the log type (for example, logs relating to firewalls may show the size or length of a packet).\\nStatus\\nstatus\\nThe vendor\\'s perspective on the state of a system, process, or entity. Status should NOT be used as the result of an action.\\nSubject\\nsubject\\nEmail subject line. For non-email logs, this field could represent the subject in some form of communicated information.\\nThreat ID\\nthreatId\\nAn Identification Number specified for a given threat, as defined from a third-party security system or device, such as a firewall, IPS/IDS, AV, Endpoint Protection System, etc.\\nUser Agent\\nuserAgent\\nThe User Agent string from web server logs.\\nVersion\\nversion\\nA value that represents a version (OS version, patch version, doc version, etc.).\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nDashboards\\n/\\nFilter Data with Lucene Searches\\n/\\nLucene Search Syntax\\n/\\nMetadata Fields\\n', 'Classification': \"\\nWeb Console Display Name, Lucene Search Syntax, Field Description\\nClassification, classificationName, Classifications include Compromise, Attack, or Malware. The value is determined based on the MPE Rule’s assigned Common Event.\\nClassificationType, classificationTypeName, One of the major activity groups (Operations, Audit, or Security) used to group log message types.\\nCommon Event, commonEventName, A short, plain-language description of the log that determines its Classification.\\nCVE, cve, Common Vulnerabilities and Exposure. This field is used to refer to specific vulnerabilities for a product.\\nDirection, directionName, Direction of activity between a log's origin and impacted zones. Values can be Internal, External, Outbound, Local, or Unknown.\\nMPE Rule Name, mpeRuleName, Message Processing Engine (MPE) rule, which identifies and normalizes log messages and then assigns them to a Log Type (Common Event).\\nPolicy, policy, The LogRhythm Policy (e.g., FIM, RIM, Agent, etc.) resulting in the log being generated.\\nReason, reason, The reason code within a log message. For example:Checkpoint: reason=mlx Syslog - AirTight IDS/IPS: REASON=1\\nResponse Code, responseCode, The response code that is returned from a prior command.\\nResult, result, Anything indicating a result, including but not exclusively a code.\\nSeverity, severity, A value indicating the severity of the log.\\nStatus, status, The current waiting state for a process, system state, network state, or attempted action.\\nThreat ID, threatId, ID number or unique identifier of a threat. Note that CVE is stored separately.\\nThreat Name, threatName, The name of a specific threat as defined from a third-party security system or device, such as a firewall, IPS/IDS, AV, Endpoint Protection System, etc.\\nVendor Info, vendorInfo, Human readable strings that may contain clarifying information not easily encapsulated by CE/Classification or a rule name.\\nVendor Message ID, vendorMessageId, Unique vendor-assigned value that identifies the log message.\\nClassification\\nclassificationName\\nClassifications include Compromise, Attack, or Malware. The value is determined based on the MPE Rule’s assigned Common Event.\\nClassificationType\\nclassificationTypeName\\nOne of the major activity groups (Operations, Audit, or Security) used to group log message types.\\nCommon Event\\ncommonEventName\\nA short, plain-language description of the log that determines its Classification.\\nCVE\\ncve\\nCommon Vulnerabilities and Exposure. This field is used to refer to specific vulnerabilities for a product.\\nDirection\\ndirectionName\\nDirection of activity between a log's origin and impacted zones. Values can be Internal, External, Outbound, Local, or Unknown.\\nMPE Rule Name\\nmpeRuleName\\nMessage Processing Engine (MPE) rule, which identifies and normalizes log messages and then assigns them to a Log Type (Common Event).\\nPolicy\\npolicy\\nThe LogRhythm Policy (e.g., FIM, RIM, Agent, etc.) resulting in the log being generated.\\nReason\\nreason\\nThe reason code within a log message. For example:\\nCheckpoint: reason=mlx Syslog - AirTight IDS/IPS: REASON=1\\nResponse Code\\nresponseCode\\nThe response code that is returned from a prior command.\\nResult\\nresult\\nAnything indicating a result, including but not exclusively a code.\\nSeverity\\nseverity\\nA value indicating the severity of the log.\\nStatus\\nstatus\\nThe current waiting state for a process, system state, network state, or attempted action.\\nThreat ID\\nthreatId\\nID number or unique identifier of a threat. Note that CVE is stored separately.\\nThreat Name\\nthreatName\\nThe name of a specific threat as defined from a third-party security system or device, such as a firewall, IPS/IDS, AV, Endpoint Protection System, etc.\\nVendor Info\\nvendorInfo\\nHuman readable strings that may contain clarifying information not easily encapsulated by CE/Classification or a rule name.\\nVendor Message ID\\nvendorMessageId\\nUnique vendor-assigned value that identifies the log message.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nDashboards\\n/\\nFilter Data with Lucene Searches\\n/\\nLucene Search Syntax\\n/\\nMetadata Fields\\n', 'Host': '\\nWeb Console Display Name, Lucene Search Syntax, Field Description\\nHost (Impacted)Host (Origin), impactedHostoriginHost, The host involved in the log activity, which may include the IP address, host name, or Ethernet address:Host (Impacted) is the destination.Host (Origin) is the source.\\nHostname (Impacted)Hostname (Origin), impactedNameoriginName, The name of the host involved in the log activity (for example, a DNS name or a Netbios name):Hostname (Impacted) is the destination.Hostname (Origin) is the source.\\nInterface (Impacted)Interface (Origin), impactedInterfaceoriginInterface, The interface number of a device or physical port number of a switch:Interface (Impacted) is the destination interface.Interface (Origin)\\xa0is the source interface.\\nIP\\xa0Address (Impacted)IP\\xa0Address (Origin), impactedIporiginIp, The IP\\xa0addresses for the log activity:IP Address (Impacted) is the destination address.IP\\xa0Address (Origin) is the source address.\\nKnown Host (Impacted)Known Host (Origin), impactedHostNameoriginHostName, The host record associated with a specific Entity:Known Host (Origin) is the source of the log activity.Known Host (Impacted) is the destination of the log activity.\\nMac Address (Impacted)Mac Address (Origin), impactedMacoriginMac, The MAC address involved in the log message:MAC Address (Origin) is the source.MAC Address (Impacted) is the destination.\\nNAT IP\\xa0Address (Impacted)NAT IP Address (Origin), impactedNatIporiginNatIp, The IP address that was translated via NAT\\xa0device logs:NAT\\xa0IP\\xa0Address (Origin)\\xa0is the source.NAT\\xa0IP\\xa0Address (Impacted) is the destination.\\nSerial Number, serialNumber, This is the serial number for a specific device or system.\\nHost (Impacted)\\nHost (Origin)\\nimpactedHost\\noriginHost\\nThe host involved in the log activity, which may include the IP address, host name, or Ethernet address:\\nHost (Impacted) is the destination.\\nHost (Origin) is the source.\\nHostname (Impacted)\\nHostname (Origin)\\nimpactedName\\noriginName\\nThe name of the host involved in the log activity (for example, a DNS name or a Netbios name):\\nHostname (Impacted) is the destination.\\nHostname (Origin) is the source.\\nInterface (Impacted)\\nInterface (Origin)\\nimpactedInterface\\noriginInterface\\nThe interface number of a device or physical port number of a switch:\\nInterface (Impacted) is the destination interface.\\nInterface (Origin)\\xa0is the source interface.\\nIP\\xa0Address (Impacted)\\nIP\\xa0Address (Origin)\\nimpactedIp\\noriginIp\\nThe IP\\xa0addresses for the log activity:\\nIP Address (Impacted) is the destination address.\\nIP\\xa0Address (Origin) is the source address.\\nKnown Host (Impacted)\\nKnown Host (Origin)\\nimpactedHostName\\noriginHostName\\nThe host record associated with a specific Entity:\\nKnown Host (Origin) is the source of the log activity.\\nKnown Host (Impacted) is the destination of the log activity.\\nMac Address (Impacted)\\nMac Address (Origin)\\nimpactedMac\\noriginMac\\nThe MAC address involved in the log message:\\nMAC Address (Origin) is the source.\\nMAC Address (Impacted) is the destination.\\nNAT IP\\xa0Address (Impacted)\\nNAT IP Address (Origin)\\nimpactedNatIp\\noriginNatIp\\nThe IP address that was translated via NAT\\xa0device logs:\\nNAT\\xa0IP\\xa0Address (Origin)\\xa0is the source.\\nNAT\\xa0IP\\xa0Address (Impacted) is the destination.\\nSerial Number\\nserialNumber\\nThis is the serial number for a specific device or system.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nDashboards\\n/\\nFilter Data with Lucene Searches\\n/\\nLucene Search Syntax\\n/\\nMetadata Fields\\n', 'Identity': \"\\nWeb Console Display Name, Lucene Search Syntax, Field Description\\nGroup, group, User group or role referenced or impacted by the log activity. This group is typically an Active Directory group name or other type of logical container.\\nIdentity ID, identityID, Uniquely identifies an identity.\\nIdentity Name, identityName, The name of an identity.\\nRecipient, recipient, Email address or VOIP\\xa0caller number. For non-email logs, this field could represent the user who received a form of information.\\nRecipient Identity, recipientIdentity, Identity that has the Recipient's email address associated with it.\\nSender, sender, Email originator or VOIP\\xa0caller number. For non-email logs, this field could represent the user who received a form of information.\\nSender Identity, senderIdentity, Identity that has the Sender's email address associated with it.\\nUser (Origin), login, The user logon that is the source of the log activity.\\nUser (Impacted), account, The user account that is the recipient of the action (for example, a password reset on a user account).\\nUser Identity (Origin), userOriginIdentity, The identity that has the login in the User (Origin) field associated with it.\\nUser Identity (Impacted), userImpactedIdentity, The identity that has the User (Impacted) field associated with it.\\nGroup\\ngroup\\nUser group or role referenced or impacted by the log activity. This group is typically an Active Directory group name or other type of logical container.\\nIdentity ID\\nidentityID\\nUniquely identifies an identity.\\nIdentity Name\\nidentityName\\nThe name of an identity.\\nRecipient\\nrecipient\\nEmail address or VOIP\\xa0caller number. For non-email logs, this field could represent the user who received a form of information.\\nRecipient Identity\\nrecipientIdentity\\nIdentity that has the Recipient's email address associated with it.\\nSender\\nsender\\nEmail originator or VOIP\\xa0caller number. For non-email logs, this field could represent the user who received a form of information.\\nSender Identity\\nsenderIdentity\\nIdentity that has the Sender's email address associated with it.\\nUser (Origin)\\nlogin\\nThe user logon that is the source of the log activity.\\nUser (Impacted)\\naccount\\nThe user account that is the recipient of the action (for example, a password reset on a user account).\\nUser Identity (Origin)\\nuserOriginIdentity\\nThe identity that has the login in the User (Origin) field associated with it.\\nUser Identity (Impacted)\\nuserImpactedIdentity\\nThe identity that has the User (Impacted) field associated with it.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nDashboards\\n/\\nFilter Data with Lucene Searches\\n/\\nLucene Search Syntax\\n/\\nMetadata Fields\\n', 'KBytes and Packets': '\\nWeb Console Display Name, Lucene Search Syntax, Field Description\\nHost (Impacted) KBytes RcvdHost (Impacted) KBytes SentHost (Impacted) KBytes Total, kBytesInkBytesOutimpactedHostTotalKBytes, KBytes involved in the impacted host activity:Host (Impacted) KBytes Rcvd is the number of bytes the impacted host received.Host (Impacted) KBytes Sent is the number of bytes the impacted host sent.Host (Impacted) KBytes Total is the sum of KBytes In and KBytes Out.\\nHost (Impacted) Packets RcvdHost (Impacted) Packets SentHost (Impacted) Packets Total, itemsPacketsInitemsPacketsOutimpactedHostTotalPackets, Packets involved in the impacted host activity:Host (Impacted) Packets Rcvd is the number of packets the impacted host received.Host (Impacted) Packets Sent is the number of packets the impacted host sent.Host (Impacted) Packets Total is the sum of Packets In and Packets Out.\\nBytes InboundBytes Outbound, kBytesoutboundKBytes, Total KBytes transferred from a device, system, or process:Bytes Inbound. Total Bytes received.Bytes Outbound. Total Bytes sent.\\nWeb Console Display Name\\nHost (Impacted) KBytes Rcvd\\nHost (Impacted) KBytes Sent\\nHost (Impacted) KBytes Total\\nkBytesIn\\nkBytesOut\\nimpactedHostTotalKBytes\\nKBytes involved in the impacted host activity:\\nHost (Impacted) KBytes Rcvd is the number of bytes the impacted host received.\\nHost (Impacted) KBytes Sent is the number of bytes the impacted host sent.\\nHost (Impacted) KBytes Total is the sum of KBytes In and KBytes Out.\\nHost (Impacted) Packets Rcvd\\nHost (Impacted) Packets Sent\\nHost (Impacted) Packets Total\\nitemsPacketsIn\\nitemsPacketsOut\\nimpactedHostTotalPackets\\nPackets involved in the impacted host activity:\\nHost (Impacted) Packets Rcvd is the number of packets the impacted host received.\\nHost (Impacted) Packets Sent is the number of packets the impacted host sent.\\nHost (Impacted) Packets Total is the sum of Packets In and Packets Out.\\nBytes Inbound\\nBytes Outbound\\nkBytes\\noutboundKBytes\\nTotal KBytes transferred from a device, system, or process:\\nBytes Inbound. Total Bytes received.\\nBytes Outbound. Total Bytes sent.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nDashboards\\n/\\nFilter Data with Lucene Searches\\n/\\nLucene Search Syntax\\n/\\nMetadata Fields\\n', 'Location': \"\\nWeb Console Display Name, Lucene Search Syntax, Field Description\\nCountry (Impacted)Country (Origin), impactedCountryoriginCountry, The country involved in the log activity:Country (Impacted) is the destination area.Country (Origin) is the source area.The Country values are derived from the LogRhythm SIEM's GeoLocation feature.\\nEntity (Impacted)Entity (Origin), impactedEntityNameoriginEntityName, The resolved host entities involved in the log data:Entity (Impacted) is the destination host.Entity (Origin) is the source host.An Entity is a record that represents a logical grouping of LogRhythm SIEM or log objects in the SIEM. Administrators define Entities for security management and organization.\\nLocation (Impacted)Location (Origin), impactedLocationoriginLocation, The geographic area involved in the log activity:Location (Origin) is the source area.Location (Impacted) is the destination area.The Location values are derived from the LogRhythm SIEM's GeoLocation feature.\\nRegion (Impacted)Region (Origin), impactedRegionoriginRegion, The region involved in the log activity:Region (Origin) is the source area.Region (Impacted) is the destination area.The Region values are derived from theLogRhythm SIEM's GeoLocation feature.\\nRoot Entity, rootEntityId, The root entity (top-most entity) for a log source.In the search syntax, provide the ID number that the root entity is mapped to in the LogRhythm Client Console, rather than the name of the root entity.\\nZone (Impacted)Zone (Origin), impactedZoneNameoriginZoneName, The resolved zone (Internal, External, or DMZ) that LogRhythm identified in the log activity:Zone (Origin) is the source zone.Zone (Impacted)\\xa0is the destination zone.Administrators assign zones in the Host records and Network records.\\nCountry (Impacted)\\nCountry (Origin)\\nimpactedCountry\\noriginCountry\\nThe country involved in the log activity:\\nCountry (Impacted) is the destination area.\\nCountry (Origin) is the source area.\\nThe Country values are derived from the LogRhythm SIEM's GeoLocation feature.\\nEntity (Impacted)\\nEntity (Origin)\\nimpactedEntityName\\noriginEntityName\\nThe resolved host entities involved in the log data:\\nEntity (Impacted) is the destination host.\\nEntity (Origin) is the source host.\\nAn Entity is a record that represents a logical grouping of LogRhythm SIEM or log objects in the SIEM. Administrators define Entities for security management and organization.\\nLocation (Impacted)\\nLocation (Origin)\\nimpactedLocation\\noriginLocation\\nThe geographic area involved in the log activity:\\nLocation (Origin) is the source area.\\nLocation (Impacted) is the destination area.\\nThe Location values are derived from the LogRhythm SIEM's GeoLocation feature.\\nRegion (Impacted)\\nRegion (Origin)\\nimpactedRegion\\noriginRegion\\nThe region involved in the log activity:\\nRegion (Origin) is the source area.\\nRegion (Impacted) is the destination area.\\nThe Region values are derived from theLogRhythm SIEM's GeoLocation feature.\\nRoot Entity\\nrootEntityId\\nThe root entity (top-most entity) for a log source.\\nIn the search syntax, provide the ID number that the root entity is mapped to in the LogRhythm Client Console, rather than the name of the root entity.\\nZone (Impacted)\\nZone (Origin)\\nimpactedZoneName\\noriginZoneName\\nThe resolved zone (Internal, External, or DMZ) that LogRhythm identified in the log activity:\\nZone (Origin) is the source zone.\\nZone (Impacted)\\xa0is the destination zone.\\nAdministrators assign zones in the Host records and Network records.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nDashboards\\n/\\nFilter Data with Lucene Searches\\n/\\nLucene Search Syntax\\n/\\nMetadata Fields\\n', 'Log': '\\nWeb Console Display Name, Lucene Search Syntax, Field Description\\nFirst Log Date, normalMsgDate, First occurrence of a single log in an aggregated log.\\nLast Log Date, normalDateMax, Latest occurrence of a single log in an aggregated log.\\nLog Count, count, Number of logs.\\nLog Date, normalDate, The creation date contained in the log. This value can be in UTC or a user-selected time zone.\\nLog Message, logMessage, Text from the log that is parsed into metadata fields.\\nLog Source, logSourceName, A unique identifier that generated the log on a specific host.\\nLog Source Entity, entityName, A logical collection of unique networks, devices, and systems.\\nLog Source Host, logSourceHostName, The system or device where the Log Source originated.\\nLog Source Type, logSourceTypeName, Type of facility or source where the log originated.\\nLog Sequence Number, sequenceNumber, The order in which the log was collected, in relation to other logs.\\nRule Block, ruleBlockNumber, The AIE rule block number that matched the log returned from an AIE drill down.\\nFirst Log Date\\nnormalMsgDate\\nFirst occurrence of a single log in an aggregated log.\\nLast Log Date\\nnormalDateMax\\nLatest occurrence of a single log in an aggregated log.\\nLog Count\\ncount\\nNumber of logs.\\nLog Date\\nnormalDate\\nThe creation date contained in the log. This value can be in UTC or a user-selected time zone.\\nLog Message\\nlogMessage\\nText from the log that is parsed into metadata fields.\\nLog Source\\nlogSourceName\\nA unique identifier that generated the log on a specific host.\\nLog Source Entity\\nentityName\\nA logical collection of unique networks, devices, and systems.\\nLog Source Host\\nlogSourceHostName\\nThe system or device where the Log Source originated.\\nLog Source Type\\nlogSourceTypeName\\nType of facility or source where the log originated.\\nLog Sequence Number\\nsequenceNumber\\nThe order in which the log was collected, in relation to other logs.\\nRule Block\\nruleBlockNumber\\nThe AIE rule block number that matched the log returned from an AIE drill down.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nDashboards\\n/\\nFilter Data with Lucene Searches\\n/\\nLucene Search Syntax\\n/\\nMetadata Fields\\n', 'Network': '\\nWeb Console Display Name, Lucene Search Syntax, Field Description\\nDomain (Impacted), domainImpacted, The Impacted Windows of DNS referenced or impacted by log activity.\\nDomain (Origin), domainOrigin, The domain from which a log message originated.\\nNAT TCP/UDP Port (Impacted)NAT TCP/UDP Port (Origin), impactedNatPortoriginNatPort, The TCP/UDP port that was translated via NAT\\xa0device logs:NAT\\xa0TCP/UDP\\xa0Port (Origin)\\xa0is the source.NAT\\xa0TCP/UDP\\xa0Port (Impacted) is the destination.\\nNetwork (Impacted)Network (Origin), impactedNetworkoriginNetwork, Network involved in the log activity:Network (Origin) is the source network.Network (Impacted) is the destination network.\\nProtocol, protocolName, Network protocol applicable to the log message.\\nSession, session, The user, system, or application session.\\nSession Type, sessionType, If a session code is already in use for TCP or UDP protocols, this field is used for a session type that could be ssh, console, etc. Upon the establishment of a network connection, a session type is defined for that connection.\\nTCP/UDP Port (Origin)TCP/UDP Port (Impacted), originPortimpactedPort, The TCP or UDP port number:TCP/UDP Port (Origin) is the source.TCP/UDP Port (Impacted) is the destination.\\nURL, url, URL referenced or impacted by the log activity.\\nUser Agent, userAgent, A unique string which identifies the browser or application and provides system specific details to servers hosting visited websites.\\nDomain (Impacted)\\ndomainImpacted\\nThe Impacted Windows of DNS referenced or impacted by log activity.\\nDomain (Origin)\\ndomainOrigin\\nThe domain from which a log message originated.\\nNAT TCP/UDP Port (Impacted)\\nNAT TCP/UDP Port (Origin)\\nimpactedNatPort\\noriginNatPort\\nThe TCP/UDP port that was translated via NAT\\xa0device logs:\\nNAT\\xa0TCP/UDP\\xa0Port (Origin)\\xa0is the source.\\nNAT\\xa0TCP/UDP\\xa0Port (Impacted) is the destination.\\nNetwork (Impacted)\\nNetwork (Origin)\\nimpactedNetwork\\noriginNetwork\\nNetwork involved in the log activity:\\nNetwork (Origin) is the source network.\\nNetwork (Impacted) is the destination network.\\nProtocol\\nprotocolName\\nNetwork protocol applicable to the log message.\\nSession\\nsession\\nThe user, system, or application session.\\nSession Type\\nsessionType\\nIf a session code is already in use for TCP or UDP protocols, this field is used for a session type that could be ssh, console, etc. Upon the establishment of a network connection, a session type is defined for that connection.\\nTCP/UDP Port (Origin)\\nTCP/UDP Port (Impacted)\\noriginPort\\nimpactedPort\\nThe TCP or UDP port number:\\nTCP/UDP Port (Origin) is the source.\\nTCP/UDP Port (Impacted) is the destination.\\nURL\\nurl\\nURL referenced or impacted by the log activity.\\nUser Agent\\nuserAgent\\nA unique string which identifies the browser or application and provides system specific details to servers hosting visited websites.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nLog Collection in Web Console\\n', 'Agents Grid': \"Only Global and Restricted Admins can use this feature.\\nThe Agents grid in the Web Console displays all active and retired Agents. Upon activating or retiring any Agents in the Client Console, they are displayed in the Web Console's Agents grid.\\nTo access the Agents grid:\\nOn the top navigation bar, click\\xa0the\\nAdministration\\nicon, and then click\\nLog Collection.\\nThe Log Sources page appears.\\nOn the top navigation bar, click\\xa0the\\nAdministration\\nicon, and then click\\nLog Collection.\\nThe Log Sources page appears.\\nOn the left side, click\\nAgents\\n.\\nOn the left side, click\\nAgents\\n.\\n\", 'View Active and Retired Agents': 'By default, the grid displays active Agents. To view retired Agents, click the\\nShow Retired Agents\\ncheck box in the upper-right corner of the page.\\nBy default, the grid displays 100 Agents. To load more Agents into the grid, scroll to the bottom. The list expands to add another 100 Agents. Repeat this process as needed until all Agents are shown.\\n', 'Grid Columns': '', 'Column Descriptions': 'The following columns are visible in the Agents grid. Clicking any column header sorts by that metric.\\nColumn, Description\\nAgent Name, The name of the Agent.\\nHost, The default Host record to which log messages collected by the Agent should be assigned.\\nEntity, The Entity assigned to the Agent.\\nType, Indicates whether the Agent is a Windows Agent or a Linux Agent.\\nLog Sources, Displays a count of active Log Sources associated with the Agent.\\nVersion, The SIEM version associated with the Agent.\\nStatus, Indicates whether the Agent is Active or Retired.\\nData Processor, The highest-priority data processor to which the Agent forwards logs, as configured inModify System Monitor Basic Properties.\\nLast Heartbeat, Indicates the date and time of the most recent heartbeat received for the Agent.A yellow background highlights Agents in a Warning status, and a red background highlights those in Error status, as configured inSystem Monitor Basic Properties.An Agent progresses to Warning status once one heartbeat interval is missed and will progress to Error status after a second complete heartbeat interval has been missed.\\nColumn\\nDescription\\nAgent Name\\nThe name of the Agent.\\nHost\\nThe default Host record to which log messages collected by the Agent should be assigned.\\nEntity\\nThe Entity assigned to the Agent.\\nType\\nIndicates whether the Agent is a Windows Agent or a Linux Agent.\\nLog Sources\\nDisplays a count of active Log Sources associated with the Agent.\\nVersion\\nThe SIEM version associated with the Agent.\\nStatus\\nIndicates whether the Agent is Active or Retired.\\nData Processor\\nThe highest-priority data processor to which the Agent forwards logs, as configured in\\nModify System Monitor Basic Properties\\n.\\nLast Heartbeat\\nIndicates the date and time of the most recent heartbeat received for the Agent.\\nA yellow background highlights Agents in a Warning status, and a red background highlights those in Error status, as configured in\\nSystem Monitor Basic Properties\\n.\\nAn Agent progresses to Warning status once one heartbeat interval is missed and will progress to Error status after a second complete heartbeat interval has been missed.\\n', 'Filter the Grid': 'Each column can be filtered using the filter options below the column name. There are three filter types in the Agents grid:\\nFilter Type, Description\\nText, Type in the field to only display results in the column that contain the entered text.\\nDrop-list, Select one of the available options from the drop-list to only display results that match the selection.\\nDate, Use the date picker to display the last heartbeat that was received on or after the date chosen.\\nFilter Type\\nDescription\\nText\\nType in the field to only display results in the column that contain the entered text.\\nDrop-list\\nSelect one of the available options from the drop-list to only display results that match the selection.\\nDate\\nUse the date picker to display the last heartbeat that was received on or after the date chosen.\\n\\n\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nSearch\\n', 'Manage the Searches Page': 'The Searches page provides access to your saved searches (including any investigations that you have saved in the Client Console) and search history, as well as the searches that have been shared with you. Shared searches are created by Global Administrators as a way to direct users toward specific sets of data.\\nOn the navigation bar, click\\nSearches\\n. Do any of the following:\\nTo sort the searches:\\nSelect the tab containing the searches you want to sort.\\nClick the\\nSort\\nicon. When you first click the icon, the column contents are sorted alphabetically which is indicated by an Arrow icon.\\nClick the\\nSort\\nicon again. The column contents are sorted reverse alphabetical order as indicated by an Arrow icon.\\nSelect the tab containing the searches you want to sort.\\nClick the\\nSort\\nicon. When you first click the icon, the column contents are sorted alphabetically which is indicated by an Arrow icon.\\nClick the\\nSort\\nicon again. The column contents are sorted reverse alphabetical order as indicated by an Arrow icon.\\nTo resize the columns:\\nPlace the cursor to the right of the title bar for the column you want to resize until the resizing cursor appears.\\nPress and hold the left mouse button as you drag the column to the left or right until the column is the width you want, then release the mouse button.\\nPlace the cursor to the right of the title bar for the column you want to resize until the resizing cursor appears.\\nPress and hold the left mouse button as you drag the column to the left or right until the column is the width you want, then release the mouse button.\\nTo edit a search:\\nYou must have write permission to directly edit a search.\\nClick the\\nEdit\\nicon for the search that you want to edit.\\nThe Search dialog box appears.\\n(Optional)\\nEdit the Criteria fields as needed by following the same procedures described in\\nUse Search\\n.\\n(Optional)\\nEdit the Properties fields as needed by following the same procedures described in\\nSave Searches\\n.\\nWhen you are finished editing the search, click\\nSave\\n.\\nTo edit a search:\\nYou must have write permission to directly edit a search.\\nClick the\\nEdit\\nicon for the search that you want to edit.\\nThe Search dialog box appears.\\nClick the\\nEdit\\nicon for the search that you want to edit.\\nThe Search dialog box appears.\\n(Optional)\\nEdit the Criteria fields as needed by following the same procedures described in\\nUse Search\\n.\\n(Optional)\\nEdit the Criteria fields as needed by following the same procedures described in\\nUse Search\\n.\\n(Optional)\\nEdit the Properties fields as needed by following the same procedures described in\\nSave Searches\\n.\\n(Optional)\\nEdit the Properties fields as needed by following the same procedures described in\\nSave Searches\\n.\\nWhen you are finished editing the search, click\\nSave\\n.\\nWhen you are finished editing the search, click\\nSave\\n.\\nTo copy a search:\\nClick the\\nEdit\\nicon for the search that you want to copy.\\nThe Search dialog box appears.\\nClick\\nCopy\\n.\\nThe copied search is added to your list of saved searches under the same name as the original search with \"- copy\" added to the end of it. You can edit the copied search as needed.\\nTo copy a search:\\nClick the\\nEdit\\nicon for the search that you want to copy.\\nThe Search dialog box appears.\\nClick the\\nEdit\\nicon for the search that you want to copy.\\nThe Search dialog box appears.\\nClick\\nCopy\\n.\\nThe copied search is added to your list of saved searches under the same name as the original search with \"- copy\" added to the end of it. You can edit the copied search as needed.\\nClick\\nCopy\\n.\\nThe copied search is added to your list of saved searches under the same name as the original search with \"- copy\" added to the end of it. You can edit the copied search as needed.\\nTo delete a search:\\nYou must have write permission to delete a search.\\nClick the\\nDelete\\nicon next to the search that you want to delete.\\nThe Delete Search dialog box appears.\\nTo confirm that you want to delete the search, click\\nDelete\\n, otherwise click\\nCancel\\n.\\nIf you are a Global Administrator and you delete a public search, the search is deleted for all users.\\nTo delete a search:\\nYou must have write permission to delete a search.\\nClick the\\nDelete\\nicon next to the search that you want to delete.\\nThe Delete Search dialog box appears.\\nClick the\\nDelete\\nicon next to the search that you want to delete.\\nThe Delete Search dialog box appears.\\nTo confirm that you want to delete the search, click\\nDelete\\n, otherwise click\\nCancel\\n.\\nIf you are a Global Administrator and you delete a public search, the search is deleted for all users.\\nTo confirm that you want to delete the search, click\\nDelete\\n, otherwise click\\nCancel\\n.\\nIf you are a Global Administrator and you delete a public search, the search is deleted for all users.\\nTo filter searches by keywords:\\nDetermine which column you want to filter (Name, Description, Owner Name, or Read Permissions) and click in the\\nType Here\\nfield below the column name.\\nBegin typing the keyword(s) string that you want to filter the searches by.\\nAs you begin typing, the text string filters out searches that do not include the search term in their descriptions. Continue typing until you are satisfied with the level of filtering.\\nTo filter searches by keywords:\\nDetermine which column you want to filter (Name, Description, Owner Name, or Read Permissions) and click in the\\nType Here\\nfield below the column name.\\nDetermine which column you want to filter (Name, Description, Owner Name, or Read Permissions) and click in the\\nType Here\\nfield below the column name.\\nBegin typing the keyword(s) string that you want to filter the searches by.\\nAs you begin typing, the text string filters out searches that do not include the search term in their descriptions. Continue typing until you are satisfied with the level of filtering.\\nBegin typing the keyword(s) string that you want to filter the searches by.\\nAs you begin typing, the text string filters out searches that do not include the search term in their descriptions. Continue typing until you are satisfied with the level of filtering.\\nTo add a search to the My Favorites tab:\\nGo to the\\nAll Searches\\n,\\nShared Searches\\n, or\\nMy Saved\\ntab.\\nFind the search you want to add to your favorites by doing one of the following:\\nScroll through the list until you find the search you want.\\nClick in the\\nType Here\\nfield below a column name and begin typing a keyword string to find the search you want to add.\\nClick the\\nStar\\nicon next to the search you want to add.\\nThe search is added to the My Favorites tab.\\nTo add a search to the My Favorites tab:\\nGo to the\\nAll Searches\\n,\\nShared Searches\\n, or\\nMy Saved\\ntab.\\nGo to the\\nAll Searches\\n,\\nShared Searches\\n, or\\nMy Saved\\ntab.\\nFind the search you want to add to your favorites by doing one of the following:\\nScroll through the list until you find the search you want.\\nClick in the\\nType Here\\nfield below a column name and begin typing a keyword string to find the search you want to add.\\nFind the search you want to add to your favorites by doing one of the following:\\nScroll through the list until you find the search you want.\\nScroll through the list until you find the search you want.\\nClick in the\\nType Here\\nfield below a column name and begin typing a keyword string to find the search you want to add.\\nClick in the\\nType Here\\nfield below a column name and begin typing a keyword string to find the search you want to add.\\nClick the\\nStar\\nicon next to the search you want to add.\\nThe search is added to the My Favorites tab.\\nClick the\\nStar\\nicon next to the search you want to add.\\nThe search is added to the My Favorites tab.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nSearch\\n', 'Perform Pivot Searches': 'Pivot searches offer two methods for building and running searches based on event metadata. You can run a pivot search from the Analyzer grid or from a TopX widget in the Dashboard. A pivot search from the Analyzer grid defaults to the log date and time, while a pivot search from a TopX widget defaults to the current time and date. Additionally, a pivot search from the Analyzer grid displays results for all metadata that go into the poly fields Host and Application. Host has the values Known Host, Hostname, and IP Address, while Application has the values Known Application, TCP/UDP port, and Protocol. A pivot search from a TopX widget only allows you to search the exact value shown in the widget.\\nTo run a pivot search:\\nDo one of the following:\\nOn either the Dashboards page or Analyze page, on the lower-right side of the page, click the\\nLogs\\ntab to open the Analyzer grid.\\nHover your mouse over the metadata field containing the value that you want to search.\\nA Configuration icon appears in the field.\\nClick the\\nConfiguration\\nicon. The event row turns blue and the Inspector panel appears. The metadata type and value as well as the Log Date are listed in the Inspector panel.\\nOn the navigation bar, click\\nDashboards\\n.\\nOn a TopX widget in the dashboard, hover your mouse over the widget and click the\\nSettings\\nicon.\\nA blue border appears around the widget and the Inspector panel opens on the right.\\nClick the label or the chart element that represents the metadata you want to pivot against.\\nBe sure to only click once. Double-clicking initiates a drilldown search. For more information, see Drill into Chart Metadata from the Dashboards.\\nOn either the Dashboards page or Analyze page, on the lower-right side of the page, click the\\nLogs\\ntab to open the Analyzer grid.\\nHover your mouse over the metadata field containing the value that you want to search.\\nA Configuration icon appears in the field.\\nClick the\\nConfiguration\\nicon. The event row turns blue and the Inspector panel appears. The metadata type and value as well as the Log Date are listed in the Inspector panel.\\nHover your mouse over the metadata field containing the value that you want to search.\\nA Configuration icon appears in the field.\\nClick the\\nConfiguration\\nicon. The event row turns blue and the Inspector panel appears. The metadata type and value as well as the Log Date are listed in the Inspector panel.\\nOn the navigation bar, click\\nDashboards\\n.\\nOn a TopX widget in the dashboard, hover your mouse over the widget and click the\\nSettings\\nicon.\\nA blue border appears around the widget and the Inspector panel opens on the right.\\nClick the label or the chart element that represents the metadata you want to pivot against.\\nBe sure to only click once. Double-clicking initiates a drilldown search. For more information, see Drill into Chart Metadata from the Dashboards.\\nOn a TopX widget in the dashboard, hover your mouse over the widget and click the\\nSettings\\nicon.\\nA blue border appears around the widget and the Inspector panel opens on the right.\\nClick the label or the chart element that represents the metadata you want to pivot against.\\nBe sure to only click once. Double-clicking initiates a drilldown search. For more information, see Drill into Chart Metadata from the Dashboards.\\nClick the label or the chart element that represents the metadata you want to pivot against.\\nBe sure to only click once. Double-clicking initiates a drilldown search. For more information, see Drill into Chart Metadata from the Dashboards.\\n(Optional)\\nTo narrow your search to a specific time frame, type the time (in hours and minutes) before the date in the\\nhh\\nand\\nmm\\nfields on the left side of the box, and type the time after the date in the time fields on the right side of the box. When pivoting from the Analyzer grid, the date and time shown are the log date and time. When pivoting off a widget, the date and time shown are the current date and time.\\nIf you are building a pivot search based on multiple metadata values, you can also specify a time frame in a later step using the Advanced Search dialog box. If a time frame is never specified, the time criteria for the search defaults to the last 24 hours.\\n(Optional)\\nTo narrow your search to a specific time frame, type the time (in hours and minutes) before the date in the\\nhh\\nand\\nmm\\nfields on the left side of the box, and type the time after the date in the time fields on the right side of the box. When pivoting from the Analyzer grid, the date and time shown are the log date and time. When pivoting off a widget, the date and time shown are the current date and time.\\nIf you are building a pivot search based on multiple metadata values, you can also specify a time frame in a later step using the Advanced Search dialog box. If a time frame is never specified, the time criteria for the search defaults to the last 24 hours.\\nDo one of the following:\\nIf the search criteria is sufficient, click\\nSearch Now\\n.\\nThe search begins processing. For further instructions, see\\nUse Search\\n.\\nTo continue adding search criteria using the Pivot Search feature and/or the Advanced Search dialog box, proceed as follows:\\nClick\\n+ Add to Search\\n.\\nA search task floats towards the Search button on the upper menu bar. A blue oval appears next to the button indicating that a search value has been added to the Advanced Search dialog box.\\n(Optional)\\nContinue adding search criteria with Pivot Search using the same procedures described in the preceding steps 1 through 3.\\nThe number in the blue oval next to the Search button increases for every item that you add to the search.\\nClick\\nSearch\\non the upper menu bar to display the Advanced Search dialog box.\\n(Optional)\\nContinue to refine your search in the Advanced Search dialog box as needed by following the same procedures described in\\nUse Search\\n.\\nWhen you are ready to start the search, see\\nUse Search\\nfor further instructions.\\nIf the search criteria is sufficient, click\\nSearch Now\\n.\\nThe search begins processing. For further instructions, see\\nUse Search\\n.\\nTo continue adding search criteria using the Pivot Search feature and/or the Advanced Search dialog box, proceed as follows:\\nClick\\n+ Add to Search\\n.\\nA search task floats towards the Search button on the upper menu bar. A blue oval appears next to the button indicating that a search value has been added to the Advanced Search dialog box.\\n(Optional)\\nContinue adding search criteria with Pivot Search using the same procedures described in the preceding steps 1 through 3.\\nThe number in the blue oval next to the Search button increases for every item that you add to the search.\\nClick\\nSearch\\non the upper menu bar to display the Advanced Search dialog box.\\n(Optional)\\nContinue to refine your search in the Advanced Search dialog box as needed by following the same procedures described in\\nUse Search\\n.\\nWhen you are ready to start the search, see\\nUse Search\\nfor further instructions.\\nClick\\n+ Add to Search\\n.\\nA search task floats towards the Search button on the upper menu bar. A blue oval appears next to the button indicating that a search value has been added to the Advanced Search dialog box.\\nClick\\n+ Add to Search\\n.\\nA search task floats towards the Search button on the upper menu bar. A blue oval appears next to the button indicating that a search value has been added to the Advanced Search dialog box.\\n(Optional)\\nContinue adding search criteria with Pivot Search using the same procedures described in the preceding steps 1 through 3.\\nThe number in the blue oval next to the Search button increases for every item that you add to the search.\\n(Optional)\\nContinue adding search criteria with Pivot Search using the same procedures described in the preceding steps 1 through 3.\\nThe number in the blue oval next to the Search button increases for every item that you add to the search.\\nClick\\nSearch\\non the upper menu bar to display the Advanced Search dialog box.\\nClick\\nSearch\\non the upper menu bar to display the Advanced Search dialog box.\\n(Optional)\\nContinue to refine your search in the Advanced Search dialog box as needed by following the same procedures described in\\nUse Search\\n.\\n(Optional)\\nContinue to refine your search in the Advanced Search dialog box as needed by following the same procedures described in\\nUse Search\\n.\\nWhen you are ready to start the search, see\\nUse Search\\nfor further instructions.\\nWhen you are ready to start the search, see\\nUse Search\\nfor further instructions.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nSearch\\n', 'Save Searches': 'For quick access to routine searches, you have the option to save any search that you build. You also have the option to share your saved searches with other users by selecting public read permissions (as with the Client Console, the range of read permissions for you to choose from depends on your user role). Your saved searches are available on the Searches page, where you can also access your search history and any searches that other users have shared with you.\\nTo save a search:\\nFrom the top right of the Web Console, click\\nSearch\\n.\\nIn the Search dialog box, build your search and then click\\nAdvanced\\n.\\nThe Save Search dialog box appears.\\n(Optional)\\nIn the Criteria panel, modify your search if needed by following the same procedures described in\\nPerform Pivot Searches\\n.\\nIn the Properties panel, complete the following fields:\\nField\\nDescription\\nName\\nType a descriptive name for the search to help you locate it in the future. If you do not want to type a name, leave the default text \"Ad Hoc Search\" in the field.\\nDescription\\n(Optional)\\nThe Web Console automatically generates a description of the search based on its Boolean strings. If you prefer a custom description, delete the generated text in the Description text box and replace it with your own. You can also leave the text box blank.\\nEntity\\n(For Global Administrators only; other users cannot modify this field) If you are saving the search for users from a specific entity, click the\\nEntity\\nlist and select accordingly.\\nRead Permission\\nClick to select the minimum user permission level required to view the search. The options available to you in the list depend on your user role.\\nWrite Permission\\nClick to select the minimum user permission level required to make public changes to the search. The options available to you in the list depend on your selection in the Read Permission field.\\nRead and write permission settings in the Web Console behave the same way as they do in the Client Console. For more information on the different permission levels, see\\nObject Permissions Manager\\n.\\nLayout\\nClick to select the dashboard layout that displays with search results on the Analyze page. Read and Write permissions may impact the set of available dashboards.\\nReturn By\\nClick to select how search results are ordered and returned on the Analyze page. For example, Date (Desc) returns the most recently dated results first.\\nSelect Log Repositories\\nClick to select the log repositories that you want to search.\\nThe Default Log Repositories option is configured in the Client Console. To select individual Log Repositories, click\\nSelect\\n, then click to select the ones that you want to search. Selected items appear in blue text.\\nYou cannot run or save a search against both the Platform Manager and the Data Processor Log Repositories.\\nIn the Properties panel, complete the following fields:\\nField, Description\\nName, Type a descriptive name for the search to help you locate it in the future. If you do not want to type a name, leave the default text \"Ad Hoc Search\" in the field.\\nDescription, (Optional)The Web Console automatically generates a description of the search based on its Boolean strings. If you prefer a custom description, delete the generated text in the Description text box and replace it with your own. You can also leave the text box blank.\\nEntity, (For Global Administrators only; other users cannot modify this field) If you are saving the search for users from a specific entity, click theEntitylist and select accordingly.\\nRead Permission, Click to select the minimum user permission level required to view the search. The options available to you in the list depend on your user role.\\nWrite Permission, Click to select the minimum user permission level required to make public changes to the search. The options available to you in the list depend on your selection in the Read Permission field.Read and write permission settings in the Web Console behave the same way as they do in the Client Console. For more information on the different permission levels, seeObject Permissions Manager.\\nLayout, Click to select the dashboard layout that displays with search results on the Analyze page. Read and Write permissions may impact the set of available dashboards.\\nReturn By, Click to select how search results are ordered and returned on the Analyze page. For example, Date (Desc) returns the most recently dated results first.\\nSelect Log Repositories, Click to select the log repositories that you want to search.The Default Log Repositories option is configured in the Client Console. To select individual Log Repositories, clickSelect, then click to select the ones that you want to search. Selected items appear in blue text.You cannot run or save a search against both the Platform Manager and the Data Processor Log Repositories.\\nClick to select the minimum user permission level required to make public changes to the search. The options available to you in the list depend on your selection in the Read Permission field.\\nRead and write permission settings in the Web Console behave the same way as they do in the Client Console. For more information on the different permission levels, see\\nObject Permissions Manager\\n.\\nClick to select the log repositories that you want to search.\\nThe Default Log Repositories option is configured in the Client Console. To select individual Log Repositories, click\\nSelect\\n, then click to select the ones that you want to search. Selected items appear in blue text.\\nYou cannot run or save a search against both the Platform Manager and the Data Processor Log Repositories.\\n(Optional)\\nConfirm or update the\\nMaximum Results\\nand\\nQuery Timeout\\nsettings. After the search is saved, the Maximum Results and Query Timeout settings persist for the saved search.\\nClick\\nSave\\n.\\nThe search is saved and added to the Searches page under the My Saved tab. They are not available to other users.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nSearch\\n', 'Use Search': 'Search allows you to query data from your default Data Processors. If you have not set a default Data Processor, then the search queries all available Data Processors.\\nTo use Search:\\nFrom the top right of the Web Console, click\\nSearch\\n.\\nThe Search dialog box appears.\\nThe recent searches list included at the bottom of the Search dialog box allows you to re-run a previous search without having to build it again. Click the\\nRun\\nicon next to a search to rerun it. You can also edit your recent searches by clicking the\\nEdit\\nicon next to the search you want. For more information on editing searches, see\\nManage the Searches Page\\n.\\nIf at any time you want to remove all the search filters that have been applied so you can begin building a new search, click\\nReset\\n.\\nFrom the top right of the Web Console, click\\nSearch\\n.\\nThe Search dialog box appears.\\nThe recent searches list included at the bottom of the Search dialog box allows you to re-run a previous search without having to build it again. Click the\\nRun\\nicon next to a search to rerun it. You can also edit your recent searches by clicking the\\nEdit\\nicon next to the search you want. For more information on editing searches, see\\nManage the Searches Page\\n.\\nIf at any time you want to remove all the search filters that have been applied so you can begin building a new search, click\\nReset\\n.\\n(Optional)\\nTo see real-time logs or events that match your query, toggle the\\nTail\\noption.\\n(Optional)\\nTo see real-time logs or events that match your query, toggle the\\nTail\\noption.\\nDo one of the following:\\nTimeframe (Not using tail)\\n. Click\\nin the last [xx hours/days]\\nas needed to set a\\xa0time frame\\xa0for your search results. Point to a date to see which dates have hot, warm, or no data. The default search time frame is in the last 24 hours.\\nDuration (Using tail)\\n. Select the number of minutes you want the tail to run. The maximum is 15.\\nTimeframe (Not using tail)\\n. Click\\nin the last [xx hours/days]\\nas needed to set a\\xa0time frame\\xa0for your search results. Point to a date to see which dates have hot, warm, or no data. The default search time frame is in the last 24 hours.\\nTimeframe (Not using tail)\\n. Click\\nin the last [xx hours/days]\\nas needed to set a\\xa0time frame\\xa0for your search results. Point to a date to see which dates have hot, warm, or no data. The default search time frame is in the last 24 hours.\\nDuration (Using tail)\\n. Select the number of minutes you want the tail to run. The maximum is 15.\\nDuration (Using tail)\\n. Select the number of minutes you want the tail to run. The maximum is 15.\\n(Optional)\\nApply a Log Source Filter.\\nClick\\nLog Source Filter\\n.\\nIn the Log Source Filter dialog box, do any of the following:\\nFrom the Select Sources lists, apply any of the following filters as needed to target the log source(s) that you are looking for:\\nEntity\\nHost\\nType\\nStatus\\nLists and Log Sources\\nClick\\nLog Source Filter\\n.\\nIn the Log Source Filter dialog box, do any of the following:\\nFrom the Select Sources lists, apply any of the following filters as needed to target the log source(s) that you are looking for:\\nEntity\\nHost\\nType\\nStatus\\nLists and Log Sources\\nFrom the Select Sources lists, apply any of the following filters as needed to target the log source(s) that you are looking for:\\nEntity\\nHost\\nType\\nStatus\\nLists and Log Sources\\nEntity\\nHost\\nType\\nStatus\\nLists and Log Sources\\nTo filter log sources by keywords in their names, type a keyword text string in the\\nSearch all sources containing\\nfield.\\nYou can hide the Entity, Host, and/or Type metadata columns to widen the columns that you want to remain visible. Wider column widths help to improve readability and reduce data truncation. To hide or unhide these columns, do the following:\\nTo filter log sources by keywords in their names, type a keyword text string in the\\nSearch all sources containing\\nfield.\\nYou can hide the Entity, Host, and/or Type metadata columns to widen the columns that you want to remain visible. Wider column widths help to improve readability and reduce data truncation. To hide or unhide these columns, do the following:\\nTo filter log sources by keywords in their names, type a keyword text string in the\\nSearch all sources containing\\nfield.\\nYou can hide the Entity, Host, and/or Type metadata columns to widen the columns that you want to remain visible. Wider column widths help to improve readability and reduce data truncation. To hide or unhide these columns, do the following:\\nOn the right side of the metadata columns, click the\\nConfiguration\\nicon.\\nThe column selection box appears.\\nSelect or clear the column\\ncheck boxes\\nto show or hide them as needed. Highlighted blue text on a button indicates that the column is visible. Non-highlighted text indicates that the column is hidden. This procedure affects the columns in both the\\nSelect\\nand\\nSelected\\nsources panels.\\nWhen you are finished filtering, select the log sources that you want to add to the Selected sources panel by clicking the\\nPlus\\nicons next to them.\\nTo add all the filtered log sources to the panel at once, click\\nAdd all xx\\n.\\nTo remove a source from the Selected sources list, click the\\nMinus\\nicon next to it. To remove all the log sources at once, click\\nRemove all xx\\n.\\nClick\\nOK\\n.\\nOn the right side of the metadata columns, click the\\nConfiguration\\nicon.\\nThe column selection box appears.\\nSelect or clear the column\\ncheck boxes\\nto show or hide them as needed. Highlighted blue text on a button indicates that the column is visible. Non-highlighted text indicates that the column is hidden. This procedure affects the columns in both the\\nSelect\\nand\\nSelected\\nsources panels.\\nWhen you are finished filtering, select the log sources that you want to add to the Selected sources panel by clicking the\\nPlus\\nicons next to them.\\nTo add all the filtered log sources to the panel at once, click\\nAdd all xx\\n.\\nTo remove a source from the Selected sources list, click the\\nMinus\\nicon next to it. To remove all the log sources at once, click\\nRemove all xx\\n.\\nClick\\nOK\\n.\\nOn the right side of the metadata columns, click the\\nConfiguration\\nicon.\\nThe column selection box appears.\\nSelect or clear the column\\ncheck boxes\\nto show or hide them as needed. Highlighted blue text on a button indicates that the column is visible. Non-highlighted text indicates that the column is hidden. This procedure affects the columns in both the\\nSelect\\nand\\nSelected\\nsources panels.\\nWhen you are finished filtering, select the log sources that you want to add to the Selected sources panel by clicking the\\nPlus\\nicons next to them.\\nTo add all the filtered log sources to the panel at once, click\\nAdd all xx\\n.\\nTo remove a source from the Selected sources list, click the\\nMinus\\nicon next to it. To remove all the log sources at once, click\\nRemove all xx\\n.\\nClick\\nOK\\n.\\nOn the right side of the metadata columns, click the\\nConfiguration\\nicon.\\nThe column selection box appears.\\nSelect or clear the column\\ncheck boxes\\nto show or hide them as needed. Highlighted blue text on a button indicates that the column is visible. Non-highlighted text indicates that the column is hidden. This procedure affects the columns in both the\\nSelect\\nand\\nSelected\\nsources panels.\\nWhen you are finished filtering, select the log sources that you want to add to the Selected sources panel by clicking the\\nPlus\\nicons next to them.\\nTo add all the filtered log sources to the panel at once, click\\nAdd all xx\\n.\\nTo remove a source from the Selected sources list, click the\\nMinus\\nicon next to it. To remove all the log sources at once, click\\nRemove all xx\\n.\\nClick\\nOK\\n.\\n(Optional)\\nChange the repository toggle to search events instead of logs.\\nFor information on Event classifications, see the\\nEvent Classifications\\ntable.\\n(Optional)\\nChange the repository toggle to search events instead of logs.\\nFor information on Event classifications, see the\\nEvent Classifications\\ntable.\\nS\\nelect a search filter, and then type a search term in the\\nSearch\\nfield.\\xa0For a list of available filters, see the\\nSearch Filters\\ntable.\\nS\\nelect a search filter, and then type a search term in the\\nSearch\\nfield.\\xa0For a list of available filters, see the\\nSearch Filters\\ntable.\\n(Optional)\\nTo include more than one search term for a particular filter or group, click the\\n+Value\\nbutton to the right of the Search field.\\n(Optional)\\nTo include more than one search term for a particular filter or group, click the\\n+Value\\nbutton to the right of the Search field.\\n(Optional)\\nTo add a filter, click\\n+Filter\\nand select a filter from the list.\\nAs you add filters and groups, use the accompanying lists to build search criteria statements for how you want the filters and groups to be applied. Choose from the following operators:\\nAll of the following\\nor\\nAny of the following\\nis\\nor\\nis not\\n(for Log Message, this is\\ncontains\\nor\\ndoes not contain\\n.)\\nEXAMPLE\\nThe following search is set to find\\nall\\nlogs that were either associated with Mike or Jane over the last 24 hours, or logs that did not originate from any of the addresses on the WC IP Address list.\\n(Optional)\\nTo add a filter, click\\n+Filter\\nand select a filter from the list.\\nAs you add filters and groups, use the accompanying lists to build search criteria statements for how you want the filters and groups to be applied. Choose from the following operators:\\nAll of the following\\nor\\nAny of the following\\nis\\nor\\nis not\\n(for Log Message, this is\\ncontains\\nor\\ndoes not contain\\n.)\\nis\\nor\\nis not\\n(for Log Message, this is\\ncontains\\nor\\ndoes not contain\\n.)\\nEXAMPLE\\nThe following search is set to find\\nall\\nlogs that were either associated with Mike or Jane over the last 24 hours, or logs that did not originate from any of the addresses on the WC IP Address list.\\n\\n(Optional)\\nFor more search criteria, click\\nAdvanced\\n. Use the panel on the right of the dialog box to do any of the following:\\nFilter by Entity, Permissions, or Log Repository.\\nControl the way the results are returned using the options in the Advanced dialog box.\\nSave a search or tail. For more information, see\\nSave Searches\\n.\\n(Optional)\\nFor more search criteria, click\\nAdvanced\\n. Use the panel on the right of the dialog box to do any of the following:\\nFilter by Entity, Permissions, or Log Repository.\\nControl the way the results are returned using the options in the Advanced dialog box.\\nSave a search or tail. For more information, see\\nSave Searches\\n.\\nWhen you are finished defining your search criteria, click\\nSearch\\n.\\nA search task displays in the taskbar indicating that the search or tail is in progress. You can hover your mouse over the search task to view more information.\\nAdditional information regarding the status periodically displays directly above the right side of the taskbar.\\nDepending on the processing time for a particular search, you may receive a status message in blue font on the search task stating \"SEARCHING: FIRST RESULTS\"\\nThe \"SEARCHING: FIRST RESULTS\" message indicates that the first set of results are available (which is usually the first 10,000 logs). If you receive the message, you can click the search task to view the preliminary results while the search continues to run in the background. You will receive notification when the search is complete.\\nIf you want to change the processing time, you can change the default Web Console Query Timeout setting. For more information, see\\nChange the Default Web Console Search Timeout Period\\n. You can also change the Query Timeout for an individual search using the Search dialog box. For more information, see\\nSave Searches\\n.\\nWhen the search is complete, the search task shows either COMPLETED: ALL RESULTS in blue font, COMPLETED: MAX RESULTS in blue font, or COMPLETED: NO RESULTS\\nCOMPLETED: MAX RESULTS indicates that the search has hit the configured maximum number of results and the remaining results are not returned. The default number of maximum results is 30,000.\\nWhen you are finished defining your search criteria, click\\nSearch\\n.\\nA search task displays in the taskbar indicating that the search or tail is in progress. You can hover your mouse over the search task to view more information.\\nAdditional information regarding the status periodically displays directly above the right side of the taskbar.\\nDepending on the processing time for a particular search, you may receive a status message in blue font on the search task stating \"SEARCHING: FIRST RESULTS\"\\nThe \"SEARCHING: FIRST RESULTS\" message indicates that the first set of results are available (which is usually the first 10,000 logs). If you receive the message, you can click the search task to view the preliminary results while the search continues to run in the background. You will receive notification when the search is complete.\\nIf you want to change the processing time, you can change the default Web Console Query Timeout setting. For more information, see\\nChange the Default Web Console Search Timeout Period\\n. You can also change the Query Timeout for an individual search using the Search dialog box. For more information, see\\nSave Searches\\n.\\nWhen the search is complete, the search task shows either COMPLETED: ALL RESULTS in blue font, COMPLETED: MAX RESULTS in blue font, or COMPLETED: NO RESULTS\\nCOMPLETED: MAX RESULTS indicates that the search has hit the configured maximum number of results and the remaining results are not returned. The default number of maximum results is 30,000.\\nWhen your search has completed, do one of the following:\\nClick the search task. If your search produced results, the Analyze page appears and displays the results. If your search did not produce any results, the search task is removed from the taskbar.\\nIf you ran a tail, the search task remains in the taskbar and indicates how much time remains in the tail.\\nRemove search tasks from your view by doing one of the following:\\nDismiss a single search task without viewing the results by clicking the\\nClose\\nicon.\\nDismiss multiple search tasks at once by doing the following:\\nClick the\\nConfiguration\\nicon on the taskbar at the lower-right side of the page to open the taskbar inspector.\\nDo one of the following:\\nTo dismiss all search tasks with no results, click\\nClear Tasks with No Results\\n.\\nTo dismiss all search tasks that have completed running, click\\nClear Completed Tasks\\n.\\nTo dismiss all search tasks that have completed running and those that are still running, click\\nClear and Cancel All Tasks\\n.\\nClick the search task. If your search produced results, the Analyze page appears and displays the results. If your search did not produce any results, the search task is removed from the taskbar.\\nIf you ran a tail, the search task remains in the taskbar and indicates how much time remains in the tail.\\nClick the search task. If your search produced results, the Analyze page appears and displays the results. If your search did not produce any results, the search task is removed from the taskbar.\\nIf you ran a tail, the search task remains in the taskbar and indicates how much time remains in the tail.\\nRemove search tasks from your view by doing one of the following:\\nDismiss a single search task without viewing the results by clicking the\\nClose\\nicon.\\nDismiss multiple search tasks at once by doing the following:\\nClick the\\nConfiguration\\nicon on the taskbar at the lower-right side of the page to open the taskbar inspector.\\nDo one of the following:\\nTo dismiss all search tasks with no results, click\\nClear Tasks with No Results\\n.\\nTo dismiss all search tasks that have completed running, click\\nClear Completed Tasks\\n.\\nTo dismiss all search tasks that have completed running and those that are still running, click\\nClear and Cancel All Tasks\\n.\\nDismiss a single search task without viewing the results by clicking the\\nClose\\nicon.\\nDismiss multiple search tasks at once by doing the following:\\nClick the\\nConfiguration\\nicon on the taskbar at the lower-right side of the page to open the taskbar inspector.\\nDo one of the following:\\nTo dismiss all search tasks with no results, click\\nClear Tasks with No Results\\n.\\nTo dismiss all search tasks that have completed running, click\\nClear Completed Tasks\\n.\\nTo dismiss all search tasks that have completed running and those that are still running, click\\nClear and Cancel All Tasks\\n.\\nClick the\\nConfiguration\\nicon on the taskbar at the lower-right side of the page to open the taskbar inspector.\\nDo one of the following:\\nTo dismiss all search tasks with no results, click\\nClear Tasks with No Results\\n.\\nTo dismiss all search tasks that have completed running, click\\nClear Completed Tasks\\n.\\nTo dismiss all search tasks that have completed running and those that are still running, click\\nClear and Cancel All Tasks\\n.\\nTo dismiss all search tasks with no results, click\\nClear Tasks with No Results\\n.\\nTo dismiss all search tasks that have completed running, click\\nClear Completed Tasks\\n.\\nTo dismiss all search tasks that have completed running and those that are still running, click\\nClear and Cancel All Tasks\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nSingle Sign-On\\n', 'SSO Known Issues and Recommendations': '', 'AD Authentication': 'We recommend you disable AD authentication in Configuration Manager to force SSO use and encourage pre-existing AD authentication users to start using SSO authentication.\\nAD Authentication can be re-enabled for troubleshooting\\nand can coexist with SSO if AD authentication is also required.\\nWe recommend you disable AD authentication in Configuration Manager to force SSO use and encourage pre-existing AD authentication users to start using SSO authentication.\\nAD Authentication can be re-enabled for troubleshooting\\nand can coexist with SSO if AD authentication is also required.\\n', 'AD-to-IdP Synchronization': 'For a consistent and reliable SSO experience, we recommend using the Identity Provider (IdP) in conjunction with Active Directory to Identity Provider (AD-to-IdP) synchronization.\\n\\n', 'Multi-Factor Authentication': 'SSO with MFA is only possible using IdP multi-factor authentication. The MFA setting in Configuration Manager applies only to SQL and Active Directory logins.\\n\\n', 'Multiple Web Consoles': 'SSO currently supports multiple web consoles in a load-balanced configuration. This configuration is not part of the LogRhythm SIEM and would require a third-party hardware or software solution. The SSO configuration is part of the Authentication Service that is common to all Web Consoles. If you have multiple Web Consoles in a non-load-balanced configuration, you must choose one to use with SSO. You must specify which Web Console to use in the SSO configuration parameter Web Console Callback URL.\\n\\n', 'Saving the SSO Configuration': 'When the Web Console saves the SSO configuration, users may see the following sequence of statuses in the upper-right corner:\\nYellow Disconnecting status.\\nRed Disconnected status.\\nNotification message: You have lost the live data connection. Please check your internet connection and refresh your browser.\\nRefresh your browser to reconnect the Web Console.\\n\\n', 'SQL Authentication': 'SQL Authentication must be enabled in Configuration Manager for SSO to work. SSO will fail if SQL Authentication is disabled.\\n\\n', 'SSO User Auto-Provisioning': 'When a user is auto-provisioned via SSO, the Description field in their Client Console\\xa0Person record is populated with \"Auto Provisioning <firstName> <lastName>\".\\nThe uniqueness determinant for\\xa0user matching with LogRhythm SSO is the combination of first name and last name in the Name field of the Client Console Person record. SSO auto-provisioning fails when a second user happens to have the same unique combination of first name and last name that matches an existing Person record.\\xa0Using first name and last name as the uniqueness determinant can cause issues when the same person has two or more logins (for example, Chris User the analyst, and Chris User the administrator of the SOC), or when two people have the same first name and last name.\\nSSO user auto-provisioning for the second user fails because the first name and last name match an existing Name field in the Client Console Person record.\\nIt does not matter if the Login field is different (for example, Chris.User@company.com\\xa0and Chris-Admin.User@company.com).\\nThe middle name is not used to determine uniqueness.\\nSSO user auto-provisioning for the second user fails because the first name and last name match an existing Name field in the Client Console Person record.\\nIt does not matter if the Login field is different (for example, Chris.User@company.com\\xa0and Chris-Admin.User@company.com).\\nThe middle name is not used to determine uniqueness.\\nWorkaround:\\nManually edit the user\\'s Name field in the Person record (for example, change the first name to Joe-Admin so the resulting first name and last name combination is Joe-Admin User).\\nAdditional Issues:\\nThis change may not be acceptable to a company\\'s HR department.\\nIf the user is part of AD Group-Based Synchronization, the AD admin must perform the manual edit because\\xa0AD is the source authority for AD-synchronized users.\\nManually edit the user\\'s Name field in the Person record (for example, change the first name to Joe-Admin so the resulting first name and last name combination is Joe-Admin User).\\nAdditional Issues:\\nThis change may not be acceptable to a company\\'s HR department.\\nIf the user is part of AD Group-Based Synchronization, the AD admin must perform the manual edit because\\xa0AD is the source authority for AD-synchronized users.\\nThis change may not be acceptable to a company\\'s HR department.\\nIf the user is part of AD Group-Based Synchronization, the AD admin must perform the manual edit because\\xa0AD is the source authority for AD-synchronized users.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nSingle Sign-On\\n', 'SSO User Auto-Provisioning': 'SIEM management and auditing functions require every Web Console user to be associated with a Person record and Login field in the Client Console.\\nDuring a Single Sign-On (SSO) login, the SIEM identifies user associations by comparing the following fields:\\nField, Location, Portal/Console\\nnameID, SAML assertion, Identity Provider (IdP)\\nLogin, People tab in the Deployment Manager, Client Console\\n\\nIf the SIEM cannot identify a Person record with a Login field that matches the nameID field from the Identity Provider (IdP), the SIEM creates a new Person record and associated User Login record with the following values:\\nPerson Record Field, Value\\nName, First name and last name of the user provided in the IdP.\\nLogin, Email address for the user provided in the IdP.\\nAuto-provisioning will fail if the Name field in an existing Person record contains the same unique combination of first name and last name provided in the IdP. In this case, a SIEM administrator must modify the existing Person record by updating the Name field with a different combination of first name and last name. For subsequent SSO logins, this user will be associated with the auto-provisioned user.\\n\\n', 'SSO Auto-Provisioning and Client Console Accounts': \"SSO auto-provisioned users who did not previously exist in the Client Console may initially only log in to the Web Console via SSO because the SSO auto-provisioned user is assigned a random, complex, and unknowable password on first login. If these users want to use their\\xa0SSO auto-provisioned account to log in without SSO, either to the Client Console or the Web Console, a SIEM administrator can execute the following procedure:\\nBefore executing this procedure:\\nIf you want the SSO auto-provisioned user's new password to be synched with Active Directory, you must first create this user login using either Active Directory Group-Based Authorization or manually creating a Person record tied to a Windows/AD account.\\n\\nLog in to the Client Console as a SIEM administrator.\\nOn the main toolbar, click\\nDeployment Manager\\n.\\nClick the\\nPeople\\ntab.\\nRight-click on the user's Person Record, and then click\\nUser Account Properties\\n.\\nBefore proceeding, make sure you understand the Enforce Password Policy setting and the implications of changing it.\\nEnforce Password Policy\\nThe Enforce Password Policy settings are retrieved from Windows Local Security Policy. (You can view this policy with the Windows MMC Local Security Policy (secpol.msc) in the Password Policy folder.) The default setting for Minimum Password Age is 1 day. If the SIEM administrator resets a user password with this default setting, the user cannot change their own password for 1 day unless the SIEM administrator disables the Enforce Password Policy. When the SIEM administrator changes the Enforce Password Policy setting, the following warning message is triggered:\\nYou have chosen to change password policy enforcement. This will require you to reset the user password. If you wish to continue with this operation, click OK. Otherwise click Cancel.\\nThe SIEM administrator can disable the Enforce Password Policy setting and immediately change the user's password. However, if the SIEM administrator later re-enables this setting, the warning message is triggered again and the password must be reset again.\\nIf the SIEM administrator does not want to disable the Enforce Password Policy setting, there are two options:\\n1.\\xa0After resetting the user's password, the user must wait 1 day to change it.\\n2. The SIEM administrator can set the Minimum Password Age to 0 days, and the user can change their password immediately. This option is not available to LR Cloud customers.\\nEnforce Password Policy\\nThe Enforce Password Policy settings are retrieved from Windows Local Security Policy. (You can view this policy with the Windows MMC Local Security Policy (secpol.msc) in the Password Policy folder.) The default setting for Minimum Password Age is 1 day. If the SIEM administrator resets a user password with this default setting, the user cannot change their own password for 1 day unless the SIEM administrator disables the Enforce Password Policy. When the SIEM administrator changes the Enforce Password Policy setting, the following warning message is triggered:\\nThe SIEM administrator can disable the Enforce Password Policy setting and immediately change the user's password. However, if the SIEM administrator later re-enables this setting, the warning message is triggered again and the password must be reset again.\\nIf the SIEM administrator does not want to disable the Enforce Password Policy setting, there are two options:\\n1.\\xa0After resetting the user's password, the user must wait 1 day to change it.\\n2. The SIEM administrator can set the Minimum Password Age to 0 days, and the user can change their password immediately. This option is not available to LR Cloud customers.\\nIn Account Options, set Enforce Password Policy based on your preferred option as outlined in the above note.\\nAfter changing the user's password, give them their temporary password.\\nThe user must login to the Web Console via SSO using their normal SSO credentials.\\nUpon successful login with SSO credentials, the user must then change their password to the temporary password provided by the SIEM administrator.\\nIn the User Options menu, click\\nSettings\\n, then click\\nChange Password\\n.\\nEnter the temporary password in the Old Password field.\\nEnter the desired new password in the New Password field.\\nThis new password will be used to log in to the Client Console.\\nClick\\nSave\\n.\\nUpon successful login with SSO credentials, the user must then change their password to the temporary password provided by the SIEM administrator.\\nIn the User Options menu, click\\nSettings\\n, then click\\nChange Password\\n.\\nEnter the temporary password in the Old Password field.\\nEnter the desired new password in the New Password field.\\nThis new password will be used to log in to the Client Console.\\nClick\\nSave\\n.\\nThe new password will not be synchronized with Active Directory and must be manually updated. If the user wants their password synchronized with Active Directory,\\nyou must first create this user login using either Active Directory Group-Based Authorization or manually creating a Person record tied to a Windows/AD account.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nUser Interface\\n', 'Resource Center': 'The Web Console Resource Center can be accessed from anywhere in the software by clicking the bullhorn icon at the top-right of the screen. The information provided in the Resource Center is a great way to stay up-to-date on the latest SIEM news, releases, features, and maintenance periods.\\nIf the Resource Center bullhorn icon does not appear, you may need to disable any adblockers and/or whitelist the “pendo.io” domain.\\n', 'How to Enable or Disable the Resource Center': 'Open the LogRhythm Configuration Manager on your Platform Manager.\\nOpen the LogRhythm Configuration Manager on your Platform Manager.\\nOn the left side, click\\nWeb Services\\n.\\nThe Web Console UI screen appears.\\nOn the left side, click\\nWeb Services\\n.\\nThe Web Console UI screen appears.\\nIn the Resource Center & Metrics section, click\\nOff\\nto disable the Resource Center.\\nIn the Resource Center & Metrics section, click\\nOff\\nto disable the Resource Center.\\n\\n', 'Resource Center Sections': 'The following sections are available in the Resource Center. Clicking any of the section titles will expand the content for that section. You can return to the main Resource Center menu from within a section at any time by clicking the back arrow at the top-left of the Resource Center.\\nSection, Description\\nAnnouncements, This section allows you to stay up-to-date with new content and SIEM updates.\\nLogRhythm Community, Click to open theLogRhythm Communityhomepage. The Community is a great place to access knowledge articles, product downloads, and to read helpful forum posts from LogRhythm employees and users.\\nOnboarding, Click to access numerous interactive guides to help users grow accustomed to new features.\\nDocumentation, Opens theSIEM Documentationhomepage, the hub for all technical articles about the SIEM software.\\nContact Support, Opens theLogRhythm Support Portalhomepage.\\nSection\\nDescription\\nAnnouncements\\nThis section allows you to stay up-to-date with new content and SIEM updates.\\nLogRhythm Community\\nClick to open the\\nLogRhythm Community\\nhomepage. The Community is a great place to access knowledge articles, product downloads, and to read helpful forum posts from LogRhythm employees and users.\\nOnboarding\\nClick to access numerous interactive guides to help users grow accustomed to new features.\\nDocumentation\\nOpens the\\nSIEM Documentation\\nhomepage, the hub for all technical articles about the SIEM software.\\nContact Support\\nOpens the\\nLogRhythm Support Portal\\nhomepage.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nUser Settings\\n', 'Change the Default Web Console Search Timeout Period': 'Each user can configure the Query Timeout period in his or her Web Console deployment. This configuration is user specific.\\nChanging the Query Timeout setting in the Web Console automatically updates this setting in your user preferences in the Client Console.\\nTo configure the Query Timeout setting:\\nOn the top navigation bar, click the\\nUser\\nicon, then click\\nSettings\\n.\\nThe User Settings dialog box displays.\\nIn the Query Timeout field, type the time you want a search to run before it times out.\\nClick\\nClose\\n.\\nThe Query Timeout setting configured in the User Settings is applied to all new searches, including AIE Drill Down and pivot searches.\\xa0To change the time for a single search, see\\nUse Search\\n.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nWidgets\\n', 'Component Status Widget': '\\nThe Component Status widget\\nis only available to Global Admins or Restricted Admins with elevated View and Manage privileges.\\nThe Component Status widget allows you to see whether all components of your deployment are running without having to load the Client Console.\\nThe widget displays the following data:\\nComponent\\n. The software and associated databases required to run the LogRhythm Solution. This includes:\\nAdvanced Intelligence Engine\\nCollector\\nData Processor\\nDX Cluster\\nPlatform Manager\\nSystem Monitor\\nAdvanced Intelligence Engine\\nCollector\\nData Processor\\nDX Cluster\\nPlatform Manager\\nSystem Monitor\\nName (Host)\\n. The Component’s host. When no host is designated, the Component name is listed.\\nStatus\\n. Critical, Warning, Notice, or Normal.\\nLast Heartbeat\\n. A signal indicating the last successful heartbeat of the Component.\\nEntity\\n. The physical location where LogRhythm is deployed.\\nNotices\\n. Further information about a problem with the component.\\nThe widget provides a visual indicator when components are not working as expected. When a component is not responding, the indicator to the left of the component name turns red. When a component is delayed, the indicator to the left of the component name turns yellow. When a component is working normally, the indicator to the left of the component name remains blue.\\nTo configure the Component Status widget to show and hide different components:\\nHover your mouse over the widget and click the\\nSettings\\nicon.\\nA blue border appears around the widget and the Inspector panel opens on the right.\\nIn the Inspector panel, do any of the following:\\nClick in the\\nTitle\\nfield and type a new title.\\nClick on any Component Type to show or hide it in the widget. Component types in blue are shown in the widget and Component types in gray are not.\\nClick in the\\nTitle\\nfield and type a new title.\\nClick on any Component Type to show or hide it in the widget. Component types in blue are shown in the widget and Component types in gray are not.\\nClick the\\nSave\\nicon on the upper-right side of the page to save the modified widget to your dashboard layout.\\n(Optional)\\nClick the arrow to collapse the Inspector panel.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nWidgets\\n', 'Current Processing Rate Widgets': '\\nThe Current Processing Rate widgets\\nare only available to Global Admins or Restricted Admins with elevated View and Manage privileges.\\nCurrent Processing Rate widgets display charts representing the processing rates of any one of the following data sets:\\nLog Rate (MPS)\\n. The messages per second (MPS) rate of log messages processed by the Data Processors Message Processing Engine (MPE).\\nAI Engine Rate\\n. The rate of logs processed by the Advanced Intelligence (AI) Engine (provided that an AI Engine has been integrated into your LogRhythm SIEM deployment). Note: The Data may not send a copy of every log to the AI Engine for processing, depending on how the administrator defined the Global Log Processing Rules in the Client Console. Consequently, the AI Engine rate may differ from the log rate.\\nEvent Rate\\n. The rate of events processed per second in the Log Manager.\\nAlarm Rate\\n. The rate of alarms processed per second in the Platform Manager.\\nAI Engine Event Rate\\n. The rate of events processed per second in the AI Engine(provided that an AI Engine has been integrated into your LogRhythm SIEM deployment).\\nThe default chart setting for the Current Processing Rate widget, which can be seen on the predefined Executive Dashboard layout for Global Administrators, shows the log messages per second (MPS) rate of the Data Processor in your deployment. The number in the middle of the chart (\"20\" in the following example) is the average MPS rate in the last three minutes (excluding the current minute). The smaller numbers on the left and right show the minimum and maximum MPS rates over the last 24 hours.\\n\\nReview your processing rate charts periodically and observe the volume of data as it is collected, processed, and analyzed. If the numbers are different from what you expect, you should investigate for possible security or operational issues.\\nTo configure Current Processing Rate widgets to show different types of SIEM data sets:\\nHover your mouse over the widget and click the\\nSettings\\nicon.\\nA blue border appears around the widget and the Inspector panel opens on the right.\\nIn the Inspector panel, do any of the following:\\nClick in the\\nTitle\\nfield and type a new title.\\nIn the\\nSource\\nfield, select one of the following data sets to display on the Current Processing Rate chart.\\nLog Rate (MPS)\\nAI Engine Rate\\nEvent Rate\\nAlarm Rate\\nAI Engine Event Rate\\nClick in the\\nTitle\\nfield and type a new title.\\nIn the\\nSource\\nfield, select one of the following data sets to display on the Current Processing Rate chart.\\nLog Rate (MPS)\\nAI Engine Rate\\nEvent Rate\\nAlarm Rate\\nAI Engine Event Rate\\nLog Rate (MPS)\\nAI Engine Rate\\nEvent Rate\\nAlarm Rate\\nAI Engine Event Rate\\nClick the\\nSave\\nicon on the upper-right side of the page to save the modified widget to your dashboard layout.\\n(Optional)\\nClick the arrow to collapse the Inspector panel.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nWidgets\\n', 'Customize Dashboard Widgets': 'To create a custom Dashboard, you can add, move, resize, delete, and rename widgets. You can also configure widget settings to simplify finding the data you need.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nWidgets\\n', 'System Database Usage Widget': '\\nThe System Database Usage widget\\nis only available to Global Admins or Restricted Admins with elevated View and Manage privileges.\\nThe System Database Usage widget allows you to easily monitor database levels by showing the percentage of each database that is currently being used.\\nThe default chart setting for the System Database Usage widget displays the usage of the following five databases.\\nAlarms Database\\n. Data related to all alarms, alarm notifications, and alarm histories generated by the LogRhythm Alarming and Response Manager (ARM).\\nEvents Database\\n. Log data that qualified as an Event.\\nPlatform Manager Database (EMDB)\\n. All configuration information.\\nLogMart\\n. Log metadata that qualified as an Event, or data that was sent because of a processing rule. Also includes tracking statistics for the log data volume.\\nCase Management Database (CMDB)\\n. Data for all cases as well as most of the associated evidence.\\nThe widget provides a visual indicator when database usage is high. The colored bar that represents the usage of each database changes from blue to orange when the database’s usage exceeds the configured high usage percentage. The default setting for the high usage indicator for each database is 75%. The databases are shown in order from high usage to low usage and adjust automatically to changes.\\nTo configure the System Database Usage widget to show and hide the percentages of databases that are being used:\\nHover your mouse over the widget and click the\\nSettings\\nicon.\\nA blue border appears around the widget and the Inspector panel opens on the right.\\nIn the Inspector panel, do any of the following:\\nClick in the\\nTitle\\nfield and type a new title.\\nSelect or clear the\\ncheck box\\ncorresponding to each database to display it or remove it from the widget.\\nSet the High Usage Indicator for each visible database. The default value is 75%. To set a custom value for the widget, click in the value field and then type a new value.\\nClick in the\\nTitle\\nfield and type a new title.\\nSelect or clear the\\ncheck box\\ncorresponding to each database to display it or remove it from the widget.\\nSet the High Usage Indicator for each visible database. The default value is 75%. To set a custom value for the widget, click in the value field and then type a new value.\\nClick the\\nSave\\nicon on the upper-right side of the page to save the modified widget to your dashboard layout.\\n(Optional)\\nClick the arrow to collapse the Inspector panel.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nWidgets\\n', 'Threat Activity Map': \"\\nThe Threat Activity Map widget provides instant visibility into the geographical origin of log data in your deployment as well as visibility into which locations are impacted by log data in your deployment. The Threat Activity Map widget provides analysts with a starting point for investigating areas of the world that appear to have activities of interest.\\nTo ensure that the Threat Activity Map widget is working properly, you must enable the GeoLocation IP resolver on all of your Data Processors. To enable GeoLocation, set the GeoIPResolutionMode property to Country, Region, or City in the Data Processor Advanced Properties. The City level provides the most detailed information. For more information, see\\nData Processor\\nin the Client Console (Administrator's Guide).\\nFor more information on what to do if the Threat Activity Map widget is not properly displaying data, see\\nTroubleshoot Threat Activity Map\\n.\\nThe Threat Activity Map widget displays log data containing location metadata. Any dashboard-level filters do not apply to the Threat Activity Map.\\n\", 'Understand the Threat Activity Map Widget': \"The Threat Activity Map widget is displayed and managed through the Threat Activity Map widget widget, which automatically appears in the widget menu on the Dashboards page for all Global Administrators and Global Analysts. For more information about adding widgets to dashboards, see\\nAdd Widgets\\n.\\n\\nThe widget's minimum size is 3 columns by 2 rows, but it can be expanded to take up a larger area. For more information on resizing widgets, see\\nResize Widgets\\n.\\nThe Threat Activity Map widget plots the volume of events occurring in the environment based on the location data available in the Data Indexer. The map performs live updates and adjusts the plotted points based on new logs entering the Data Indexer.\\nYour Threat Activity Map widget only shows events from live clusters. If one or more clusters in your deployment goes down, data from those clusters are no longer represented in your Threat Activity Map widget and a status indicator appears in the Inspector panel. The time stamp at the top of the widget shows the date and time that the map was last updated.\\n\", 'Understand Nodes': 'The nodes in the Threat Activity Map widget widget represent events happening in your environment around the world. Nodes on the map change size based on the relative volume of events in each location. Areas with more events have larger nodes.\\nNodes are automatically aggregated by the proximity of activities. The aggregation of data in a node is not always aggregated at the country/region/city level. For example, if there is activity in France, The Netherlands, Belgium, and Germany, a single node may represent the data for all of these areas when the map is zoomed out.\\nWhen you zoom in, the log data for a larger node is split into smaller nodes to show more specific locations where threat activity is occurring.\\n', 'Understand Origin vs. Impacted Displays': 'Nodes appear as pie charts and give a visual indication of how many times the location contained the origin of activity and/or how many times it was the impacted location. You can configure the nodes to show only origin, only impacted, or origin and impacted information.\\nTo see a breakdown of the types of events represented by the pie chart, hover over the node. For more specific information about threat activity, you must drill down to see the specific log data.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nWidgets\\n/\\nCustomize Dashboard Widgets\\n', 'Add Widgets': 'To add widgets to a dashboard layout:\\nOn the navigation bar, click\\nDashboards\\n.\\nClick the\\nAdd Widget\\nicon.\\nSelect and grab a widget from the menu:\\nMouse action\\n. Hover your mouse over the widget so that your cursor turns into a four-directional arrow. Press and hold the left mouse button over the widget to grab it.\\nTouch action\\n. Press and hold (long press) the widget until the cursor turns into a four-directional arrow.\\nMouse action\\n. Hover your mouse over the widget so that your cursor turns into a four-directional arrow. Press and hold the left mouse button over the widget to grab it.\\nTouch action\\n. Press and hold (long press) the widget until the cursor turns into a four-directional arrow.\\nDrag the widget to the location on the page where you want to place it.\\nAs you drag the widget onto the page, the layout zooms out. Look for the blue squares that indicate where you can place the widget.\\nRelease your mouse button to drop the widget into a location.\\nIf you release the widget onto a square already occupied by another widget, the latter widget along with all the widgets positioned after it are automatically moved over to the next adjacent squares.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nWidgets\\n/\\nCustomize Dashboard Widgets\\n', 'Resize Widgets': \"To resize a widget:\\nHover your mouse over the widget that you want to resize and look for the resizing handle on the lower right.\\nMouse action\\n. Hover your mouse over the lower-right corner of a widget until the cursor turns into a two-directional diagonal arrow. Press and hold the left mouse button over the widget to grab it.\\nTouch action\\n. Press and hold (long press) the widget's resizing handle until the cursor turns into a two-directional diagonal arrow.\\nMouse action\\n. Hover your mouse over the lower-right corner of a widget until the cursor turns into a two-directional diagonal arrow. Press and hold the left mouse button over the widget to grab it.\\nTouch action\\n. Press and hold (long press) the widget's resizing handle until the cursor turns into a two-directional diagonal arrow.\\nDo either of the following:\\nTo increase the size of the widget, drag the handle down and/or to the right for each square that you want to add to its size and coverage.\\nIf you enlarge the widget onto a square already occupied by another widget, the latter widget along with all the widgets positioned after it automatically shift into the next adjacent square(s).\\nTo decrease the size of a widget, drag the handle up and/or to the left for each square that you want to subtract from its size and coverage.\\nAs you reduce the size of a widget, the widgets positioned after it automatically shift to fill in the empty square(s).\\nTo increase the size of the widget, drag the handle down and/or to the right for each square that you want to add to its size and coverage.\\nIf you enlarge the widget onto a square already occupied by another widget, the latter widget along with all the widgets positioned after it automatically shift into the next adjacent square(s).\\nTo decrease the size of a widget, drag the handle up and/or to the left for each square that you want to subtract from its size and coverage.\\nAs you reduce the size of a widget, the widgets positioned after it automatically shift to fill in the empty square(s).\\nWhen you are satisfied with the size of the widget, release your mouse button (or long press).\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n\"}\n",
      "{'General': 'Go to homepage\\nLogRhythm SIEM\\nlogrhythm.com\\ncommunity\\nsupport\\nuniversity\\nfeedback\\nLogRhythm SIEM\\n/\\nWeb Console User Guide\\n/\\nWidgets\\n/\\nThreat Activity Map\\n', 'Troubleshoot Threat Activity Map': 'If the Threat Activity Map widget is not showing any data, here are some ways to troubleshoot the problem:\\nEnsure that GeoLocation data is turned on in your deployment.\\nInstall and properly configure your data indexer(s).\\nVerify that all Data Indexerservices are running.\\nVerify that all Web Services are running.\\nVerify that you have events in your deployment that happened in the last 48 hours and that they contain GeoLocation information.\\nCheck the date range of your Threat Activity Map widget widget to ensure that the range includes ample time for your last piece of data.\\nAdjust the polling rate to reduce the load on the environment. This adjustment is done in the Configuration tool.\\nIf you still do not have any data, try running a search from the Searches page. For more information on running a search, see\\nUse Search\\n. If your searches are failing and if you have no data in your Threat Activity Map widget, there may be a problem with your Data Indexer configuration.\\nTry one of the following:\\nGo to your Data Indexer configuration page and verify that your EMDB Host and Public IPs are set correctly.\\xa0For more information, see\\nData Indexer\\n.\\nGo to your Data Indexer configuration page and verify that your EMDB Host and Public IPs are set correctly.\\xa0For more information, see\\nData Indexer\\n.\\nIn the NGPNode table of your EMDB, verify that the nodes listed are accurate and healthy. Remove rows referring to any nodes not in use. Contact\\nLogRhythm customer support\\nfor assistance, if needed.\\nCopyright © 2024 LogRhythm, Inc. All Rights Reserved\\n•\\nPowered by\\nScroll Viewport\\n&\\nAtlassian Confluence\\n\\nPlease note, these errors can depend on your browser setup.\\n\\nIf this problem persists, please contact our support.\\n'}\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"WS_Data_DB\"]  # Replace with your database name\n",
    "collection = db[\"LogRhythm7_15Docs\"]  # Replace with your collection name\n",
    "\n",
    "# Get distinct topics\n",
    "topics = collection.distinct(\"content_sections\")\n",
    "\n",
    "# Print the list of topics\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56334bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
